{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import Linear\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import yaml\n",
    "import importlib\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LIBRARY = \"/global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules\"\n",
    "ARTIFACT_LIBRARY = \"/global/cscratch1/sd/danieltm/ExaTrkX/lightning_checkpoints\"\n",
    "sys.path.append(MODEL_LIBRARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(\"LightningModules/Processing/prepare_feature_store.yaml\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preprocess_dm = FeatureStore(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading detector...\n",
      "Detector loaded.\n",
      "Writing outputs to /global/cscratch1/sd/danieltm/ExaTrkX/trackml/feature_store_endcaps\n",
      "/global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001000\n",
      "Preparing 1000\n",
      "Layerless truth graph built for /global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001000 with size (2, 123429)\n",
      "Cell features for 1000\n",
      "Loading event /global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001000 with a 0 pT cut\n",
      "/global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001001\n",
      "Preparing 1001\n",
      "Layerless truth graph built for /global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001001 with size (2, 91386)\n",
      "Cell features for 1001\n",
      "Loading event /global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001001 with a 0 pT cut\n",
      "/global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001002\n",
      "Preparing 1002\n",
      "Layerless truth graph built for /global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001002 with size (2, 128914)\n",
      "Cell features for 1002\n",
      "Loading event /global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001002 with a 0 pT cut\n",
      "/global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001003\n",
      "Preparing 1003\n",
      "Layerless truth graph built for /global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001003 with size (2, 103420)\n",
      "Cell features for 1003\n",
      "Loading event /global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001003 with a 0 pT cut\n",
      "/global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001004\n",
      "Preparing 1004\n",
      "Layerless truth graph built for /global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001004 with size (2, 144774)\n",
      "Cell features for 1004\n",
      "Loading event /global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001004 with a 0 pT cut\n",
      "Layerless truth graph built for /global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001007 with size (2, 112300)\n",
      "Cell features for 1007\n",
      "Loading event /global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001007 with a 0 pT cut\n",
      "/global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001008\n",
      "Preparing 1008\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36magg_series\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_series_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_aggregate_series_fast\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_complex_internals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Incompatible index for Cython grouper\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Incompatible index for Cython grouper",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c0135c810ce7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreprocess_dm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/core/datamodule.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_prepared_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrank_zero_only\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/u2/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Processing/feature_construction.py\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mprocess_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/global/u2/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Processing/utils.py\u001b[0m in \u001b[0;36mprepare_event\u001b[0;34m(event_file, detector_orig, detector_proc, cell_features, output_dir, pt_min, adjacent, endcaps, layerless, layerwise, noise, cell_information, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mfeature_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayerless_true_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayerwise_true_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjacent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madjacent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendcaps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendcaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayerless\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayerless\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayerwise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayerwise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevent_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/u2/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Processing/utils.py\u001b[0m in \u001b[0;36mbuild_event\u001b[0;34m(event_file, pt_min, feature_scale, adjacent, endcaps, layerless, layerwise, noise)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mhits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mhits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'R'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mhit_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'particle_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'layer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func_or_funcs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_named\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_agg_general\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterate_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36magg_series\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_series_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_series_pure_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_aggregate_series_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0msplitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_splitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0;31m#     raise AssertionError('Start %s must be less than end %s'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;31m#                          % (str(start), str(end)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_sorted_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_chop\u001b[0;34m(self, sdata, slice_obj)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSeriesSplitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataSplitter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             return self._constructor(\n\u001b[0;32m-> 1183\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m             ).__finalize__(self)\n\u001b[1;32m   1185\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mget_slice\u001b[0;34m(self, slobj, axis)\u001b[0m\n\u001b[1;32m   1544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m         return self.__class__(\n\u001b[0;32m-> 1546\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1547\u001b[0m         )\n\u001b[1;32m   1548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2018\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2019\u001b[0m                 \u001b[0msortorder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msortorder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2020\u001b[0;31m                 \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2021\u001b[0m             )\n\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, levels, codes, sortorder, names, dtype, copy, name, verify_integrity, _set_identity)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# we've already validated levels and codes, so shortcut here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_codes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "preprocess_dm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = torch.load(\"/global/cscratch1/sd/danieltm/ExaTrkX/trackml/feature_store_endcaps/1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(cell_data=[103305, 9], event_file=/global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001000, hid=[103305], layerless_true_edges=[2, 123429], layers=[103305], pid=[103305], x=[103305, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(\"LightningModules/Embedding/train_embedding.yaml\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = LayerlessEmbedding(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Optionally load the Weights & Biases logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wandb_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/wandb_data\"\n",
    "wandb_logger = WandbLogger(project=\"EmbeddingStudy\", group=\"LayerlessEndcaps\", log_model=True, save_dir = wandb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs = config['max_epochs'], gpus=1, logger=wandb_logger, callbacks=stringlist_to_classes(config[\"callbacks\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmurnanedaniel\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /global/cscratch1/sd/danieltm/ExaTrkX/wandb_data/wandb/run-20201013_111443-hd6lqvip\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mworthy-frog-58\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/murnanedaniel/EmbeddingStudy\" target=\"_blank\">https://wandb.ai/murnanedaniel/EmbeddingStudy</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/murnanedaniel/EmbeddingStudy/runs/hd6lqvip\" target=\"_blank\">https://wandb.ai/murnanedaniel/EmbeddingStudy/runs/hd6lqvip</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | layers    | ModuleList | 1 M   \n",
      "1 | emb_layer | Linear     | 4 K   \n",
      "2 | norm      | LayerNorm  | 1 K   \n",
      "3 | act       | Tanh       | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f3b0d361a448d481387e983c16d58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0;31m# ------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    843\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m                 )\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_closure\u001b[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[1;32m   1014\u001b[0m                 training_step_output = self.training_forward(split_batch, batch_idx, opt_idx,\n\u001b[0;32m-> 1015\u001b[0;31m                                                              hiddens)\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_forward\u001b[0;34m(self, batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/u2/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/embedding_base.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0me_spatial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me_spatial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_bidir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0my_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_cluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_bidir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-45d4afebefac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/states.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mentering\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# The INTERRUPTED state can be set inside the run function. To indicate that run was interrupted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPUBackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu_backend.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m   1237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;31m# CORE TRAINING LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_keyboard_interrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare_train_loop_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/utilities/device_dtype_mixin.py\u001b[0m in \u001b[0;36mcpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \"\"\"\n\u001b[1;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \"\"\"\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \"\"\"\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Callback Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Add to the callback list any data manipulation methods. For example, EmbeddingInferenceCallback automatically builds the training, validation and testing set for the next stage of the pipeline after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "callback_list = [EmbeddingInferenceCallback()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs = config['max_epochs'], gpus=1, logger=wandb_logger, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "   ##  Model Load and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     110
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class EmbeddingBase(LightningModule):\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        '''\n",
    "        Initialise the Lightning Module that can scan over different embedding training regimes\n",
    "        '''\n",
    "        # Assign hyperparameters\n",
    "        self.hparams = hparams\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = [torch.optim.AdamW(self.parameters(), lr=(self.hparams[\"lr\"]), betas=(0.9, 0.999), eps=1e-08, amsgrad=True)]\n",
    "        scheduler = [\n",
    "            {\n",
    "                'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer[0], factor=self.hparams[\"factor\"], patience=self.hparams[\"patience\"]),\n",
    "                'monitor': 'checkpoint_on',\n",
    "                'interval': 'epoch',\n",
    "                'frequency': 1\n",
    "            }\n",
    "        ]\n",
    "#         scheduler = [torch.optim.lr_scheduler.StepLR(optimizer[0], step_size=1, gamma=0.3)]\n",
    "        return optimizer, scheduler\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        if 'ci' in self.hparams[\"regime\"]:\n",
    "            spatial = self(torch.cat([batch.cell_data, batch.x], axis=-1))\n",
    "        else:\n",
    "            spatial = self(batch.x)\n",
    "\n",
    "        e_bidir = torch.cat([batch.layerless_true_edges,\n",
    "                               torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)\n",
    "\n",
    "        e_spatial = torch.empty([2,0], dtype=torch.int64, device=self.device)\n",
    "\n",
    "        if 'rp' in self.hparams[\"regime\"]:\n",
    "        # Get random edge list\n",
    "            n_random = int(self.hparams[\"randomisation\"]*e_bidir.shape[1])\n",
    "            e_spatial = torch.cat([e_spatial, torch.randint(e_bidir.min(), e_bidir.max(), (2, n_random), device=self.device)], axis=-1)\n",
    "\n",
    "        if 'hnm' in self.hparams[\"regime\"]:\n",
    "            e_spatial = torch.cat([e_spatial, build_edges(spatial, self.hparams[\"r_train\"], self.hparams[\"knn\"], res)], axis=-1)\n",
    "            # e_spatial = torch.cat([e_spatial, radius_graph(spatial, r=self.hparams[\"r_train\"], max_num_neighbors=self.hparams[\"knn\"])], axis=-1)\n",
    "\n",
    "        e_spatial, y_cluster = graph_intersection(e_spatial, e_bidir)\n",
    "\n",
    "        e_spatial = torch.cat([e_spatial, e_bidir.transpose(0,1).repeat(1,self.hparams[\"weight\"]).view(-1, 2).transpose(0,1)], axis=-1)\n",
    "        y_cluster = np.concatenate([y_cluster.astype(int), np.ones(e_bidir.shape[1]*self.hparams[\"weight\"])])\n",
    "\n",
    "        hinge = torch.from_numpy(y_cluster).float().to(device)\n",
    "        hinge[hinge == 0] = -1\n",
    "\n",
    "        reference = spatial.index_select(0, e_spatial[1])\n",
    "        neighbors = spatial.index_select(0, e_spatial[0])\n",
    "        d = torch.sum((reference - neighbors)**2, dim=-1)\n",
    "\n",
    "        loss = torch.nn.functional.hinge_embedding_loss(d, hinge, margin=self.hparams[\"margin\"], reduction=\"mean\")\n",
    "\n",
    "        result = pl.TrainResult(minimize=loss)\n",
    "        result.log('train_loss', loss, prog_bar=True)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        if 'ci' in self.hparams[\"regime\"]:\n",
    "            spatial = self(torch.cat([batch.cell_data, batch.x], axis=-1))\n",
    "        else:\n",
    "            spatial = self(batch.x)\n",
    "\n",
    "        e_bidir = torch.cat([batch.layerless_true_edges,\n",
    "                               torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)\n",
    "\n",
    "        # Get random edge list\n",
    "        e_spatial = build_edges(spatial, self.hparams[\"r_val\"], 100, res)\n",
    "        # e_spatial = radius_graph(spatial, r=self.hparams[\"r_val\"], max_num_neighbors=1000)\n",
    "\n",
    "        e_spatial, y_cluster = graph_intersection(e_spatial, e_bidir)\n",
    "\n",
    "        hinge = torch.from_numpy(y_cluster).float().to(device)\n",
    "        hinge[hinge == 0] = -1\n",
    "\n",
    "        reference = spatial.index_select(0, e_spatial[1])\n",
    "        neighbors = spatial.index_select(0, e_spatial[0])\n",
    "        d = torch.sum((reference - neighbors)**2, dim=-1)\n",
    "\n",
    "        val_loss = torch.nn.functional.hinge_embedding_loss(d, hinge, margin=self.hparams[\"margin\"], reduction=\"mean\")\n",
    "\n",
    "        result = pl.EvalResult(checkpoint_on=val_loss)\n",
    "        result.log('val_loss', val_loss, prog_bar=True)\n",
    "\n",
    "        cluster_true = 2*len(batch.layerless_true_edges[0])\n",
    "        cluster_true_positive = y_cluster.sum()\n",
    "        cluster_positive = len(e_spatial[0])\n",
    "\n",
    "        result.log_dict({'eff': torch.tensor(cluster_true_positive/cluster_true), 'pur': torch.tensor(cluster_true_positive/cluster_positive)}, prog_bar=True)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_idx, second_order_closure=None, on_tpu=False, using_native_amp=False, using_lbfgs=False):\n",
    "        # warm up lr\n",
    "        if (self.hparams[\"warmup\"] is not None) and (self.trainer.global_step < self.hparams[\"warmup\"]):\n",
    "            lr_scale = min(1., float(self.trainer.global_step + 1) / self.hparams[\"warmup\"])\n",
    "            for pg in optimizer.param_groups:\n",
    "                pg['lr'] = lr_scale * self.hparams[\"lr\"]\n",
    "\n",
    "        # update params\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "class LayerlessEmbedding(EmbeddingBase):\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__(hparams)\n",
    "        '''\n",
    "        Initialise the Lightning Module that can scan over different embedding training regimes\n",
    "        '''\n",
    "\n",
    "        # Construct the MLP architecture\n",
    "        layers = [Linear(hparams[\"in_channels\"], hparams[\"emb_hidden\"])]\n",
    "        ln = [Linear(hparams[\"emb_hidden\"], hparams[\"emb_hidden\"]) for _ in range(hparams[\"nb_layer\"]-1)]\n",
    "        layers.extend(ln)\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.emb_layer = nn.Linear(hparams[\"emb_hidden\"], hparams[\"emb_dim\"])\n",
    "        self.norm = nn.LayerNorm(hparams[\"emb_hidden\"])\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "#         hits = self.normalize(hits)\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "            x = self.act(x)\n",
    "#         x = self.norm(x) #Option of LayerNorm\n",
    "        x = self.emb_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run_label = \"hd6lqvip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wandb_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/wandb_data\"\n",
    "best_run_path = get_best_run(run_label,wandb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chkpnt = torch.load(best_run_path)\n",
    "model = LayerlessEmbedding(chkpnt[\"hyper_parameters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = model.load_from_checkpoint(best_run_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 validated\n",
      "5 validated\n",
      "10 validated\n",
      "15 validated\n",
      "20 validated\n",
      "25 validated\n",
      "30 validated\n",
      "35 validated\n",
      "40 validated\n",
      "45 validated\n",
      "Eff: 0.9750146118157859 Pur: 0.013130086934014518\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    cluster_total_positive, cluster_total_true, cluster_total_true_positive = 0, 0, 0\n",
    "    for i, batch in enumerate(model.val_dataloader()):\n",
    "            data = batch.to(device)\n",
    "            if 'ci' in model.hparams['regime']:\n",
    "                spatial = model(torch.cat([data.cell_data, data.x], axis=-1))\n",
    "            else:\n",
    "                spatial = model(data.x)\n",
    "            e_spatial = build_edges(spatial, 1.7, 500, res)  \n",
    "            e_bidir = torch.cat([batch.layerless_true_edges.to(device), \n",
    "                                   torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T.to(device)], axis=-1) \n",
    "            e_spatial, y_cluster = graph_intersection(e_spatial, e_bidir)\n",
    "            \n",
    "            #Cluster performance\n",
    "            cluster_true = 2*len(batch.layerless_true_edges[0])\n",
    "            cluster_true_positive = y_cluster.sum()\n",
    "            cluster_positive = len(e_spatial[0])\n",
    "            \n",
    "            cluster_total_true_positive += cluster_true_positive\n",
    "            cluster_total_positive += cluster_positive\n",
    "            cluster_total_true += cluster_true\n",
    "            if i % 5 == 0:\n",
    "                print(i, \"validated\")\n",
    "\n",
    "    cluster_eff = (cluster_total_true_positive / max(cluster_total_true, 1))\n",
    "    cluster_pur = (cluster_total_true_positive / max(cluster_total_positive, 1))\n",
    "print(\"Eff:\", cluster_eff, \"Pur:\", cluster_pur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Debug Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_events = os.listdir(model.hparams[\"input_dir\"])\n",
    "all_events = sorted([os.path.join(model.hparams[\"input_dir\"], event) for event in all_events])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = torch.load(all_events[0], map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(cell_data=[103305, 9], event_file=/global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_all/event000001000, hid=[103305], layerless_true_edges=[2, 123429], layers=[103305], pid=[103305], x=[103305, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = sample.to(device)\n",
    "if 'ci' in model.hparams['regime']:\n",
    "    spatial = model(torch.cat([data.cell_data, data.x], axis=-1))\n",
    "else:\n",
    "    spatial = model(data.x)\n",
    "e_spatial = build_edges(spatial, 1.52, 500, res)  \n",
    "e_bidir = torch.cat([sample.layerless_true_edges.to(device), \n",
    "                       torch.stack([sample.layerless_true_edges[1], sample.layerless_true_edges[0]], axis=1).T.to(device)], axis=-1) \n",
    "e_spatial, y_cluster = graph_intersection(e_spatial, e_bidir)\n",
    "\n",
    "#Cluster performance\n",
    "cluster_true = 2*len(sample.layerless_true_edges[0])\n",
    "cluster_true_positive = y_cluster.sum()\n",
    "cluster_positive = len(e_spatial[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9650892415882816, 0.020561669126978318)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_true_positive / cluster_true, cluster_true_positive / cluster_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 123429])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.layerless_true_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120241.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cluster.sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 validated\n",
      "5 validated\n",
      "10 validated\n",
      "15 validated\n",
      "20 validated\n",
      "25 validated\n",
      "30 validated\n",
      "35 validated\n",
      "40 validated\n",
      "45 validated\n",
      "Eff: 0.9750146118157859 Pur: 0.013130086934014518\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    cluster_total_positive, cluster_total_true, cluster_total_true_positive = 0, 0, 0\n",
    "    for i, batch in enumerate(model.val_dataloader()):\n",
    "            data = batch.to(device)\n",
    "            if 'ci' in model.hparams['regime']:\n",
    "                spatial = model(torch.cat([data.cell_data, data.x], axis=-1))\n",
    "            else:\n",
    "                spatial = model(data.x)\n",
    "            e_spatial = build_edges(spatial, 1.7, 500, res)  \n",
    "            e_bidir = torch.cat([batch.layerless_true_edges.to(device), \n",
    "                                   torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T.to(device)], axis=-1) \n",
    "            e_spatial, y_cluster = graph_intersection(e_spatial, e_bidir)\n",
    "            \n",
    "            #Cluster performance\n",
    "            cluster_true = 2*len(batch.layerless_true_edges[0])\n",
    "            cluster_true_positive = y_cluster.sum()\n",
    "            cluster_positive = len(e_spatial[0])\n",
    "            \n",
    "            cluster_total_true_positive += cluster_true_positive\n",
    "            cluster_total_positive += cluster_positive\n",
    "            cluster_total_true += cluster_true\n",
    "            if i % 5 == 0:\n",
    "                print(i, \"validated\")\n",
    "\n",
    "    cluster_eff = (cluster_total_true_positive / max(cluster_total_true, 1))\n",
    "    cluster_pur = (cluster_total_true_positive / max(cluster_total_positive, 1))\n",
    "print(\"Eff:\", cluster_eff, \"Pur:\", cluster_pur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Build Filter Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import shuffle, choice\n",
    "from time import time as tt\n",
    "import os\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     5
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 already built\n",
      "1 already built\n",
      "2 already built\n",
      "3 already built\n",
      "4 already built\n",
      "5 already built\n",
      "6 already built\n",
      "7 already built\n",
      "8 already built\n",
      "9 already built\n",
      "10 already built\n",
      "11 already built\n",
      "12 already built\n",
      "13 already built\n",
      "14 already built\n",
      "15 already built\n",
      "16 already built\n",
      "17 already built\n",
      "18 already built\n",
      "19 already built\n",
      "20 already built\n",
      "21 already built\n",
      "22 already built\n",
      "23 already built\n",
      "24 already built\n",
      "25 already built\n",
      "26 already built\n",
      "27 already built\n",
      "28 already built\n",
      "29 already built\n",
      "30 already built\n",
      "31 already built\n",
      "32 already built\n",
      "33 already built\n",
      "34 already built\n",
      "35 already built\n",
      "36 already built\n",
      "37 already built\n",
      "38 already built\n",
      "39 already built\n",
      "40 already built\n",
      "41 already built\n",
      "42 already built\n",
      "43 already built\n",
      "44 already built\n",
      "45 already built\n",
      "46 already built\n",
      "47 already built\n",
      "48 already built\n",
      "49 already built\n",
      "50 already built\n",
      "51 already built\n",
      "52 already built\n",
      "53 already built\n",
      "54 already built\n",
      "55 already built\n",
      "56 already built\n",
      "57 already built\n",
      "58 already built\n",
      "59 already built\n",
      "60 already built\n",
      "61 already built\n",
      "62 already built\n",
      "63 already built\n",
      "64 already built\n",
      "65 already built\n",
      "66 already built\n",
      "67 already built\n",
      "68 already built\n",
      "69 already built\n",
      "70 already built\n",
      "71 already built\n",
      "72 already built\n",
      "73 already built\n",
      "74 already built\n",
      "75 already built\n",
      "76 already built\n",
      "77 already built\n",
      "78 already built\n",
      "79 already built\n",
      "80 already built\n",
      "81 already built\n",
      "82 already built\n",
      "83 already built\n",
      "84 already built\n",
      "85 already built\n",
      "86 already built\n",
      "87 already built\n",
      "88 already built\n",
      "89 already built\n",
      "90 already built\n",
      "91 already built\n",
      "92 already built\n",
      "93 already built\n",
      "94 already built\n",
      "95 already built\n",
      "96 already built\n",
      "97 already built\n",
      "98 already built\n",
      "99 already built\n",
      "100 already built\n",
      "101 already built\n",
      "102 already built\n",
      "103 already built\n",
      "104 already built\n",
      "105 already built\n",
      "106 already built\n",
      "107 already built\n",
      "108 already built\n",
      "109 already built\n",
      "110 already built\n",
      "111 already built\n",
      "112 already built\n",
      "113 already built\n",
      "114 already built\n",
      "115 already built\n",
      "116 already built\n",
      "117 already built\n",
      "118 already built\n",
      "119 already built\n",
      "120 already built\n",
      "121 already built\n",
      "122 already built\n",
      "123 already built\n",
      "124 already built\n",
      "125 already built\n",
      "126 already built\n",
      "127 already built\n",
      "128 already built\n",
      "129 already built\n",
      "130 already built\n",
      "131 already built\n",
      "132 already built\n",
      "133 already built\n",
      "134 already built\n",
      "135 already built\n",
      "136 already built\n",
      "137 already built\n",
      "138 already built\n",
      "139 already built\n",
      "140 already built\n",
      "141 already built\n",
      "142 already built\n",
      "143 already built\n",
      "144 already built\n",
      "145 already built\n",
      "146 already built\n",
      "147 already built\n",
      "148 already built\n",
      "149 already built\n",
      "150 already built\n",
      "151 already built\n",
      "152 already built\n",
      "153 already built\n",
      "154 already built\n",
      "155 already built\n",
      "156 already built\n",
      "157 already built\n",
      "158 already built\n",
      "159 already built\n",
      "160 already built\n",
      "161 already built\n",
      "162 already built\n",
      "163 already built\n",
      "164 already built\n",
      "165 already built\n",
      "166 already built\n",
      "167 already built\n",
      "168 already built\n",
      "169 already built\n",
      "170 already built\n",
      "171 already built\n",
      "172 already built\n",
      "173 already built\n",
      "174 already built\n",
      "175 saved in time 19.609458923339844 with efficiency 0.9718126654624939 and purity 0.014860891737043858\n",
      "176 saved in time 8.079134464263916 with efficiency 0.9712509512901306 and purity 0.013983985409140587\n",
      "177 saved in time 4.590465545654297 with efficiency 0.9754307270050049 and purity 0.014424999244511127\n",
      "178 saved in time 6.988777160644531 with efficiency 0.9772685766220093 and purity 0.013498621992766857\n",
      "179 saved in time 6.2446606159210205 with efficiency 0.97397381067276 and purity 0.013039084151387215\n",
      "180 saved in time 3.4943747520446777 with efficiency 0.9743065237998962 and purity 0.013530666939914227\n",
      "183 saved in time 3.093226671218872 with efficiency 0.9742752313613892 and purity 0.013168469071388245\n",
      "184 saved in time 6.086920738220215 with efficiency 0.9771608114242554 and purity 0.01289978064596653\n",
      "185 saved in time 3.6462392807006836 with efficiency 0.9775840044021606 and purity 0.013561778701841831\n",
      "186 saved in time 4.026283025741577 with efficiency 0.9739923477172852 and purity 0.014467374421656132\n",
      "187 saved in time 7.274864912033081 with efficiency 0.9734030961990356 and purity 0.012878838926553726\n",
      "188 saved in time 14.698934316635132 with efficiency 0.9754016399383545 and purity 0.011276479810476303\n",
      "189 saved in time 2.7454264163970947 with efficiency 0.9772472381591797 and purity 0.013937817886471748\n",
      "190 saved in time 2.4512412548065186 with efficiency 0.9768065810203552 and purity 0.014377595856785774\n",
      "191 saved in time 13.65261697769165 with efficiency 0.975134015083313 and purity 0.01078153308480978\n",
      "192 saved in time 4.008490562438965 with efficiency 0.9742957949638367 and purity 0.012637672945857048\n",
      "193 saved in time 3.7308290004730225 with efficiency 0.9761843085289001 and purity 0.012393184937536716\n",
      "194 saved in time 6.618800163269043 with efficiency 0.9759333729743958 and purity 0.01264231838285923\n",
      "195 saved in time 2.9088900089263916 with efficiency 0.9713939428329468 and purity 0.013953254558146\n",
      "196 saved in time 9.906839609146118 with efficiency 0.9763903617858887 and purity 0.012960114516317844\n",
      "197 saved in time 5.465498208999634 with efficiency 0.9759247303009033 and purity 0.013225131668150425\n",
      "198 saved in time 9.90664553642273 with efficiency 0.9691707491874695 and purity 0.011725567281246185\n",
      "199 saved in time 8.378413677215576 with efficiency 0.9744914174079895 and purity 0.012270106002688408\n",
      "200 saved in time 3.9728786945343018 with efficiency 0.9762303233146667 and purity 0.013587933033704758\n",
      "201 saved in time 8.02078890800476 with efficiency 0.974402129650116 and purity 0.012027885764837265\n",
      "202 saved in time 2.7733452320098877 with efficiency 0.9752321839332581 and purity 0.014628603123128414\n",
      "203 saved in time 3.0460751056671143 with efficiency 0.9741442203521729 and purity 0.014027143828570843\n",
      "204 saved in time 5.714386940002441 with efficiency 0.9774306416511536 and purity 0.013543004170060158\n",
      "205 saved in time 6.168207883834839 with efficiency 0.9754588007926941 and purity 0.012659274972975254\n",
      "206 saved in time 8.602808952331543 with efficiency 0.9754568934440613 and purity 0.012979205697774887\n",
      "207 saved in time 13.061161994934082 with efficiency 0.9712737798690796 and purity 0.011456330306828022\n",
      "208 saved in time 3.518829107284546 with efficiency 0.9739155769348145 and purity 0.013114824891090393\n",
      "209 saved in time 3.050868272781372 with efficiency 0.9799420833587646 and purity 0.01853751391172409\n",
      "210 saved in time 4.403079271316528 with efficiency 0.9734674692153931 and purity 0.01203068345785141\n",
      "211 saved in time 2.994108200073242 with efficiency 0.974452555179596 and purity 0.012698420323431492\n",
      "212 saved in time 4.963488578796387 with efficiency 0.9758093953132629 and purity 0.012806130573153496\n",
      "213 saved in time 5.130938529968262 with efficiency 0.9762632846832275 and purity 0.012098247185349464\n",
      "214 saved in time 3.1279900074005127 with efficiency 0.9770476222038269 and purity 0.014127127826213837\n",
      "215 saved in time 3.630894422531128 with efficiency 0.9750105142593384 and purity 0.013565903529524803\n",
      "216 saved in time 5.34363865852356 with efficiency 0.9752146005630493 and purity 0.012086376547813416\n",
      "217 saved in time 5.4342896938323975 with efficiency 0.9778793454170227 and purity 0.015200101770460606\n",
      "218 saved in time 7.584556579589844 with efficiency 0.9705491662025452 and purity 0.013087956234812737\n",
      "219 saved in time 4.9711761474609375 with efficiency 0.9776950478553772 and purity 0.01346862968057394\n",
      "220 saved in time 5.978137254714966 with efficiency 0.9755710363388062 and purity 0.011891867034137249\n",
      "221 saved in time 3.711799383163452 with efficiency 0.9766538739204407 and purity 0.013967892155051231\n",
      "222 saved in time 8.6461021900177 with efficiency 0.9769293069839478 and purity 0.012923221103847027\n",
      "223 saved in time 8.039517402648926 with efficiency 0.9765451550483704 and purity 0.011764260940253735\n",
      "224 saved in time 3.5910651683807373 with efficiency 0.9759081602096558 and purity 0.015412235632538795\n",
      "225 saved in time 8.103836059570312 with efficiency 0.9700000286102295 and purity 0.01206660084426403\n",
      "226 saved in time 4.592527151107788 with efficiency 0.9778208136558533 and purity 0.013716185465455055\n",
      "227 saved in time 9.355055093765259 with efficiency 0.9737561345100403 and purity 0.012152289971709251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228 saved in time 7.577373743057251 with efficiency 0.9734491109848022 and purity 0.0114508755505085\n",
      "229 saved in time 4.85268497467041 with efficiency 0.9778352379798889 and purity 0.013209590688347816\n",
      "230 saved in time 3.0476913452148438 with efficiency 0.9769854545593262 and purity 0.016115104779601097\n",
      "231 saved in time 7.175201654434204 with efficiency 0.9754022359848022 and purity 0.011560174636542797\n",
      "232 saved in time 5.224979639053345 with efficiency 0.9771357178688049 and purity 0.013785049319267273\n",
      "233 saved in time 5.325516223907471 with efficiency 0.9754731059074402 and purity 0.012260735034942627\n",
      "234 saved in time 5.422729015350342 with efficiency 0.977002739906311 and purity 0.013290743343532085\n",
      "235 saved in time 4.603063344955444 with efficiency 0.9712920188903809 and purity 0.013574021868407726\n",
      "236 saved in time 6.792486667633057 with efficiency 0.973650336265564 and purity 0.012095351703464985\n",
      "237 saved in time 3.920006513595581 with efficiency 0.9767962098121643 and purity 0.014381453394889832\n",
      "238 saved in time 9.571607112884521 with efficiency 0.9745509028434753 and purity 0.0123749990016222\n",
      "239 saved in time 6.136793851852417 with efficiency 0.9764781594276428 and purity 0.014565568417310715\n",
      "240 saved in time 8.303566455841064 with efficiency 0.974225640296936 and purity 0.013040450401604176\n",
      "241 saved in time 3.3792030811309814 with efficiency 0.9763009548187256 and purity 0.015005228109657764\n",
      "242 saved in time 9.385803937911987 with efficiency 0.9759473204612732 and purity 0.011460140347480774\n",
      "243 saved in time 4.306371450424194 with efficiency 0.9722534418106079 and purity 0.01300114020705223\n",
      "244 saved in time 4.287419557571411 with efficiency 0.9764165878295898 and purity 0.013863199390470982\n",
      "245 saved in time 11.009872198104858 with efficiency 0.9766319394111633 and purity 0.012346419505774975\n",
      "246 saved in time 3.6702420711517334 with efficiency 0.9766594767570496 and purity 0.014354542829096317\n",
      "247 saved in time 4.244662284851074 with efficiency 0.9768414497375488 and purity 0.01350599154829979\n",
      "248 saved in time 2.902696371078491 with efficiency 0.9738666415214539 and purity 0.016168612986803055\n",
      "249 saved in time 8.229055643081665 with efficiency 0.9774022698402405 and purity 0.01350918784737587\n",
      "250 saved in time 7.462052345275879 with efficiency 0.9745242595672607 and purity 0.01310134306550026\n",
      "251 saved in time 6.762196779251099 with efficiency 0.9717981219291687 and purity 0.011972599662840366\n",
      "252 saved in time 4.976394891738892 with efficiency 0.9760082960128784 and purity 0.013469468802213669\n",
      "253 saved in time 4.622081279754639 with efficiency 0.9745945334434509 and purity 0.013370578177273273\n",
      "254 saved in time 9.899225950241089 with efficiency 0.9770691394805908 and purity 0.01251872070133686\n",
      "255 saved in time 6.10202169418335 with efficiency 0.9757600426673889 and purity 0.01237981766462326\n",
      "256 saved in time 3.3245856761932373 with efficiency 0.9773440361022949 and purity 0.015698792412877083\n",
      "257 saved in time 4.146505355834961 with efficiency 0.9748932123184204 and purity 0.01394956186413765\n",
      "258 saved in time 5.0491416454315186 with efficiency 0.9762094616889954 and purity 0.012761704623699188\n",
      "259 saved in time 4.553962230682373 with efficiency 0.9778303503990173 and purity 0.013215446844696999\n",
      "260 saved in time 7.63983416557312 with efficiency 0.974970281124115 and purity 0.01153266429901123\n",
      "261 saved in time 4.293880224227905 with efficiency 0.9744738340377808 and purity 0.013112588785588741\n",
      "262 saved in time 7.339541673660278 with efficiency 0.9779092073440552 and purity 0.013504991307854652\n",
      "263 saved in time 5.547752141952515 with efficiency 0.9763859510421753 and purity 0.01334308460354805\n",
      "264 saved in time 10.51665449142456 with efficiency 0.9733222126960754 and purity 0.011728617362678051\n",
      "265 saved in time 4.999251127243042 with efficiency 0.9758135080337524 and purity 0.012536385096609592\n",
      "266 saved in time 3.063899517059326 with efficiency 0.9763895273208618 and purity 0.01538267731666565\n",
      "267 saved in time 11.867679119110107 with efficiency 0.9772495627403259 and purity 0.01202557422220707\n",
      "268 saved in time 6.210842132568359 with efficiency 0.9760562181472778 and purity 0.012129957787692547\n",
      "269 saved in time 6.36398720741272 with efficiency 0.9777169823646545 and purity 0.01457776129245758\n",
      "270 saved in time 4.762684106826782 with efficiency 0.9760583639144897 and purity 0.013112843036651611\n",
      "271 saved in time 3.2299208641052246 with efficiency 0.9759092926979065 and purity 0.01602349616587162\n",
      "272 saved in time 7.358719825744629 with efficiency 0.9785035848617554 and purity 0.014111317694187164\n",
      "273 saved in time 4.163309335708618 with efficiency 0.9745628237724304 and purity 0.014936604537069798\n",
      "274 saved in time 6.444567918777466 with efficiency 0.977518618106842 and purity 0.014445848762989044\n",
      "275 saved in time 4.226610898971558 with efficiency 0.9763688445091248 and purity 0.014283678494393826\n",
      "276 saved in time 6.386447906494141 with efficiency 0.9770676493644714 and purity 0.014963583089411259\n",
      "277 saved in time 9.218969106674194 with efficiency 0.9735360145568848 and purity 0.01267384085804224\n",
      "278 saved in time 6.150020122528076 with efficiency 0.9710212349891663 and purity 0.012592829763889313\n",
      "279 saved in time 4.928046226501465 with efficiency 0.9745382070541382 and purity 0.01605517603456974\n",
      "280 saved in time 6.2150373458862305 with efficiency 0.9788278937339783 and purity 0.012228738516569138\n",
      "281 saved in time 4.631671667098999 with efficiency 0.9762282967567444 and purity 0.01343145314604044\n",
      "282 saved in time 2.9990367889404297 with efficiency 0.9767040014266968 and purity 0.01581914909183979\n",
      "283 saved in time 4.814415454864502 with efficiency 0.9733234643936157 and purity 0.01286285649985075\n",
      "284 saved in time 7.5510430335998535 with efficiency 0.9741630554199219 and purity 0.011216799728572369\n",
      "285 saved in time 9.213711500167847 with efficiency 0.9760059118270874 and purity 0.01214013434946537\n",
      "286 saved in time 4.950464248657227 with efficiency 0.9728181958198547 and purity 0.012919907458126545\n",
      "287 saved in time 6.451836347579956 with efficiency 0.9744024872779846 and purity 0.012382250279188156\n",
      "288 saved in time 6.408443212509155 with efficiency 0.9765095114707947 and purity 0.014627785421907902\n",
      "289 saved in time 3.1187736988067627 with efficiency 0.9769017696380615 and purity 0.015552105382084846\n",
      "290 saved in time 7.035552024841309 with efficiency 0.9768557548522949 and purity 0.01383229810744524\n",
      "291 saved in time 8.960043668746948 with efficiency 0.9742239117622375 and purity 0.01129657682031393\n",
      "292 saved in time 4.732547044754028 with efficiency 0.9744951725006104 and purity 0.012911851517856121\n",
      "293 saved in time 4.385699033737183 with efficiency 0.9747899174690247 and purity 0.01341007836163044\n",
      "294 saved in time 4.891589403152466 with efficiency 0.9759997725486755 and purity 0.012644867412745953\n",
      "295 saved in time 4.343390703201294 with efficiency 0.97684246301651 and purity 0.013301944360136986\n",
      "296 saved in time 7.82886815071106 with efficiency 0.975609540939331 and purity 0.012690833769738674\n",
      "297 saved in time 4.5526041984558105 with efficiency 0.9744731187820435 and purity 0.013024398125708103\n",
      "298 saved in time 3.86270809173584 with efficiency 0.9742236733436584 and purity 0.01371461246162653\n",
      "299 saved in time 3.182708501815796 with efficiency 0.9771990776062012 and purity 0.015929214656352997\n",
      "300 saved in time 6.237613201141357 with efficiency 0.9761332869529724 and purity 0.012340736575424671\n",
      "301 saved in time 3.8267388343811035 with efficiency 0.9744025468826294 and purity 0.013738584704697132\n",
      "302 saved in time 4.936654329299927 with efficiency 0.972194492816925 and purity 0.012966020964086056\n",
      "303 saved in time 6.065907716751099 with efficiency 0.975903332233429 and purity 0.011967348866164684\n",
      "304 saved in time 11.124496936798096 with efficiency 0.9753833413124084 and purity 0.011554401367902756\n",
      "305 saved in time 5.985975027084351 with efficiency 0.9756598472595215 and purity 0.01194284949451685\n",
      "306 saved in time 5.5373148918151855 with efficiency 0.9767193794250488 and purity 0.012919546104967594\n",
      "307 saved in time 6.094444751739502 with efficiency 0.9760379791259766 and purity 0.012157254852354527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308 saved in time 4.7257561683654785 with efficiency 0.9759190082550049 and purity 0.012709198519587517\n",
      "309 saved in time 7.496848821640015 with efficiency 0.9778451323509216 and purity 0.014505395665764809\n",
      "310 saved in time 4.935279846191406 with efficiency 0.9765825271606445 and purity 0.013296309858560562\n",
      "311 saved in time 5.466214418411255 with efficiency 0.9752486348152161 and purity 0.012857114896178246\n",
      "312 saved in time 6.127147674560547 with efficiency 0.9753738641738892 and purity 0.012836756184697151\n",
      "313 saved in time 8.701187372207642 with efficiency 0.9747382402420044 and purity 0.011258518323302269\n",
      "314 saved in time 3.5704307556152344 with efficiency 0.9754422903060913 and purity 0.014028764329850674\n",
      "315 saved in time 3.721390724182129 with efficiency 0.979171872138977 and purity 0.015528693795204163\n",
      "316 saved in time 5.823700904846191 with efficiency 0.9773044586181641 and purity 0.014840010553598404\n",
      "317 saved in time 5.697456121444702 with efficiency 0.9760504961013794 and purity 0.013044639490544796\n",
      "318 saved in time 5.489018678665161 with efficiency 0.9745874404907227 and purity 0.014213922433555126\n",
      "319 saved in time 9.597255945205688 with efficiency 0.9704416990280151 and purity 0.01061498373746872\n",
      "320 saved in time 8.084367036819458 with efficiency 0.975297749042511 and purity 0.012536736205220222\n",
      "321 saved in time 5.528783798217773 with efficiency 0.9738824367523193 and purity 0.012246075086295605\n",
      "322 saved in time 8.929492712020874 with efficiency 0.975919246673584 and purity 0.012938164174556732\n",
      "323 saved in time 9.665521621704102 with efficiency 0.9755722880363464 and purity 0.012966451235115528\n",
      "324 saved in time 5.042520999908447 with efficiency 0.9766635894775391 and purity 0.012377528473734856\n",
      "325 saved in time 5.26071310043335 with efficiency 0.974960446357727 and purity 0.012744171544909477\n",
      "326 saved in time 5.769520282745361 with efficiency 0.9780552387237549 and purity 0.013260944746434689\n",
      "327 saved in time 4.270146131515503 with efficiency 0.9734194874763489 and purity 0.013772770762443542\n",
      "328 saved in time 9.023428678512573 with efficiency 0.97525954246521 and purity 0.011632881127297878\n",
      "329 saved in time 4.698460340499878 with efficiency 0.9765150547027588 and purity 0.013274994678795338\n",
      "330 saved in time 9.280406713485718 with efficiency 0.9747774004936218 and purity 0.011986326426267624\n",
      "331 saved in time 3.582002878189087 with efficiency 0.9759140610694885 and purity 0.014638491906225681\n",
      "332 saved in time 3.940479040145874 with efficiency 0.9757956862449646 and purity 0.013769417069852352\n",
      "333 saved in time 9.074243307113647 with efficiency 0.9758145809173584 and purity 0.012307584285736084\n",
      "334 saved in time 6.274753570556641 with efficiency 0.9720350503921509 and purity 0.013278973288834095\n",
      "335 saved in time 9.161997556686401 with efficiency 0.9756028652191162 and purity 0.012837089598178864\n",
      "336 saved in time 9.176818370819092 with efficiency 0.9711405634880066 and purity 0.012295934371650219\n",
      "337 saved in time 6.930519104003906 with efficiency 0.9755189418792725 and purity 0.01166566088795662\n",
      "338 saved in time 4.5949742794036865 with efficiency 0.9765685796737671 and purity 0.017476633191108704\n",
      "339 saved in time 8.017973184585571 with efficiency 0.9743468165397644 and purity 0.011259310878813267\n",
      "340 saved in time 4.080148696899414 with efficiency 0.9704138040542603 and purity 0.013272206299006939\n",
      "341 saved in time 8.495969295501709 with efficiency 0.9708712697029114 and purity 0.012617362663149834\n",
      "342 saved in time 4.111109018325806 with efficiency 0.9749565124511719 and purity 0.013241274282336235\n",
      "343 saved in time 10.051950931549072 with efficiency 0.9740505218505859 and purity 0.011676177382469177\n",
      "344 saved in time 5.111772060394287 with efficiency 0.9786741137504578 and purity 0.015378233045339584\n",
      "345 saved in time 4.321636199951172 with efficiency 0.9772785305976868 and purity 0.014456159435212612\n",
      "346 saved in time 6.0054755210876465 with efficiency 0.9763357639312744 and purity 0.012605939991772175\n",
      "347 saved in time 11.36723256111145 with efficiency 0.9739763736724854 and purity 0.011701881885528564\n",
      "348 saved in time 8.117552518844604 with efficiency 0.9755752086639404 and purity 0.012946780771017075\n",
      "349 saved in time 3.3961517810821533 with efficiency 0.9784260392189026 and purity 0.01492795255035162\n",
      "350 saved in time 6.901332139968872 with efficiency 0.9760864973068237 and purity 0.012226858176290989\n",
      "351 saved in time 7.237975120544434 with efficiency 0.9766646027565002 and purity 0.013802673667669296\n",
      "352 saved in time 4.598120927810669 with efficiency 0.9738636612892151 and purity 0.013239660300314426\n",
      "353 saved in time 4.96341347694397 with efficiency 0.9772247672080994 and purity 0.013091781176626682\n",
      "354 saved in time 11.449039697647095 with efficiency 0.973888635635376 and purity 0.011671419255435467\n",
      "355 saved in time 7.20986270904541 with efficiency 0.9769740104675293 and purity 0.013280217535793781\n",
      "356 saved in time 7.175410270690918 with efficiency 0.9758083820343018 and purity 0.011547406204044819\n",
      "357 saved in time 6.037943124771118 with efficiency 0.9754040837287903 and purity 0.012642014771699905\n",
      "358 saved in time 8.288242816925049 with efficiency 0.9757446050643921 and purity 0.012794584967195988\n",
      "359 saved in time 7.837791681289673 with efficiency 0.9768581390380859 and purity 0.010835237801074982\n",
      "360 saved in time 4.056085586547852 with efficiency 0.9757457971572876 and purity 0.01409395132213831\n",
      "361 saved in time 5.78135871887207 with efficiency 0.9749912023544312 and purity 0.012062565423548222\n",
      "362 saved in time 4.126889944076538 with efficiency 0.9716461896896362 and purity 0.014990601688623428\n",
      "363 saved in time 4.662925481796265 with efficiency 0.977381706237793 and purity 0.013642353937029839\n",
      "364 saved in time 6.982621431350708 with efficiency 0.9759213328361511 and purity 0.012269541621208191\n",
      "365 saved in time 5.302367448806763 with efficiency 0.9730625748634338 and purity 0.01300801895558834\n",
      "366 saved in time 5.170118570327759 with efficiency 0.9718957543373108 and purity 0.012913478538393974\n",
      "367 saved in time 5.207021713256836 with efficiency 0.9756901264190674 and purity 0.012830987572669983\n",
      "368 saved in time 9.980628252029419 with efficiency 0.9755989909172058 and purity 0.012425198219716549\n",
      "369 saved in time 5.954238176345825 with efficiency 0.9758577942848206 and purity 0.011834288015961647\n",
      "370 saved in time 6.064918041229248 with efficiency 0.9729878902435303 and purity 0.014247809536755085\n",
      "371 saved in time 4.637192964553833 with efficiency 0.9767729043960571 and purity 0.013555910438299179\n",
      "372 saved in time 9.93564224243164 with efficiency 0.9743183851242065 and purity 0.011861143633723259\n",
      "373 saved in time 7.602748394012451 with efficiency 0.9747942090034485 and purity 0.011213555932044983\n",
      "374 saved in time 3.817922592163086 with efficiency 0.9734104871749878 and purity 0.014596429653465748\n",
      "375 saved in time 6.919731378555298 with efficiency 0.9739112854003906 and purity 0.011510458774864674\n",
      "376 saved in time 4.884042739868164 with efficiency 0.9741867184638977 and purity 0.01311235036700964\n",
      "377 saved in time 5.436627149581909 with efficiency 0.9772486686706543 and purity 0.01237886119633913\n",
      "378 saved in time 6.584499835968018 with efficiency 0.97784823179245 and purity 0.011732863262295723\n",
      "379 saved in time 5.1159827709198 with efficiency 0.9761455655097961 and purity 0.012643209658563137\n",
      "380 saved in time 5.702014446258545 with efficiency 0.9757351279258728 and purity 0.012669429183006287\n",
      "381 saved in time 6.3712992668151855 with efficiency 0.9744905233383179 and purity 0.012015233747661114\n",
      "382 saved in time 9.17407488822937 with efficiency 0.97395920753479 and purity 0.01240859366953373\n",
      "383 saved in time 6.000842094421387 with efficiency 0.9763557314872742 and purity 0.012873667292296886\n",
      "384 saved in time 7.581117153167725 with efficiency 0.9755249619483948 and purity 0.01158598531037569\n",
      "385 saved in time 4.254289388656616 with efficiency 0.9701867699623108 and purity 0.01352002564817667\n",
      "386 saved in time 5.961963891983032 with efficiency 0.9723527431488037 and purity 0.01291672233492136\n",
      "387 saved in time 4.313497304916382 with efficiency 0.9768297672271729 and purity 0.014250416308641434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388 saved in time 6.119096040725708 with efficiency 0.9711686968803406 and purity 0.011790670454502106\n",
      "389 saved in time 5.32355260848999 with efficiency 0.9706615805625916 and purity 0.012653309851884842\n",
      "390 saved in time 5.6304967403411865 with efficiency 0.9758285880088806 and purity 0.012323803268373013\n",
      "391 saved in time 4.5782551765441895 with efficiency 0.9773653745651245 and purity 0.013238915242254734\n",
      "392 saved in time 2.8875114917755127 with efficiency 0.9747465252876282 and purity 0.015873940661549568\n",
      "393 saved in time 5.168769359588623 with efficiency 0.9748778343200684 and purity 0.013479077257215977\n",
      "394 saved in time 3.623133659362793 with efficiency 0.9709728956222534 and purity 0.01493295282125473\n",
      "395 saved in time 7.162531852722168 with efficiency 0.976101815700531 and purity 0.012013661675155163\n",
      "396 saved in time 5.305725574493408 with efficiency 0.9766198396682739 and purity 0.013144426047801971\n",
      "397 saved in time 4.473874807357788 with efficiency 0.9755510687828064 and purity 0.014348044991493225\n",
      "398 saved in time 6.444389820098877 with efficiency 0.9762758016586304 and purity 0.01264746580272913\n",
      "399 saved in time 7.391890287399292 with efficiency 0.9738807082176208 and purity 0.011427436023950577\n",
      "400 saved in time 6.219035387039185 with efficiency 0.9745116233825684 and purity 0.011946451850235462\n",
      "401 saved in time 6.346921443939209 with efficiency 0.9749990701675415 and purity 0.011728930287063122\n",
      "402 saved in time 7.51200270652771 with efficiency 0.9752073287963867 and purity 0.011987203732132912\n",
      "403 saved in time 6.398585796356201 with efficiency 0.9756688475608826 and purity 0.013156368397176266\n",
      "404 saved in time 4.36505913734436 with efficiency 0.9745627641677856 and purity 0.013220197521150112\n",
      "405 saved in time 5.573299169540405 with efficiency 0.9761295318603516 and purity 0.012852703221142292\n",
      "406 saved in time 3.5648136138916016 with efficiency 0.9759590029716492 and purity 0.014557143673300743\n",
      "407 saved in time 3.56929349899292 with efficiency 0.9782214164733887 and purity 0.014824085868895054\n",
      "408 saved in time 11.538997650146484 with efficiency 0.974257230758667 and purity 0.011767413467168808\n",
      "409 saved in time 6.742166519165039 with efficiency 0.9770604372024536 and purity 0.014046411029994488\n",
      "410 saved in time 5.705920696258545 with efficiency 0.9763951897621155 and purity 0.01215161569416523\n",
      "411 saved in time 9.473235368728638 with efficiency 0.9752013683319092 and purity 0.012319938279688358\n",
      "412 saved in time 4.449492454528809 with efficiency 0.9759153723716736 and purity 0.01312214508652687\n",
      "413 saved in time 7.876263856887817 with efficiency 0.9703428149223328 and purity 0.011459673754870892\n",
      "414 saved in time 7.501157999038696 with efficiency 0.9752580523490906 and purity 0.013009462505578995\n",
      "415 saved in time 7.501568794250488 with efficiency 0.9747218489646912 and purity 0.012006459757685661\n",
      "416 saved in time 5.537230491638184 with efficiency 0.9767192602157593 and purity 0.014678538776934147\n",
      "417 saved in time 5.456069469451904 with efficiency 0.9762877821922302 and purity 0.014067232608795166\n",
      "418 saved in time 6.4284987449646 with efficiency 0.9768453240394592 and purity 0.011831381358206272\n",
      "419 saved in time 4.668551921844482 with efficiency 0.9768146872520447 and purity 0.013324689120054245\n",
      "420 saved in time 4.349578142166138 with efficiency 0.9766917824745178 and purity 0.014944992959499359\n",
      "421 saved in time 3.268275022506714 with efficiency 0.9746713638305664 and purity 0.015245404094457626\n",
      "422 saved in time 6.669066429138184 with efficiency 0.9767934679985046 and purity 0.014312179759144783\n",
      "423 saved in time 6.913502216339111 with efficiency 0.9750860333442688 and purity 0.012861599214375019\n",
      "424 saved in time 6.587032079696655 with efficiency 0.970558762550354 and purity 0.01348903775215149\n",
      "425 saved in time 4.8777031898498535 with efficiency 0.9702622294425964 and purity 0.013081757351756096\n",
      "426 saved in time 4.061240911483765 with efficiency 0.9742207527160645 and purity 0.014103226363658905\n",
      "427 saved in time 7.866512298583984 with efficiency 0.9711486101150513 and purity 0.012280605733394623\n",
      "428 saved in time 3.9909751415252686 with efficiency 0.9766143560409546 and purity 0.014171690680086613\n",
      "429 saved in time 6.047369003295898 with efficiency 0.9744744300842285 and purity 0.012176468968391418\n",
      "430 saved in time 5.3514509201049805 with efficiency 0.9776436686515808 and purity 0.014080829918384552\n",
      "431 saved in time 6.88896369934082 with efficiency 0.9753114581108093 and purity 0.012291560880839825\n",
      "432 saved in time 6.911730527877808 with efficiency 0.9751933813095093 and purity 0.011756181716918945\n",
      "433 saved in time 4.6767942905426025 with efficiency 0.9779500365257263 and purity 0.013679184019565582\n",
      "434 saved in time 6.407586336135864 with efficiency 0.9755968451499939 and purity 0.01299574039876461\n",
      "435 saved in time 8.554222822189331 with efficiency 0.9750723242759705 and purity 0.012086951173841953\n",
      "436 saved in time 6.4028589725494385 with efficiency 0.9720020294189453 and purity 0.01236298680305481\n",
      "437 saved in time 7.818140745162964 with efficiency 0.9766392707824707 and purity 0.013260358944535255\n",
      "438 saved in time 3.641880989074707 with efficiency 0.976621150970459 and purity 0.014389105141162872\n",
      "439 saved in time 4.083616018295288 with efficiency 0.9758949875831604 and purity 0.013639301061630249\n",
      "440 saved in time 6.376568555831909 with efficiency 0.976703405380249 and purity 0.012499937787652016\n",
      "441 saved in time 11.011157751083374 with efficiency 0.9765210151672363 and purity 0.01091039553284645\n",
      "442 saved in time 4.027151346206665 with efficiency 0.9776168465614319 and purity 0.014714713208377361\n",
      "443 saved in time 6.368301153182983 with efficiency 0.9729146957397461 and purity 0.011487005278468132\n",
      "444 saved in time 3.7100443840026855 with efficiency 0.9768930077552795 and purity 0.014051401056349277\n",
      "445 saved in time 6.099389553070068 with efficiency 0.9754348397254944 and purity 0.011895202100276947\n",
      "446 saved in time 4.7096474170684814 with efficiency 0.9768965840339661 and purity 0.013773790560662746\n",
      "447 saved in time 7.263225555419922 with efficiency 0.9766018986701965 and purity 0.011446459218859673\n",
      "448 saved in time 6.416604995727539 with efficiency 0.9740232825279236 and purity 0.011446257121860981\n",
      "449 saved in time 9.142405271530151 with efficiency 0.975262463092804 and purity 0.01220657303929329\n",
      "450 saved in time 5.437256813049316 with efficiency 0.9730556011199951 and purity 0.01208570972084999\n",
      "451 saved in time 3.8405349254608154 with efficiency 0.9727303981781006 and purity 0.014312788844108582\n",
      "452 saved in time 7.132256984710693 with efficiency 0.9706943035125732 and purity 0.011481063440442085\n",
      "453 saved in time 9.153606176376343 with efficiency 0.9763755202293396 and purity 0.012828292325139046\n",
      "454 saved in time 8.947494745254517 with efficiency 0.9757378101348877 and purity 0.012615316547453403\n",
      "455 saved in time 3.688046932220459 with efficiency 0.9765749573707581 and purity 0.014309222809970379\n",
      "456 saved in time 6.911602973937988 with efficiency 0.9739479422569275 and purity 0.012275373563170433\n",
      "457 saved in time 4.983999013900757 with efficiency 0.9757382273674011 and purity 0.012607102282345295\n",
      "458 saved in time 10.48497223854065 with efficiency 0.973193883895874 and purity 0.0118103651329875\n",
      "459 saved in time 5.316188812255859 with efficiency 0.9774428009986877 and purity 0.01557680033147335\n",
      "460 saved in time 4.473222255706787 with efficiency 0.9775707721710205 and purity 0.014066169038414955\n",
      "461 saved in time 3.0612947940826416 with efficiency 0.9750438332557678 and purity 0.01587744988501072\n",
      "462 saved in time 6.514824390411377 with efficiency 0.977328896522522 and purity 0.013663049787282944\n",
      "463 saved in time 9.201326370239258 with efficiency 0.9744606018066406 and purity 0.011554846540093422\n",
      "464 saved in time 3.896376132965088 with efficiency 0.9745055437088013 and purity 0.01476626843214035\n",
      "465 saved in time 6.8440821170806885 with efficiency 0.9773467183113098 and purity 0.011980975978076458\n",
      "466 saved in time 6.758357763290405 with efficiency 0.9728963375091553 and purity 0.011319674551486969\n",
      "467 saved in time 4.027181625366211 with efficiency 0.9766643047332764 and purity 0.015376033261418343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468 saved in time 3.299240827560425 with efficiency 0.9766583442687988 and purity 0.014890764839947224\n",
      "469 saved in time 4.869976043701172 with efficiency 0.9726958870887756 and purity 0.013000458478927612\n",
      "470 saved in time 3.923867702484131 with efficiency 0.9792667031288147 and purity 0.014230718836188316\n",
      "471 saved in time 3.4190239906311035 with efficiency 0.977222740650177 and purity 0.014683919958770275\n",
      "472 saved in time 3.8673324584960938 with efficiency 0.9769026041030884 and purity 0.01491751428693533\n",
      "473 saved in time 5.5350120067596436 with efficiency 0.9700981974601746 and purity 0.013714967295527458\n",
      "474 saved in time 4.583243370056152 with efficiency 0.9755825996398926 and purity 0.013895264826714993\n",
      "475 saved in time 3.416478157043457 with efficiency 0.9768549799919128 and purity 0.015326096676290035\n",
      "476 saved in time 9.589285850524902 with efficiency 0.9739679098129272 and purity 0.011956250295042992\n",
      "477 saved in time 6.104372024536133 with efficiency 0.9751519560813904 and purity 0.012780256569385529\n",
      "478 saved in time 3.721900224685669 with efficiency 0.9776400327682495 and purity 0.017035914584994316\n",
      "479 saved in time 9.531446933746338 with efficiency 0.9717011451721191 and purity 0.011875213123857975\n",
      "480 saved in time 3.6804263591766357 with efficiency 0.9776350259780884 and purity 0.01482379250228405\n",
      "481 saved in time 4.087952375411987 with efficiency 0.9769676923751831 and purity 0.013720237649977207\n",
      "482 saved in time 4.219421625137329 with efficiency 0.9764893651008606 and purity 0.013765622861683369\n",
      "483 saved in time 4.7954206466674805 with efficiency 0.9768968820571899 and purity 0.013550776056945324\n",
      "484 saved in time 4.750323057174683 with efficiency 0.9692617654800415 and purity 0.01300917100161314\n",
      "485 saved in time 3.4985673427581787 with efficiency 0.9772668480873108 and purity 0.014977802522480488\n",
      "486 saved in time 3.9938158988952637 with efficiency 0.9716590046882629 and purity 0.014176205731928349\n",
      "487 saved in time 7.2487053871154785 with efficiency 0.975597620010376 and purity 0.013235346414148808\n",
      "488 saved in time 7.193605184555054 with efficiency 0.9730010628700256 and purity 0.011792188510298729\n",
      "489 saved in time 3.8001279830932617 with efficiency 0.9765946865081787 and purity 0.014062497764825821\n",
      "490 saved in time 4.02628493309021 with efficiency 0.9698488712310791 and purity 0.014454513788223267\n",
      "491 saved in time 3.5097880363464355 with efficiency 0.9784210324287415 and purity 0.015383479185402393\n",
      "492 saved in time 3.4615588188171387 with efficiency 0.9755204916000366 and purity 0.016586685553193092\n",
      "493 saved in time 5.142000436782837 with efficiency 0.9714094400405884 and purity 0.012744859792292118\n",
      "494 saved in time 5.9163596630096436 with efficiency 0.972383439540863 and purity 0.01217852532863617\n",
      "495 saved in time 5.549962520599365 with efficiency 0.9713000059127808 and purity 0.012819969095289707\n",
      "496 saved in time 6.643062114715576 with efficiency 0.9749805927276611 and purity 0.01187907624989748\n",
      "497 saved in time 4.560565233230591 with efficiency 0.9751433730125427 and purity 0.01569696143269539\n",
      "498 saved in time 8.82121467590332 with efficiency 0.9753400087356567 and purity 0.011542042717337608\n",
      "499 saved in time 2.9682366847991943 with efficiency 0.9757391214370728 and purity 0.015661615878343582\n",
      "500 saved in time 8.789048910140991 with efficiency 0.9749688506126404 and purity 0.011226439848542213\n",
      "501 saved in time 4.511739492416382 with efficiency 0.971899688243866 and purity 0.01329243928194046\n",
      "502 saved in time 5.07771897315979 with efficiency 0.9713900685310364 and purity 0.012342841364443302\n",
      "503 saved in time 7.590803146362305 with efficiency 0.9758777618408203 and purity 0.013090531341731548\n",
      "504 saved in time 6.986037254333496 with efficiency 0.9760700464248657 and purity 0.01247041393071413\n",
      "505 saved in time 4.108130931854248 with efficiency 0.9767322540283203 and purity 0.014256334863603115\n",
      "506 saved in time 3.9508121013641357 with efficiency 0.9768661260604858 and purity 0.014404679648578167\n",
      "507 saved in time 7.38636589050293 with efficiency 0.9755403399467468 and purity 0.013205385766923428\n",
      "508 saved in time 4.609619855880737 with efficiency 0.9727399349212646 and purity 0.01316726952791214\n",
      "509 saved in time 7.475279092788696 with efficiency 0.9753237962722778 and purity 0.013788502663373947\n",
      "510 saved in time 6.350845813751221 with efficiency 0.9768086671829224 and purity 0.014666656032204628\n",
      "511 saved in time 6.983073949813843 with efficiency 0.9745678901672363 and purity 0.012302733957767487\n",
      "512 saved in time 3.1886730194091797 with efficiency 0.977936863899231 and purity 0.015665357932448387\n",
      "513 saved in time 5.1968772411346436 with efficiency 0.975841224193573 and purity 0.012977980077266693\n",
      "514 saved in time 5.9530816078186035 with efficiency 0.971653163433075 and purity 0.01194140687584877\n",
      "515 saved in time 5.441150903701782 with efficiency 0.9746062159538269 and purity 0.012307492084801197\n",
      "516 saved in time 3.9706063270568848 with efficiency 0.9765514135360718 and purity 0.014346595853567123\n",
      "517 saved in time 10.638801336288452 with efficiency 0.9720554947853088 and purity 0.01173770148307085\n",
      "518 saved in time 5.371217727661133 with efficiency 0.9776099324226379 and purity 0.01219372171908617\n",
      "519 saved in time 3.6380395889282227 with efficiency 0.9780079126358032 and purity 0.014450758695602417\n",
      "520 saved in time 7.498126029968262 with efficiency 0.9754692912101746 and purity 0.014044217765331268\n",
      "521 saved in time 5.1647789478302 with efficiency 0.9739407300949097 and purity 0.014093977399170399\n",
      "522 saved in time 6.666132211685181 with efficiency 0.9758148789405823 and purity 0.012845922261476517\n",
      "523 saved in time 4.181214809417725 with efficiency 0.9746357202529907 and purity 0.014237236231565475\n",
      "524 saved in time 3.594390392303467 with efficiency 0.9758289456367493 and purity 0.014287274330854416\n",
      "525 saved in time 3.4564261436462402 with efficiency 0.9770323634147644 and purity 0.014968281611800194\n",
      "526 saved in time 4.510090351104736 with efficiency 0.9787662625312805 and purity 0.013619973324239254\n",
      "527 saved in time 5.7196385860443115 with efficiency 0.9770534634590149 and purity 0.012767876498401165\n",
      "528 saved in time 3.6597421169281006 with efficiency 0.9755574464797974 and purity 0.015042316168546677\n",
      "529 saved in time 9.355096340179443 with efficiency 0.9726739525794983 and purity 0.012384421192109585\n",
      "530 saved in time 4.414212465286255 with efficiency 0.9764738082885742 and purity 0.01330606173723936\n",
      "531 saved in time 6.241084098815918 with efficiency 0.9767250418663025 and purity 0.012880460359156132\n",
      "532 saved in time 9.06083345413208 with efficiency 0.9744651317596436 and purity 0.012943089939653873\n",
      "533 saved in time 7.097124338150024 with efficiency 0.9765196442604065 and purity 0.01203326229006052\n",
      "534 saved in time 5.138985872268677 with efficiency 0.9755455851554871 and purity 0.012471414171159267\n",
      "535 saved in time 4.460273265838623 with efficiency 0.9726853370666504 and purity 0.01304733008146286\n",
      "536 saved in time 3.6441519260406494 with efficiency 0.9737392067909241 and purity 0.013883051462471485\n",
      "537 saved in time 7.6346776485443115 with efficiency 0.9755098223686218 and purity 0.011851242743432522\n",
      "538 saved in time 3.9371120929718018 with efficiency 0.9751209616661072 and purity 0.014544395729899406\n",
      "539 saved in time 3.3984971046447754 with efficiency 0.9738268852233887 and purity 0.014953536912798882\n",
      "540 saved in time 4.612834215164185 with efficiency 0.9746222496032715 and purity 0.01364166010171175\n",
      "541 saved in time 7.824034929275513 with efficiency 0.9748552441596985 and purity 0.013805883005261421\n",
      "542 saved in time 3.8702127933502197 with efficiency 0.9769128561019897 and purity 0.01403998862951994\n",
      "543 saved in time 11.769762754440308 with efficiency 0.9744255542755127 and purity 0.011578444391489029\n",
      "544 saved in time 4.058601379394531 with efficiency 0.9728262424468994 and purity 0.013638191856443882\n",
      "545 saved in time 3.2845444679260254 with efficiency 0.9782789349555969 and purity 0.01572464592754841\n",
      "546 saved in time 3.6340925693511963 with efficiency 0.9759668111801147 and purity 0.014680263586342335\n",
      "547 saved in time 8.317827701568604 with efficiency 0.9760549068450928 and purity 0.01272439956665039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548 saved in time 3.9462060928344727 with efficiency 0.9759878516197205 and purity 0.014099648222327232\n",
      "549 saved in time 7.66972541809082 with efficiency 0.970918595790863 and purity 0.011449471116065979\n",
      "550 saved in time 5.551919937133789 with efficiency 0.9709728956222534 and purity 0.012359976768493652\n",
      "551 saved in time 5.439236879348755 with efficiency 0.9761096239089966 and purity 0.01394704170525074\n",
      "552 saved in time 5.1783435344696045 with efficiency 0.9725041389465332 and purity 0.013024965301156044\n",
      "553 saved in time 6.696347236633301 with efficiency 0.9731869697570801 and purity 0.013756928965449333\n",
      "554 saved in time 5.386262893676758 with efficiency 0.9760524034500122 and purity 0.01312621682882309\n",
      "555 saved in time 6.1654298305511475 with efficiency 0.9769564270973206 and purity 0.012724032625555992\n",
      "556 saved in time 9.440470218658447 with efficiency 0.9765316843986511 and purity 0.012797151692211628\n",
      "557 saved in time 6.764110803604126 with efficiency 0.9785719513893127 and purity 0.014250176027417183\n",
      "558 saved in time 6.047463893890381 with efficiency 0.9753921627998352 and purity 0.014575558714568615\n",
      "559 saved in time 4.9137022495269775 with efficiency 0.9757798910140991 and purity 0.013376946561038494\n",
      "560 saved in time 4.39642333984375 with efficiency 0.979930579662323 and purity 0.015084924176335335\n",
      "561 saved in time 4.702513217926025 with efficiency 0.9787566661834717 and purity 0.013908430933952332\n",
      "562 saved in time 3.6240437030792236 with efficiency 0.9767522811889648 and purity 0.01490869466215372\n",
      "563 saved in time 9.029611587524414 with efficiency 0.9762236475944519 and purity 0.01122360210865736\n",
      "564 saved in time 4.916348218917847 with efficiency 0.974418580532074 and purity 0.012379979714751244\n",
      "565 saved in time 6.5042994022369385 with efficiency 0.9767827987670898 and purity 0.01309464406222105\n",
      "566 saved in time 4.147264003753662 with efficiency 0.9781731963157654 and purity 0.013990296982228756\n",
      "567 saved in time 6.661783695220947 with efficiency 0.9782940149307251 and purity 0.013529307208955288\n",
      "568 saved in time 6.4878740310668945 with efficiency 0.9767499566078186 and purity 0.013978984206914902\n",
      "569 saved in time 6.767876148223877 with efficiency 0.9775430560112 and purity 0.012379536405205727\n",
      "570 saved in time 6.572449684143066 with efficiency 0.9748921394348145 and purity 0.012069637887179852\n",
      "571 saved in time 5.023350477218628 with efficiency 0.977567732334137 and purity 0.012449068948626518\n",
      "572 saved in time 3.3693525791168213 with efficiency 0.9768590927124023 and purity 0.01568751037120819\n",
      "573 saved in time 8.460747241973877 with efficiency 0.9762494564056396 and purity 0.010691401548683643\n",
      "574 saved in time 4.49892520904541 with efficiency 0.9713262319564819 and purity 0.012580176815390587\n",
      "575 saved in time 7.01366400718689 with efficiency 0.9712727069854736 and purity 0.013219943270087242\n",
      "576 saved in time 5.750633955001831 with efficiency 0.9762466549873352 and purity 0.013171643950045109\n",
      "577 saved in time 4.732738256454468 with efficiency 0.9748193025588989 and purity 0.012709096074104309\n",
      "578 saved in time 3.7346858978271484 with efficiency 0.9785714149475098 and purity 0.013872679322957993\n",
      "579 saved in time 7.001590013504028 with efficiency 0.9768161773681641 and purity 0.013378322124481201\n",
      "580 saved in time 5.130164384841919 with efficiency 0.9754030108451843 and purity 0.013088759034872055\n",
      "581 saved in time 9.912429332733154 with efficiency 0.9752759337425232 and purity 0.012324941344559193\n",
      "582 saved in time 7.1974897384643555 with efficiency 0.9763379096984863 and purity 0.013433015905320644\n",
      "583 saved in time 2.936086893081665 with efficiency 0.9705967903137207 and purity 0.014943481422960758\n",
      "584 saved in time 5.914716005325317 with efficiency 0.9744387865066528 and purity 0.01229487732052803\n",
      "585 saved in time 3.373647689819336 with efficiency 0.974419116973877 and purity 0.015126177109777927\n",
      "586 saved in time 3.615971088409424 with efficiency 0.9772963523864746 and purity 0.01391743216663599\n",
      "587 saved in time 5.04718279838562 with efficiency 0.9755561947822571 and purity 0.013692020438611507\n",
      "588 saved in time 7.01409387588501 with efficiency 0.9774660468101501 and purity 0.011435153894126415\n",
      "589 saved in time 2.278088092803955 with efficiency 0.9714321494102478 and purity 0.018451979383826256\n",
      "590 saved in time 4.957729816436768 with efficiency 0.9702566266059875 and purity 0.012837528251111507\n",
      "591 saved in time 5.13988184928894 with efficiency 0.9783601760864258 and purity 0.012228847481310368\n",
      "592 saved in time 6.871951580047607 with efficiency 0.9747328758239746 and purity 0.013393722474575043\n",
      "593 saved in time 4.450275659561157 with efficiency 0.9760088324546814 and purity 0.01400480791926384\n",
      "594 saved in time 5.301996469497681 with efficiency 0.9788671135902405 and purity 0.012799035757780075\n",
      "595 saved in time 4.908246278762817 with efficiency 0.9742593765258789 and purity 0.012164024636149406\n",
      "596 saved in time 4.589020490646362 with efficiency 0.9758127927780151 and purity 0.012976305559277534\n",
      "597 saved in time 3.8642194271087646 with efficiency 0.9720051288604736 and purity 0.014708846807479858\n",
      "598 saved in time 4.01507830619812 with efficiency 0.9769011735916138 and purity 0.013757459819316864\n",
      "599 saved in time 7.527828931808472 with efficiency 0.9747515320777893 and purity 0.013647971674799919\n",
      "600 saved in time 8.579901933670044 with efficiency 0.9760069251060486 and purity 0.012254465371370316\n",
      "601 saved in time 3.943253993988037 with efficiency 0.9769789576530457 and purity 0.01361200213432312\n",
      "602 saved in time 5.146328926086426 with efficiency 0.9768252968788147 and purity 0.014648850075900555\n",
      "603 saved in time 7.6624064445495605 with efficiency 0.9748497605323792 and purity 0.012713173404335976\n",
      "604 saved in time 4.910681486129761 with efficiency 0.9769967794418335 and purity 0.012718388810753822\n",
      "605 saved in time 6.117830753326416 with efficiency 0.975191593170166 and purity 0.014187428168952465\n",
      "606 saved in time 3.5507001876831055 with efficiency 0.9773212671279907 and purity 0.014185532927513123\n",
      "607 saved in time 9.941342830657959 with efficiency 0.9734385013580322 and purity 0.012031810358166695\n",
      "608 saved in time 4.163989543914795 with efficiency 0.9746536016464233 and purity 0.012926723808050156\n",
      "609 saved in time 4.3829967975616455 with efficiency 0.9753285050392151 and purity 0.012960804626345634\n",
      "610 saved in time 4.49491286277771 with efficiency 0.9759784936904907 and purity 0.01296809408813715\n",
      "611 saved in time 4.996698379516602 with efficiency 0.9761966466903687 and purity 0.013047863729298115\n",
      "612 saved in time 5.4742443561553955 with efficiency 0.9776254296302795 and purity 0.01323600672185421\n",
      "613 saved in time 3.4480628967285156 with efficiency 0.9769935607910156 and purity 0.014615737833082676\n",
      "614 saved in time 4.047886848449707 with efficiency 0.9751291871070862 and purity 0.013705456629395485\n",
      "615 saved in time 5.388992071151733 with efficiency 0.9712344408035278 and purity 0.013683773577213287\n",
      "616 saved in time 4.879185914993286 with efficiency 0.9759458899497986 and purity 0.01324679609388113\n",
      "617 saved in time 6.710093259811401 with efficiency 0.9767957329750061 and purity 0.013930759392678738\n",
      "618 saved in time 4.535111904144287 with efficiency 0.9745422601699829 and purity 0.016018187627196312\n",
      "619 saved in time 4.319720268249512 with efficiency 0.9733595252037048 and purity 0.01398186944425106\n",
      "620 saved in time 4.060612440109253 with efficiency 0.9760650396347046 and purity 0.013070776127278805\n",
      "621 saved in time 4.927592754364014 with efficiency 0.9745984077453613 and purity 0.012522832490503788\n",
      "622 saved in time 3.3802030086517334 with efficiency 0.9775872826576233 and purity 0.01490706019103527\n",
      "623 saved in time 6.633272171020508 with efficiency 0.9737440943717957 and purity 0.01153890136629343\n",
      "624 saved in time 4.277264356613159 with efficiency 0.9759799242019653 and purity 0.013303577899932861\n",
      "625 saved in time 6.27484393119812 with efficiency 0.9745064973831177 and purity 0.01150541938841343\n",
      "626 saved in time 4.062486410140991 with efficiency 0.9745562076568604 and purity 0.013024810701608658\n",
      "627 saved in time 5.589580297470093 with efficiency 0.9715952277183533 and purity 0.012123443186283112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628 saved in time 4.134125709533691 with efficiency 0.9767816066741943 and purity 0.013175752013921738\n",
      "629 saved in time 3.2027738094329834 with efficiency 0.976128876209259 and purity 0.015981217846274376\n",
      "630 saved in time 2.638453245162964 with efficiency 0.9798627495765686 and purity 0.016364291310310364\n",
      "631 saved in time 3.62778639793396 with efficiency 0.9728982448577881 and purity 0.014694999903440475\n",
      "632 saved in time 5.723304748535156 with efficiency 0.9709454774856567 and purity 0.013236130587756634\n",
      "633 saved in time 4.583170175552368 with efficiency 0.9769526124000549 and purity 0.012989972718060017\n",
      "634 saved in time 3.743157148361206 with efficiency 0.9693625569343567 and purity 0.013614049181342125\n",
      "635 saved in time 6.693454027175903 with efficiency 0.9707096219062805 and purity 0.013377239927649498\n",
      "636 saved in time 4.117932319641113 with efficiency 0.9751002192497253 and purity 0.013564390130341053\n",
      "637 saved in time 7.7734034061431885 with efficiency 0.9698284864425659 and purity 0.012406671419739723\n",
      "638 saved in time 6.456763029098511 with efficiency 0.9770455956459045 and purity 0.013544373214244843\n",
      "639 saved in time 3.65153431892395 with efficiency 0.9720097780227661 and purity 0.013867758214473724\n",
      "640 saved in time 4.878754138946533 with efficiency 0.9779430031776428 and purity 0.013019334524869919\n",
      "641 saved in time 3.335153579711914 with efficiency 0.9770766496658325 and purity 0.014485686086118221\n",
      "642 saved in time 4.3477783203125 with efficiency 0.976397693157196 and purity 0.013674902729690075\n",
      "643 saved in time 8.690861225128174 with efficiency 0.9754282236099243 and purity 0.011303885839879513\n",
      "644 saved in time 7.666208505630493 with efficiency 0.9758580923080444 and purity 0.01240877341479063\n",
      "645 saved in time 3.497509717941284 with efficiency 0.9749500751495361 and purity 0.014261378906667233\n",
      "646 saved in time 8.405730962753296 with efficiency 0.9718960523605347 and purity 0.012856392189860344\n",
      "647 saved in time 4.206743240356445 with efficiency 0.971386194229126 and purity 0.012911333702504635\n",
      "648 saved in time 3.645948648452759 with efficiency 0.9747748374938965 and purity 0.013793300837278366\n",
      "649 saved in time 5.556864500045776 with efficiency 0.9756544232368469 and purity 0.012476817704737186\n",
      "650 saved in time 3.3383264541625977 with efficiency 0.9748703241348267 and purity 0.014552625827491283\n",
      "651 saved in time 4.04493522644043 with efficiency 0.9761422276496887 and purity 0.013860383071005344\n",
      "652 saved in time 4.743428707122803 with efficiency 0.9756923317909241 and purity 0.013150742277503014\n",
      "653 saved in time 4.7629783153533936 with efficiency 0.9756041765213013 and purity 0.013957041315734386\n",
      "654 saved in time 5.896132707595825 with efficiency 0.9722561836242676 and purity 0.012088226154446602\n",
      "655 saved in time 4.322072982788086 with efficiency 0.9780948162078857 and purity 0.013765392825007439\n",
      "656 saved in time 3.6133391857147217 with efficiency 0.9748700261116028 and purity 0.014457951299846172\n",
      "657 saved in time 8.7112877368927 with efficiency 0.9707884192466736 and purity 0.011463251896202564\n",
      "658 saved in time 4.657840013504028 with efficiency 0.975952684879303 and purity 0.012404656037688255\n",
      "659 saved in time 5.2697813510894775 with efficiency 0.9747840166091919 and purity 0.01362457126379013\n",
      "660 saved in time 6.6839118003845215 with efficiency 0.976130485534668 and purity 0.01141663733869791\n",
      "661 saved in time 4.367450714111328 with efficiency 0.9721807241439819 and purity 0.014152328483760357\n",
      "662 saved in time 5.7199554443359375 with efficiency 0.9724327921867371 and purity 0.011893472634255886\n",
      "663 saved in time 5.206358909606934 with efficiency 0.976925253868103 and purity 0.012969200499355793\n",
      "664 saved in time 2.9204089641571045 with efficiency 0.9763264060020447 and purity 0.015007632784545422\n",
      "665 saved in time 9.092892169952393 with efficiency 0.9741569757461548 and purity 0.011820736341178417\n",
      "666 saved in time 5.0955810546875 with efficiency 0.9768514633178711 and purity 0.01249148603528738\n",
      "667 saved in time 8.399108409881592 with efficiency 0.9724398255348206 and purity 0.010646337643265724\n",
      "668 saved in time 4.550092458724976 with efficiency 0.9765886664390564 and purity 0.01250366773456335\n",
      "669 saved in time 4.4456398487091064 with efficiency 0.9757832884788513 and purity 0.012895526364445686\n",
      "670 saved in time 8.062270164489746 with efficiency 0.9723730683326721 and purity 0.01232604868710041\n",
      "671 saved in time 4.280941486358643 with efficiency 0.9756348133087158 and purity 0.013422725722193718\n",
      "672 saved in time 5.72807502746582 with efficiency 0.9742794632911682 and purity 0.011439219117164612\n",
      "673 saved in time 8.34045696258545 with efficiency 0.9754502177238464 and purity 0.011264391243457794\n",
      "674 saved in time 4.640997648239136 with efficiency 0.9737409949302673 and purity 0.012547111138701439\n",
      "675 saved in time 10.409279823303223 with efficiency 0.9756835103034973 and purity 0.011755899526178837\n",
      "676 saved in time 3.1755781173706055 with efficiency 0.9750552177429199 and purity 0.014351530000567436\n",
      "677 saved in time 4.2510364055633545 with efficiency 0.973145067691803 and purity 0.012512030079960823\n",
      "678 saved in time 5.885484218597412 with efficiency 0.9755952954292297 and purity 0.011843637563288212\n",
      "679 saved in time 7.605145692825317 with efficiency 0.9739194512367249 and purity 0.012194466777145863\n",
      "680 saved in time 3.603945732116699 with efficiency 0.9753562808036804 and purity 0.013930656015872955\n",
      "681 saved in time 7.1439573764801025 with efficiency 0.9749161005020142 and purity 0.012688154354691505\n",
      "682 saved in time 8.34365439414978 with efficiency 0.9757662415504456 and purity 0.012412178330123425\n",
      "683 saved in time 4.128282070159912 with efficiency 0.975752592086792 and purity 0.013281947001814842\n",
      "684 saved in time 4.568242311477661 with efficiency 0.9759817719459534 and purity 0.013106425292789936\n",
      "685 saved in time 4.154247522354126 with efficiency 0.9766974449157715 and purity 0.013837961480021477\n",
      "686 saved in time 3.4263744354248047 with efficiency 0.9756774306297302 and purity 0.015438422560691833\n",
      "687 saved in time 9.648289203643799 with efficiency 0.9751036167144775 and purity 0.011397894471883774\n",
      "688 saved in time 5.5862038135528564 with efficiency 0.9772250056266785 and purity 0.012753456830978394\n",
      "689 saved in time 4.564206838607788 with efficiency 0.9758482575416565 and purity 0.012351496145129204\n",
      "690 saved in time 3.880876302719116 with efficiency 0.9766064286231995 and purity 0.01314996276050806\n",
      "691 saved in time 4.83244252204895 with efficiency 0.9731040596961975 and purity 0.015627143904566765\n",
      "692 saved in time 3.785529375076294 with efficiency 0.9781046509742737 and purity 0.0144691476598382\n",
      "693 saved in time 4.072545289993286 with efficiency 0.9786304831504822 and purity 0.016451556235551834\n",
      "694 saved in time 3.9419939517974854 with efficiency 0.975078821182251 and purity 0.014244494959712029\n",
      "695 saved in time 5.375958204269409 with efficiency 0.9717295169830322 and purity 0.012932466343045235\n",
      "696 saved in time 5.804481029510498 with efficiency 0.971030592918396 and purity 0.012016342021524906\n",
      "697 saved in time 4.3556623458862305 with efficiency 0.9767755270004272 and purity 0.013652811758220196\n",
      "698 saved in time 4.9063568115234375 with efficiency 0.9748502969741821 and purity 0.01251190435141325\n",
      "699 saved in time 3.3125617504119873 with efficiency 0.9770339131355286 and purity 0.014416251331567764\n",
      "700 saved in time 6.539473295211792 with efficiency 0.974711000919342 and purity 0.014133666642010212\n",
      "701 saved in time 5.967334747314453 with efficiency 0.971907377243042 and purity 0.012446044944226742\n",
      "702 saved in time 3.148298978805542 with efficiency 0.9759243130683899 and purity 0.015584263019263744\n",
      "703 saved in time 3.844139337539673 with efficiency 0.971851110458374 and purity 0.013221513479948044\n",
      "704 saved in time 6.163223028182983 with efficiency 0.9761431217193604 and purity 0.0136050870642066\n",
      "705 saved in time 3.979308605194092 with efficiency 0.9759366512298584 and purity 0.013965697959065437\n",
      "706 saved in time 3.705165147781372 with efficiency 0.9760453701019287 and purity 0.014146022498607635\n",
      "707 saved in time 5.247704744338989 with efficiency 0.9716581702232361 and purity 0.01258508488535881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "708 saved in time 8.159034013748169 with efficiency 0.9752033352851868 and purity 0.012690642848610878\n",
      "709 saved in time 7.352030515670776 with efficiency 0.9707821011543274 and purity 0.011364519596099854\n",
      "710 saved in time 5.098478555679321 with efficiency 0.9781163930892944 and purity 0.01270937081426382\n",
      "711 saved in time 6.8767313957214355 with efficiency 0.974664032459259 and purity 0.011477028951048851\n",
      "712 saved in time 3.291045665740967 with efficiency 0.9730522632598877 and purity 0.014075011014938354\n",
      "713 saved in time 4.301570415496826 with efficiency 0.9763053059577942 and purity 0.013419702649116516\n",
      "714 saved in time 5.27614688873291 with efficiency 0.9752607941627502 and purity 0.012635168619453907\n",
      "715 saved in time 6.855776786804199 with efficiency 0.9765353202819824 and purity 0.012775050476193428\n",
      "716 saved in time 3.803161144256592 with efficiency 0.9769737720489502 and purity 0.014016248285770416\n",
      "717 saved in time 6.556797027587891 with efficiency 0.9721676111221313 and purity 0.01369596365839243\n",
      "718 saved in time 3.9744362831115723 with efficiency 0.9765681624412537 and purity 0.01408309955149889\n",
      "719 saved in time 6.3260557651519775 with efficiency 0.9748072028160095 and purity 0.01173580065369606\n",
      "720 saved in time 3.26023268699646 with efficiency 0.9755334258079529 and purity 0.014332068152725697\n",
      "721 saved in time 3.682048797607422 with efficiency 0.9765418767929077 and purity 0.014335951767861843\n",
      "722 saved in time 8.514943599700928 with efficiency 0.9767932891845703 and purity 0.012167075648903847\n",
      "723 saved in time 6.5915000438690186 with efficiency 0.9735612273216248 and purity 0.01166698057204485\n",
      "724 saved in time 6.076308727264404 with efficiency 0.9764392375946045 and purity 0.014213774353265762\n",
      "725 saved in time 2.6450798511505127 with efficiency 0.974415123462677 and purity 0.015490741468966007\n",
      "726 saved in time 8.53574252128601 with efficiency 0.9752653241157532 and purity 0.01119875069707632\n",
      "727 saved in time 4.130324840545654 with efficiency 0.9748777747154236 and purity 0.01354114431887865\n",
      "728 saved in time 4.415896654129028 with efficiency 0.9738259315490723 and purity 0.012926850467920303\n",
      "729 saved in time 5.110044002532959 with efficiency 0.9779813885688782 and purity 0.0129131143912673\n",
      "730 saved in time 6.171297073364258 with efficiency 0.9767356514930725 and purity 0.012143958359956741\n",
      "731 saved in time 8.421696662902832 with efficiency 0.9753406643867493 and purity 0.012557419948279858\n",
      "732 saved in time 5.240524053573608 with efficiency 0.9765975475311279 and purity 0.013002078980207443\n",
      "733 saved in time 3.503868341445923 with efficiency 0.9759190678596497 and purity 0.015231669880449772\n",
      "734 saved in time 5.953915596008301 with efficiency 0.9760444164276123 and purity 0.014780335128307343\n",
      "735 saved in time 4.642706871032715 with efficiency 0.97567218542099 and purity 0.013108094222843647\n",
      "736 saved in time 4.050185441970825 with efficiency 0.9760323762893677 and purity 0.013884778134524822\n",
      "737 saved in time 4.482780933380127 with efficiency 0.9745948910713196 and purity 0.013614065945148468\n",
      "738 saved in time 4.922430515289307 with efficiency 0.9771572947502136 and purity 0.013754356652498245\n",
      "739 saved in time 5.144458293914795 with efficiency 0.9773046970367432 and purity 0.013055961579084396\n",
      "740 saved in time 4.026814699172974 with efficiency 0.9733532071113586 and purity 0.014360354281961918\n",
      "741 saved in time 3.399435043334961 with efficiency 0.976051926612854 and purity 0.015843726694583893\n",
      "742 saved in time 5.942014932632446 with efficiency 0.9752612113952637 and purity 0.013545499183237553\n",
      "743 saved in time 7.5692760944366455 with efficiency 0.9771850109100342 and purity 0.012088081799447536\n",
      "744 saved in time 10.710277795791626 with efficiency 0.9758995771408081 and purity 0.012532690539956093\n",
      "745 saved in time 7.668519496917725 with efficiency 0.975477397441864 and purity 0.011941349133849144\n",
      "746 saved in time 4.799651622772217 with efficiency 0.9749414324760437 and purity 0.012427732348442078\n",
      "747 saved in time 3.3447868824005127 with efficiency 0.9772102236747742 and purity 0.014959236606955528\n",
      "748 saved in time 5.578559398651123 with efficiency 0.9771910905838013 and purity 0.01154980156570673\n",
      "749 saved in time 9.371431350708008 with efficiency 0.9749337434768677 and purity 0.01194695383310318\n",
      "750 saved in time 3.47243070602417 with efficiency 0.9766978621482849 and purity 0.013693783432245255\n",
      "751 saved in time 4.466423034667969 with efficiency 0.9744319319725037 and purity 0.012989060021936893\n",
      "752 saved in time 5.941025257110596 with efficiency 0.9753022789955139 and purity 0.012254282832145691\n",
      "753 saved in time 3.154102087020874 with efficiency 0.977384626865387 and purity 0.014714056625962257\n",
      "754 saved in time 3.844844341278076 with efficiency 0.9769517183303833 and purity 0.014318352565169334\n",
      "755 saved in time 7.1339499950408936 with efficiency 0.9767496585845947 and purity 0.012294258922338486\n",
      "756 saved in time 3.390744924545288 with efficiency 0.976449728012085 and purity 0.015032544732093811\n",
      "757 saved in time 3.5322725772857666 with efficiency 0.975293755531311 and purity 0.014840163290500641\n",
      "758 saved in time 4.212925672531128 with efficiency 0.9755789637565613 and purity 0.013237902894616127\n",
      "759 saved in time 6.282460689544678 with efficiency 0.9712851047515869 and purity 0.012077592313289642\n",
      "760 saved in time 5.847278833389282 with efficiency 0.9721972346305847 and purity 0.0132760563865304\n",
      "761 saved in time 7.9937989711761475 with efficiency 0.9762341380119324 and purity 0.012355487793684006\n",
      "762 saved in time 3.6794168949127197 with efficiency 0.9769001603126526 and purity 0.013824786990880966\n",
      "763 saved in time 5.382574558258057 with efficiency 0.9766880869865417 and purity 0.01278896164149046\n",
      "764 saved in time 6.76245379447937 with efficiency 0.9746766090393066 and purity 0.011778238229453564\n",
      "765 saved in time 5.119175434112549 with efficiency 0.9768899083137512 and purity 0.01251224149018526\n",
      "766 saved in time 3.0226104259490967 with efficiency 0.9773846864700317 and purity 0.015430373139679432\n",
      "767 saved in time 6.354370594024658 with efficiency 0.9765067100524902 and purity 0.012035124935209751\n",
      "768 saved in time 10.140720129013062 with efficiency 0.9710442423820496 and purity 0.011974452994763851\n",
      "769 saved in time 4.947036981582642 with efficiency 0.975982129573822 and purity 0.013466957025229931\n",
      "770 saved in time 4.115732192993164 with efficiency 0.9790922999382019 and purity 0.016946302726864815\n",
      "771 saved in time 2.9632468223571777 with efficiency 0.9730190634727478 and purity 0.014941801317036152\n",
      "772 saved in time 5.168937921524048 with efficiency 0.9754262566566467 and purity 0.012865522876381874\n",
      "773 saved in time 2.6695756912231445 with efficiency 0.9759155511856079 and purity 0.01599465310573578\n",
      "774 saved in time 4.37407374382019 with efficiency 0.9769630432128906 and purity 0.014233778230845928\n",
      "775 saved in time 9.989354372024536 with efficiency 0.9715650081634521 and purity 0.011162173002958298\n",
      "776 saved in time 3.1200828552246094 with efficiency 0.9781416654586792 and purity 0.015022086910903454\n",
      "777 saved in time 6.769373178482056 with efficiency 0.9742177128791809 and purity 0.01262099388986826\n",
      "778 saved in time 3.5921549797058105 with efficiency 0.9752721786499023 and purity 0.014087444171309471\n",
      "779 saved in time 6.149840831756592 with efficiency 0.9753983020782471 and purity 0.011758536100387573\n",
      "780 saved in time 3.070566177368164 with efficiency 0.9782105088233948 and purity 0.01494821161031723\n",
      "781 saved in time 5.790915012359619 with efficiency 0.9770364165306091 and purity 0.014269096776843071\n",
      "782 saved in time 5.473585844039917 with efficiency 0.9744857549667358 and purity 0.01214772928506136\n",
      "783 saved in time 7.5408241748809814 with efficiency 0.97393399477005 and purity 0.011206223629415035\n",
      "784 saved in time 10.312906980514526 with efficiency 0.9711642861366272 and purity 0.012145779095590115\n",
      "785 saved in time 5.147814035415649 with efficiency 0.9748778343200684 and purity 0.012190785259008408\n",
      "786 saved in time 4.098641872406006 with efficiency 0.9783188104629517 and purity 0.013533791527152061\n",
      "787 saved in time 9.358295917510986 with efficiency 0.9753698110580444 and purity 0.011952368542551994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788 saved in time 3.439405918121338 with efficiency 0.9755462408065796 and purity 0.014334630221128464\n",
      "789 saved in time 2.8287363052368164 with efficiency 0.9793485999107361 and purity 0.015896642580628395\n",
      "790 saved in time 6.409420490264893 with efficiency 0.9746114611625671 and purity 0.012623842805624008\n",
      "791 saved in time 3.9032399654388428 with efficiency 0.9761679768562317 and purity 0.013229691423475742\n",
      "792 saved in time 2.9365618228912354 with efficiency 0.9763109087944031 and purity 0.015924103558063507\n",
      "793 saved in time 7.4150965213775635 with efficiency 0.9743428230285645 and purity 0.013261855579912663\n",
      "794 saved in time 4.009437799453735 with efficiency 0.9759846925735474 and purity 0.014205804094672203\n",
      "795 saved in time 5.868675231933594 with efficiency 0.9755136370658875 and purity 0.01275657583028078\n",
      "796 saved in time 5.76665997505188 with efficiency 0.9749670624732971 and purity 0.012709160335361958\n",
      "797 saved in time 4.249470472335815 with efficiency 0.9739661812782288 and purity 0.013418174348771572\n",
      "798 saved in time 4.641306161880493 with efficiency 0.974747359752655 and purity 0.013297772966325283\n",
      "799 saved in time 5.460691452026367 with efficiency 0.9752185940742493 and purity 0.015204880386590958\n",
      "800 saved in time 6.552693843841553 with efficiency 0.9767128229141235 and purity 0.013103064149618149\n",
      "801 saved in time 7.0572240352630615 with efficiency 0.9757580161094666 and purity 0.012409144081175327\n",
      "802 saved in time 3.608067035675049 with efficiency 0.9745614528656006 and purity 0.013754528015851974\n",
      "803 saved in time 3.499743700027466 with efficiency 0.9750561714172363 and purity 0.014021248556673527\n",
      "804 saved in time 5.4165732860565186 with efficiency 0.9752868413925171 and purity 0.012448787689208984\n",
      "805 saved in time 2.801872968673706 with efficiency 0.9766024947166443 and purity 0.015286488458514214\n",
      "806 saved in time 3.792013168334961 with efficiency 0.9766649007797241 and purity 0.014614204876124859\n",
      "807 saved in time 8.615137577056885 with efficiency 0.97413569688797 and purity 0.012428626418113708\n",
      "808 saved in time 3.2154221534729004 with efficiency 0.9763273596763611 and purity 0.01414243783801794\n",
      "809 saved in time 5.042417526245117 with efficiency 0.9761887788772583 and purity 0.013213702477514744\n",
      "810 saved in time 3.7229206562042236 with efficiency 0.9764161705970764 and purity 0.013911627233028412\n",
      "811 saved in time 6.2211408615112305 with efficiency 0.9756984114646912 and purity 0.012274463661015034\n",
      "812 saved in time 2.911708116531372 with efficiency 0.977727472782135 and purity 0.015804989263415337\n",
      "813 saved in time 5.1482250690460205 with efficiency 0.9740409255027771 and purity 0.013118095695972443\n",
      "814 saved in time 4.9877870082855225 with efficiency 0.9749675989151001 and purity 0.01279615331441164\n",
      "815 saved in time 3.2711212635040283 with efficiency 0.9773630499839783 and purity 0.015213477425277233\n",
      "816 saved in time 7.083014249801636 with efficiency 0.9757533669471741 and purity 0.013173628598451614\n",
      "817 saved in time 4.2320451736450195 with efficiency 0.9772710800170898 and purity 0.01421122346073389\n",
      "818 saved in time 4.62097430229187 with efficiency 0.9747006893157959 and purity 0.013282918371260166\n",
      "819 saved in time 3.9448604583740234 with efficiency 0.9762632250785828 and purity 0.01379088219255209\n",
      "820 saved in time 2.6026203632354736 with efficiency 0.9729571342468262 and purity 0.016699843108654022\n",
      "821 saved in time 5.314173221588135 with efficiency 0.9765887260437012 and purity 0.013031577691435814\n",
      "822 saved in time 5.85151219367981 with efficiency 0.978123128414154 and purity 0.012448957189917564\n",
      "823 saved in time 3.300309419631958 with efficiency 0.9758279919624329 and purity 0.015162644907832146\n",
      "824 saved in time 2.7779171466827393 with efficiency 0.9780779480934143 and purity 0.016146281734108925\n",
      "825 saved in time 4.442471504211426 with efficiency 0.9774856567382812 and purity 0.014329817146062851\n",
      "826 saved in time 5.330577850341797 with efficiency 0.9751119613647461 and purity 0.01367033552378416\n",
      "827 saved in time 6.48511004447937 with efficiency 0.9782987833023071 and purity 0.012340167537331581\n",
      "828 saved in time 4.421992301940918 with efficiency 0.9758768081665039 and purity 0.012920401059091091\n",
      "829 saved in time 6.260857820510864 with efficiency 0.976051926612854 and purity 0.014803155325353146\n",
      "830 saved in time 5.969184398651123 with efficiency 0.9757713675498962 and purity 0.014446025714278221\n",
      "831 saved in time 11.293131589889526 with efficiency 0.9747660160064697 and purity 0.01133734080940485\n",
      "832 saved in time 7.100649833679199 with efficiency 0.9773586988449097 and purity 0.014046795666217804\n",
      "833 saved in time 3.868718147277832 with efficiency 0.9772030711174011 and purity 0.013776818290352821\n",
      "834 saved in time 6.789816617965698 with efficiency 0.9737763404846191 and purity 0.011892926879227161\n",
      "835 saved in time 4.350106716156006 with efficiency 0.9739111065864563 and purity 0.013170972466468811\n",
      "836 saved in time 3.4280149936676025 with efficiency 0.9758106470108032 and purity 0.014083761721849442\n",
      "837 saved in time 6.866065740585327 with efficiency 0.9760386943817139 and purity 0.013188544660806656\n",
      "838 saved in time 3.5073161125183105 with efficiency 0.9786760210990906 and purity 0.014647423289716244\n",
      "839 saved in time 3.8294451236724854 with efficiency 0.9773483276367188 and purity 0.014606619253754616\n",
      "840 saved in time 6.990006923675537 with efficiency 0.9763181209564209 and purity 0.012415959499776363\n",
      "841 saved in time 7.097968101501465 with efficiency 0.975006103515625 and purity 0.013873136602342129\n",
      "842 saved in time 6.914614200592041 with efficiency 0.9743983745574951 and purity 0.012361484579741955\n",
      "843 saved in time 6.892590045928955 with efficiency 0.9748911261558533 and purity 0.012516153044998646\n",
      "844 saved in time 9.172396659851074 with efficiency 0.9753739833831787 and purity 0.011950577609241009\n",
      "845 saved in time 3.694809675216675 with efficiency 0.9775111675262451 and purity 0.014104234054684639\n",
      "846 saved in time 3.9383108615875244 with efficiency 0.9785939455032349 and purity 0.014356538653373718\n",
      "847 saved in time 10.339189291000366 with efficiency 0.9755223393440247 and purity 0.01224669348448515\n",
      "848 saved in time 4.783328056335449 with efficiency 0.9761363863945007 and purity 0.013164100237190723\n",
      "849 saved in time 9.401992082595825 with efficiency 0.9774428009986877 and purity 0.011805885471403599\n",
      "850 saved in time 4.13479208946228 with efficiency 0.9756148457527161 and purity 0.013320710510015488\n",
      "851 saved in time 8.858456134796143 with efficiency 0.9757028818130493 and purity 0.010927528142929077\n",
      "852 saved in time 4.998854637145996 with efficiency 0.9715381860733032 and purity 0.012536046095192432\n",
      "853 saved in time 6.455898284912109 with efficiency 0.9734707474708557 and purity 0.011231029406189919\n",
      "854 saved in time 3.904278039932251 with efficiency 0.9740655422210693 and purity 0.013274680823087692\n",
      "855 saved in time 4.493170261383057 with efficiency 0.9729514718055725 and purity 0.013968158513307571\n",
      "856 saved in time 5.428317308425903 with efficiency 0.9732399582862854 and purity 0.013051129877567291\n",
      "857 saved in time 10.103637218475342 with efficiency 0.9730885028839111 and purity 0.012117291800677776\n",
      "858 saved in time 4.519263982772827 with efficiency 0.9776557087898254 and purity 0.012750495225191116\n",
      "859 saved in time 3.965994358062744 with efficiency 0.9764015674591064 and purity 0.01348197739571333\n",
      "860 saved in time 7.996135473251343 with efficiency 0.9739611148834229 and purity 0.012533803470432758\n",
      "861 saved in time 5.3341286182403564 with efficiency 0.9762969017028809 and purity 0.012712753377854824\n",
      "862 saved in time 5.653655767440796 with efficiency 0.9748315215110779 and purity 0.01251140609383583\n",
      "863 saved in time 6.911139726638794 with efficiency 0.9769281148910522 and purity 0.011489524506032467\n",
      "864 saved in time 4.852295398712158 with efficiency 0.9760967493057251 and purity 0.012743043713271618\n",
      "865 saved in time 5.238288879394531 with efficiency 0.979463517665863 and purity 0.013695668429136276\n",
      "866 saved in time 4.057431697845459 with efficiency 0.9764238595962524 and purity 0.014746559783816338\n",
      "867 saved in time 11.36263394355774 with efficiency 0.9746703505516052 and purity 0.010973097756505013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868 saved in time 4.069558143615723 with efficiency 0.9734039902687073 and purity 0.013819612562656403\n",
      "869 saved in time 3.550947904586792 with efficiency 0.9756342768669128 and purity 0.01365542970597744\n",
      "870 saved in time 4.937993764877319 with efficiency 0.9746291041374207 and purity 0.012551581487059593\n",
      "871 saved in time 6.558716535568237 with efficiency 0.9757558703422546 and purity 0.011769412085413933\n",
      "872 saved in time 4.496351003646851 with efficiency 0.9771519303321838 and purity 0.01251448504626751\n",
      "873 saved in time 4.098477363586426 with efficiency 0.9753175377845764 and purity 0.014163214713335037\n",
      "874 saved in time 4.273937225341797 with efficiency 0.976206362247467 and purity 0.01338314637541771\n",
      "875 saved in time 5.999286651611328 with efficiency 0.9772440791130066 and purity 0.013690563850104809\n",
      "876 saved in time 8.042337417602539 with efficiency 0.9748940467834473 and purity 0.012316535227000713\n",
      "877 saved in time 7.462734222412109 with efficiency 0.9766360521316528 and purity 0.013279341161251068\n",
      "878 saved in time 3.4052469730377197 with efficiency 0.9776394367218018 and purity 0.014349101111292839\n",
      "879 saved in time 5.678138732910156 with efficiency 0.9761912822723389 and purity 0.012403083965182304\n",
      "880 saved in time 5.3551435470581055 with efficiency 0.9760693311691284 and purity 0.012481317855417728\n",
      "881 saved in time 5.304821252822876 with efficiency 0.976998507976532 and purity 0.012441523373126984\n",
      "882 saved in time 6.945361614227295 with efficiency 0.975806474685669 and purity 0.013251762837171555\n",
      "883 saved in time 3.8189146518707275 with efficiency 0.9772337079048157 and purity 0.013880650512874126\n",
      "884 saved in time 10.81062936782837 with efficiency 0.976169764995575 and purity 0.012182706966996193\n",
      "885 saved in time 6.5340354442596436 with efficiency 0.9682477116584778 and purity 0.011401742696762085\n",
      "886 saved in time 3.587197780609131 with efficiency 0.9772065877914429 and purity 0.014712576754391193\n",
      "887 saved in time 4.14192008972168 with efficiency 0.9763981103897095 and purity 0.013581869192421436\n",
      "888 saved in time 4.38246488571167 with efficiency 0.973598837852478 and purity 0.013439326547086239\n",
      "889 saved in time 5.790694236755371 with efficiency 0.9760574102401733 and purity 0.011801485903561115\n",
      "890 saved in time 6.655125856399536 with efficiency 0.9764812588691711 and purity 0.013546141795814037\n",
      "891 saved in time 6.196957111358643 with efficiency 0.9761319160461426 and purity 0.012026894837617874\n",
      "892 saved in time 5.097127914428711 with efficiency 0.9777002930641174 and purity 0.012440428137779236\n",
      "893 saved in time 3.8210654258728027 with efficiency 0.9776925444602966 and purity 0.014356652274727821\n",
      "894 saved in time 6.568068265914917 with efficiency 0.9736858606338501 and purity 0.011598671786487103\n",
      "895 saved in time 5.339112758636475 with efficiency 0.9745318293571472 and purity 0.014362765476107597\n",
      "896 saved in time 3.8654825687408447 with efficiency 0.9768621325492859 and purity 0.013753887265920639\n",
      "897 saved in time 4.548974990844727 with efficiency 0.9732166528701782 and purity 0.015596231445670128\n",
      "898 saved in time 5.882061243057251 with efficiency 0.975534975528717 and purity 0.012938947416841984\n",
      "899 saved in time 6.252872705459595 with efficiency 0.9766167402267456 and purity 0.012372182682156563\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/trackml_processed/embedding_processed/0_pt_cut_endcaps/train\"\n",
    "train, ratio = False, 8\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(model.train_dataloader().dataset):\n",
    "            tic = tt()\n",
    "            if not os.path.exists(os.path.join(save_dir, batch.event_file[-4:])):\n",
    "\n",
    "                data = batch.to(device)\n",
    "                if 'ci' in model.hparams['regime']:\n",
    "                    spatial = model(torch.cat([data.cell_data, data.x], axis=-1))\n",
    "                else:\n",
    "                    spatial = model(data.x)\n",
    "                e_spatial = build_edges(spatial, 1.7, 500, res)  \n",
    "                e_bidir = torch.cat([batch.layerless_true_edges.to(device), \n",
    "                                       torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T.to(device)], axis=-1) \n",
    "                e_spatial, y_cluster = graph_intersection(e_spatial, e_bidir)\n",
    "\n",
    "                # Remove duplicate edges by distance from vertex\n",
    "                R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)\n",
    "                e_spatial = e_spatial[:, (R_dist[e_spatial[0]] < R_dist[e_spatial[1]])]\n",
    "\n",
    "                e_spatial, y = graph_intersection(e_spatial, e_bidir)  \n",
    "\n",
    "                # Re-introduce random direction, to avoid training bias\n",
    "                random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()\n",
    "                e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]\n",
    "\n",
    "                batch.embedding = spatial.cpu().detach()\n",
    "\n",
    "                if train and (ratio != 0): # Sample only ratio:1 fake:true edges, to keep trainset manageable\n",
    "\n",
    "                    num_true = y.sum()\n",
    "                    fake_indices = choice(np.where(~y)[0], int(num_true*ratio), replace=True)\n",
    "                    true_indices = np.where(y)[0]\n",
    "                    combined_indices = np.concatenate([true_indices, fake_indices])\n",
    "                    shuffle(combined_indices)\n",
    "\n",
    "                    batch.e_radius = e_spatial[:,combined_indices].cpu()\n",
    "                    batch.y = torch.from_numpy(y[combined_indices]).float()\n",
    "\n",
    "                else:\n",
    "                    batch.e_radius = e_spatial.cpu()\n",
    "                    batch.y = torch.from_numpy(y).float()\n",
    "\n",
    "\n",
    "                with open(os.path.join(save_dir, batch.event_file[-4:]), 'wb') as pickle_file:\n",
    "                    torch.save(batch, pickle_file)\n",
    "\n",
    "                print(i, \"saved in time\", tt()-tic, \"with efficiency\", (batch.y.sum()/batch.layerless_true_edges.shape[1]).item(), \"and purity\", (batch.y.sum()/batch.e_radius.shape[1]).item())\n",
    "\n",
    "            else:\n",
    "                print(i, \"already built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def post_process(pl_module, load_dir, save_dir, train_split):\n",
    "    print(\"Training finished, running inference to filter graphs...\")\n",
    "\n",
    "    # By default, the set of examples propagated through the pipeline will be train+val+test set\n",
    "    datatypes = [\"train\", \"val\", \"test\"]\n",
    "    [os.makedirs(os.path.join(save_dir, datatype), exist_ok=True) for datatype in datatypes]\n",
    "    \n",
    "    loadsets = load_datasets(load_dir, train_split)\n",
    "    \n",
    "    total_length = sum([len(dataset) for dataset in loadsets])\n",
    "    batch_incr = 0\n",
    "\n",
    "    pl_module.eval()\n",
    "    with torch.no_grad():\n",
    "        for set_idx, (datatype, dataset) in enumerate(zip(datatypes, loadsets)):\n",
    "            for batch_idx, event in enumerate(dataset):\n",
    "#                 print(event)\n",
    "                percent = (batch_incr / total_length) * 100\n",
    "                sys.stdout.flush()\n",
    "                sys.stdout.write(f'{percent:.01f}% inference complete \\r')\n",
    "                if (not os.path.exists(os.path.join(save_dir, datatype, event[-4:]))):\n",
    "                    batch = torch.load(event, map_location=torch.device('cpu'))\n",
    "                    data = batch.to(pl_module.device) #Is this step necessary??\n",
    "                    data = construct_downstream(data, pl_module)\n",
    "                    save_downstream(data, pl_module, datatype, save_dir)\n",
    "\n",
    "                batch_incr += 1\n",
    "\n",
    "def construct_downstream(batch, pl_module):\n",
    "   \n",
    "    if 'ci' in pl_module.hparams['regime']:\n",
    "        spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))\n",
    "    else:\n",
    "        spatial = pl_module(batch.x)\n",
    "    e_spatial = build_edges(spatial, 1.7, 500, res)  \n",
    "    e_bidir = torch.cat([batch.layerless_true_edges.to(device), \n",
    "                           torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T.to(device)], axis=-1) \n",
    "    e_spatial, y_cluster = graph_intersection(e_spatial, e_bidir)\n",
    "\n",
    "    # Remove duplicate edges by distance from vertex\n",
    "    R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)\n",
    "    e_spatial = e_spatial[:, (R_dist[e_spatial[0]] < R_dist[e_spatial[1]])]\n",
    "\n",
    "    e_spatial, y = graph_intersection(e_spatial, e_bidir)  \n",
    "\n",
    "    # Re-introduce random direction, to avoid training bias\n",
    "    random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()\n",
    "    e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]\n",
    "\n",
    "    batch.embedding = spatial.cpu().detach()\n",
    "    \n",
    "    batch.e_radius = e_spatial.cpu()\n",
    "    batch.y = torch.from_numpy(y).float()\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def save_downstream(batch, pl_module, datatype, save_dir):\n",
    "\n",
    "    with open(os.path.join(save_dir, datatype, batch.event_file[-4:]), 'wb') as pickle_file:\n",
    "        torch.save(batch, pickle_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_datasets(input_dir, train_split, seed = 0):\n",
    "    '''\n",
    "    Prepare the random Train, Val, Test split, using a seed for reproducibility. Seed should be\n",
    "    changed across final varied runs, but can be left as default for experimentation.\n",
    "    '''\n",
    "    torch.manual_seed(seed)\n",
    "    all_events = os.listdir(input_dir)\n",
    "    all_events = sorted([os.path.join(input_dir, event) for event in all_events])\n",
    "    train_events, val_events, test_events = random_split(all_events, train_split)\n",
    "\n",
    "    return train_events, val_events, test_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "load_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/trackml/feature_store_endcaps\"\n",
    "save_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/trackml_processed/embedding_processed/0_pt_cut_endcaps/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished, running inference to filter graphs...\n",
      "46.7% inference complete \r"
     ]
    }
   ],
   "source": [
    "train_split = [8700, 50, 50]\n",
    "post_process(model, load_dir, save_dir, train_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../pipeline.yaml\") as f:\n",
    "    pipeline_config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 16614<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.18MB of 0.18MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/global/cscratch1/sd/danieltm/ExaTrkX/wandb_data/wandb/run-20201027_122737-enm731r3/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/global/cscratch1/sd/danieltm/ExaTrkX/wandb_data/wandb/run-20201027_122737-enm731r3/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>val_loss</td><td>6.70294</td></tr><tr><td>_timestamp</td><td>1603826867</td></tr><tr><td>global_step</td><td>99</td></tr><tr><td>eff</td><td>0.99386</td></tr><tr><td>pur</td><td>0.017</td></tr><tr><td>_runtime</td><td>556</td></tr><tr><td>_step</td><td>33</td></tr><tr><td>epoch</td><td>9</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_step</td><td>▁</td></tr><tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">grateful-mountain-71</strong>: <a href=\"https://wandb.ai/murnanedaniel/FilteringStudy/runs/enm731r3\" target=\"_blank\">https://wandb.ai/murnanedaniel/FilteringStudy/runs/enm731r3</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.8<br/>\n",
       "                Resuming run <strong style=\"color:#cdcd00\">grateful-mountain-71</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/murnanedaniel/FilteringStudy\" target=\"_blank\">https://wandb.ai/murnanedaniel/FilteringStudy</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/murnanedaniel/FilteringStudy/runs/enm731r3\" target=\"_blank\">https://wandb.ai/murnanedaniel/FilteringStudy/runs/enm731r3</a><br/>\n",
       "                Run data is saved locally in <code>/global/cscratch1/sd/danieltm/ExaTrkX/wandb_data/wandb/run-20201027_123018-enm731r3</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "INFO:lightning:GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning:TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "INFO:lightning:Set SLURM handle signals.\n",
      "\n",
      "  | Name         | Type        | Params\n",
      "---------------------------------------------\n",
      "0 | input_layer  | Linear      | 5 K   \n",
      "1 | layers       | ModuleList  | 1 M   \n",
      "2 | output_layer | Linear      | 769   \n",
      "3 | layernorm    | LayerNorm   | 1 K   \n",
      "4 | batchnorm    | BatchNorm1d | 1 K   \n",
      "5 | act          | Tanh        | 0     \n",
      "INFO:lightning:\n",
      "  | Name         | Type        | Params\n",
      "---------------------------------------------\n",
      "0 | input_layer  | Linear      | 5 K   \n",
      "1 | layers       | ModuleList  | 1 M   \n",
      "2 | output_layer | Linear      | 769   \n",
      "3 | layernorm    | LayerNorm   | 1 K   \n",
      "4 | batchnorm    | BatchNorm1d | 1 K   \n",
      "5 | act          | Tanh        | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(30., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "WARNING:root:Truncating wandb.Table object to 10000 rows.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db3af6d87a74ee1b81b0392d5cc607f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n",
      "INFO:lightning:Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished, running inference to filter graphs...\n",
      "92.9% inference complete \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "INFO:lightning:Set SLURM handle signals.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1a9f0456534154a2b1c1c3c14ae04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch_geometric/data/dataloader.py\", line 34, in __call__\n    return self.collate(batch)\n  File \"/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch_geometric/data/dataloader.py\", line 15, in collate\n    return Batch.from_data_list(batch, self.follow_batch)\n  File \"/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch_geometric/data/batch.py\", line 48, in from_data_list\n    item = item + cumsum[key]\nRuntimeError: CUDA error: initialization error\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4083044b9eb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/states.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mentering\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# The INTERRUPTED state can be set inside the run function. To indicate that run was interrupted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, test_dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m   1355\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__test_given_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__test_using_best_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m__test_using_best_weights\u001b[0;34m(self, ckpt_path, test_dataloaders)\u001b[0m\n\u001b[1;32m   1395\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PL_TESTING_MODE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1398\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PL_TESTING_MODE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/states.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mentering\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# The INTERRUPTED state can be set inside the run function. To indicate that run was interrupted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPUBackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu_backend.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m   1207\u001b[0m             \u001b[0;31m# only load test dataloader for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0;31m# self.reset_test_dataloader(ref_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m             \u001b[0meval_loop_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_loop_results\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, test_mode)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# run evaluation (val_step + val_step_end + val_epoch_end)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;31m# log the final eval loop metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, model, dataloaders, max_batches, test_mode)\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mdl_max_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataloader_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch_geometric/data/dataloader.py\", line 34, in __call__\n    return self.collate(batch)\n  File \"/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch_geometric/data/dataloader.py\", line 15, in collate\n    return Batch.from_data_list(batch, self.follow_batch)\n  File \"/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch_geometric/data/batch.py\", line 48, in from_data_list\n    item = item + cumsum[key]\nRuntimeError: CUDA error: initialization error\n"
     ]
    }
   ],
   "source": [
    "for stage in pipeline_config[\"model_list\"]:\n",
    "    \n",
    "    # Set resume_id if it is given, else it is None and new model is built\n",
    "    resume_id = get_resume_id(stage)\n",
    "    \n",
    "    # Get config file, from given location OR from ckpnt\n",
    "    model_config = load_config(stage, resume_id)\n",
    "    \n",
    "    # Define a logger (default: Weights & Biases)\n",
    "    logger = get_logger(model_config, resume_id)\n",
    "    \n",
    "#     # Load the model and configuration file for this stage\n",
    "    model_class = build_model(stage)\n",
    "    model = model_class(model_config)\n",
    "    \n",
    "#     # Load the trainer, handling any resume conditions\n",
    "    trainer = build_trainer(model_config, logger, resume_id)\n",
    "        \n",
    "    trainer.fit(model)\n",
    "    trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model Load and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class FilterBase(LightningModule):\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        '''\n",
    "        Initialise the Lightning Module that can scan over different filter training regimes\n",
    "        '''\n",
    "        # Assign hyperparameters\n",
    "        self.hparams = hparams\n",
    "        datatypes = [\"train\", \"val\", \"test\"]\n",
    "        input_dirs = [os.path.join(self.hparams[\"input_dir\"], datatype) for datatype in datatypes]\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = [torch.optim.AdamW(self.parameters(), lr=(self.hparams[\"lr\"]), betas=(0.9, 0.999), eps=1e-08, amsgrad=True)]\n",
    "        scheduler = [\n",
    "            {\n",
    "                'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer[0], factor=self.hparams[\"factor\"], patience=self.hparams[\"patience\"]),\n",
    "                'monitor': 'checkpoint_on',\n",
    "                'interval': 'epoch',\n",
    "                'frequency': 1\n",
    "            }\n",
    "        ]\n",
    "#         scheduler = [torch.optim.lr_scheduler.StepLR(optimizer[0], step_size=1, gamma=0.3)]\n",
    "        return optimizer, scheduler\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        emb = (None if (self.hparams[\"emb_channels\"] == 0)\n",
    "               else batch.embedding)  # Does this work??\n",
    "\n",
    "        if self.hparams['ratio'] != 0:\n",
    "            num_true, num_false = batch.y.bool().sum(), (~batch.y.bool()).sum()\n",
    "            fake_indices = torch.where(~batch.y.bool())[0][torch.randint(num_false, (num_true.item()*self.hparams['ratio'],))]\n",
    "            true_indices = torch.where(batch.y.bool())[0]\n",
    "            combined_indices = torch.cat([true_indices, fake_indices])\n",
    "            # Shuffle indices:\n",
    "            combined_indices[torch.randperm(len(combined_indices))]\n",
    "            weight = (torch.tensor(self.hparams[\"weight\"]) if (\"weight\" in self.hparams) \n",
    "                      else torch.tensor(self.hparams['ratio'])) \n",
    "\n",
    "        else:\n",
    "            combined_indices = torch.range(batch.e_radius.shape[1])\n",
    "            weight = (torch.tensor(self.hparams[\"weight\"]) if (\"weight\" in self.hparams) \n",
    "                      else torch.tensor((~batch.y.bool()).sum() / batch.y.sum())) \n",
    "\n",
    "        output = (self(torch.cat([batch.cell_data, batch.x], axis=-1), batch.e_radius[:,combined_indices], emb).squeeze()\n",
    "                  if ('ci' in self.hparams[\"regime\"])\n",
    "                  else self(batch.x, batch.e_radius[:,combined_indices], emb).squeeze())\n",
    "\n",
    "        if ('pid' in self.hparams[\"regime\"]):\n",
    "            y_pid = batch.pid[batch.e_radius[0,combined_indices]] == batch.pid[batch.e_radius[1,combined_indices]]\n",
    "            loss = F.binary_cross_entropy_with_logits(output, y_pid.float(), pos_weight = weight)\n",
    "        else:\n",
    "            loss = F.binary_cross_entropy_with_logits(output, batch.y[combined_indices], pos_weight = weight)\n",
    "\n",
    "        result = pl.TrainResult(minimize=loss)\n",
    "        result.log('train_loss', loss, prog_bar=True)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        emb = (None if (self.hparams[\"emb_channels\"] == 0)\n",
    "               else batch.embedding)  # Does this work??\n",
    "\n",
    "        subset_ind = torch.randint(batch.e_radius.shape[1], (int(batch.e_radius.shape[1]*self.hparams['val_subset']),))\n",
    "\n",
    "        output = self(torch.cat([batch.cell_data, batch.x], axis=-1), batch.e_radius[:, subset_ind], emb).squeeze() if ('ci' in self.hparams[\"regime\"]) else self(batch.x, batch.e_radius[:, subset_ind], emb).squeeze()\n",
    "\n",
    "        val_loss = F.binary_cross_entropy_with_logits(output, batch.y[subset_ind])\n",
    "\n",
    "        result = pl.EvalResult(checkpoint_on=val_loss)\n",
    "        result.log('val_loss', val_loss)\n",
    "\n",
    "        #Edge filter performance\n",
    "        preds = F.sigmoid(output) > 0.5 #Maybe send to CPU??\n",
    "        edge_positive = preds.sum().float()\n",
    "        if ('pid' in self.hparams[\"regime\"]):\n",
    "            y_pid = batch.pid[batch.e_radius[0,subset_ind]] == batch.pid[batch.e_radius[1,subset_ind]]\n",
    "            edge_true = y_pid.sum()\n",
    "            edge_true_positive = (y_pid & preds).sum().float()\n",
    "        else:\n",
    "            edge_true = batch.y[subset_ind].sum()\n",
    "            edge_true_positive = (batch.y[subset_ind].bool() & preds).sum().float()\n",
    "\n",
    "\n",
    "        result.log_dict({'eff': torch.tensor(edge_true_positive/edge_true), 'pur': torch.tensor(edge_true_positive/edge_positive)})\n",
    "        return result\n",
    "\n",
    "    def optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_idx, second_order_closure=None, on_tpu=False, using_native_amp=False, using_lbfgs=False):\n",
    "        # warm up lr\n",
    "        if (self.hparams[\"warmup\"] is not None) and (self.trainer.global_step < self.hparams[\"warmup\"]):\n",
    "            lr_scale = min(1., float(self.trainer.global_step + 1) / self.hparams[\"warmup\"])\n",
    "            for pg in optimizer.param_groups:\n",
    "                pg['lr'] = lr_scale * self.hparams[\"lr\"]\n",
    "\n",
    "        # update params\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "class VanillaFilter(FilterBase):\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__(hparams)\n",
    "        '''\n",
    "        Initialise the Lightning Module that can scan over different filter training regimes\n",
    "        '''\n",
    "\n",
    "        # Construct the MLP architecture\n",
    "        self.input_layer = Linear(hparams[\"in_channels\"]*2 + hparams[\"emb_channels\"]*2, hparams[\"hidden\"])\n",
    "        layers = [Linear(hparams[\"hidden\"], hparams[\"hidden\"]) for _ in range(hparams[\"nb_layer\"]-1)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.output_layer = nn.Linear(hparams[\"hidden\"], 1)\n",
    "        self.layernorm = nn.LayerNorm(hparams[\"hidden\"])\n",
    "        self.batchnorm = nn.BatchNorm1d(num_features=hparams[\"hidden\"], track_running_stats=False)\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, e, emb=None):\n",
    "        if emb is not None:\n",
    "            x = self.input_layer(torch.cat([x[e[0]], emb[e[0]], x[e[1]], emb[e[1]]], dim=-1))\n",
    "        else:\n",
    "            x = self.input_layer(torch.cat([x[e[0]], x[e[1]]], dim=-1))\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "            x = self.act(x)\n",
    "            if self.hparams[\"layernorm\"]: x = self.layernorm(x) #Option of LayerNorm\n",
    "            if self.hparams[\"batchnorm\"]: x = self.batchnorm(x) #Option of Batch\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run_label = \"o12x2se4\"\n",
    "# run_label = \"4uovj4x7\"\n",
    "run_label = \"z0fb086x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wandb_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/wandb_data\"\n",
    "best_run_path = get_best_run(run_label,wandb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chkpnt = torch.load(best_run_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = VanillaFilter(chkpnt[\"hyper_parameters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = model.load_from_checkpoint(best_run_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-bc8580e7faaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0medge_total_positive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_total_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_total_true_positive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    edge_total_positive, edge_total_true, edge_total_true_positive = 0, 0, 0\n",
    "    for i, batch in enumerate(model.val_dataloader()):\n",
    "            data = batch.to(device)\n",
    "                \n",
    "            emb = (None if (model.hparams[\"emb_channels\"] == 0) \n",
    "                   else data.embedding) \n",
    "        \n",
    "            subset_ind = torch.randint(data.e_radius.shape[1], (int(data.e_radius.shape[1]*0.1),))\n",
    "\n",
    "            output = model(torch.cat([data.cell_data, data.x], axis=-1), data.e_radius[:, subset_ind], emb).squeeze() if ('ci' in model.hparams[\"regime\"]) else model(data.x, data.e_radius[:, subset_ind], emb).squeeze()\n",
    "\n",
    "            val_loss = F.binary_cross_entropy_with_logits(output, data.y[subset_ind])\n",
    "\n",
    "            result = pl.EvalResult(checkpoint_on=val_loss)\n",
    "            result.log('val_loss', val_loss)\n",
    "\n",
    "            #Edge filter performance\n",
    "            preds = F.sigmoid(output) > 0.3 #Maybe send to CPU??\n",
    "            edge_positive = preds.sum().float()\n",
    "            if ('pid' in model.hparams[\"regime\"]):\n",
    "                y_pid = data.pid[data.e_radius[0,subset_ind]] == batch.pid[data.e_radius[1,subset_ind]]\n",
    "                edge_true = y_pid.sum()\n",
    "                edge_true_positive = (y_pid & preds).sum().float()\n",
    "            else:\n",
    "                edge_true = data.y[subset_ind].sum()\n",
    "                edge_true_positive = (data.y[subset_ind].bool() & preds).sum().float()\n",
    "            \n",
    "            edge_total_positive += edge_positive\n",
    "            edge_total_true += edge_true\n",
    "            edge_total_true_positive += edge_true_positive\n",
    "            \n",
    "            if i % 5 == 0:\n",
    "                print(i, \"validated\")\n",
    "\n",
    "    edge_eff = (edge_total_true_positive / max(edge_total_true, 1))\n",
    "    edge_pur = (edge_total_true_positive / max(edge_total_positive, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9926, device='cuda:0'), tensor(0.1092, device='cuda:0'))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_eff, edge_pur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.hparams[\"filter_cut\"] = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "## Debug Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_events = os.listdir(os.path.join(model.hparams[\"input_dir\"], \"train\"))\n",
    "all_events = sorted([os.path.join(os.path.join(model.hparams[\"input_dir\"], \"train\"), event) for event in all_events])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = torch.load(all_events[0], map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [2009721 x 24], m2: [6 x 768] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:283",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-3ff8019c75e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#     subset_ind = torch.randint(data.e_radius.shape[1], (int(data.e_radius.shape[1]*0.2),))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msubset_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me_radius\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me_radius\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me_radius\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-7b966dc02d0c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, e, emb)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1608\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [2009721 x 24], m2: [6 x 768] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:283"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "edge_total_positive, edge_total_true, edge_total_true_positive = 0, 0, 0\n",
    "with torch.no_grad():\n",
    "    data = sample.to(device)\n",
    "\n",
    "    emb = (None if (model.hparams[\"emb_channels\"] == 0) \n",
    "           else data.embedding) \n",
    "    val_loss = torch.tensor(0)\n",
    "    for i in np.arange(0, 1., 0.2):\n",
    "#     subset_ind = torch.randint(data.e_radius.shape[1], (int(data.e_radius.shape[1]*0.2),))\n",
    "        subset_ind = torch.arange(start=int(data.e_radius.shape[1]*i), end=int(data.e_radius.shape[1]*(i+0.2)))\n",
    "        output = model(torch.cat([data.cell_data, data.x], axis=-1), data.e_radius[:, subset_ind], emb).squeeze()\n",
    "        val_loss = val_loss + F.binary_cross_entropy_with_logits(output, data.y[subset_ind])\n",
    "\n",
    "        #Edge filter performance\n",
    "        preds = F.sigmoid(output) > 0.18 #Maybe send to CPU??\n",
    "        edge_positive = preds.sum().float()\n",
    "        edge_true = data.y[subset_ind].sum()\n",
    "        edge_true_positive = (data.y[subset_ind].bool() & preds).sum().float()\n",
    "\n",
    "        edge_total_positive += edge_positive\n",
    "        edge_total_true += edge_true\n",
    "        edge_total_true_positive += edge_true_positive\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8c7536b70a08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0medge_total_true_positive\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0medge_total_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_total_true_positive\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0medge_total_positive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "edge_total_true_positive / edge_total_true, edge_total_true_positive / edge_total_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "av_coords = (sample.x[sample.e_radius[0,subset_ind]] + sample.x[sample.e_radius[1,subset_ind]])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2aab7fa1b8d0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(av_coords[:,2].cpu(), hist_kws={'weights': data.y[subset_ind].cpu()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2aab7eeff490>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD6CAYAAACxrrxPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXic1Xn38e89o33fZa2WbMt4x9iyDYQdAoY0hmZhDYSkhCaBkJb2TUjTkpamSdM0TUhCKDQQaMO+JSY4mJ2wGFvyjrzKtqzV2vddM+f9YzSOMFpG0sw8s9yf6/J1WaOHmRtL+unMee5zjhhjUEopFfxsVheglFLKOzTQlVIqRGigK6VUiNBAV0qpEKGBrpRSIUIDXSmlQoRHgS4i60XkoIhUishdE1xztYjsE5EKEXncu2UqpZSaikzVhy4iduAQ8EmgFigDrjPG7BtzTQnwNHCRMaZdRLKMMU2TPW9GRoYpKiqaZflKKRVetm/f3mKMyRzvcxEe/PdrgUpjzFEAEXkSuBLYN+aarwD3GWPaAaYKc4CioiLKy8s9eHmllFJuInJ8os95MuWSB9SM+bh29LGxFgILReQ9EflARNZPv0yllFKz4ckI3dPnKQEuAPKBP4nIcmNMx9iLRORW4FaAwsJCL720Ukop8GyEXgcUjPk4f/SxsWqBjcaYYWPMMVxz7iWnPpEx5kFjTKkxpjQzc9wpIKWUUjPkSaCXASUiUiwiUcC1wMZTrvkdrtE5IpKBawrmqBfrVEopNYUpA90YMwLcDmwG9gNPG2MqROQeEdkwetlmoFVE9gFvAv/PGNPqq6KVUkp93JRti75SWlpqtMtFKaWmR0S2G2NKx/ucrhRVSqkQoYGulFIhQgNdKaVChLf60JVSQeTxrdUfe+z6dbo2JNjpCF0ppUKEBrpSSoUIDXSllAoRGuhKKRUiNNCVUipEaKArpVSI0EBXSqkQoX3oalLar6xU8NARulJKhQgNdKWUChEa6EopFSI00JVSKkRooCulVIjQQFdKqRChga6UUiFCA10ppUKEBrpSSoUIDXSllAoRGuhKKRUiNNCVUipEaKArpVSI0EBXSqkQoYGulFIhwqNAF5H1InJQRCpF5K5xPn+ziDSLyK7RP7d4v1SllFKTmfKACxGxA/cBnwRqgTIR2WiM2XfKpU8ZY273QY1KKaU84MkIfS1QaYw5aowZAp4ErvRtWUoppabLk0DPA2rGfFw7+tipPisie0TkWREp8Ep1SimlPOatm6IvAkXGmBXAq8Cj410kIreKSLmIlDc3N3vppZVSSoFngV4HjB1x548+dpIxptUYMzj64a+B1eM9kTHmQWNMqTGmNDMzcyb1KqWUmoAngV4GlIhIsYhEAdcCG8deICI5Yz7cAOz3XolKKaU8MWWXizFmRERuBzYDduBhY0yFiNwDlBtjNgJ3iMgGYARoA272Yc1KKaXGMWWgAxhjNgGbTnns7jF//w7wHe+WppRSajp0pahSSoUIDXSllAoRGuhKKRUiNNCVCjMNnf3sru3AGGN1KcrLPLopqpQKDe8faeH2x3fS1jtEUkwkxRnxVpekvEhH6EqFAWMMv37nKDc+tI20+Cii7DZ21bRbXZbyMg10pcLAY1ur+f5L+7l0STa/u+0TLM1NYm9dJ8MOp9WlKS/SQFcqDPx+Vx2Lc5L41Q2rSIiO4IzCVAaGnRw40W11acqLNNCVCnEtPYOUH29n/dI5iAgA8zLjSYqJYGe1TruEEg105bGu/mHue7OSx7dWW12KmobX9zdiDFy6NPvkYzYRVhakcKixm57BEQurU96kga489m5lC3Ud/fzDC3v5540VjOj8a1B4paKR/NRYFs1J/MjjKwtTcRrYU9thUWXK2zTQlUf6hxxsq2pjeV4yt5xTzCPvV/HlR8vpHhi2ujQ1id7BEd6pbOHSJX+ebnGbkxRDbnIMO6s10EOF9qErj3xwrJWhEScXnJbJ3116GiXZCXzn+b3c/9YRvrV+kdXlhb2JpsFS4yIZGnF+ZLplrJWFqWza20Brz+C4n1fBRQNdTWnY4eT9yhYWZieQkxwLwDVrCnl1XxNPl9fwN5csJCrCNmGoXL+u0J/lqjFe2ddIalwkpXNTx/38/EzXwqLajn5/lqV8RKdc1JS2H2+nd8jBeQs/esrUDWcW0tIzxKv7Gi2qTE3G4TS8caCJixdnE2Ef/0c9KzEGu02o10APCRroalIOp+Gdw80UpMZSnP7RZeLnlWSSnxrLY1uPW1SdmkxVay+d/cNcumT86RYAu02YkxRDQ8eAHytTvqKBriZ1rKWX9r5hzinJ/NhNNbtNuG5tIe8faeVoc49FFaqJHDrRTVSEjXNLJj+/Nyc5hvrOft2sKwRooKtJHWvpRYCSrIRxP//50nwibMIT27Q3PdA0dg+wIDOB2Cj7pNflpsTSN+SgvlNH6cFOA11Nqqq1l5zkGGIixw+FrMQYLls6h2e21+q+IAGmuXuQBRP8Ih4rNzkGgIq6Tl+XpHxMA11NaGjESW17H3On2GL1hnWFdPQNU1GvgRAohkacdPQNMz9z6kCfkxyLABX1Xb4vTPmUBrqa0If1nQw7DEXpkwf6WfPTSY+P4khTr58qU1Np6RnEgEcj9KgIGxmJ0foLOQRooKsJlR1rA6AoPW7S60SEFfnJ1Hb0+aMs5YHmbtdCoflZnh1gkZscoyP0EKCBriZUVtVOenwUiTGRU167Ij+Fpq5BhkZ0Hj0QNPcMIjDluyu33JRYGjoHdMVokNNAV+NyOg3lx9s8DoQV+ckYoE4XqASEpu5BUuOjJryZfarcFNcKYB2lBzcNdDWuyuYeOvqGKcqYfLrFbUV+CgB17TrtEghaugfJSoz2+Pocd6eLBnpQ00BX4yqrcs+fezZCz0yMJjk2UvcECQBOY2jpGSRzGoEeFxVBfmqs3hgNchroalxlx9rITIwmLT7K4/8mPzWWunYNdKu19w4x4jRkJnge6ABLc5PYpyP0oObRbosish64F7ADvzbG/PsE130WeBZYY4wp91qVyudO3SnxrYPN5KfGfmy5/2TyU2KpqO+if8gx5epE5TvuDpfpTLkALM1NZnNFIz2DIyRE60aswWjKEbqI2IH7gMuBJcB1IrJknOsSgW8CW71dpPKvjr4hOvqHKZpiQdGp8lJd8+3avmitptFAz0yMmdZ/tzQ3CYD9DTpKD1aeTLmsBSqNMUeNMUPAk8CV41z3r8CPAN0QIshVt7kCea6H8+dueaOdEjrtYq3mnkESoiOm/S7ptNEj6g41dvuiLOUHngR6HlAz5uPa0cdOEpFVQIEx5iUv1qYsUt8xgF2E7KTpvWWPjbKTHh9FrQa6pZq7p3dD1C0vJZb4KDuHG3XnzGA165uiImID/gv4Ow+uvVVEykWkvLm5ebYvrXykvrOf7ORoImzT//bIT42lVlsXLWOMmXGgiwgLshI43KQj9GDlyU9sHVAw5uP80cfcEoFlwFsiUgWcCWwUkdJTn8gY86AxptQYU5qZOfkezcoaxhjqO/rJHT1qbrryU+PoGhihSw+PtkTP4Aj9w45pd7iA68a43WZjT20nj2+tPvlHBQ9PAr0MKBGRYhGJAq4FNro/aYzpNMZkGGOKjDFFwAfABu1yCU6d/cP0DTlOrhycLp1Ht1Zzz8w6XNyyEqPpHhihf8jhzbKUn0zZm2SMGRGR24HNuNoWHzbGVIjIPUC5MWbj5M+ggkn96FFkMw303BTXVqy17f0szknyYmXKE80nO1xcgT7dEbb7vklT98C0b4or63nUbGqM2QRsOuWxuye49oLZl6WsUt/ZjwBzkqbX8uYWFWEjNT6K1l7d5MkKzd2DRNltJMdOvaHaeLJGWx0buwY10IOQrhRVH1Hf0U9mYjRRETP/1kiNi6S9d8iLVSlPtfcNkxofOa0FYWMlx0USZbfR1K3dx8FIA119RH1H/4ynW9xS46Lo6NObolboHhgmyYPtjidiEyErKZqmLn2HFYw00NVJ3QPDdA2MzDrQU+Ki6B4c0TNGLdDVP7tAB9eN0UYdoQclDXR1UkOn+4bozObP3VLjXIGio3T/chpD98AISbGz24clKzFGO12ClO7Ao06qH936dqoe9Kk6J1LjXDs0tvcNzWiBi5qZnoERDHh0wtRksrTTJWjpCF2dVN/RT9o0TrmZSGr8nwNd+Y97Mddsp1yyRztddB49+Gigq5PqOwdmPX8OkBgTgV1Ep1z8rHtgBGDWUy7JcZFE2kXn0YOQBroCoH/IQVvvELnJs5s/B1enRHJcpI7Q/ayz3zsjdJsIWYkxJ7fhVcFDA10B0NA5On/uhRE6aC+6FboHhhEgIWb2t8ayEqNp6tIRerDRQFeAa7oFvBno2ovub139IyTGRGCb4aKisbKTYujSTpego4GuAGjo6CcxJsJrR49pL7r/dQ0MkzTDJf+nGtvpooKHBroCXD3oOV6YP3fTXnT/6xoYnnXLolv2mD1dVPDQQFcMjThp7h4kZ4Z7oI9nbC+68o+u/hGSvDB/DqN7ukTYtNMlyGigKw43deMwxrsjdO1F96thh5P+YYfXplxsImQnRtOoN0aDiga6Yl+965R3b47QtRfdv072oHtphA6uG6ONnRrowUQDXbGvoYtIu5CeEOW159RedP/q8lIP+ljZSTH0Djlo6dF59GChga7Y39DFnKQYr7S7jZUaF6kjdD9xL/tP9NKUC7gCHeDQCT00OlhooIc5Ywz76ru8Ot3ilhoXpSN0P+kanXJJ9uoI3dW6eLBRAz1YaKCHubqOfroGRsiZ5Za540mJi6J7YISBYV2c4mtd/cNE2ISYSO/9SCdERxAXZeeQBnrQ0EAPc764Ierm7kV3b8urfMe9qGimR8+NR0TITorhgE65BA0N9DC3r6ELkZkfCj2ZlNFe9Np2DXRf6x7wXg/6WNlJMRw60Y0xxuvPrbxPAz3M7W/oojgjflaHQk/EPULXQPe9rn7vrRIdKzspmt4hB3X6LisoaKCHuX0NXSzOSfLJcyfFRmITqG3v88nzKxdjDF0DwyR7scPFzf3OTefRg4MGehjr7B+mpq2fJT4KdJsIKXFR1OgI3ae6BkYYdhgSfTTlAnDwRI/Xn1t5nwZ6GDvQ4LohuiTXN4EOkBwbSYO+Xfcp977l3lr2P1ZMpJ3c5BgOnujy+nMr79NAD2P73IHuoxE6QEpsJA26fNynTrgD3Qdz6AAL5yRysFFH6MFAAz2M7a3rJDMxmqzEaJ+9RnJcJCe6BnA4tUvCV9xb3PqiywXgtOxEjjT1MKJ72wc8jwJdRNaLyEERqRSRu8b5/FdFZK+I7BKRd0VkifdLVd72YV0ny/OSvdq7fKrk2EgcTqMHJfiQe0dEX3S5ACzMTmTI4aSqVW9uB7opA11E7MB9wOXAEuC6cQL7cWPMcmPMSuA/gP/yeqXKax7fWs0j71VxePRt9ONbq332Wimxrl50XVzkO41dA8RE2nzSegpw2pxEAA7qAqOA58l3wFqg0hhz1BgzBDwJXDn2AmPM2Dsm8YC+vw5wDZ39GCDPS2eITiT55GpRHaH7SmPXgM/mzwEWZCVgtwn7G/TGaKDzZNItD6gZ83EtsO7Ui0TkNuBOIAq4aLwnEpFbgVsBCgsLp1ur8iL3Yh9fB3rKaOdFQ6eO0H2lsWvQJx0ubjGRdhZkJlBR3+mz11De4bX3aMaY+4wx84FvA/84wTUPGmNKjTGlmZmZ3nppNQP1o4dC+zIIwBUGidEROkL3oaauAZ/dEHVbmpvEh/U6Qg90ngR6HVAw5uP80ccm8iRw1WyKUr5X29Hv89G5W05KjM6h+4jTaWjqHvTZDVFw3WMZHD139oG3j/j0nouaHU8CvQwoEZFiEYkCrgU2jr1ARErGfPgp4LD3SlTeNjjsoKV70G+BnpsSS71OufhEW98QI07j8xG6e3tlfacV2KYMdGPMCHA7sBnYDzxtjKkQkXtEZMPoZbeLSIWI7MI1j/5Fn1WsZq2+c8B1QzTVTyP05FgaNAh8wtcti265o9sr672QwObRr3VjzCZg0ymP3T3m79/0cl3Kh9w75/lrhJ6XEkNr7xADww5iIu1+ec1w0eReVOSHeyFp8VE6dRbgdKVoGKrv6CcpJsLnozq3nJOjOx2le1vjyWX/vp1yAchJjqFev4YBTQM9DNW2+++GKLjm0EEXF/mCe9l/gh8CPTcllrbRd1oqMGmgh5nugWFaewbJ9dP8OUDuyRtqGuje1tg9QHp8FBE23/8o5ya7vo76TitwaaCHmYr6LgyQ78cR+pxk7ZDwlaauQTJ9uLnaWDn6TivgaaCHmQ/rXKv9cv0Y6NERdjISorVDwgeaugdOHkLha0kxkSRER+jXMYBpoIeZHdXtpMRG+u2GqFtuSoyeS+kDjV0DZCf5Z4QOrq+jvtMKXBroYcQYQ1lVO0UZ8X5/7dzkWJ179TKH09DcPei3ETq4vo5N3QN6YzRAaaCHkeq2Ppq7B5mbHuf313Yv/zdGN+L0ltaeQZwGsvwY6DkpsTiNHhodqDTQw0h5VTsAc9P8P0LPS4mlb8hBV/+I3187VLlbFrP9dFMU/tzpUqEbdQUkDfQwUn68jcSYCLL8OOfq5l5cpHu6eI97UZE/p1zS4qOIjbSzu6bDb6+pPKeBHkbKqtopnZuKzYdHzk1Ee9G9r7Hb/4EuIhSmxbH9eLvfXlN5TgM9TLT3DlHZ1ENpUZolr39ytajeGPWaxq5BRCAjIcqvr1uYHsfhph46+4b9+rpqahroYcI9oiqdm2rJ62cmRBNpFx2he1FT1wAZCdFE2P37Y1yY5rqpvqNGR+mBRgM9TJQdbyPSLpxekGLJ69tsQnZSDA0a6F7j7x50t/zUWOw2YYdOuwQcDfQwUV7VzvK8ZEu3r81LiaW6rc+y1w81jV2DZCf6b/7cLTrCzuKcRJ1HD0Aa6GFgYNjB3tpO1lg0f+42LzOeqlYNdG9p6h7waw/6WKsLU9lV08GIw2nJ66vxaaCHgb11nQw5nJbdEHWbl5FAW+8QHX1DltYRCoYdTlp7hyyZcgFYNTeVviEHB07oAqNA4vtNlJVXjXdA7/XrCif9b8qq2gBYbdENUbfi0S0Hjrb0sqrQv50ZoaalZxBj/NuyOJb7e2lndTvL8pItqUF9nI7Qw8DmikaW5CSRFm9tiBZnugL9WHOvpXWEAvcq0Sw/rhIdKy8lluykaJ1HDzAa6CHu4Iludtd08NnV+VaXQmFaHHabcKxFA322rFglOpaIsKowle3VGuiBRAM9xD1TXkOkXbhqZa7VpRBpt1GYFqeB7gVNo4FuxTYObqvnplLT1n+yFmU9nUMPYf+35ThPbKtmYXYimysarS4HcM2jH2nusbqMoNfYNYjdJqTHWxfoq0bn0XdUt7N+WY5ldag/00APYQdPdNE75LBsdajb2Bu5g8MOjjT34HQabDb/7ykTKhq7BshMiMZu4b/h0twkoiNsvFfZqoEeIDTQQ1j58XYSYyJYkJVodSknZSRGM+wwnOga8OsxeKGmsXvQspZFt+gIO5cuncPvd9Xx3U8tnnTR2ky6s9T06Rx6iGrqHuBQYzerClMtHcWdKiPBFUI6jz47de19J7ckttK1awroGhhhc8UJq0tRaKCHrOd31OE0rhV9gcQd6Ed1Hn3GHE5DTVu/JUcJnuqseekUpMXy5LYaq0tReBjoIrJeRA6KSKWI3DXO5+8UkX0iskdEXheRud4vVXmqZ3CEX79zjOKMeDIs6lOeSFJMBFF2G0d1hD5j9R39DDmcFFlwlOCpbDbhmtICthxtpUq/ppabMtBFxA7cB1wOLAGuE5Elp1y2Eyg1xqwAngX+w9uFhoLHt1Z/7I8v3P9WJS09g6xfOscnzz8bIkJGQpROuczC8dH9cOamWz9CB/jc6gJsAk+X6yjdap6M0NcClcaYo8aYIeBJ4MqxFxhj3jTGuHdd+gCwfhVLmKpt7+N/3jnGVStzKUizfgQ3nvSEaA30Wahqdf3bFWUExtd3TnIMF56WxTPba3WzLot5Euh5wNhfvbWjj03kr4A/zqYoNXP/8fJBBPjW+kVWlzKhjIRoatr6GBrRH/6ZON7aS3SEzZKtcydyzZoCmrsHefNgs9WlhDWvti2KyBeAUuD8CT5/K3ArQGGhtix5247qdjburucbFy0I6JbAzMQonAaq23oDqqUyWFS19jE3Pc7SPv5TpwsdTkNSTAT3vVnJxYuydI2BRTwZodcBBWM+zh997CNE5BLgu8AGY8zgeE9kjHnQGFNqjCnNzMycSb1qAsdaernzqV1kJkbz1fPnW13OpP7c6aLTLjNxvLU3YObP3ew24dKlc9hV08GTZTqXbhVPAr0MKBGRYhGJAq4FNo69QETOAB7AFeZN3i9TTWbLkVauuu89OvuHuf+GVcRHB/Z6MfdydZ1Hnz6n03C8te/kVsSB5IyCFNYVp/Gjlw/Q2jPumE752JSBbowZAW4HNgP7gaeNMRUico+IbBi97MdAAvCMiOwSkY0TPJ3ysu3H27nxoa1kJkbzu9s+YfkhFp6IjbJrp8sMnegaYHDEydwAaFk8lYjw/auW0Ts4wg//eMDqcsKSR0M5Y8wmYNMpj9095u+XeLku5YEtR1p4cU8D5yzI4L4bVpEcG2l1SR6bl5Ggm3TNwMkOlwCbcnEryU7k1vPm8au3jvD51fmsm5dudUlhJbDfm6sJvXO4mT9+eILFOUk8dHMp0RHWHf48E0tyk3iqrIZhh5NIuy5Y9pS7B31XTcfJvweab1xUwot76vnr327nl9et4pySDKtLChv6kxSE3jrYxB8/PMGyvGSuX1sYdGEOUFqUSv+wgwMNeibldFS19mK3SUC/G4uNsvPYX51JdmIMNz28lQf/dARjjNVlhQUN9CDzXmULr+xrZGVBCteUFgTUxlvT4T6Tsvx4m8WVBJfjLX2kxUVhk8D+uhemx/H818/msqVz+MGmAzxRVkPf0IjVZYU8DfQg8nR5DS/tbWBpbhKfXZUftGEOkJMcS25yjJ5JOU1Vrb2kJwTHAdvx0RH86oZVfHv9IvbVd/Lz1w9zqFHfkfmSBnoQ6Bkc4dnttdz13B4WZCUE9ch8rNVFaRro02CMcQW6xYd9T4eI8LUL5vO1CxYQE2nnkfer2Li7nhGnrhL2Bb0pGqDae4f4p99/yI7j7dR3us5sXD03lU+vyCUiRG4iri5M4cXd9dR39Af0ytZA0dQ9yMCwk/SEwNpB0xN5KbHcduECXqk4wXtHWmno6Gf9sjlkTWP7Aj0kY2oa6AGoobOfGx/aRnVbH1csm0NJdiILshI4f2Emz+/42CLdoLV6rqtnfvvxdg10D7i3pw2mEfpYkXYbn1qRS35aHM/vqGXDL97j59edwZqiVCTA7wkECw30AHOkuYebHtpGV/8w//vltZwZwn28i3MSiY20s/14O58+PdfqcgKeu00xGEfoY52en0JWYjQv7Kzj6ge2kJcSy0WLsvj06bmsLQ78hXGBLDTeu4eI7cfb+Px/b2FwxMETt54Z0mEOEGG3sbIgRefRPVTV2ktEgLcseionOZaX7jiXH/zlcpbkJvHcjlqueXALL3+oR9nNho7QA8TG3fX8/TO7yU2O4ZEvreX9I63sqe20uiyfWz03lfvfPkLv4EjA70FjteOtfRSkxYXEDXGA5NhIrl9XyPXrCukbGuGGX2/lb57ayRNJZ3JGgB2dGCx0hG4xp9Pwi9cPc8cTOzk9P5kXvv6JgDgr0l9WF6XicBp213ZYXUrAO9rSG5B7uHhDXFQE/3NTKVmJMdzyaDnVAboKNtBpoFuorXeILzy0lZ+8eoirVuby21vWkRqkN7xmalWBayS2vUqnXSbTOzjCocZuluUmW12Kz2QkRPObL61hxGn40iPb6BnUhUjTpYFuAWMMHxxt5eevH2Z3TQf/9pfL+Ok1K4NyCf9sJcdFUpKVwPZqDfTJ7KrpwOE0rAnxm4bzMxP47y+s5lhLL/+yscLqcoKOTlpaYE9tJxt317MgK4FHvrSG/NTQfBs9mbE9xanxUbxf2cqj71fxxbOLrCsqgJVVtWETWFWYQl17v9Xl+NRZ89O57cIF/OKNSi5clMUVy3OsLilo6Ajdz5zG8MaBJrKTorn57KKwDPNTLc1JYsjh5HCjbqc7kbKqNhbnJJEYE/wdLp644+ISTi9I4TvP76WhM7R/gXmTBrqf7a3rpLlnkIsWZQf8Bkv+Mi8zgdhIOx/Wh35Xz0wMO5zsrO5gTRAcXuItkXYb916zkmGHkzuf2o3Dqbs1ekKnXDw03rJjmN7SY6cxvHmgiazEaJbmJnmrtKBntwlLcpKoaOhkcMQRlvcSJrOvvou+IQelRaHVyjfVz1RRRjz/vGEp33p2Dz/ctJ95mQn+LC8o6Qjdjyrqu2jqHuTCRVk6Oj/FsrwkBoadvF/ZanUpAaesyrXFcLiM0B/fWn3yz4jDcNb8dH797jG2HtPvjalooPuJ02l440AjmQnRLM8L3dazmZqfmUB0hI1NexusLiXglFe1U5gWR3aS5xtZhZJPLc/htOxEXtxdz2HdfndSGuh+8sz2Ghq7BrlwUaaOzscRYbexOCeJV/Y1MuzQrVXdjDGUVbWFzeh8PDYRrl1TQFZiDI9vq6ajb8jqkgKWBrof7G/o4nsbK5iXEc+K/BSrywlYy3KT6ewfZssRfWvtdqyll9beIdaE2Pz5dEVH2vnCmXMZdjh5r7LF6nIClga6j3UPDPP1x3aQFBPJNWsKdHQ+iZLsBOKj7PxRN2g66eT8eYgvKPJEWnwUK/JTKDveTv+Qw+pyApIGug8ZY/jWs3uobuvjl9evCpse4pmKtNu4cFEWmytOMDSi0y4AZVXtpMVHMS+M9veZzDkLMhgacZ78Rac+StsWfWTE4eT7L+3njx+e4B+uWMTa4jQqmz6+cGai1q1w9bnV+fxhTwMvV5xgQ5jvkf7YB8d5fX8jOcmxPLGtxupyAkJuSizzMuJ5/0gLZy8I7e2lZ0JH6D7Q3jvETQ9v45H3q/jyJ4r5yrnzrC4paJxXkklhWhy/3XLc6lIsV9veT3vfMKfNSbS6lIBybkkGXQMj7CnSIAMAABF6SURBVA2D7aWnSwPdy4619LLhvncpr2rnx59bwd2fXqLHa02DzSZcv66QbVVtHDwR3i1q26vbibSLtrmeoiQ7kczEaN6tbMEYXUE6lga6l/3zxgpauof4q3OKGXaYjyySUJ65urSAqAgbj20N31H6wLCDPbUdLM1NJiZSV86OZRPhnAUZNHQO8M5h7XgZy6NAF5H1InJQRCpF5K5xPn+eiOwQkRER+Zz3ywwOO6vbeftQM+cvzKQgTTfdmonHt1bz8ocnWJKTxFNlNfzmvWNWl2SJV/c1MjDsZJWe3DOuMwpSSI6N5KevHdJR+hhTBrqI2IH7gMuBJcB1IrLklMuqgZuBx71dYDC59/XDpMVHsW6etpjN1rriNAZHnOyuCc950me215ISG8m8TO1uGU+E3cYFp2Wys7qDtw41W11OwPBkhL4WqDTGHDXGDAFPAleOvcAYU2WM2QOEba/ZrpoO3jrYzFfOnaebS3lBYVocc5Ji2HqsNexGYCc6B3j3cDNnFKbquoVJrJ6bSn5qLD99VUfpbp4Eeh4wtmeqdvQxNca9rx0iNS6Sm86aa3UpIUFEOGt+Og2dA7x1MLxGYM/vrMVpXIdZqIlF2GzccXEJe2o7eXVfo9XlBAS/3hQVkVtFpFxEypubQ+eHdGd1O28ebOYr583Tk+u96IzCFFLjIvnPVw7iDJP9sJ1Ow7PltawtSiM9IdrqcgLeZ87Ioyg9jv969VDYfI9MxpP0qQMKxnycP/rYtBljHgQeBCgtLbX8X3+8zpPp7G9ujOGpsmq+/4f9ZCREcdNZRV6sTkXYbFy8OJtnt9eyueIEl4fBUWS/313H0ZZevnlJCb2Dwbe83d/dXBF2G9+8pIS/fWo3z26v5eo1BRNe640zDQKdJyP0MqBERIpFJAq4Ftjo27IC1+Cwg6buAQ43dfOb96v49nN7WZqXxHNfO5sEHZ173cqCFBZkJfCTVw+F/Kk1A8MOfvzyQZbnJfPpFeG9SnY6Npyex7riNL63sSLst9edMtCNMSPA7cBmYD/wtDGmQkTuEZENACKyRkRqgc8DD4hISB7X/buddfzLH/bxs9cO85v3qqhu6+Nfr1rG47ecydx07UbwBZsId35yIZVNPfx+14zeGAaNh987Rn3nAP9wxWJsNr0Z6im7Tfj5dWcQF2Xn64/toG9oxOqSLOPRkNIYswnYdMpjd4/5exmuqZiQVd/Rz7aqNpbnJbM4J5GkmEiyk2K48Uy9Cepr65fOYUlOEj977TBXLM8JyYU2rT2D/OrNI1yyOJuz5useJdOVnRTDvdeewY0Pb+WfflfBT64+3eqSLKFzBB56fX8jMZE2rlqZR2xUYAVKqK9CtdmE71yxiBsf2saPNx/kn/7i1GUQwe/e1w/TP+zgrssXWV1K0DqnJINvXFTCz18/zHkLM7hyZfg14+nSfw/sre1k/4luzlmQEXBhHi7OLcnkprPm8tC7x/hTiC0kea+yhd9+cJzSualsO9amW0XMwjcvLmFFfjI/3HQgLKdeNNA98NPXDhEbaefs+RlWlxKW3AE3PzOBrMRobntsBw/+6ajVZXnFocZuvvp/28lMjOaypXOsLifo2W3C3X+xhBNdAzzwdmh8j0yHBvoUdtV08MaBJs4tyQjJudtgEmm3cc2aAvqGHbywozboVwc2dQ/wpd+UERNl54tnFen3l5eUFqXxqRU5PPCnIzR09ltdjl/pHPokRhxOfrBpP6lxkZw1T29UBYKc5FjWL53DS3sb+Kfff8g9G5YFZUdIa88gtzxaTlvvEE//9VnsrQvPPWtma6KpqbvWL+LVfY38x8sH+ek1K/1clXV0hD6J77+0n23H2vjup5YQraOngHH2/HTOK8nktx9U853n9wbdCsE/HWpm/b3vcOBEN7+47gyW5+t+595WkBbHLecU88LOOj44Gj6HjmugT+Cxrcd55P0qbjmnmM+tDumOzKAjIly2NJs7LlrAU+U1/P2zuxl2BP6+cM3dg3zh11u56eFtAPz1efNo6h7UG6A+8vULF5CXEsuND23ll28cDvmFaaBTLh/jcBrePtTE935fwQWnZfKdKxZbXZIah4hw56WnEWm38ZNXD3GspZefX3uGJfvQP/bBceo7B6hp68Mmgt3m6sqx2YQIm9DZP8ymvQ28V9mC08Da4jSuWJZDVISOp3wpITqCP3zjHP7x9x/yn68coiA1lgsXZZGXEuvRge2z3RrEChrouPZk+dPhFvbVd/Kvf9hH/7CDBVkJ/Py6M7AH4fxsuHh8azXpCdFcu6aAF3bW8cmfvs1fnpHPDz+z3C+vX9fRz2MfHOfJshraeoc+8rnndnx0VWtBWixfv2ABdpuQnRTjl/oUpMZHcd/1q7hsaT3ffnYP/zt6Vm1iTATnL8wMuc41DXRgT10nmytOkJ8ay3VrC1mSm8Qli7NI8uC3uLLeivwU8lPjeKqsmie2VeN0Gr63YQlxUb759h4YdvDA20e5/+1Khh2G4ox4LliYyYKsBGwiOJyGy5fPwWkMDidE2IV5GfGIiE6vWGTD6bm09gxS3zFAfUc/+xq6eGlPQ8j9cg37QO8eGObF3fUUpMby1+fP5wu6lD8opcVHcet583ltfyNPb6+hrKqNe6/17g3H/9tynL11nby67wTtfcMsy03i8uU5pMZFfezaD462feTjrad8rPwvOsJOcUY8xRnxrClK4743K3m6rIavXTCfjBDZqjisA90Yw8bd9QyNOPnsqvwZnQ6jI67AYbcJly2dw1fPn8/fPrWLz9z/Hv/vstO45Zx5s2ptbOsd4vkdtfzyjUo6+ofJSozmy58oZkFWgherV/4UFWHj2rUF3P/WEe58ejeP3LwmKNtfTxXWgb6nrpOK+i7WL51DVoi99Qpnx1p6ueVcV8vaDzYd4JnyWh77yjqyEj37Gjd1D/Dyhyf44Ggre2o7qW13LU4pzohnw+m5LJyTqEfDhYCc5FiuWJ7Dxt31/Oz1w/ztJSVIkH9dwyLQxxtFd41OteSnxvKJBaF1Y0RBXFQE168tZFtVGy/taeCKe9/hO5cv5sqVuUTYP95dMjDs4MXd9byws44tR1oxQGpcJPmpcSzPS2ZeZgJ5KbH+/x9RPrWuOM21/e7rhzne2ssPP7PcZ/de/CF4K58FpzE8t72WYYeTz63O106WECUirCtOpyg9ntcPNPJ3z+zml29W8o2LFrB6birGwJDDyUt7Gnhs63FaeoYoSo/jgtOyWJGfHHI3zNTHiQg/+fzprkNUXjnIgYZufvCZZRSlx+M0JujeiYVloG850srhph6uXJnr8dtwFbyyk2LYeNs5vLKvkZ+9dog7n979sWsuXpTFl88p5uz56TyxrWacZ1HBZDr3tmw24bYLF7AiP5k7ntjJZ+/fAoBdhOKMeK5fVxg0++yEXaCf6Bxgc8UJFs1JZG1RmtXlKD95sswV0l84cy5HmnroGRxBBD6xIIMV+SkUZ+iJU+Hu3JJMXr3zfMqr2jjROcBr+5vYcqSV37x3jC9/ojgotv8Iq0Bv6OznqbIaoiPtfGZVftDfAFHTZxOhJDvx5Me9gw62HGlly5Hw2e9DTSwjIZr1y1yHkUdF2JmbHscT26p5ZEsVXzq72NriPBAWa48buwZ4fOtxfvFGJV0Dw1xTWqAHOiulprQ0N5mrSwuobu3j0S1VAX9oRsin2qv7GvnFG4eJsNu48LRMzlmQqacOKaU8tiI/BaeBZ8pruPxn7/DFsz++d32g7PES0oG+o7qdbzyxg5zkWG4+u4h4HZUrpWZgZUEKdpvwVFk1D793jJvPLgrI9saQnXI51tLLLY+Wk5UYw01nzdUwV0rNyvK8ZG5YN5eGzgH+++2jbDnaSs9gYE3BhGSgt/cOcfNvtmGM4ZEvrfFoq0yllJrK4pwkvnhWETaBF3fX8+9/3M+j71dR1xEYR92FZKDfvbGCuvZ+fv3FNczL1P02lFLesyArgb+5ZCF3XFzCeSWZVLX28ulfvMt7lS1WlxZ6gb5pbwMv7q7njotLWD031epylFIhak5SDJcuncNtFywgPT6KGx/ayv1vHbH08PKQCvSWnkH+8Xcfsjwvma9dMN/qcpRSYSAjMZrf3fYJLl+ew49ePsC/v3zAslAPmTuFxhj+8YUP6RkY4SdXn07kOBswKaWUL8RHR/DL684gNS6SB94+SkyEnb/95EK/1+FR6onIehE5KCKVInLXOJ+PFpGnRj+/VUSKvF3oZEYcTn6waT8vV5zgzksXsnDMSkCllPIHEeGeDcu4ujSfe18/zH1vVvq9hilH6CJiB+4DPgnUAmUistEYs2/MZX8FtBtjFojItcCPgGt8UfCpWnoG+cbjO9lytJUbz5zLV86d54+XVUqpj7HZhB9+ZgWDI05+vPkgO6vbuevyRSzI8s8g05Mpl7VApTHmKICIPAlcCYwN9CuBfx79+7PAL0VEjI8mkpq6Bthb18me2k6eLncd0Pufnz+dz63O98XLKaWUx+w215a8i+Yk8as3K7nsZ+9wdWk+5y/MZG56PHPT43y2KMmTZ80Dxu4nWgusm+gaY8yIiHQC6YDX+3jue7OSH28+CIAILM1N4n9uKmVZnvfOjlRKqdmIsNv42gXzuWZNAT9//TCPbT3+kW2Z77lyKTedVeT91/X6M05CRG4Fbh39sEdEDs72OauAl+6Y8NMZTPOXyg2zK8fbpl1/ANHarRPM9fu9dm/8zI95Do/q/+KP4Iszf7kJT7L3JNDrgIIxH+ePPjbeNbUiEgEkAx/bj9QY8yDwoAev6RUiUm6MKfXX63lbMNevtVsnmOsP5trB+vo96XIpA0pEpFhEooBrgY2nXLORP//C+Rzwhq/mz5VSSo1vyhH66Jz47cBmwA48bIypEJF7gHJjzEbgIeD/RKQSaMMV+koppfzIozl0Y8wmYNMpj9095u8DwOe9W5pX+G16x0eCuX6t3TrBXH8w1w4W1y86M6KUUqFB18crpVSICPlAF5F/FZE9IrJLRF4RkVyra/KUiPxYRA6M1v+CiKRYXdN0iMjnRaRCRJwiEhSdC1NtcxHIRORhEWkSkQ+trmW6RKRARN4UkX2j3zPftLqm6RCRGBHZJiK7R+v/F0vqCPUpFxFJMsZ0jf79DmCJMearFpflERG5FFfH0IiI/AjAGPNti8vymIgsBpzAA8DfG2PKLS5pUqPbXBxizDYXwHWnbHMRsETkPKAH+F9jzDKr65kOEckBcowxO0QkEdgOXBVE//YCxBtjekQkEngX+KYx5gN/1hHyI3R3mI+KB4LmN5gx5hVjjPuMqw9wrQEIGsaY/caYWS8e86OT21wYY4YA9zYXQcEY8ydcXWZBxxjTYIzZMfr3bmA/rhXoQcG49Ix+GDn6x+9ZE/KBDiAi/yYiNbgWdN091fUB6svAH60uIsSNt81F0IRKqBjdrfUMYKu1lUyPiNhFZBfQBLxqjPF7/SER6CLymoh8OM6fKwGMMd81xhQAjwG3W1vtR01V++g13wVGcNUfUDypXylPiUgC8BzwN6e8uw54xhiHMWYlrnfSa0XE79NeIXHAhTHmEg8vfQxXP/33fFjOtExVu4jcDPwFcHEgrr6dxr99MPBkmwvlI6Nzz88Bjxljnre6npkyxnSIyJvAesCvN6hDYoQ+GREpGfPhlcABq2qZLhFZD3wL2GCM6bO6njDgyTYXygdGbyo+BOw3xvyX1fVMl4hkurvQRCQW1411v2dNOHS5PAechqvb4jjwVWNMUIy6RrdSiObPG519ECwdOgAi8pfAL4BMoAPYZYy5zNqqJiciVwA/48/bXPybxSV5TESeAC7AteNfI/A9Y8xDlhblIRE5B3gH2IvrZxXgH0ZXqQc8EVkBPIrr+8YGPG2MucfvdYR6oCulVLgI+SkXpZQKFxroSikVIjTQlVIqRGigK6VUiNBAV0qpEKGBrpRSIUIDXSmlQoQGulJKhYj/D5Y5CE8YkZU+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(av_coords[:,2].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2aab7ef8e150>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXTcZ3n3//c1o32XrNFiLbZsy/uaKE5CNmd3WBIoBJxAIS2QH4VQnpY+ELqkNDwcSvkVyo9f6CElaWkhSUOAxgkOJiEOSZzYsZPYsiVbtiwv2jdr30dzPX9oZGRZtkbSjGa7Xuf4HM13bn3nGlv6+J77e3/vW1QVY4wx4c8R7AKMMcb4hwW6McZECAt0Y4yJEBboxhgTISzQjTEmQligG2NMhPAp0EVkq4hUiUi1iDw4xfPFIrJLRN4VkXIRea//SzXGGHMpMt08dBFxAseAW4E6YB9wj6pWTmjzKPCuqv6riKwGdqjq4oBVbYwx5gK+9NA3A9WqWqOqw8BTwF2T2iiQ5v06HWjwX4nGGGN8EeNDmwKgdsLjOuDKSW2+DvxWRL4IJAO3THfS7OxsXbx4sW9VGmOMAeDtt99uU1XXVM/5Eui+uAf4D1X9ZxG5GvgvEVmrqp6JjUTkfuB+gOLiYvbv3++nlzfGmOggIqcv9pwvQy71QNGEx4XeYxN9GngaQFXfBBKA7MknUtVHVbVMVctcrin/gzHGGDNLvgT6PqBUREpEJA7YBmyf1OYMcDOAiKxiLNBb/VmoMcaYS5s20FXVDTwA7ASOAE+raoWIPCwid3qbfRn4rIgcBJ4E7lNbxtEYY+aVT2PoqroD2DHp2EMTvq4ErvFvacYYY2bC7hQ1xpgIYYFujDERwgLdGGMihAW6McZECAt0Y6bw1WfK+fMn3w12GcbMiL/uFDUmorxc1UJX/wh9Q26S4+3XxIQH66EbM0lLzyCtPUMMj3rYU9Me7HKM8ZkFujGTVDZ0n/v6lSq74dmEDwt0YyapbBwL9CsWZ/LKsRbspmcTLizQjZmkoqGbwsxE7tywkNqzA5xs6wt2Scb4xALdmEmONHSzOj+NLStyABt2MeHDAt2YCfqG3Jxs72PNwnSKspJY4krm98cs0E14sEA3ZoKjTd2owuqFYzsq3rDcxZ6adgZHRoNcmTHTs0A3ZoLxGS7Hm3t4Yu8ZVGHI7eEfXzga5MqMmZ4FujETVDZ2kxjrJD0xFoCS7GRiHEJVc0+QKzNmehboxkxQ2dBNfkYCIgJArNNBSXYyJ1ttposJfRboxni5Rz0cbephYXriecddqfGc7R+2+egm5FmgG+NV09bHkNtDfnrCecfTE2MZdnvoHnAHqTJjfONToIvIVhGpEpFqEXlwiue/JyIHvH+OiUin/0s1JrDGL4jmZ5zfQ89IigOgoWtg3msyZiamXUZORJzAI8CtQB2wT0S2e/cRBUBV/2JC+y8CmwJQqzEBVdHQRVyMA1dK/HnHM7wXSBs6B1iVnxaM0ozxiS899M1AtarWqOow8BRw1yXa3wM86Y/ijJlPlY3drMxLxemQ846Pz3hp6BoMRlnG+MyXQC8Aaic8rvMeu4CILAJKgJfnXpox8+tUWz9LXSkXHE9JiMEpQkOnDbmY0Obvi6LbgGdUdcrb6kTkfhHZLyL7W1vtdmoTOkY9SlP3IAszEi54ziFCWmIMjRboJsT5Euj1QNGEx4XeY1PZxiWGW1T1UVUtU9Uyl8vle5XGBFhrzxCjHiV/0pTFcemJcTR02pCLCW2+BPo+oFRESkQkjrHQ3j65kYisBDKBN/1bojGBV+/tfU/VQwfISIq1WS4m5E0b6KrqBh4AdgJHgKdVtUJEHhaROyc03QY8pXb3hQlDjV3jgX6xHnosTV2DjHrsx9uELp92v1XVHcCOSccemvT46/4ry5j51egdThkbcrnwNor0xFjcHqWtd4jctKl78cYEm90pagxjQy7JcU7SEqbu42QkxZ5rZ0yoskA3hrEhl4UZiecW5ZosI9F7t6gFuglhFujGAI1dgxfc8j/R+M1FjTbTxYQwn8bQjYlUT+w9A8CJ1j5W5TnOPZ4sIdZBSnyMDbmYkGY9dBP13KMe+obc58bJpyIi5KcnnJsNY0woskA3Ua9rYAQYu3noUhZmJNrNRSakWaCbqPeHQL94Dx3GbjqyHroJZRboJup1egP9UkMuAAvTE2nrHWZwZMqliowJOgt0E/V87aGPz4JpsmV0TYiyQDdRr6t/hKQ4J7HOS/86jK/zYnPRTaiyQDdRr3NgeNrhFoACbw/dNrowocoC3US9roGRaWe4AOSlWw/dhDYLdBP1xgJ9+h56fIyT7JR4m+liQpYFuolqgyOjDI54zm0EPZ2FGQnU21x0E6Is0E1UOzfDxYcxdBibumhb0ZlQZYFuotp4oPveQ0+kvnMA28fFhCILdBPVuvp9m4M+bmFGAv3Do3R6v8+YUGKBbqJa58AwAqQm+BbohZlJgG10YUKTT4EuIltFpEpEqkXkwYu0+aiIVIpIhYg84d8yjQmMroER0hJjcTqm3thissLMsbnodR0W6Cb0TLseuog4gUeAW4E6YJ+IbFfVygltSoGvAdeoaoeI5ASqYGP8qdPHKYvjxm8ush66CUW+9NA3A9WqWqOqw8BTwF2T2nwWeERVOwBUtcW/ZRoTGF39Mwv0jKRYkuKc1FsP3YQgXwK9AKid8LjOe2yi5cByEdktIntEZKu/CjQmUAZHRunoHyY7Zfq7RMeJCAUZidR39gewMmNmx19b0MUApcAWoBB4VUTWqWrnxEYicj9wP0BxcbGfXtqY2alp7cOjkJuWMKPvK8hMtCEXE5J86aHXA0UTHhd6j01UB2xX1RFVPQkcYyzgz6Oqj6pqmaqWuVyu2dZsjF8ca+4BZhHoGYl2UdSEJF8CfR9QKiIlIhIHbAO2T2rzP4z1zhGRbMaGYGr8WKcxflfV3INThAUzGHKBsR56Z/8IfUPuAFVmzOxMG+iq6gYeAHYCR4CnVbVCRB4WkTu9zXYC7SJSCewC/reqtgeqaGP84VhTD9mpccQ4ZnY7hs10MaHKpzF0Vd0B7Jh07KEJXyvwl94/xoSFquaeGQ+3wISbizoGWJ6b6u+yjJk1u1PURKXeITd1HQOzDHTvzUXWQzchxgLdRKXj4xdEU2ce6K6UeOKcDpuLbkKOBbqJSn+Y4RI/4+91OIT8jAQbQzchxwLdRKWqpl4SYh1kJs9shsu4goxE6jvs5iITWizQTVQ61tzD8txUHOLbolyTFWTYzUUm9Figm6hU5Q302SrITKS5e4gh96gfqzJmbizQTdQ52zdMa88QK+YS6N656I22v6gJIRboJuqMXxBdnje3HjrYzUUmtFigm6gzHuhz6aEXZvzh5iJjQoUFuok6VU09pCXEzGrK4ri89AQcYjcXmdBigW6iTlVTDyvyUpFZznABiItxkJuWYD10E1Is0E1UUVWqmnso9cMaLLbRhQk1Fugmqpxs66Nn0M36gvQ5n8s2ujChxgLdRJUDtWObaG0szpjzuQozE2nsHGRk1DPncxnjDxboJqq8e6aT5DgnpTlzH3JZkp2C26OcOWvDLiY0WKCbqHKgtpP1hRk4HbO/IDpuaU4KACdaeud8LmP8wQLdRI3BkVGONHb7ZbgFYKkrGYDqVgt0Exos0E3UOFzfhdujbCzyT6CnJsSSmxbPiZY+v5zPmLmyQDdRY/yC6CY/BTrAspwU66GbkOFToIvIVhGpEpFqEXlwiufvE5FWETng/fMZ/5dqzNy8W9tJQUYiObPYdu5ilrpSqGnpZWxbXWOCa9pNokXECTwC3ArUAftEZLuqVk5q+t+q+kAAajTGLw6c6fTb+Pm4ZTkp9Ay5aekZmtX+pMb4ky899M1AtarWqOow8BRwV2DLMsa/WnoGqe8c8OtwC4z10AGqbaaLCQG+BHoBUDvhcZ332GQfFpFyEXlGRIqmOpGI3C8i+0Vkf2tr6yzKNWZ2Dpzx3lDk50BfNj510cbRTQjw10XR54DFqroeeBH4yVSNVPVRVS1T1TKXy+WnlzZmegdqO4lxCGv9cMv/RDmp8aTGx1gP3YQEXwK9HpjY4y70HjtHVdtVdcj78MfA5f4pzxj/ePdMJ6vy00iIdfr1vCLCkpwU66GbkOBLoO8DSkWkRETigG3A9okNRCR/wsM7gSP+K9GYuRn1KOV1nX4fbhm3zJViPXQTEqYNdFV1Aw8AOxkL6qdVtUJEHhaRO73N/lxEKkTkIPDnwH2BKtiYmapp7aVveJQNAQr0pTnJNHcP0TM4EpDzG+OraactAqjqDmDHpGMPTfj6a8DX/FuaMf5xsK4LgA2F/h0/H7fMNX5htC9gnwKM8YXdKWoiXnnd2AqLS7zB62+2SJcJFRboJuKV13WxpiDdLyssTqU4K4lYp9gSACboLNBNRBt2e6hs7A7YcAtArNPBogXJ1kM3QWeBbiLaseYeht0e1hcGdmx7mcsW6TLBZ4FuIlq594Lo+gD20GFspsvp9n6G3bYdnQkeC3QT0crrOklPjKU4Kymgr7MyL41Rj3KsuSegr2PMpVigm4hWXtfF+sJ0RAJzQXTcBu+QzvgnAmOCwQLdRKzBkVGqmnsCPtwCUJSVSEZSLIfqOwP+WsZcjAW6iViVjd2MejTgF0RhbE2XdQXpHKy1HroJHgt0E7HKvVvOzUcPffx1jjX3MDgyOi+vZ8xkFugmYpXXdeFKjSdvnnYSWleQgdujVDZ2z8vrGTOZBbqJWOX1XawvCPwF0XEbisY+CRyyC6MmSCzQTUTqGRzhRGvvvIyfj8tLSyA7Jd5mupigsUA3Eemtk2dRhbLFmfP2miLChsJ0yutsposJDgt0E5FeO95GfIyDyxfNX6ADrCtMp7q1l74h97y+rjFggW4i1O7qNjaXZPl9y7npbCjMQBUO19uwi5l/Fugm4jR1DXK8pZfrSrPn/bXHN6E+ZIFugsAC3USc16vbALhm2fwHuis1noXpCed2STJmPvkU6CKyVUSqRKRaRB68RLsPi4iKSJn/SjRmZl4/3sqC5DhW5aUF5fXXF2ZwyC6MmiCYNtBFxAk8AtwBrAbuEZHVU7RLBb4E7PV3kcb4SlV5vbqda5Zl4wjQDkXTWVeYzqn2fjr7h4Py+iZ6+dJD3wxUq2qNqg4DTwF3TdHuG8C3gUE/1mfMjFQ199DWO8S1QRg/H7e5JAuAN060B60GE518CfQCoHbC4zrvsXNE5DKgSFV/fakTicj9IrJfRPa3trbOuFhjpvP68bHx82uDMH4+blNRBmkJMbxS1RK0Gkx0mvNFURFxAN8FvjxdW1V9VFXLVLXM5XLN9aWNucBrx9tY4kpmYUZi0GqIcTq4brmLV6paUdWg1WGiT4wPbeqBogmPC73HxqUCa4FXvGtm5AHbReROVd3vr0KNmc6Qe5S9J9v5WFnR9I1n4Ym9Z6Y8fu+VxRccu3FFDr8ub6SysZs1C+dntUdjfOmh7wNKRaREROKAbcD28SdVtUtVs1V1saouBvYAFuZm3u062srgiIcbVgT/098Ny8dqeKXKhhbN/Jm2h66qbhF5ANgJOIHHVbVCRB4G9qvq9kufwZj58e+7T1KQkcj1pRcG+sV614HiSo1nXUE6r1S18IUbl83ra5vo5cuQC6q6A9gx6dhDF2m7Ze5lGTMzFQ1d7D15lq/dsZIYZ2jcL7dlhYtHdlXT1T9CelJssMsxUSA0fvKNmaP/2H2KxFgn2664cDw7WLasyMGj8Fq1DbuY+WGBbsJee+8Qzx5s4I8uKwipnvDGogwykmLZddQC3cwPC3QT9p7Ye4Zht4f73rM42KWcx+kQri918ftjrXg8Nn3RBJ5PY+jGzIeZTAscNzLq4b/2nOa60mxKc1MDVdqsbVnhYvvBBg43dM3r7kkmOlkP3YS17QcaaOkZ4k+uWRzsUqZ044ocnA5hZ0VTsEsxUcAC3YQtj0f54SvVrMxLZcvynGCXM6XM5DiuWpLFbw5boJvAs0A3YWtnRRMnWvv4/I3Lgrayoi+2rs3nRGsf1S09wS7FRDgLdBOWVJX/f1c1JdnJvG9dfrDLuaTbV+ciAi8csl66CSwLdBOWXjnWSkVDN392w1KcIdw7B8hJS+Cy4kx+Y+PoJsBslosJKW29Q7T3DrFimt2GfrirmoXpCXxwU8El24WKrWvy+OaOI9Se7acoK8nn75vNzB8TvSzQTUhQVfadPMvzhxoYGVVuWpnDzStz8K7geZ7fH2tl36kO/uHONcTFhMeHzNu9gb6zoonPXLfkgufne60ZE5nC47fBRLSugRG+8MQ7/OpAPYuyktlUlMHLR1t4rrwBz6T1xFt6Bvny0wdZlpPCx64IzDK5gVC8IInV+Wk228UElPXQTdB99ZlyXjrSzNY1eVxbmo0AKfExvFbdRt/QKB9Yv5D0pFhGPcpf/PcBeodG+NlnriQh1hns0mdk69o8vvfSMVq6B8lJSwh2OSYCWaCbeTdxeKG9d4idFU3csMLF9cv/sOzt1rV5JMXH8NuKJm7851d4cOtKmroH2V3dzrc/vI4VeaF3V+h03rsuj+++eIxnDzTw2esvHHYxZq4s0E1Q7T7RjkOEq5YsOO+4iHDDchfLc1PYU9POV35RDsBdGxfy0QDtSBRoy3JSuaw4gyf3neEz15VMeX3AmLmwMXQTNAPDo7xzuoMNRemkJUy9SmJ+eiJP/z9X892PbuDDlxXyzQ+tC+sg3La5mJrWPvaf7gh2KSYCWQ/dBM2+U2cZHvVwzbLsS7YTEf7oskL+6LLCeaoscN6/Pp+Hn6vkybfOcMXirFmfx6YzmqlYD90ExahHebOmnSWuZPLTE4NdzrxJiovhzo0L2XGoka6BkWCXYyKMTz10EdkKfJ+xPUV/rKr/OOn5zwFfAEaBXuB+Va30c60mghyu76JrYIS7NiwMdilzNtPe8j1XFPPE3jM8e6CeT169OICVmWgzbQ9dRJzAI8AdwGrgHhFZPanZE6q6TlU3Av8EfNfvlZqIsudkOwuS41gehrNV5mpdYTprFqbx5Fu1qNrGF8Z/fOmhbwaqVbUGQESeAu4CzvXAVbV7QvtkwH5KzUV19A9zur2f21bn4gjjC5xzsW1zMX/3P4d5paqVG1f6b+nfqT4t2Lh69PAl0AuA2gmP64ArJzcSkS8AfwnEATdNdSIRuR+4H6C42H7IolV5bSdAxO/gc6mhmA9uXMi/7z7JZ/5zP1+5fQUp8TFhPXvHhAa/XRRV1UdUdSnwVeBvL9LmUVUtU9Uyl8s1VRMTBQ7WdVGclURWclywSwma1IRYnv3CNdy+JpdvvXCUn+49w1snz/La8VZ+d6SZw/VdDI2MBrtME2Z86aHXAxPv5Cj0HruYp4B/nUtRJnIdbeqmqXuQD0TAxdC5Sk2I5ZF7L+Px3af45q8rOdLYfd7zToewJDuZG5a7WOJKCVKVJpz4Euj7gFIRKWEsyLcB905sICKlqnrc+/B9wHGMmcKzBxpwCKwrSPf5eyJ5XFhE+PS1JXg8itujxMc4iHEKZ872c7Sxh8P1XTy++yQf2lTI5Ysyg12uCXHTBrqqukXkAWAnY9MWH1fVChF5GNivqtuBB0TkFmAE6AA+FciiTXiYHMQeVZ7ce4ZlOSmkxNs9bRMlT/r7WJKdwpLsFG5amcMTe8/wi3fq6OgfvuiSwsaAj/PQVXUHsGPSsYcmfP0lP9dlwoiva3mfae+nc2CE29bkBuw1I6XnPi4h1smn3rOYX71bz8tHWxhxe7gjxLfcM8Fj3SQzbw7UdRLrFFblX3o3ormIxI0inA7hw5cVEOMQXqtuY2V+GiXZycEuy4Qgu/XfzAu3x8Ohui5W5acRHxNe65iHAhHhvevyyUyK5Zfv1DEy6gl2SSYEWQ/dzIvq5l4GRkbZGOFzz30x208RcTEOPrSpkMd3n+SlymYbejEXsB66mRcH6jpJinNSmht9t/r707KcFK5YnMXr1W3Unu0PdjkmxFigm4Abco9ypLGbtQXpOB02Q2Ou7libR1piLM8erLe1YMx5LNBNwFU2dDMyqjbc4icJsU5uWZVLQ+cgRxp7gl2OCSEW6CbgDtZ1kpEUS/GCpGCXEjE2FmWwIDmO3x1txmO9dONlgW4CqnfITXVLLxsKM6J2ZcVAcDqEm1bm0Ng1SGVD9/TfYKKCBboJqEP1XXgUNhTZcIu/rS/MIDsl3nrp5hwLdBNQB2s7yUtLIC8tIdilRJzxXnpz9xAV1ks3WKCbADrbN8yZs/3WOw+g9YXpuFLj2XW0xWa8GAt0EzgHajsQYEOh7ysrmplxiHDtsmyaugc51W7z0qOdBboJCFXlQG0ni7OTyUiK3o0s5sOGwgwSYh3sqWkPdikmyCzQTUDUdw7Q1jvMJhtuCbi4GAeXF2dS0dBF9+BIsMsxQWSBbgLiQG0nToewZqENt8yHK5cswKOw7+TZYJdigsgC3fjdqEc5WNfFyrxUEuNsZcX5kJ0ST2lOCm+dOsuoxy6ORisLdON3J1p76Rty23DLPLt6yQJ6Bt1UNtoUxmhly+cavztQ20lCrIPltrLivFqel0pmUixvnmib0Z6tk0XLblCRyKceuohsFZEqEakWkQeneP4vRaRSRMpF5Hcissj/pZpwMDA8SkVDF+sKMohx2gfA+eQQ4T1LsznV3k9NW2+wyzFBMO1vnIg4gUeAO4DVwD0isnpSs3eBMlVdDzwD/JO/CzXhYf/ps4yMKlctyQp2KVFpc0kWqQkxvFRpNxpFI1+6UJuBalWtUdVh4CngrokNVHWXqo7f1bAHKPRvmSYceFTZU9NOSXYy+emJwS4nKsU6HWxZ7uJUex8nWvuCXY6ZZ74EegFQO+FxnffYxXwaeGEuRZnwdLSxm47+Ea5esiDYpUS1ssVZpCfG8tKRZuulRxm/XhQVkU8AZcANF3n+fuB+gOJiu8ASCvx5AWz3iXYyEmNZlZ8217LMHMQ6HWxZ4eLZAw0cb7Gx9GjiSw+9Hiia8LjQe+w8InIL8DfAnao6NNWJVPVRVS1T1TKXyzWbek2Iauwa4GRbH1ctWWDbzIWAyxdlkpEUy4uV1kuPJr4E+j6gVERKRCQO2AZsn9hARDYBP2IszFv8X6YJdW+eaCfWKZQtzgx2KQaIcTi4eWUu9Z0DPFfeGOxyzDyZNtBV1Q08AOwEjgBPq2qFiDwsInd6m30HSAF+LiIHRGT7RU5nIlDvkJsDtZ1sLMokKc5ubQgVm4ozyE9P4NsvHGVwZDTY5Zh54NNvn6ruAHZMOvbQhK9v8XNdJozsPdmO26Ncs8wuhoYShwjvXZfPY6+f5PHdJ/n8lmXBLskEmHWnzJwMjoyy50Q7K/NSyUm1XYlCzVJXCreuzuWHu05w9+VFuFLjzz13sQviJnzZrXxmTn75Tj19w6NcW5od7FLMRXztjpUMjozy3RePBbsUE2AW6GbWPB7lx6/XUJCRSMmC5GCXYy5iiSuFT169mKf2nWGvbYIR0SzQzay9fLSFmtY+ri3NRsSmKoayL9+2nEVZSfzl0wfpGrBNMCKVBbqZtUdfG+udr7VNLEJecnwM39+2iebuQf7mV4dsbnqEskA3s7LjUCNvnTzLp68tsRuJwsSGogz+4tblPF/eyC/eueDeQBMBLNDNjDV3D/LXvzrEhsJ0/vhqWyk5nHzuhqVcWZLF3z97mKbuwWCXY/zMAt3MiMej/NXPD47NmvjYRmJtzfOw4nQI39+2iZSEGH7yxim6bTw9otg8dDOli81RHnaP8trxNr7xwbUsdaXMc1VmNqb6t7z78iIefbWG/9xzis9et4T4GNv7NRJY98r47EhjN9964Sg3rnDxCduOLKwtzEjkns1FNHYO8t/7avHYRdKIYIFupqWqvFLVwk/3nGZ5birfuXuDTVOMACvy0njf+nyONvVw1DaWjggW6OaSRj3Kf++v5beVzawrTOfnn7ua7JT46b/RhIUrSxaQnhjLnpqzwS7F+IEFurmkd053UF7Xxa2rc/lYWREJsTbWGkmcDuHKkiyqW3tp6bFZL+HOAt1clEeV16pbKchIZMtylw2zRKiyxVk4HcJe66WHPZvlYi7qSGM3bb3DbLui6FyY2wp9kSclPoZ1Bem8c6aD29bk2oyXMGY9dDMlVeXVY61kJcexxm7tj3hXlWQx5PZwoLYz2KWYObBAN1M61d5PbccA1y7Ltlv7o0BRVhIL0xPYU9Nu67yEMQt0M6XXjreSFOfksmLbIzQaiAhXLVlAc/cQe0/aWHq48inQRWSriFSJSLWIPDjF89eLyDsi4haRj/i/TDOfjjf3cLSph6uXLiAuxv7PjxabijNZmZfK9oMNvGnrpoelaX9bRcQJPALcAawG7hGR1ZOanQHuA57wd4Fm/oyPm//HG6dwpcZz9RLbIzSaOB3CvZuLWZWXynMHG3jjRFuwSzIz5Mssl81AtarWAIjIU8BdQOV4A1U95X3OE4AazTwYdnv4+du1VDR0s7YgnQ9fVmCzHaJQjNPBPVcW89RbtTxf3khGYhyrF6YFuyzjI18+TxcAtRMe13mPmQjyYmUTlQ3d3LE2j3uuKLIwj2IxDgf3bC4mJzWeFw43Muqxi6ThYl4HSEXkfhHZLyL7W1tb5/OlzSW09Q6xp+Ysly/K5LpSu4HIjA2/bF2bR3vfMG+dtPH0cOFLoNcDRRMeF3qPzZiqPqqqZapa5nK5ZnMKEwC/OdyE0yncujo32KWYELIiN5Ul2cn87mgLgyOjwS7H+MCXQN8HlIpIiYjEAduA7YEty8yXmtZeKhu72bLcRWpCbLDLMSFERLhjbT79w6P8/ph9og4H0wa6qrqBB4CdwBHgaVWtEJGHReROABG5QkTqgLuBH4lIRSCLNv4x6lF2HGokIzGWa5ZlB7scE4IKMhPZWJTB7uo2TrT2BrscMw2f1nJR1R3AjknHHprw9T7GhmJMmKhq6uEHLx+noWuQj5UV2VZy5qJuW53L0aZu3vv91/jiTcv47PW2w1GossW5ItBUC2jd691h6ERrL//n+Up2VbWSGOvk+lIX6wttrRZzcRlJcXzp5uUcqu/k//3tMX75Tj0/uHfTuTV+LrT6q0oAAA4kSURBVPXzZuaXdcuiSFvvEJ987C3eOdPJl29dzhsP3sTWtXk2q8VMKz0xlh9+/HJ+8qeb6R8e5TM/2U9rz1CwyzKTWKBHiSH3KH/207dp6x3ivz69mS/eXEpmclywyzJh5oblLh67r4yO/mH+7KdvM+y2ewlDiQ25RAFV5d5/28vbpzvYdkURh+u7OVxve0ia2VmzMJ3vfGQDX3zyXb7+XAVrbXnlkGGBHkIutnnEXMcj3zjRztunO7hxhYv1hRlzOpcxAB/YsJDKxm7+9ZUT3LVxIVeW2Lo/ocACPcIdb+5hx6FGVuencfMqu3HI+M9f3baCo43dPHewgeyUeJa6UoJdUtSzQI9gbT1DPLnvDLlpCdxdVojDLn4aP3I6hP/vnk3c/M+/52d7T/P5G5aRnRo/q3PN5NNpoD7JRgIL9ACbzx++p/fV8m5tB4PDHnLTE3jm7TocIvzxVYts3rCZs4v9LH/y6sX88JVqfvLmKW5amcOJ1l7+5aVjrC/M4Icfv8zW1J9HFuhhqGdwhPgY53m/KE/vr+UrvygnPsbBkHfmgUPg09cusdksJqCykuP4xJWLeGz3SX7+dh2JsU42l2Tx0pFm/vczB/neRzfi8G5j6PEobo9ayAdIVAV6IHvLFzv3TPUNuUmKc543N3z83D2DI+yqamXfybOkJcbwyMcv4z1Ls3n9eBt//ctDXFeazWOfuoIf/f4EtR0DpCbEUJKd7Je6jLmUxdnJfO76pXhUKchM5BNXLeKRXdV8Z2cVWclxfOX2lTy9v5ZHX62hrXeI65e7uH1NHresyiEjyToc/hJVgR7qdle3seNQIyvz07j78kISYseGSYbco/y+qpXdJ9oY9SibijI51d7Hvf+2l49cXsjOw00sy0nhEe/H2wUp8SxImd1YpjGzVZCZeN7jz29ZSnvvMI/vPskz++voGXKzKCuJjUUZvHXyLC9WNhMf4+DW1blctWTBuWs8Z/uG6egfZol1RmbMAn2evHOmg98cbuLaZdkXLIQ16lG+8Xwlvz7USFFmIlVN3Tyyq5qPX7mIpu4BfnO4ie5BNxsK07llVS4LUuIZdnuo7ejn8d0ncaXE8/h9V5BmqyWaECIi/O37VjHq8VDfOcD91y+lumVsga87VanvHODFymaeL2/k3TOdXLYok8P1XZxs6wNgZV4qd6zLJ8uGDH1mge4HgyOjdA2MkJ44daAeb+nhl+/UkRgXw28qmjhQ20lJdjLxsQ7OtPfzfHkDu6pauWbpAu5Yl8/p9n6eeusMP3j5OAoUZCRy75WLKM5KOnfOuBgHf/f+1Xzk8kLSEmNZmJE45WsbE0wOh/APd60993g80EWEwswk7nvPYg7Vd/Hr8kaeO9hAVnIct63OxekQflvZzHu//xrf+9hGrl56/jz3M2f7qajv4qolC85dIwrGkGqozayxQL8IX/8B3aMe/uTf9/HWybO8b30+V5ZknTf+3dg1wBN7z5CTmsD91y+hprWX58ob+cRje8+1iXM6+PoHVhPnnYlSkp3MF25axs7DTSzOTubyRZkXnXK4Kt/2ezThS0RYX5jB8txUOvqHyUtLOPf7s9SVwq8PNXLPv+1hWU4KN6/KYXlOKj969QSn2/sBeKe2k09etYiiCZ0dX4VLSM+EBfoleFR5qbKZuBgHNyyfemu2f9pZxZs17eSnJ7D9YAO1Z/v54KYC+obc1HYM8OvyBuJjHHzqPYtJiHWyemE6S3NSyEyKIyMpluKsJAoyE4mPcZ73A5aWEMvdZUUXvJ4xkSgh1kl++vmfMhdmJPL8F6/l6f21vHSkmcdeO4nbo2QkxfK+dfksXpDMk/vO8G+v1XB3WRHrCmwJAgv0i1BVfn2okTdPjO2n2DUwwgc2LDyvzfPlDTz6ag2fvHoRy3NT2XW0hZePtnCovgu3d2PdpDgnn7625LzhmPgYJ/3Do/QPj9LQOTh/b8qYMJMcH8OfXFPCn1xTQvfgCMebe6ls6MbpnQb5Zzcs5ad7TvPkW2eoKExny4oc8tIScHs8HK7v5p3THYyq8sdXLQryO5kfURvoA8Oj7Dt1lmU5U9+u/OKRZt480c41SxfgdAivHm9jZNTDtiuK6B50c7Cuk688U87lizL52/et5pm367h5VS5FWUlUNHSTlxZPUVYSeekJxDhszq0xszHVsMh4mMNY4P/ptSW8fLSFN2vaKa/rojQnhaauQXqG3CTEOvi7/zlMXUc/X7195bn58OOG3R5ePtpCjFO4cUXOeecOR1EX6MNuD2+caOPV460MjniIOSIUZyXx0SvGhjf6htz88JVqXqlqpWxRJu9dlw9AbIyD3x1pYcM//Ja+4bENc12p8RfcCbc8N5Xluanz8l78NffdmHAW63Rw+5o8rivN5o0T7ew/dZb8jAQ+vDSbpa4Uqpq7+dHva2jsHOTbH15PYtzYtaqa1l5++W49Z/uGgbELttuumHqY06OKx6PEhPjOXj4FuohsBb4POIEfq+o/Tno+HvhP4HKgHfiYqp7yb6kz4/Hoef8bqyoH6zrZcaiRnkE3K/NSua7Uxa6jLXzlF+W8fbqDjORYntx7hu5BNxuLMvjgpoJz4+Y3r8wlIzGOWKewLCeFpTkpbCrKsJsijJlCMDobSXEx3LIql1smLUL3jbvWkp+eyHd2VrH9YAO5afHkpiVQXtdFVnIcn71uCT2DI/zq3Xp+8HI1rtR47liXT0p8DKrKy0db+MHLx2ntGWJFbiobizNZmZcakts2iqpeuoGIEzgG3ArUAfuAe1S1ckKbzwPrVfVzIrIN+JCqfuxS5y0rK9P9+/fPtX5gLLx3VbWw/WADp9v7qevo52zfMGWLs7hjbR7rC9P53ovHeb26jYKMRN6/Pp9FC8ZuWvCo0tg1wCO7TuAQuGNtPn96bQlVTT1TvtbFroBbb9mY0DT+O/tGdRv7TnVQ29FPfccAsU7hppW55z5ht/eOLWbX0DlInNPBNcsW0DPoZv/pDhYkx1Gam0JFQzc9g24SY51cVpzBwx9cy1JXCt2DI+w7eZYjjd2kJ8XhSoknPz2BNQvT/N6rF5G3VbVsyud8CPSrga+r6u3ex18DUNVvTWiz09vmTRGJAZoAl17i5HMJ9FGP0tY7RGPXIO+e6eAnb5ziVHs/2SlxrMhLpSgziZT4GF493sqx5rF5r6nxMWxZmcOVJVkXTAG898pijjX3kBTnpDBzbPqTBbQxkWEmnTCPKstzU9lZ0cTOiiZGPcoXblyG6tjYvUeVEy297D/dQUVDFx4dm2Z8ur0PzxRpl5Ucx+1rcrl9TR4l2clkJseRGh8zp20fLxXovgy5FAC1Ex7XAVderI2qukWkC1gAtM283Ev78Ws1fOuFo4xO+NvbWJTBD25bwda1eRd8DDrR2svbpzrYssLFS0daLnre+Rr3NsbMr5l0zhwibC7JYnNJFn/3/tUXnMMhQmluKqW5qfQMjuD2KPtPneXODQu5askC1hem0zfkpqVniJNtfbxY2cz2Aw08+dYfIjTGITx819qAzHef14uiInI/cL/3Ya+IVPnjvKeBZ8e+zGYW/4l83B9F+M+s3kOICff3EO71g72HWfNzHkz5Hj7+rTm9zkXnYPoS6PXAxEu/hd5jU7Wp8w65pDN2cfQ8qvoo8KgPrzkrIrL/Yh9FwoW9h+AL9/rB3kOomO/34Mto/T6gVERKRCQO2AZsn9RmO/Ap79cfAV6+1Pi5McYY/5u2h+4dE38A2MnYtMXHVbVCRB4G9qvqduAx4L9EpBo4y1joG2OMmUc+jaGr6g5gx6RjD034ehC427+lzUrAhnPmkb2H4Av3+sHeQ6iY1/cw7bRFY4wx4SH0bnUyxhgzKxEX6CLyDREpF5EDIvJbEVk4/XeFFhH5jogc9b6PX4lIRrBrmgkRuVtEKkTEIyJhNUtBRLaKSJWIVIvIg8GuZ6ZE5HERaRGRw8GuZbZEpEhEdolIpffn6EvBrmmmRCRBRN4SkYPe9/AP8/K6kTbkIiJpqtrt/frPgdWq+rkglzUjInIbYzOF3CLybQBV/WqQy/KZiKwCPMCPgL9SVf+s8RBgvixzEepE5HqgF/hPVV07XftQJCL5QL6qviMiqcDbwAfD7N9BgGRV7RWRWOB14EuquieQrxtxPfTxMPdKBsLufyxV/a2qur0P9zA29z9sqOoRVfXLTWPzbDNQrao1qjoMPAXcFeSaZkRVX2VsplnYUtVGVX3H+3UPcISxu9HDho7p9T6M9f4JeBZFXKADiMg3RaSWsZuxHpqufYj7U+CFYBcRJaZa5iKsgiTSiMhiYBOw99ItQ4+IOEXkANACvKiqAX8PYRnoIvKSiBye4s9dAKr6N6paBPwMeCC41U5tuvfgbfM3gJux9xFSfKnfmLkQkRTgF8D/mvTJOyyo6qiqbmTsE/ZmEQn4EFhYbnChqrf42PRnjM2f//sAljMr070HEbkPeD9wcyjedTuDf4Nw4ssyF2YeeMedfwH8TFV/Gex65kJVO0VkF7AVCOjF6rDsoV+KiJROeHgXcDRYtcyWd0ORrwB3qmp/sOuJIr4sc2ECzHtB8THgiKp+N9j1zIaIuMZnp4lIImMX2gOeRZE4y+UXwArGZlmcBj6nqmHVy/IuoRDPHxY42xNOM3VE5EPADwAX0AkcGF9PP9SJyHuBf+EPy1x8M8glzYiIPAlsYWyVv2bg71X1saAWNUMici3wGnCIsd9jgL/23rEeFkRkPfATxn6OHMDTqvpwwF830gLdGGOiVcQNuRhjTLSyQDfGmAhhgW6MMRHCAt0YYyKEBboxxkQIC3RjjIkQFujGGBMhLNCNMSZC/F8yJ86qWTzu6QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(av_coords[:,2].cpu(), hist_kws={'weights': preds.float().cpu()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2aab7fceea10>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(av_coords[:,2].cpu(), hist_kws={'weights': (data.y[subset_ind].bool().cpu() & ~preds.cpu()).float()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2aab7ff73bd0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(subset_ind, hist_kws={'weights': preds.float().cpu()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2aab7c890a90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(subset_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(119409, device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(F.sigmoid(output) > 0.3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   109,    559,   5044,  ..., 103302, 103302, 100242],\n",
       "        [     0,      0,      0,  ...,  63199,  90855, 103302]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 123429])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.layerless_true_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(120268., device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = torch.load(all_events[0], map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def construct_downstream(batch, pl_module):\n",
    "\n",
    "    emb = (None if (pl_module.hparams[\"emb_channels\"] == 0)\n",
    "           else batch.embedding)  # Does this work??\n",
    "    \n",
    "    sections = 16\n",
    "    cut_list = []\n",
    "    for j in range(sections):\n",
    "#         print(j)\n",
    "        subset_ind = torch.chunk(torch.arange(batch.e_radius.shape[1]), sections)[j]\n",
    "        output = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1), batch.e_radius[:, subset_ind], emb).squeeze() if ('ci' in pl_module.hparams[\"regime\"]) else pl_module(batch.x, batch.e_radius[:, subset_ind], emb).squeeze()\n",
    "        av_coords = (batch.x[batch.e_radius[0,subset_ind]] + batch.x[batch.e_radius[1,subset_ind]])/2\n",
    "#         dynamic_cut = torch.tensor([0.05]*len(subset_ind), device=device)\n",
    "#         dynamic_cut[((av_coords[:,2] < 0.5) & (av_coords[:,2] > -0.5))] = 0.01\n",
    "        dynamic_cut = 0.15\n",
    "#         dynamic_cut = 0.1 if (9 <= j < 14) else 0.1\n",
    "        cut = F.sigmoid(output) > dynamic_cut\n",
    "        cut_list.append(cut)\n",
    "#     print(\"Predicted!\")\n",
    "    y_pid = batch.pid[batch.e_radius[0]] == batch.pid[batch.e_radius[1]]\n",
    "    cut_list = torch.cat(cut_list)\n",
    "    batch.edge_index = batch.e_radius[:, cut_list]\n",
    "#     batch.e_radius = None\n",
    "    batch.embedding = None\n",
    "    batch.y_filter = batch.y[cut_list]\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    processed = construct_downstream(sample.to(device), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9613, device='cuda:0')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.y_filter.sum() / processed.y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9366, device='cuda:0')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.y_filter.sum() / processed.layerless_true_edges.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0563, device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.y_filter.sum() / len(processed.y_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2053390])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.y_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9879, device='cuda:0')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.y_filter.sum() / processed.y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9626, device='cuda:0')"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.y_filter.sum() / processed.layerless_true_edges.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0314, device='cuda:0')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.y_filter.sum() / len(processed.y_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch = sample.to(device)\n",
    "\n",
    "    emb = (None if (model.hparams[\"emb_channels\"] == 0)\n",
    "           else batch.embedding)  # Does this work??\n",
    "\n",
    "    sections = 8\n",
    "    cut_list = []\n",
    "    for j in range(sections):\n",
    "    #         print(j)\n",
    "        subset_ind = torch.chunk(torch.arange(batch.e_radius.shape[1]), sections)[j]\n",
    "        output = model(torch.cat([batch.cell_data, batch.x], axis=-1), batch.e_radius[:, subset_ind], emb).squeeze() if ('ci' in model.hparams[\"regime\"]) else model(batch.x, batch.e_radius[:, subset_ind], emb).squeeze()\n",
    "        cut = F.sigmoid(output) > model.hparams[\"filter_cut\"]\n",
    "        cut_list.append(cut)\n",
    "    #     print(\"Predicted!\")\n",
    "    y_pid = batch.pid[batch.e_radius[0]] == batch.pid[batch.e_radius[1]]\n",
    "    cut_list = torch.cat(cut_list)\n",
    "    batch.edge_index = batch.e_radius[:, cut_list]\n",
    "    batch.e_radius = None\n",
    "    batch.embedding = None\n",
    "    if \"pid\" not in model.hparams[\"regime\"]:\n",
    "        batch.y = batch.y[cut_list]\n",
    "    else:\n",
    "        batch.y = None\n",
    "    batch.y_pid = y_pid[cut_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(5076., device='cuda:0')\n",
      "tensor(0.9354, device='cuda:0')\n",
      "tensor(0.0459, device='cuda:0')\n",
      "1\n",
      "tensor(6405., device='cuda:0')\n",
      "tensor(0.9026, device='cuda:0')\n",
      "tensor(0.0601, device='cuda:0')\n",
      "2\n",
      "tensor(6156., device='cuda:0')\n",
      "tensor(0.9581, device='cuda:0')\n",
      "tensor(0.0566, device='cuda:0')\n",
      "3\n",
      "tensor(5700., device='cuda:0')\n",
      "tensor(0.9484, device='cuda:0')\n",
      "tensor(0.0486, device='cuda:0')\n",
      "4\n",
      "tensor(5304., device='cuda:0')\n",
      "tensor(0.9327, device='cuda:0')\n",
      "tensor(0.0405, device='cuda:0')\n",
      "5\n",
      "tensor(5270., device='cuda:0')\n",
      "tensor(0.9230, device='cuda:0')\n",
      "tensor(0.0424, device='cuda:0')\n",
      "6\n",
      "tensor(4484., device='cuda:0')\n",
      "tensor(0.9349, device='cuda:0')\n",
      "tensor(0.0345, device='cuda:0')\n",
      "7\n",
      "tensor(4497., device='cuda:0')\n",
      "tensor(0.9128, device='cuda:0')\n",
      "tensor(0.0341, device='cuda:0')\n",
      "8\n",
      "tensor(5020., device='cuda:0')\n",
      "tensor(0.9709, device='cuda:0')\n",
      "tensor(0.0405, device='cuda:0')\n",
      "9\n",
      "tensor(10126., device='cuda:0')\n",
      "tensor(0.9958, device='cuda:0')\n",
      "tensor(0.0903, device='cuda:0')\n",
      "10\n",
      "tensor(11166., device='cuda:0')\n",
      "tensor(0.9937, device='cuda:0')\n",
      "tensor(0.1003, device='cuda:0')\n",
      "11\n",
      "tensor(8977., device='cuda:0')\n",
      "tensor(0.9962, device='cuda:0')\n",
      "tensor(0.0772, device='cuda:0')\n",
      "12\n",
      "tensor(8127., device='cuda:0')\n",
      "tensor(0.9932, device='cuda:0')\n",
      "tensor(0.0698, device='cuda:0')\n",
      "13\n",
      "tensor(12505., device='cuda:0')\n",
      "tensor(0.9898, device='cuda:0')\n",
      "tensor(0.1114, device='cuda:0')\n",
      "14\n",
      "tensor(10552., device='cuda:0')\n",
      "tensor(0.9144, device='cuda:0')\n",
      "tensor(0.0921, device='cuda:0')\n",
      "15\n",
      "tensor(10903., device='cuda:0')\n",
      "tensor(0.6994, device='cuda:0')\n",
      "tensor(0.0753, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    batch = sample.to(device)\n",
    "\n",
    "    emb = (None if (model.hparams[\"emb_channels\"] == 0)\n",
    "           else batch.embedding)  # Does this work??\n",
    "\n",
    "    sections = 16\n",
    "    cut_list = []\n",
    "    for j in range(sections):\n",
    "        print(j)\n",
    "        subset_ind = torch.chunk(torch.arange(batch.e_radius.shape[1]), sections)[j]\n",
    "        output = model(torch.cat([batch.cell_data, batch.x], axis=-1), batch.e_radius[:, subset_ind], emb).squeeze() if ('ci' in model.hparams[\"regime\"]) else model(batch.x, batch.e_radius[:, subset_ind], emb).squeeze()\n",
    "        av_coords = (batch.x[batch.e_radius[0,subset_ind]] + batch.x[batch.e_radius[1,subset_ind]])/2\n",
    "#         dynamic_cut = torch.tensor([0.1]*len(subset_ind), device=device)\n",
    "#         dynamic_cut[((av_coords[:,2] < 1) & (av_coords[:,2] > -1))] = 0.05\n",
    "#         dynamic_cut = 0.5 if (9 <= j < 14) else 0.05\n",
    "        dynamic_cut = 0.1\n",
    "        cut = F.sigmoid(output) > dynamic_cut\n",
    "        cut_list.append(cut)\n",
    "#         print(cut.sum())\n",
    "        print(batch.y[subset_ind].sum())\n",
    "        print((batch.y[subset_ind].bool() & cut).sum() / batch.y[subset_ind].sum())\n",
    "        print((batch.y[subset_ind].bool() & cut).sum() / cut.float().sum())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_cut[((av_coords[:,2] < 1) & (av_coords[:,2] > -1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True,  ..., True, True, True], device='cuda:0')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(av_coords[:,2]) < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10048605])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(120268.)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8509, device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.y.sum() / sample.layerless_true_edges.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r = sample.x[sample.layerless_true_edges[:,:70],0].cpu()\n",
    "phi = sample.x[sample.layerless_true_edges[:,:70],1].cpu()\n",
    "z = sample.x[sample.layerless_true_edges[:,:70],2].cpu()\n",
    "x = r*np.cos(phi)\n",
    "y = r*np.sin(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Build Graph Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def post_process(pl_module, load_dir, save_dir):\n",
    "    print(\"Training finished, running inference to filter graphs...\")\n",
    "\n",
    "    # By default, the set of examples propagated through the pipeline will be train+val+test set\n",
    "    datatypes = [\"train\", \"val\", \"test\"]\n",
    "    [os.makedirs(os.path.join(save_dir, datatype), exist_ok=True) for datatype in datatypes]\n",
    "    \n",
    "    input_dirs = [os.path.join(load_dir, datatype) for datatype in datatypes]\n",
    "    loadsets = [load_dataset(input_dir) for input_dir in input_dirs]\n",
    "    \n",
    "    total_length = sum([len(dataset) for dataset in loadsets])\n",
    "    batch_incr = 0\n",
    "\n",
    "    pl_module.eval()\n",
    "    with torch.no_grad():\n",
    "        for set_idx, (datatype, dataset) in enumerate(zip(datatypes, loadsets)):\n",
    "            for batch_idx, event in enumerate(dataset):\n",
    "#                 print(event)\n",
    "                percent = (batch_incr / total_length) * 100\n",
    "                sys.stdout.flush()\n",
    "                sys.stdout.write(f'{percent:.01f}% inference complete \\r')\n",
    "                if (not os.path.exists(os.path.join(save_dir, datatype, event[-4:]))):\n",
    "                    batch = torch.load(event, map_location=torch.device('cpu'))\n",
    "                    data = batch.to(pl_module.device) #Is this step necessary??\n",
    "                    data = construct_downstream(data, pl_module)\n",
    "                    save_downstream(data, pl_module, datatype, save_dir)\n",
    "\n",
    "                batch_incr += 1\n",
    "\n",
    "def construct_downstream(batch, pl_module):\n",
    "\n",
    "    emb = (None if (pl_module.hparams[\"emb_channels\"] == 0)\n",
    "           else batch.embedding)  # Does this work??\n",
    "    \n",
    "    sections = 8\n",
    "    cut_list = []\n",
    "    for j in range(sections):\n",
    "#         print(j)\n",
    "        subset_ind = torch.chunk(torch.arange(batch.e_radius.shape[1]), sections)[j]\n",
    "        output = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1), batch.e_radius[:, subset_ind], emb).squeeze() if ('ci' in pl_module.hparams[\"regime\"]) else pl_module(batch.x, batch.e_radius[:, subset_ind], emb).squeeze()\n",
    "        cut = F.sigmoid(output) > pl_module.hparams[\"filter_cut\"]\n",
    "        cut_list.append(cut)\n",
    "#     print(\"Predicted!\")\n",
    "    y_pid = batch.pid[batch.e_radius[0]] == batch.pid[batch.e_radius[1]]\n",
    "    cut_list = torch.cat(cut_list)\n",
    "    batch.edge_index = batch.e_radius[:, cut_list]\n",
    "    batch.e_radius = None\n",
    "    batch.embedding = None\n",
    "    if \"pid\" not in pl_module.hparams[\"regime\"]:\n",
    "        batch.y = batch.y[cut_list]\n",
    "    else:\n",
    "        batch.y = None\n",
    "    batch.y_pid = y_pid[cut_list]\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def save_downstream(batch, pl_module, datatype, save_dir):\n",
    "\n",
    "    with open(os.path.join(save_dir, datatype, batch.event_file[-4:]), 'wb') as pickle_file:\n",
    "        torch.save(batch, pickle_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(input_dir):\n",
    "    all_events = os.listdir(input_dir)\n",
    "    all_events = sorted([os.path.join(input_dir, event) for event in all_events])\n",
    "\n",
    "    return all_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "load_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/trackml_processed/embedding_processed/0_pt_cut_endcaps\"\n",
    "save_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/trackml_processed/filter_processed/0_pt_cut_endcaps_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished, running inference to filter graphs...\n",
      "99.9% inference complete \r"
     ]
    }
   ],
   "source": [
    "post_process(model, load_dir, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for \n",
    "        for i, batch in enumerate(train_dataset):\n",
    "            tic = tt()\n",
    "            if not os.path.exists(os.path.join(save_dir, batch.event_file[-4:])):\n",
    "                data = batch.to(device)\n",
    "                emb = (None if (hparams[\"emb_channels\"] == 0) \n",
    "                           else data.embedding) \n",
    "\n",
    "                cut_list = []\n",
    "                for j in range(sections):\n",
    "                    subset_ind = torch.chunk(torch.arange(data.e_radius.shape[1]), sections)[j]\n",
    "    #                 print(subset_ind)\n",
    "                    output = model(torch.cat([data.cell_data, data.x], axis=-1), data.e_radius[:, subset_ind], emb).squeeze() if ('ci' in hparams[\"regime\"]) else model(data.x, data.e_radius[:, subset_ind], emb).squeeze()\n",
    "                    cut = F.sigmoid(output) > 0.35\n",
    "                    cut_list.append(cut)\n",
    "\n",
    "                cut_list = torch.cat(cut_list)\n",
    "                batch.edge_index = batch.e_radius[:, cut_list]\n",
    "                batch.e_radius = None\n",
    "                batch.embedding = None\n",
    "        #         batch.x = batch.x.cpu()\n",
    "        #         batch.y = torch.from_numpy(y[combined_indices]).float()\n",
    "                batch.y = batch.y[cut_list]\n",
    "\n",
    "                with open(os.path.join(save_dir, batch.event_file[-4:]), 'wb') as pickle_file:\n",
    "                    torch.save(batch, pickle_file)\n",
    "\n",
    "            print(i, \"saved in time\", tt()-tic)\n",
    "    #         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 already built\n",
      "1 already built\n",
      "2 already built\n",
      "3 already built\n",
      "4 already built\n",
      "5 already built\n",
      "6 already built\n",
      "7 already built\n",
      "8 already built\n",
      "9 already built\n",
      "10 already built\n",
      "11 already built\n",
      "12 already built\n",
      "13 already built\n",
      "14 already built\n",
      "15 already built\n",
      "16 already built\n",
      "17 already built\n",
      "18 already built\n",
      "19 already built\n",
      "20 already built\n",
      "21 already built\n",
      "22 already built\n",
      "23 already built\n",
      "24 already built\n",
      "25 already built\n",
      "26 already built\n",
      "27 already built\n",
      "28 already built\n",
      "29 already built\n",
      "30 already built\n",
      "31 already built\n",
      "32 already built\n",
      "33 already built\n",
      "34 already built\n",
      "35 already built\n",
      "36 already built\n",
      "37 already built\n",
      "38 already built\n",
      "39 already built\n",
      "40 already built\n",
      "41 already built\n",
      "42 already built\n",
      "43 already built\n",
      "44 already built\n",
      "45 already built\n",
      "46 already built\n",
      "47 already built\n",
      "48 already built\n",
      "49 already built\n",
      "50 already built\n",
      "51 already built\n",
      "52 already built\n",
      "53 already built\n",
      "54 already built\n",
      "55 already built\n",
      "56 already built\n",
      "57 already built\n",
      "58 already built\n",
      "59 saved in time 5.765902280807495 with efficiency 0.9760021567344666 and purity 0.0130076315253973\n",
      "60 saved in time 7.05396580696106 with efficiency 0.9735508561134338 and purity 0.012030930258333683\n",
      "61 saved in time 3.9281487464904785 with efficiency 0.9739189147949219 and purity 0.015038900077342987\n",
      "62 saved in time 5.078753471374512 with efficiency 0.9772769212722778 and purity 0.012835629284381866\n",
      "63 saved in time 5.212491750717163 with efficiency 0.9737910628318787 and purity 0.013132509775459766\n",
      "64 saved in time 6.096397399902344 with efficiency 0.9758517146110535 and purity 0.01308666542172432\n",
      "65 saved in time 6.22529935836792 with efficiency 0.9748522043228149 and purity 0.012425638735294342\n",
      "66 saved in time 5.6675732135772705 with efficiency 0.976715087890625 and purity 0.012747363187372684\n",
      "67 saved in time 4.536586046218872 with efficiency 0.9772036075592041 and purity 0.014253919944167137\n",
      "68 saved in time 8.890730142593384 with efficiency 0.9751096367835999 and purity 0.011339920572936535\n",
      "69 saved in time 5.502119302749634 with efficiency 0.9762612581253052 and purity 0.012536182068288326\n",
      "70 saved in time 5.28673791885376 with efficiency 0.975019633769989 and purity 0.013181144371628761\n",
      "71 saved in time 6.606716156005859 with efficiency 0.9747148752212524 and purity 0.011822326108813286\n",
      "72 saved in time 8.026198863983154 with efficiency 0.9744740128517151 and purity 0.011253179982304573\n",
      "73 saved in time 4.840726375579834 with efficiency 0.9733009934425354 and purity 0.013272532261908054\n",
      "74 saved in time 4.619588375091553 with efficiency 0.9772128462791443 and purity 0.013453198596835136\n",
      "75 saved in time 3.6973087787628174 with efficiency 0.9780367016792297 and purity 0.014985509216785431\n",
      "76 saved in time 3.9706544876098633 with efficiency 0.9774010181427002 and purity 0.015218616463243961\n",
      "77 saved in time 4.108703136444092 with efficiency 0.9763035178184509 and purity 0.015290624462068081\n",
      "78 saved in time 5.445206165313721 with efficiency 0.9766365885734558 and purity 0.01347330305725336\n",
      "79 saved in time 6.929131031036377 with efficiency 0.9747827053070068 and purity 0.01195819117128849\n",
      "80 saved in time 5.2195494174957275 with efficiency 0.9749624133110046 and purity 0.012799283489584923\n",
      "81 saved in time 4.403406143188477 with efficiency 0.9760898947715759 and purity 0.01383861806243658\n",
      "82 saved in time 5.073794364929199 with efficiency 0.9754064083099365 and purity 0.011826936155557632\n",
      "83 saved in time 5.018097877502441 with efficiency 0.9744591116905212 and purity 0.012324618175625801\n",
      "84 saved in time 5.625274896621704 with efficiency 0.9708766341209412 and purity 0.012254597619175911\n",
      "85 saved in time 3.6197195053100586 with efficiency 0.9730446338653564 and purity 0.014156992547214031\n",
      "86 saved in time 4.0516626834869385 with efficiency 0.9713116884231567 and purity 0.013535013422369957\n",
      "87 saved in time 5.309300184249878 with efficiency 0.9748419523239136 and purity 0.012841029092669487\n",
      "88 saved in time 5.467803955078125 with efficiency 0.9745949506759644 and purity 0.012207359075546265\n",
      "89 saved in time 4.794459581375122 with efficiency 0.9768110513687134 and purity 0.013216808438301086\n",
      "90 saved in time 8.142253875732422 with efficiency 0.9735791087150574 and purity 0.011797239072620869\n",
      "91 saved in time 3.167573928833008 with efficiency 0.9770463109016418 and purity 0.014605697244405746\n",
      "92 saved in time 7.640714406967163 with efficiency 0.9699689149856567 and purity 0.011947679333388805\n",
      "93 saved in time 4.6275811195373535 with efficiency 0.9712573885917664 and purity 0.013120129704475403\n",
      "94 saved in time 5.066020250320435 with efficiency 0.9766305685043335 and purity 0.012305312789976597\n",
      "95 saved in time 4.5160980224609375 with efficiency 0.9747181534767151 and purity 0.012291522696614265\n",
      "96 saved in time 2.841407537460327 with efficiency 0.9717094302177429 and purity 0.014663095586001873\n",
      "97 saved in time 4.954846382141113 with efficiency 0.9757389426231384 and purity 0.012307796627283096\n",
      "98 saved in time 3.8567588329315186 with efficiency 0.9759711623191833 and purity 0.01318386197090149\n",
      "99 saved in time 3.3322372436523438 with efficiency 0.9755355715751648 and purity 0.014155028387904167\n",
      "100 saved in time 2.93830943107605 with efficiency 0.9775171279907227 and purity 0.015598046593368053\n",
      "101 saved in time 5.723185300827026 with efficiency 0.9767054915428162 and purity 0.012452573515474796\n",
      "102 saved in time 3.8046512603759766 with efficiency 0.9764668345451355 and purity 0.01320754736661911\n",
      "103 saved in time 5.846438884735107 with efficiency 0.9764142632484436 and purity 0.012028560973703861\n",
      "104 saved in time 3.3646700382232666 with efficiency 0.9775716662406921 and purity 0.013850215822458267\n",
      "105 saved in time 4.388471603393555 with efficiency 0.9714272618293762 and purity 0.013173537328839302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-55-89672923ace6>\", line 29, in <module>\n",
      "    e_spatial, y = graph_intersection(e_spatial, e_bidir)\n",
      "  File \"/global/u2/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py\", line 14, in graph_intersection\n",
      "    l1 = pred_graph.cpu().numpy()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import shuffle, choice\n",
    "from time import time as tt\n",
    "import os\n",
    "\n",
    "save_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/trackml_processed/filter_processed/0_pt_cut_endcaps/train\"\n",
    "train, ratio = False, 8\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(model.train_dataloader().dataset):\n",
    "            tic = tt()\n",
    "            if not os.path.exists(os.path.join(save_dir, batch.event_file[-4:])):\n",
    "\n",
    "                data = batch.to(device)\n",
    "                if 'ci' in model.hparams['regime']:\n",
    "                    spatial = model(torch.cat([data.cell_data, data.x], axis=-1))\n",
    "                else:\n",
    "                    spatial = model(data.x)\n",
    "                e_spatial = build_edges(spatial, 1.7, 500, res)  \n",
    "                e_bidir = torch.cat([batch.layerless_true_edges.to(device), \n",
    "                                       torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T.to(device)], axis=-1) \n",
    "                e_spatial, y_cluster = graph_intersection(e_spatial, e_bidir)\n",
    "\n",
    "                # Remove duplicate edges by distance from vertex\n",
    "                R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)\n",
    "                e_spatial = e_spatial[:, (R_dist[e_spatial[0]] < R_dist[e_spatial[1]])]\n",
    "\n",
    "                e_spatial, y = graph_intersection(e_spatial, e_bidir)  \n",
    "\n",
    "                # Re-introduce random direction, to avoid training bias\n",
    "                random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()\n",
    "                e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]\n",
    "\n",
    "                batch.embedding = spatial.cpu().detach()\n",
    "\n",
    "                if train and (ratio != 0): # Sample only ratio:1 fake:true edges, to keep trainset manageable\n",
    "\n",
    "                    num_true = y.sum()\n",
    "                    fake_indices = choice(np.where(~y)[0], int(num_true*ratio), replace=True)\n",
    "                    true_indices = np.where(y)[0]\n",
    "                    combined_indices = np.concatenate([true_indices, fake_indices])\n",
    "                    shuffle(combined_indices)\n",
    "\n",
    "                    batch.e_radius = e_spatial[:,combined_indices].cpu()\n",
    "                    batch.y = torch.from_numpy(y[combined_indices]).float()\n",
    "\n",
    "                else:\n",
    "                    batch.e_radius = e_spatial.cpu()\n",
    "                    batch.y = torch.from_numpy(y).float()\n",
    "\n",
    "\n",
    "                with open(os.path.join(save_dir, batch.event_file[-4:]), 'wb') as pickle_file:\n",
    "                    torch.save(batch, pickle_file)\n",
    "\n",
    "                print(i, \"saved in time\", tt()-tic, \"with efficiency\", (batch.y.sum()/batch.layerless_true_edges.shape[1]).item(), \"and purity\", (batch.y.sum()/batch.e_radius.shape[1]).item())\n",
    "\n",
    "            else:\n",
    "                print(i, \"already built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"LightningModules/GNN/train_gnn.yaml\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResAGNN(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally load the Weights & Biases logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(project=config[\"project\"], group=\"LayerlessEndcaps\", log_model=True, save_dir = config[\"wandb_save_dir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs = config['max_epochs'], gpus=1, logger=wandb_logger, callbacks=stringlist_to_classes(config[\"callbacks\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmurnanedaniel\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /global/cscratch1/sd/danieltm/ExaTrkX/wandb_data/wandb/run-20201015_102508-z9d4id5q\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mneat-serenity-10\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/murnanedaniel/GNNStudy\" target=\"_blank\">https://wandb.ai/murnanedaniel/GNNStudy</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/murnanedaniel/GNNStudy/runs/z9d4id5q\" target=\"_blank\">https://wandb.ai/murnanedaniel/GNNStudy/runs/z9d4id5q</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name          | Type        | Params\n",
      "----------------------------------------------\n",
      "0 | input_network | Sequential  | 192   \n",
      "1 | edge_network  | EdgeNetwork | 5 K   \n",
      "2 | node_network  | NodeNetwork | 5 K   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06162e7823e42d381bfb0ee9b0a651e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.211020469665527"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.max_memory_allocated() / 1024**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Load and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_label = \"oew8m1sj\"\n",
    "wandb_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/wandb_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run_path = get_best_run(run_label,wandb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpnt = torch.load(best_run_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SplitCheckpointedResAGNN(chkpnt[\"hyper_parameters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.load_from_checkpoint(best_run_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SplitCheckpointedResAGNN' object has no attribute 'learning_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-62de0655cdbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 594\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SplitCheckpointedResAGNN' object has no attribute 'learning_rate'"
     ]
    }
   ],
   "source": [
    "model.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 validated\n",
      "5 validated\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    edge_total_positive, edge_total_true, edge_total_true_positive = 0, 0, 0\n",
    "    for i, batch in enumerate(model.val_dataloader()):\n",
    "            data = batch.to(device)\n",
    "                \n",
    "            emb = (None if (model.hparams[\"emb_channels\"] == 0) \n",
    "                   else data.embedding) \n",
    "        \n",
    "            subset_ind = torch.randint(data.e_radius.shape[1], (int(data.e_radius.shape[1]*model.hparams['val_subset']),))\n",
    "\n",
    "            output = model(torch.cat([data.cell_data, data.x], axis=-1), data.e_radius[:, subset_ind], emb).squeeze() if ('ci' in model.hparams[\"regime\"]) else model(data.x, data.e_radius[:, subset_ind], emb).squeeze()\n",
    "\n",
    "            val_loss = F.binary_cross_entropy_with_logits(output, data.y[subset_ind])\n",
    "\n",
    "            result = pl.EvalResult(checkpoint_on=val_loss)\n",
    "            result.log('val_loss', val_loss)\n",
    "\n",
    "            #Edge filter performance\n",
    "            preds = F.sigmoid(output) > 0.3 #Maybe send to CPU??\n",
    "            edge_positive = preds.sum().float()\n",
    "            if ('pid' in model.hparams[\"regime\"]):\n",
    "                y_pid = data.pid[data.e_radius[0,subset_ind]] == batch.pid[data.e_radius[1,subset_ind]]\n",
    "                edge_true = y_pid.sum()\n",
    "                edge_true_positive = (y_pid & preds).sum().float()\n",
    "            else:\n",
    "                edge_true = data.y[subset_ind].sum()\n",
    "                edge_true_positive = (data.y[subset_ind].bool() & preds).sum().float()\n",
    "            \n",
    "            edge_total_positive += edge_positive\n",
    "            edge_total_true += edge_true\n",
    "            edge_total_true_positive += edge_true_positive\n",
    "            \n",
    "            if i % 5 == 0:\n",
    "                print(i, \"validated\")\n",
    "\n",
    "    edge_eff = (edge_total_true_positive / max(edge_total_true, 1))\n",
    "    edge_pur = (edge_total_true_positive / max(edge_total_positive, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9926, device='cuda:0'), tensor(0.1092, device='cuda:0'))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_eff, edge_pur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"oew8m1sj\"\n",
    "wandb_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/wandb_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run_path = get_best_run(run_id,wandb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpnt = torch.load(best_run_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SplitCheckpointedResAGNN(chkpnt[\"hyper_parameters\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally load the Weights & Biases logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filepath = os.path.join(\"/global/cscratch1/sd/danieltm/ExaTrkX/lightning_checkpoints\", chkpnt[\"hyper_parameters\"][\"project\"], run_id)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    filepath=model_filepath,\n",
    "    save_top_k=3,\n",
    "    save_last=True,\n",
    "    mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(project=chkpnt[\"hyper_parameters\"][\"project\"], group=\"LayerlessEndcaps\", save_dir = wandb_dir, id=run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(resume_from_checkpoint=best_run_path, max_epochs = chkpnt[\"hyper_parameters\"]['max_epochs'], gpus=1, logger=wandb_logger, checkpoint_callback=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmurnanedaniel\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /global/cscratch1/sd/danieltm/ExaTrkX/wandb_data/wandb/run-20201022_162229-oew8m1sj\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Resuming run \u001b[33musual-disco-51\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/murnanedaniel/GNNStudy\" target=\"_blank\">https://wandb.ai/murnanedaniel/GNNStudy</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/murnanedaniel/GNNStudy/runs/oew8m1sj\" target=\"_blank\">https://wandb.ai/murnanedaniel/GNNStudy/runs/oew8m1sj</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name         | Type       | Params\n",
      "--------------------------------------------\n",
      "0 | node_encoder | Sequential | 288   \n",
      "1 | edge_network | Sequential | 9 K   \n",
      "2 | node_network | Sequential | 9 K   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be5a61e246b4ad59ac2e28b8b6b244c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2aab18749cb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 962, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/global/homes/d/danieltm/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 942, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n",
      "Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExatrkxTest",
   "language": "python",
   "name": "exatrkx-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
