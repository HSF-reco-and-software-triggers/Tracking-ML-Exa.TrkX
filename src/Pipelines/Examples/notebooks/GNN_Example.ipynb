{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Metric Learning in Embedded Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "# External imports\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import auc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "sys.path.append('..')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example notebook for running GNN on connected TrackML hits\n",
    "\n",
    "- [ ] Load PyLightning model\n",
    "- [ ] Explain connected dataset\n",
    "- [ ] Plot an event graph\n",
    "- [ ] Explain GNN concept\n",
    "- [ ] Start by training GCN, 3 steps, no residuals\n",
    "- [ ] Examine performance\n",
    "- [ ] Loop over 1, 5, 8 steps also\n",
    "- [ ] Plot different performance metrics\n",
    "- [ ] Explain attention mechanism\n",
    "- [ ] Train AGNN on 1, 3, 5, 8 steps\n",
    "- [ ] Explain residuals\n",
    "- [ ] Train ResAGNN on 8 steps\n",
    "- [ ] Explain Connected Components\n",
    "- [ ] Visualise performance, including TrackML score\n",
    "- [ ] Explain problem with mislabelled edges and how the impact score\n",
    "- [ ] Visualise performance vs. num mislabelled edges\n",
    "- [ ] Explain goal with metric learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Lightning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the case of metric learning, we store all of the model logic in Pytorch Lightning modules. We import this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'LightningModules.GNN.Models.gcn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-777032022888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mLightningModules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVanillaGCN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'LightningModules.GNN.Models.gcn'"
     ]
    }
   ],
   "source": [
    "from LightningModules.GNN.Models.gcn import VanillaGCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct PyLightning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ML model typically has many knobs to turn, as well as locations of data, some training preferences, and so on. For convenience, let's put all of these parameters into a YAML file and load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"example_gnn.yaml\") as f:\n",
    "        hparams = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plug these parameters into a constructor of the `LayerlessEmbedding` Lightning Module. This doesn't **do** anything yet - merely creates the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VanillaGCN(hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This may take a minute or two, since the data is being trimmed to particles above a certain momentum threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise this data. It is generated from a trained embedding model. That is, it takes hits from (x,y,z)-space, runs them through an MLP, and returns some 8-dimensional co-ordinates. We hope that in this higher-dimensional space, hits from the same track can be found close together. To produce a graph from this embedded data, we simply find all neighbors of each hit within a certain radius `r`, and connect the center hit with each of those neighbors. This is the graph that accompanies each event in the dataset. Specifically, it is a \"COO\"-type graph, also called an edge list. It is a (2 x N) array, where each pair of indices points from one hit to another. It is a memory-efficient way to store a graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Visualise graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's visualise the graph that has been constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trainset = model.trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "example_data = trainset[0]\n",
    "r, phi, z = example_data.x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x, y = r*np.cos(phi*np.pi), r*np.sin(phi*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(x, y, s=2)\n",
    "plt.title(\"Azimuthal View of Detector\", fontsize=24), plt.xlabel(\"x\", fontsize=18), plt.ylabel(\"y\", fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This looks the same as before, which is good - we haven't lost any information in the pipeline. Let's draw an edge connected every hit that the embedding thought was close in the latent space. We'll start with all TRUE edges (i.e. edges that connect two hits from the same track, as defined by the particle ID `pid`) plotted in black. For FAKE edges, we'll plot it in red, and just plot around 20% of them, since there's so many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "e = example_data.edge_index\n",
    "pid = example_data.pid\n",
    "true_edges = pid[e[0]] == pid[e[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "# plt.plot(x[e[:, ~true_edges]], y[e[:, ~true_edges]], c=\"r\")\n",
    "plt.plot(x[e[:, true_edges]], y[e[:, true_edges]], c=\"k\")\n",
    "plt.scatter(x, y, s=5)\n",
    "plt.title(\"Azimuthal View of Detector\", fontsize=24), plt.xlabel(\"x\", fontsize=18), plt.ylabel(\"y\", fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "plt.plot(x[e[:, (~true_edges)][:, 0:-1:5]], y[e[:, (~true_edges)][:, 0:-1:5]], c=\"r\")\n",
    "plt.scatter(x, y, s=5)\n",
    "plt.title(\"Azimuthal View of Detector\", fontsize=24), plt.xlabel(\"x\", fontsize=18), plt.ylabel(\"y\", fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "These graphs are constructed from a 2xN list of hits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is a *directed* graph, since each edge goes only in one direction. This is to simply save space! We will want it to be undirected when we train the graph, and we'll see that soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Visualise distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's look at how many edges there are per node. This will give an idea about how \"connected\" the graph is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_, node_counts = np.unique(e.numpy(), return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.histplot(node_counts, binwidth=1)\n",
    "plt.title(\"Distribution of Edges per Node\", fontsize=24), plt.xlabel(\"Hits\", fontsize=18), plt.ylabel(\"Count\", fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This gives an idea about how long each particle track is. We can see that most particle tracks leave > 10 hits, which will be useful for our graph neural networks down the track. In general, shorter tracks are harder to detect, and less useful for doing meaningful physics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Graph Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A GNN is *exactly* like a CNN, but we ease the restriction of only convolving over a gridlike structure. For example, a CNN applied to a picture of a cat will associate pixels in a grid around its eye to understand what an \"eye\" is. A GNN does this same \"averaging\" or \"smoothing\" behavior but across any edges connected to each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/2324/1*oSQyFjtUkI7_u7lJXWU68Q.gif\" width=\"800\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train in exactly the same way as we trained the metric learning model. The only difference is that this trainer may take a little longer, since it is spreading information through a graph N times in each training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(gpus=1, max_epochs=50)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.test(ckpt_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LightningModules.GNN.utils import get_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well the model learned to classify edges. One thing to note about this performance: The GNN is doing a *harder job* than the embedding. The embedding was trying to learn the nearest neighbors in the graph of true tracks, but the GNN is learning to classify whether edges connect nodes in the same track. For many edges, these two things are the same thing, but some edges will connect hits at other points along the track. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(test_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_efficiencies, all_purities = [], []\n",
    "all_cuts = np.linspace(0., 1., 11)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cut in all_cuts:\n",
    "\n",
    "        model.hparams.edge_cut = cut\n",
    "        test_results = trainer.test(ckpt_path=None)\n",
    "        print(len(test_results))\n",
    "        mean_efficiency, mean_purity = get_metrics(test_results)\n",
    "\n",
    "        all_efficiencies.append(mean_efficiency)\n",
    "        all_purities.append(mean_purity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should always visualise two important metrics: the efficiency (the number of true positives divided by the total number of possible true edges) and the purity (the number of true positives divided by the number of predicted edges). Is it clear to you why the graphs below behave as they do, as we widen the sphere around each hit to generate neighboring edges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(all_cuts, all_efficiencies, label=\"Efficiency\");\n",
    "plt.plot(all_cuts, all_purities, label=\"Purity\");\n",
    "plt.legend()\n",
    "plt.title(\"Performance\", fontsize=24), plt.xlabel(\"Edge cut\", fontsize=18), plt.ylabel(\"Eff and Purity of GNN\", fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention is a way of allowing each node to pay more **attention** to some neighbors than others. This idea came from language transformers, and in fact if you view a translation as a graph, the two are exactly the same:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1682/1*xW7d7-y0MW5QjtGvyqZN4A.gif\" width=\"800\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, it means learning an **edge weight** for each edge, which we include in the sum over each node. In our case, since we want to then use the edges as a score, we make it do double-duty as an attention weight **and** the output score predicting whether the edge is true or not. Turns out, it works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/2204/1*ABkaR2glZNP6oh08oY4l-Q.png\" width=\"800\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LightningModules.GNN.Models.agnn import ResAGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"example_gnn.yaml\") as f:\n",
    "        hparams = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ResAGNN(hparams)\n",
    "trainer = Trainer(gpus=1, max_epochs=20)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took longer to train, right? This is because there are now **two** networks; a node network that runs an MLP over the node hidden features, and an edge network that runs the node features on either end of an edge through an MLP to get the edge weight (or score) at each step of message passing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fc0daab7624d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "test_results = trainer.test(ckpt_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'LightningModules.GNN.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1f1b20c7e9a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mLightningModules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'LightningModules.GNN.utils'"
     ]
    }
   ],
   "source": [
    "from LightningModules.GNN.utils import get_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well the model learned to classify edges. One thing to note about this performance: The GNN is doing a *harder job* than the embedding. The embedding was trying to learn the nearest neighbors in the graph of true tracks, but the GNN is learning to classify whether edges connect nodes in the same track. For many edges, these two things are the same thing, but some edges will connect hits at other points along the track. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/j/jferguso/.conda/envs/exatrkx-tracking/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/global/homes/j/jferguso/.conda/envs/exatrkx-tracking/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(nan, nan)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 20/20 [00:01<00:00, 18.33it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'current_lr': 8.999999408842996e-05,\n",
      " 'eff': 1.0,\n",
      " 'loss': 0.3125014007091522,\n",
      " 'preds': array([ True,  True,  True, ...,  True,  True,  True]),\n",
      " 'pur': 0.36627092957496643,\n",
      " 'truth': array([0., 1., 0., ..., 0., 1., 1.], dtype=float32),\n",
      " 'val_loss': 0.3161224126815796}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 20/20 [00:01<00:00, 18.34it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'current_lr': 8.999999408842996e-05,\n",
      " 'eff': 0.9895049929618835,\n",
      " 'loss': 0.3125014007091522,\n",
      " 'preds': array([False, False, False, ...,  True,  True,  True]),\n",
      " 'pur': 0.5996785163879395,\n",
      " 'truth': array([0., 1., 0., ..., 0., 1., 1.], dtype=float32),\n",
      " 'val_loss': 0.316122442483902}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 20/20 [00:01<00:00, 18.38it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'current_lr': 8.999999408842996e-05,\n",
      " 'eff': 0.9749113321304321,\n",
      " 'loss': 0.31250134110450745,\n",
      " 'preds': array([False, False, False, ...,  True,  True,  True]),\n",
      " 'pur': 0.6632611155509949,\n",
      " 'truth': array([0., 1., 0., ..., 0., 1., 1.], dtype=float32),\n",
      " 'val_loss': 0.3161224126815796}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 20/20 [00:01<00:00, 18.41it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'current_lr': 8.999999408842996e-05,\n",
      " 'eff': 0.955672025680542,\n",
      " 'loss': 0.31250134110450745,\n",
      " 'preds': array([False, False, False, ...,  True,  True,  True]),\n",
      " 'pur': 0.7192283868789673,\n",
      " 'truth': array([0., 1., 0., ..., 0., 1., 1.], dtype=float32),\n",
      " 'val_loss': 0.316122442483902}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 20/20 [00:01<00:00, 18.28it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'current_lr': 8.999999408842996e-05,\n",
      " 'eff': 0.9321851134300232,\n",
      " 'loss': 0.31250137090682983,\n",
      " 'preds': array([False, False, False, ...,  True,  True,  True]),\n",
      " 'pur': 0.7703326940536499,\n",
      " 'truth': array([0., 1., 0., ..., 0., 1., 1.], dtype=float32),\n",
      " 'val_loss': 0.316122442483902}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 20/20 [00:01<00:00, 18.04it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'current_lr': 8.999999408842996e-05,\n",
      " 'eff': 0.9053646326065063,\n",
      " 'loss': 0.3125014007091522,\n",
      " 'preds': array([False, False, False, ...,  True,  True,  True]),\n",
      " 'pur': 0.8162938952445984,\n",
      " 'truth': array([0., 1., 0., ..., 0., 1., 1.], dtype=float32),\n",
      " 'val_loss': 0.3161224126815796}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 20/20 [00:01<00:00, 18.23it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'current_lr': 8.999999408842996e-05,\n",
      " 'eff': 0.8736157417297363,\n",
      " 'loss': 0.31250134110450745,\n",
      " 'preds': array([False, False, False, ...,  True,  True,  True]),\n",
      " 'pur': 0.8562251329421997,\n",
      " 'truth': array([0., 1., 0., ..., 0., 1., 1.], dtype=float32),\n",
      " 'val_loss': 0.3161224126815796}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 20/20 [00:01<00:00, 18.35it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'current_lr': 8.999999408842996e-05,\n",
      " 'eff': 0.8354741930961609,\n",
      " 'loss': 0.31250134110450745,\n",
      " 'preds': array([False, False, False, ...,  True,  True,  True]),\n",
      " 'pur': 0.893399178981781,\n",
      " 'truth': array([0., 1., 0., ..., 0., 1., 1.], dtype=float32),\n",
      " 'val_loss': 0.316122442483902}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 20/20 [00:00<00:00, 20.54it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'current_lr': 8.999999408842996e-05,\n",
      " 'eff': 0.7850809693336487,\n",
      " 'loss': 0.31250131130218506,\n",
      " 'preds': array([False, False, False, ..., False,  True,  True]),\n",
      " 'pur': 0.9291943311691284,\n",
      " 'truth': array([0., 1., 0., ..., 0., 1., 1.], dtype=float32),\n",
      " 'val_loss': 0.3161224126815796}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 20/20 [00:01<00:00, 18.26it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'current_lr': 8.999999408842996e-05,\n",
      " 'eff': 0.7025582194328308,\n",
      " 'loss': 0.31250134110450745,\n",
      " 'preds': array([False, False, False, ..., False,  True,  True]),\n",
      " 'pur': 0.9629613757133484,\n",
      " 'truth': array([0., 1., 0., ..., 0., 1., 1.], dtype=float32),\n",
      " 'val_loss': 0.3161224126815796}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 20/20 [00:01<00:00, 18.25it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'current_lr': 8.999999408842996e-05,\n",
      " 'eff': 0.0,\n",
      " 'loss': 0.3125014007091522,\n",
      " 'preds': array([False, False, False, ..., False, False, False]),\n",
      " 'pur': nan,\n",
      " 'truth': array([0., 1., 0., ..., 0., 1., 1.], dtype=float32),\n",
      " 'val_loss': 0.316122442483902}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "all_efficiencies, all_purities = [], []\n",
    "all_cuts = np.linspace(0., 1., 11)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cut in all_cuts:\n",
    "\n",
    "        model.hparams.edge_cut = cut\n",
    "        test_results = trainer.test(ckpt_path=None)\n",
    "\n",
    "        mean_efficiency, mean_purity = get_metrics(test_results)\n",
    "        \n",
    "        all_efficiencies.append(mean_efficiency)\n",
    "        all_purities.append(mean_purity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that indeed the Attention mechanism improved performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(all_cuts, all_efficiencies, label=\"Efficiency\");\n",
    "plt.plot(all_cuts, all_purities, label=\"Purity\");\n",
    "plt.legend()\n",
    "plt.title(\"Performance\", fontsize=24), plt.xlabel(\"Edge cut\", fontsize=18), plt.ylabel(\"Eff and Purity of GNN\", fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train the Attention GNN for longer! This was just a very short example.\n",
    "1. Is there an effect on performance from the number of message passing steps (hopefully yes)?\n",
    "1. Is there any performance gain from increasing the number of hidden channels?\n",
    "2. What about *decreasing* the number of channels?\n",
    "3. What about increasing/decreasing the number of dimensions in the latent space?\n",
    "5. Play with the graph convolution! This can be found in the `forward` method of the `NodeNetwork` and `EdgeNetwork` classes. There are a million ways to combine edge features with node features, and there may be combinations that we haven't found yet!\n",
    "4. Is it possible to overtrain? That is, try increasing the number of epochs and seeing if the validation loss always decreases, plateaus, or starts to increase. **Hint**: to overtrain, try reducing the number of training examples to a small number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exatrkx-tracking",
   "language": "python",
   "name": "exatrkx-tracking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
