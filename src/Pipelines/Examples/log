Running from top with args: ['run_pipeline.py', '--verbose', 'configs/pipeline_codalab.yaml']
Running stage, with args, and model library: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules
Validation sanity check: 0it [00:00, ?it/s]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   3844.9 MiB   3844.9 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   3844.9 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   3852.0 MiB      7.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   3855.1 MiB      3.1 MiB           1       l2 = truth_graph.cpu().numpy()
   129   3868.9 MiB     13.8 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   3868.9 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   3868.9 MiB      0.0 MiB           1       del l1
   132                                             
   133   3871.5 MiB      2.6 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   3871.5 MiB      0.0 MiB           1       del e_1
   135   3871.5 MiB      0.0 MiB           1       del e_2
   136                                             
   137   3871.5 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   3871.5 MiB      0.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   3874.6 MiB      3.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   3874.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   3874.6 MiB      0.0 MiB           1       del e_intersection
   150                                             
   151   3874.6 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   3874.6 MiB      0.0 MiB           1           return new_pred_graph, y


Validation sanity check:  50%|████████████████████████████████████                                    | 1/2 [00:01<00:01,  1.51s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   3937.4 MiB   3937.4 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   3937.4 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   3937.4 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   3937.4 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   3937.4 MiB      0.0 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   3937.4 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   3937.4 MiB      0.0 MiB           1       del l1
   132                                             
   133   3937.4 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   3937.4 MiB      0.0 MiB           1       del e_1
   135   3937.4 MiB      0.0 MiB           1       del e_2
   136                                             
   137   3937.4 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   3937.4 MiB      0.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   3937.4 MiB      0.0 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   3937.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   3937.4 MiB      0.0 MiB           1       del e_intersection
   150                                             
   151   3937.4 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   3937.4 MiB      0.0 MiB           1           return new_pred_graph, y


Validation sanity check: 100%|████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.20s/it]                                                                                                                                    Training: 0it [00:00, ?it/s]Training finished, running inference to build graphs...
0.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   3891.4 MiB   3891.4 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   3891.4 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   3980.5 MiB     89.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   3980.5 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   4092.4 MiB    111.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   4092.4 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   4003.0 MiB    -89.4 MiB           1       del l1
   132                                             
   133   4070.1 MiB     67.1 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   3958.4 MiB   -111.7 MiB           1       del e_1
   135   3958.4 MiB      0.0 MiB           1       del e_2
   136                                             
   137   3958.4 MiB      0.0 MiB           1       if using_weights:
   138   3958.4 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   3958.4 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   3958.4 MiB      0.0 MiB           1           del weights_list
   141   3958.4 MiB      0.0 MiB           1           del l2
   142   4070.1 MiB    111.7 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   4070.1 MiB      0.0 MiB           1           del weights_sparse
   144   3980.8 MiB    -89.3 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   4047.7 MiB     66.9 MiB           1       e_intersection = e_intersection.tocoo()    
   147   4137.3 MiB     89.6 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   4137.3 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   4025.7 MiB   -111.6 MiB           1       del e_intersection
   150                                             
   151   4025.7 MiB      0.0 MiB           1       if using_weights:
   152   4025.7 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   3891.2 MiB   3891.2 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   3891.2 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   3891.2 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   3891.2 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   3891.2 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   3891.2 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   3891.3 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   3891.3 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   3891.3 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   3891.3 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   3891.3 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   3891.3 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   4025.7 MiB    134.4 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   4025.6 MiB     -0.1 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   4025.6 MiB      0.1 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   4070.2 MiB     44.6 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   4070.2 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   4070.2 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   4070.2 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   4070.2 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   4070.2 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   4070.3 MiB      0.1 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   4070.3 MiB      0.0 MiB           1           del e_spatial       
   194   4070.3 MiB      0.0 MiB           1           del e_bidir
   195   4070.3 MiB      0.0 MiB           1           del weights_bidir
   196   4070.3 MiB      0.0 MiB           1           del y_cluster
   197   3981.0 MiB    -89.3 MiB           1           del new_weights
   198                                                 
   199   3981.0 MiB      0.0 MiB           1           del batch
   200                                                 
   201   3981.0 MiB      0.0 MiB           1           gc.collect()


0.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   3981.0 MiB   3981.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   3981.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   4096.0 MiB    115.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   4096.0 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   4240.1 MiB    144.1 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   4240.1 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   4124.9 MiB   -115.2 MiB           1       del l1
   132                                             
   133   4211.3 MiB     86.4 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   4067.4 MiB   -143.9 MiB           1       del e_1
   135   4067.4 MiB      0.0 MiB           1       del e_2
   136                                             
   137   4067.4 MiB      0.0 MiB           1       if using_weights:
   138   4067.4 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   4067.4 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   4067.4 MiB      0.0 MiB           1           del weights_list
   141   4067.4 MiB      0.0 MiB           1           del l2
   142   4211.3 MiB    143.9 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   4211.3 MiB      0.0 MiB           1           del weights_sparse
   144   4096.2 MiB   -115.1 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   4182.5 MiB     86.3 MiB           1       e_intersection = e_intersection.tocoo()    
   147   4297.6 MiB    115.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   4297.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   4153.7 MiB   -143.9 MiB           1       del e_intersection
   150                                             
   151   4153.7 MiB      0.0 MiB           1       if using_weights:
   152   4153.7 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   3981.0 MiB   3981.0 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   3981.0 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   3981.0 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   3981.0 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   3981.0 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   3981.0 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   3981.0 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   3981.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   3981.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   3981.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   3981.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   3981.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   4153.7 MiB    172.7 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   4153.9 MiB      0.1 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   4153.9 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   4268.8 MiB    115.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   4268.8 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   4268.8 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   4268.8 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   4268.8 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   4268.8 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   4268.8 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   4268.8 MiB      0.0 MiB           1           del e_spatial       
   194   4268.8 MiB      0.0 MiB           1           del e_bidir
   195   4153.9 MiB   -114.9 MiB           1           del weights_bidir
   196   4153.9 MiB      0.0 MiB           1           del y_cluster
   197   4153.9 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   4153.9 MiB      0.0 MiB           1           del batch
   200                                                 
   201   4153.9 MiB      0.0 MiB           1           gc.collect()


1.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   4153.9 MiB   4153.9 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   4153.9 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   4235.7 MiB     81.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   4235.7 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   4301.1 MiB     65.4 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   4301.3 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   4219.3 MiB    -82.0 MiB           1       del l1
   132                                             
   133   4239.8 MiB     20.5 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   4137.4 MiB   -102.5 MiB           1       del e_1
   135   4137.4 MiB      0.0 MiB           1       del e_2
   136                                             
   137   4137.4 MiB      0.0 MiB           1       if using_weights:
   138   4137.4 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   4137.4 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   4137.4 MiB      0.0 MiB           1           del weights_list
   141   4137.4 MiB      0.0 MiB           1           del l2
   142   4178.4 MiB     41.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   4178.4 MiB      0.0 MiB           1           del weights_sparse
   144   4178.4 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   4260.1 MiB     81.7 MiB           1       e_intersection = e_intersection.tocoo()    
   147   4342.1 MiB     82.0 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   4342.1 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   4239.9 MiB   -102.2 MiB           1       del e_intersection
   150                                             
   151   4239.9 MiB      0.0 MiB           1       if using_weights:
   152   4239.9 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   4153.9 MiB   4153.9 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   4153.9 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   4153.9 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   4153.9 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   4153.9 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   4153.9 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   4153.9 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   4153.9 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   4153.9 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   4153.9 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   4153.9 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   4153.9 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   4239.9 MiB     86.0 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   4239.8 MiB     -0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   4239.8 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   4239.8 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   4239.8 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   4239.8 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   4239.8 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   4239.8 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   4239.8 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   4239.8 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   4239.8 MiB      0.0 MiB           1           del e_spatial       
   194   4239.8 MiB      0.0 MiB           1           del e_bidir
   195   4239.8 MiB      0.0 MiB           1           del weights_bidir
   196   4239.8 MiB      0.0 MiB           1           del y_cluster
   197   4178.3 MiB    -61.5 MiB           1           del new_weights
   198                                                 
   199   4178.3 MiB      0.0 MiB           1           del batch
   200                                                 
   201   4178.3 MiB      0.0 MiB           1           gc.collect()


2.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   4178.3 MiB   4178.3 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   4178.3 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   4312.9 MiB    134.6 MiB           1       l1 = pred_graph.cpu().numpy()
   128   4313.0 MiB      0.1 MiB           1       l2 = truth_graph.cpu().numpy()
   129   4414.1 MiB    101.0 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   4414.1 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   4279.3 MiB   -134.7 MiB           1       del l1
   132                                             
   133   4380.4 MiB    101.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   4279.3 MiB   -101.0 MiB           1       del e_1
   135   4279.3 MiB      0.0 MiB           1       del e_2
   136                                             
   137   4279.3 MiB      0.0 MiB           1       if using_weights:
   138   4279.3 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   4279.3 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   4279.3 MiB      0.0 MiB           1           del weights_list
   141   4279.3 MiB      0.0 MiB           1           del l2
   142   4313.0 MiB     33.7 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   4313.0 MiB      0.0 MiB           1           del weights_sparse
   144   4313.0 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   4346.7 MiB     33.7 MiB           1       e_intersection = e_intersection.tocoo()    
   147   4481.4 MiB    134.6 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   4481.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   4346.6 MiB   -134.7 MiB           1       del e_intersection
   150                                             
   151   4346.6 MiB      0.0 MiB           1       if using_weights:
   152   4346.6 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   4178.3 MiB   4178.3 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   4178.3 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   4178.3 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   4178.3 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   4178.3 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   4178.3 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   4178.3 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   4178.3 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   4178.3 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   4178.3 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   4178.3 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   4178.3 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   4346.6 MiB    168.3 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   4346.6 MiB     -0.1 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   4346.6 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   4346.7 MiB      0.1 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   4346.7 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   4346.7 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   4346.7 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   4346.7 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   4346.7 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   4346.7 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   4346.7 MiB      0.0 MiB           1           del e_spatial       
   194   4346.7 MiB      0.0 MiB           1           del e_bidir
   195   4346.7 MiB      0.0 MiB           1           del weights_bidir
   196   4346.7 MiB      0.0 MiB           1           del y_cluster
   197   4313.0 MiB    -33.7 MiB           1           del new_weights
   198                                                 
   199   4313.0 MiB      0.0 MiB           1           del batch
   200                                                 
   201   4313.0 MiB      0.0 MiB           1           gc.collect()


3.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   4313.0 MiB   4313.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   4313.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   4439.6 MiB    126.6 MiB           1       l1 = pred_graph.cpu().numpy()
   128   4439.6 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   4534.7 MiB     95.1 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   4534.7 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   4408.0 MiB   -126.7 MiB           1       del l1
   132                                             
   133   4502.9 MiB     94.9 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   4407.9 MiB    -95.0 MiB           1       del e_1
   135   4407.9 MiB      0.0 MiB           1       del e_2
   136                                             
   137   4407.9 MiB      0.0 MiB           1       if using_weights:
   138   4407.9 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   4407.9 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   4407.9 MiB      0.0 MiB           1           del weights_list
   141   4407.9 MiB      0.0 MiB           1           del l2
   142   4503.0 MiB     95.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   4503.0 MiB      0.0 MiB           1           del weights_sparse
   144   4439.6 MiB    -63.3 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   4534.5 MiB     94.9 MiB           1       e_intersection = e_intersection.tocoo()    
   147   4661.3 MiB    126.8 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   4661.3 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   4503.1 MiB   -158.2 MiB           1       del e_intersection
   150                                             
   151   4503.1 MiB      0.0 MiB           1       if using_weights:
   152   4503.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   4313.0 MiB   4313.0 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   4313.0 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   4313.0 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   4313.0 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   4313.0 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   4313.0 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   4313.0 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   4313.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   4313.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   4313.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   4313.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   4313.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   4503.1 MiB    190.1 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   4502.9 MiB     -0.2 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   4502.9 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   4502.9 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   4502.9 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   4502.9 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   4502.9 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   4502.9 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   4502.9 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   4502.9 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   4502.9 MiB      0.0 MiB           1           del e_spatial       
   194   4502.9 MiB      0.0 MiB           1           del e_bidir
   195   4502.9 MiB      0.0 MiB           1           del weights_bidir
   196   4502.9 MiB      0.0 MiB           1           del y_cluster
   197   4439.6 MiB    -63.3 MiB           1           del new_weights
   198                                                 
   199   4439.6 MiB      0.0 MiB           1           del batch
   200                                                 
   201   4439.6 MiB      0.0 MiB           1           gc.collect()


4.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   4439.6 MiB   4439.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   4439.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   4559.5 MiB    119.9 MiB           1       l1 = pred_graph.cpu().numpy()
   128   4559.5 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   4709.6 MiB    150.1 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   4709.6 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   4589.5 MiB   -120.0 MiB           1       del l1
   132                                             
   133   4679.6 MiB     90.1 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   4529.6 MiB   -149.9 MiB           1       del e_1
   135   4529.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   4529.6 MiB      0.0 MiB           1       if using_weights:
   138   4529.6 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   4529.6 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   4529.6 MiB      0.0 MiB           1           del weights_list
   141   4529.6 MiB      0.0 MiB           1           del l2
   142   4679.4 MiB    149.8 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   4679.4 MiB      0.0 MiB           1           del weights_sparse
   144   4559.6 MiB   -119.8 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   4649.5 MiB     89.9 MiB           1       e_intersection = e_intersection.tocoo()    
   147   4769.6 MiB    120.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   4769.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   4619.7 MiB   -149.9 MiB           1       del e_intersection
   150                                             
   151   4619.7 MiB      0.0 MiB           1       if using_weights:
   152   4619.7 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   4439.6 MiB   4439.6 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   4439.6 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   4439.6 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   4439.6 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   4439.6 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   4439.6 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   4439.6 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   4439.6 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   4439.6 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   4439.6 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   4439.6 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   4439.6 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   4619.7 MiB    180.1 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   4619.8 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   4619.8 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   4769.5 MiB    149.8 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   4769.5 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   4769.5 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   4769.5 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   4769.5 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   4769.5 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   4769.6 MiB      0.1 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   4769.6 MiB      0.0 MiB           1           del e_spatial       
   194   4769.6 MiB      0.0 MiB           1           del e_bidir
   195   4769.6 MiB      0.0 MiB           1           del weights_bidir
   196   4769.6 MiB      0.0 MiB           1           del y_cluster
   197   4769.6 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   4769.6 MiB      0.0 MiB           1           del batch
   200                                                 
   201   4769.6 MiB      0.0 MiB           1           gc.collect()


5.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   4769.6 MiB   4769.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   4769.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   4769.6 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   4769.6 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   4832.3 MiB     62.7 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   4832.6 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   4832.6 MiB      0.0 MiB           1       del l1
   132                                             
   133   4832.6 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   4786.1 MiB    -46.5 MiB           1       del e_1
   135   4786.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   4786.1 MiB      0.0 MiB           1       if using_weights:
   138   4786.1 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   4786.1 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   4786.1 MiB      0.0 MiB           1           del weights_list
   141   4786.1 MiB      0.0 MiB           1           del l2
   142   4786.1 MiB      0.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   4786.1 MiB      0.0 MiB           1           del weights_sparse
   144   4786.1 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   4832.5 MiB     46.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   4925.5 MiB     93.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   4925.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   4879.2 MiB    -46.3 MiB           1       del e_intersection
   150                                             
   151   4879.2 MiB      0.0 MiB           1       if using_weights:
   152   4879.2 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   4769.6 MiB   4769.6 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   4769.6 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   4769.6 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   4769.6 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   4769.6 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   4769.6 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   4769.6 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   4769.6 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   4769.6 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   4769.6 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   4769.6 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   4769.6 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   4879.2 MiB    109.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   4879.2 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   4879.2 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   4879.2 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   4879.2 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   4879.2 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   4879.2 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   4879.2 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   4879.2 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   4879.2 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   4879.2 MiB      0.0 MiB           1           del e_spatial       
   194   4722.5 MiB   -156.7 MiB           1           del e_bidir
   195   4722.5 MiB      0.0 MiB           1           del weights_bidir
   196   4722.5 MiB      0.0 MiB           1           del y_cluster
   197   4652.8 MiB    -69.7 MiB           1           del new_weights
   198                                                 
   199   4652.8 MiB      0.0 MiB           1           del batch
   200                                                 
   201   4652.8 MiB      0.0 MiB           1           gc.collect()


5.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   4652.8 MiB   4652.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   4652.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   4727.5 MiB     74.7 MiB           1       l1 = pred_graph.cpu().numpy()
   128   4727.7 MiB      0.1 MiB           1       l2 = truth_graph.cpu().numpy()
   129   4821.1 MiB     93.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   4821.1 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   4746.2 MiB    -74.9 MiB           1       del l1
   132                                             
   133   4802.4 MiB     56.2 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   4765.0 MiB    -37.4 MiB           1       del e_1
   135   4765.0 MiB      0.0 MiB           1       del e_2
   136                                             
   137   4765.0 MiB      0.0 MiB           1       if using_weights:
   138   4765.0 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   4765.0 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   4765.0 MiB      0.0 MiB           1           del weights_list
   141   4765.0 MiB      0.0 MiB           1           del l2
   142   4802.2 MiB     37.2 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   4802.2 MiB      0.0 MiB           1           del weights_sparse
   144   4727.7 MiB    -74.5 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   4783.7 MiB     56.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   4858.5 MiB     74.8 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   4858.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   4821.1 MiB    -37.4 MiB           1       del e_intersection
   150                                             
   151   4821.1 MiB      0.0 MiB           1       if using_weights:
   152   4821.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   4652.8 MiB   4652.8 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   4652.8 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   4652.8 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   4652.8 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   4652.8 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   4652.8 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   4652.8 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   4652.8 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   4652.8 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   4652.8 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   4652.8 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   4652.8 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   4821.1 MiB    168.3 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   4821.1 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   4821.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   4858.4 MiB     37.3 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   4858.4 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   4858.4 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   4858.4 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   4858.4 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   4858.4 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   4858.4 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   4858.4 MiB      0.0 MiB           1           del e_spatial       
   194   4858.4 MiB      0.0 MiB           1           del e_bidir
   195   4764.9 MiB    -93.5 MiB           1           del weights_bidir
   196   4764.9 MiB      0.0 MiB           1           del y_cluster
   197   4764.9 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   4764.9 MiB      0.0 MiB           1           del batch
   200                                                 
   201   4764.9 MiB      0.0 MiB           1           gc.collect()


6.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   4764.9 MiB   4764.9 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   4764.9 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   4872.1 MiB    107.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   4872.1 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   4969.1 MiB     97.0 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   4969.1 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   4861.7 MiB   -107.4 MiB           1       del l1
   132                                             
   133   4942.3 MiB     80.6 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   4808.1 MiB   -134.2 MiB           1       del e_1
   135   4808.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   4808.1 MiB      0.0 MiB           1       if using_weights:
   138   4808.1 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   4808.1 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   4808.1 MiB      0.0 MiB           1           del weights_list
   141   4808.1 MiB      0.0 MiB           1           del l2
   142   4942.1 MiB    134.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   4942.1 MiB      0.0 MiB           1           del weights_sparse
   144   4834.9 MiB   -107.2 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   4915.4 MiB     80.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   5022.7 MiB    107.3 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   5022.7 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   4888.6 MiB   -134.2 MiB           1       del e_intersection
   150                                             
   151   4888.6 MiB      0.0 MiB           1       if using_weights:
   152   4888.6 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   4764.9 MiB   4764.9 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   4764.9 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   4764.9 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   4764.9 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   4764.9 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   4764.9 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   4764.9 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   4764.9 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   4764.9 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   4764.9 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   4764.9 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   4764.9 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   4888.6 MiB    123.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   4888.7 MiB      0.2 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   4888.7 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   4942.1 MiB     53.4 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   4942.1 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   4942.1 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   4942.1 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   4942.1 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   4942.1 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   4942.3 MiB      0.2 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   4942.3 MiB      0.0 MiB           1           del e_spatial       
   194   4942.3 MiB      0.0 MiB           1           del e_bidir
   195   4942.3 MiB      0.0 MiB           1           del weights_bidir
   196   4942.3 MiB      0.0 MiB           1           del y_cluster
   197   4835.0 MiB   -107.3 MiB           1           del new_weights
   198                                                 
   199   4835.0 MiB      0.0 MiB           1           del batch
   200                                                 
   201   4835.0 MiB      0.0 MiB           1           gc.collect()


7.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   4835.0 MiB   4835.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   4835.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   4927.8 MiB     92.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   4927.8 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   5044.2 MiB    116.4 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   5044.2 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   4951.1 MiB    -93.0 MiB           1       del l1
   132                                             
   133   5020.9 MiB     69.8 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   4904.8 MiB   -116.2 MiB           1       del e_1
   135   4904.8 MiB      0.0 MiB           1       del e_2
   136                                             
   137   4904.8 MiB      0.0 MiB           1       if using_weights:
   138   4904.8 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   4904.8 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   4904.8 MiB      0.0 MiB           1           del weights_list
   141   4904.8 MiB      0.0 MiB           1           del l2
   142   5020.8 MiB    116.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   5020.8 MiB      0.0 MiB           1           del weights_sparse
   144   4928.0 MiB    -92.8 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   4997.7 MiB     69.6 MiB           1       e_intersection = e_intersection.tocoo()    
   147   5090.6 MiB     92.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   5090.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   4974.4 MiB   -116.2 MiB           1       del e_intersection
   150                                             
   151   4974.4 MiB      0.0 MiB           1       if using_weights:
   152   4974.4 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   4835.0 MiB   4835.0 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   4835.0 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   4835.0 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   4835.0 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   4835.0 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   4835.0 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   4835.0 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   4835.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   4835.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   4835.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   4835.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   4835.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   4974.4 MiB    139.4 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   4974.5 MiB      0.1 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   4974.5 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   5020.7 MiB     46.1 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   5020.7 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   5020.7 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   5020.7 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   5020.7 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   5020.7 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   5020.9 MiB      0.2 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   5020.9 MiB      0.0 MiB           1           del e_spatial       
   194   5020.9 MiB      0.0 MiB           1           del e_bidir
   195   5020.9 MiB      0.0 MiB           1           del weights_bidir
   196   5020.9 MiB      0.0 MiB           1           del y_cluster
   197   4928.0 MiB    -92.9 MiB           1           del new_weights
   198                                                 
   199   4928.0 MiB      0.0 MiB           1           del batch
   200                                                 
   201   4928.0 MiB      0.0 MiB           1           gc.collect()


8.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   4928.0 MiB   4928.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   4928.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   5045.6 MiB    117.6 MiB           1       l1 = pred_graph.cpu().numpy()
   128   5045.6 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   5192.6 MiB    147.0 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   5192.6 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   5074.9 MiB   -117.6 MiB           1       del l1
   132                                             
   133   5163.2 MiB     88.3 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   5016.2 MiB   -147.0 MiB           1       del e_1
   135   5016.2 MiB      0.0 MiB           1       del e_2
   136                                             
   137   5016.2 MiB      0.0 MiB           1       if using_weights:
   138   5016.2 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   5016.2 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   5016.2 MiB      0.0 MiB           1           del weights_list
   141   5016.2 MiB      0.0 MiB           1           del l2
   142   5075.0 MiB     58.8 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   5075.0 MiB      0.0 MiB           1           del weights_sparse
   144   5075.0 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   5133.7 MiB     58.7 MiB           1       e_intersection = e_intersection.tocoo()    
   147   5251.3 MiB    117.6 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   5251.3 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   5104.4 MiB   -146.9 MiB           1       del e_intersection
   150                                             
   151   5104.4 MiB      0.0 MiB           1       if using_weights:
   152   5104.4 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   4928.0 MiB   4928.0 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   4928.0 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   4928.0 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   4928.0 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   4928.0 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   4928.0 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   4928.0 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   4928.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   4928.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   4928.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   4928.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   4928.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   5104.4 MiB    176.4 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   5104.4 MiB     -0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   5104.4 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   5221.7 MiB    117.3 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   5221.7 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   5221.7 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   5221.7 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   5221.7 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   5221.7 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   5221.9 MiB      0.2 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   5221.9 MiB      0.0 MiB           1           del e_spatial       
   194   5221.9 MiB      0.0 MiB           1           del e_bidir
   195   5104.3 MiB   -117.5 MiB           1           del weights_bidir
   196   5104.3 MiB      0.0 MiB           1           del y_cluster
   197   5104.3 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   5104.3 MiB      0.0 MiB           1           del batch
   200                                                 
   201   5104.3 MiB      0.0 MiB           1           gc.collect()


9.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   5104.3 MiB   5104.3 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   5104.3 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   5184.2 MiB     79.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   5184.2 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   5265.1 MiB     81.0 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   5265.3 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   5185.3 MiB    -80.0 MiB           1       del l1
   132                                             
   133   5205.3 MiB     20.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   5165.3 MiB    -40.0 MiB           1       del e_1
   135   5165.3 MiB      0.0 MiB           1       del e_2
   136                                             
   137   5165.3 MiB      0.0 MiB           1       if using_weights:
   138   5165.3 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   5165.3 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   5165.3 MiB      0.0 MiB           1           del weights_list
   141   5165.3 MiB      0.0 MiB           1           del l2
   142   5145.5 MiB    -19.9 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   5145.5 MiB      0.0 MiB           1           del weights_sparse
   144   5145.5 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   5225.1 MiB     79.7 MiB           1       e_intersection = e_intersection.tocoo()    
   147   5305.3 MiB     80.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   5305.3 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   5265.5 MiB    -39.8 MiB           1       del e_intersection
   150                                             
   151   5265.5 MiB      0.0 MiB           1       if using_weights:
   152   5265.5 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   5104.3 MiB   5104.3 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   5104.3 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   5104.3 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   5104.3 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   5104.3 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   5104.3 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   5104.3 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   5104.3 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   5104.3 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   5104.3 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   5104.3 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   5104.3 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   5265.5 MiB    161.2 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   5265.5 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   5265.5 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   5265.5 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   5265.5 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   5265.5 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   5265.5 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   5265.5 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   5265.5 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   5265.5 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   5265.5 MiB      0.0 MiB           1           del e_spatial       
   194   5265.5 MiB      0.0 MiB           1           del e_bidir
   195   5265.5 MiB      0.0 MiB           1           del weights_bidir
   196   5265.5 MiB      0.0 MiB           1           del y_cluster
   197   5265.5 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   5265.5 MiB      0.0 MiB           1           del batch
   200                                                 
   201   5265.5 MiB      0.0 MiB           1           gc.collect()


10.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   5265.5 MiB   5265.5 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   5265.5 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   5265.5 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   5265.5 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   5382.4 MiB    116.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   5382.4 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   5382.4 MiB      0.0 MiB           1       del l1
   132                                             
   133   5382.4 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   5327.6 MiB    -54.8 MiB           1       del e_1
   135   5327.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   5327.6 MiB      0.0 MiB           1       if using_weights:
   138   5327.6 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   5327.6 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   5327.6 MiB      0.0 MiB           1           del weights_list
   141   5327.6 MiB      0.0 MiB           1           del l2
   142   5355.0 MiB     27.3 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   5355.0 MiB      0.0 MiB           1           del weights_sparse
   144   5355.0 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   5409.6 MiB     54.7 MiB           1       e_intersection = e_intersection.tocoo()    
   147   5518.9 MiB    109.3 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   5518.9 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   5355.0 MiB   -163.9 MiB           1       del e_intersection
   150                                             
   151   5355.0 MiB      0.0 MiB           1       if using_weights:
   152   5355.0 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   5265.5 MiB   5265.5 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   5265.5 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   5265.5 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   5265.5 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   5265.5 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   5265.5 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   5265.5 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   5265.5 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   5265.5 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   5265.5 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   5265.5 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   5265.5 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   5355.0 MiB     89.5 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   5355.0 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   5355.0 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   5409.4 MiB     54.4 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   5409.4 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   5409.4 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   5409.4 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   5409.4 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   5409.4 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   5409.6 MiB      0.2 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   5409.6 MiB      0.0 MiB           1           del e_spatial       
   194   5317.2 MiB    -92.4 MiB           1           del e_bidir
   195   5317.2 MiB      0.0 MiB           1           del weights_bidir
   196   5317.2 MiB      0.0 MiB           1           del y_cluster
   197   5317.2 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   5317.2 MiB      0.0 MiB           1           del batch
   200                                                 
   201   5317.2 MiB      0.0 MiB           1           gc.collect()


10.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   5235.1 MiB   5235.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   5235.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   5296.7 MiB     61.6 MiB           1       l1 = pred_graph.cpu().numpy()
   128   5296.7 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   5404.6 MiB    107.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   5404.6 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   5342.9 MiB    -61.7 MiB           1       del l1
   132                                             
   133   5388.6 MiB     45.6 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   5281.4 MiB   -107.2 MiB           1       del e_1
   135   5281.4 MiB      0.0 MiB           1       del e_2
   136                                             
   137   5281.4 MiB      0.0 MiB           1       if using_weights:
   138   5281.4 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   5281.4 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   5281.4 MiB      0.0 MiB           1           del weights_list
   141   5281.4 MiB      0.0 MiB           1           del l2
   142   5358.2 MiB     76.8 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   5358.2 MiB      0.0 MiB           1           del weights_sparse
   144   5358.2 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   5373.7 MiB     15.5 MiB           1       e_intersection = e_intersection.tocoo()    
   147   5435.5 MiB     61.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   5435.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   5358.6 MiB    -77.0 MiB           1       del e_intersection
   150                                             
   151   5358.6 MiB      0.0 MiB           1       if using_weights:
   152   5358.6 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   5317.2 MiB   5317.2 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   5317.2 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   5317.2 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   5317.2 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   5317.2 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   5317.2 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   5317.2 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   5317.2 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   5235.1 MiB    -82.1 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   5235.1 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   5235.1 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   5235.1 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   5358.6 MiB    123.5 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   5358.6 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   5358.6 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   5373.8 MiB     15.2 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   5373.8 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   5373.8 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   5373.8 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   5373.8 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   5373.8 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   5373.9 MiB      0.1 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   5373.9 MiB      0.0 MiB           1           del e_spatial       
   194   5373.9 MiB      0.0 MiB           1           del e_bidir
   195   5373.9 MiB      0.0 MiB           1           del weights_bidir
   196   5373.9 MiB      0.0 MiB           1           del y_cluster
   197   5296.9 MiB    -77.0 MiB           1           del new_weights
   198                                                 
   199   5296.9 MiB      0.0 MiB           1           del batch
   200                                                 
   201   5296.9 MiB      0.0 MiB           1           gc.collect()


11.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   5296.9 MiB   5296.9 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   5296.9 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   5418.3 MiB    121.4 MiB           1       l1 = pred_graph.cpu().numpy()
   128   5418.3 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   5570.2 MiB    152.0 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   5570.2 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   5448.7 MiB   -121.5 MiB           1       del l1
   132                                             
   133   5539.9 MiB     91.2 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   5388.1 MiB   -151.8 MiB           1       del e_1
   135   5388.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   5388.1 MiB      0.0 MiB           1       if using_weights:
   138   5388.1 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   5388.1 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   5388.1 MiB      0.0 MiB           1           del weights_list
   141   5388.1 MiB      0.0 MiB           1           del l2
   142   5448.8 MiB     60.8 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   5448.8 MiB      0.0 MiB           1           del weights_sparse
   144   5448.8 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   5509.5 MiB     60.6 MiB           1       e_intersection = e_intersection.tocoo()    
   147   5630.8 MiB    121.4 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   5630.8 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   5479.0 MiB   -151.8 MiB           1       del e_intersection
   150                                             
   151   5479.0 MiB      0.0 MiB           1       if using_weights:
   152   5479.0 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   5296.9 MiB   5296.9 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   5296.9 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   5296.9 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   5296.9 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   5296.9 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   5296.9 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   5296.9 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   5296.9 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   5296.9 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   5296.9 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   5296.9 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   5296.9 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   5479.0 MiB    182.1 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   5479.1 MiB      0.1 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   5479.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   5479.1 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   5479.1 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   5479.1 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   5479.1 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   5479.1 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   5479.1 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   5479.1 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   5479.1 MiB      0.0 MiB           1           del e_spatial       
   194   5479.1 MiB      0.0 MiB           1           del e_bidir
   195   5479.1 MiB      0.0 MiB           1           del weights_bidir
   196   5479.1 MiB      0.0 MiB           1           del y_cluster
   197   5479.1 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   5479.1 MiB      0.0 MiB           1           del batch
   200                                                 
   201   5479.1 MiB      0.0 MiB           1           gc.collect()


12.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   5479.1 MiB   5479.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   5479.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   5597.2 MiB    118.1 MiB           1       l1 = pred_graph.cpu().numpy()
   128   5597.2 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   5743.1 MiB    145.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   5743.3 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   5625.1 MiB   -118.2 MiB           1       del l1
   132                                             
   133   5654.6 MiB     29.6 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   5507.0 MiB   -147.6 MiB           1       del e_1
   135   5507.0 MiB      0.0 MiB           1       del e_2
   136                                             
   137   5507.0 MiB      0.0 MiB           1       if using_weights:
   138   5507.0 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   5507.0 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   5507.0 MiB      0.0 MiB           1           del weights_list
   141   5507.0 MiB      0.0 MiB           1           del l2
   142   5566.1 MiB     59.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   5566.1 MiB      0.0 MiB           1           del weights_sparse
   144   5566.1 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   5683.9 MiB    117.8 MiB           1       e_intersection = e_intersection.tocoo()    
   147   5802.3 MiB    118.3 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   5802.3 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   5654.7 MiB   -147.6 MiB           1       del e_intersection
   150                                             
   151   5654.7 MiB      0.0 MiB           1       if using_weights:
   152   5654.7 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   5479.1 MiB   5479.1 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   5479.1 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   5479.1 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   5479.1 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   5479.1 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   5479.1 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   5479.1 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   5479.1 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   5479.1 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   5479.1 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   5479.1 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   5479.1 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   5654.7 MiB    175.5 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   5654.7 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   5654.7 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   5713.5 MiB     58.8 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   5713.5 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   5713.5 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   5713.5 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   5713.5 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   5713.5 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   5713.6 MiB      0.1 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   5713.6 MiB      0.0 MiB           1           del e_spatial       
   194   5713.6 MiB      0.0 MiB           1           del e_bidir
   195   5713.6 MiB      0.0 MiB           1           del weights_bidir
   196   5713.6 MiB      0.0 MiB           1           del y_cluster
   197   5536.4 MiB   -177.1 MiB           1           del new_weights
   198                                                 
   199   5536.4 MiB      0.0 MiB           1           del batch
   200                                                 
   201   5536.4 MiB      0.0 MiB           1           gc.collect()


13.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   5536.4 MiB   5536.4 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   5536.4 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   5641.6 MiB    105.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   5641.6 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   5773.0 MiB    131.4 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   5773.0 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   5667.8 MiB   -105.2 MiB           1       del l1
   132                                             
   133   5746.7 MiB     78.9 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   5615.3 MiB   -131.4 MiB           1       del e_1
   135   5615.3 MiB      0.0 MiB           1       del e_2
   136                                             
   137   5615.3 MiB      0.0 MiB           1       if using_weights:
   138   5615.3 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   5615.3 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   5615.3 MiB      0.0 MiB           1           del weights_list
   141   5615.3 MiB      0.0 MiB           1           del l2
   142   5667.9 MiB     52.6 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   5667.9 MiB      0.0 MiB           1           del weights_sparse
   144   5667.9 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   5720.4 MiB     52.5 MiB           1       e_intersection = e_intersection.tocoo()    
   147   5825.6 MiB    105.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   5825.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   5694.2 MiB   -131.4 MiB           1       del e_intersection
   150                                             
   151   5694.2 MiB      0.0 MiB           1       if using_weights:
   152   5694.2 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   5536.4 MiB   5536.4 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   5536.4 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   5536.4 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   5536.4 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   5536.4 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   5536.4 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   5536.4 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   5536.4 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   5536.4 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   5536.4 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   5536.4 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   5536.4 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   5694.2 MiB    157.8 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   5694.2 MiB     -0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   5694.2 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   5825.4 MiB    131.2 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   5825.4 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   5825.4 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   5825.4 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   5825.4 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   5825.4 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   5825.6 MiB      0.1 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   5825.6 MiB      0.0 MiB           1           del e_spatial       
   194   5825.6 MiB      0.0 MiB           1           del e_bidir
   195   5825.6 MiB      0.0 MiB           1           del weights_bidir
   196   5825.6 MiB      0.0 MiB           1           del y_cluster
   197   5825.6 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   5825.6 MiB      0.0 MiB           1           del batch
   200                                                 
   201   5825.6 MiB      0.0 MiB           1           gc.collect()


14.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   5825.6 MiB   5825.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   5825.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   5825.6 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   5825.6 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   5915.0 MiB     89.4 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   5915.1 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   5915.1 MiB      0.0 MiB           1       del l1
   132                                             
   133   5915.1 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   5868.8 MiB    -46.3 MiB           1       del e_1
   135   5868.8 MiB      0.0 MiB           1       del e_2
   136                                             
   137   5868.8 MiB      0.0 MiB           1       if using_weights:
   138   5868.8 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   5868.8 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   5868.8 MiB      0.0 MiB           1           del weights_list
   141   5868.8 MiB      0.0 MiB           1           del l2
   142   5868.8 MiB      0.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   5868.8 MiB      0.0 MiB           1           del weights_sparse
   144   5868.8 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   5868.8 MiB      0.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   5961.5 MiB     92.7 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   5961.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   5892.1 MiB    -69.4 MiB           1       del e_intersection
   150                                             
   151   5892.1 MiB      0.0 MiB           1       if using_weights:
   152   5892.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   5825.6 MiB   5825.6 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   5825.6 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   5825.6 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   5825.6 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   5825.6 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   5825.6 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   5825.6 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   5825.6 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   5825.6 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   5825.6 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   5825.6 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   5825.6 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   5892.1 MiB     66.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   5892.1 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   5892.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   5896.3 MiB      4.1 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   5896.3 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   5896.3 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   5896.3 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   5896.3 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   5896.3 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   5896.4 MiB      0.2 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   5896.4 MiB      0.0 MiB           1           del e_spatial       
   194   5896.4 MiB      0.0 MiB           1           del e_bidir
   195   5896.4 MiB      0.0 MiB           1           del weights_bidir
   196   5896.4 MiB      0.0 MiB           1           del y_cluster
   197   5734.4 MiB   -162.1 MiB           1           del new_weights
   198                                                 
   199   5734.4 MiB      0.0 MiB           1           del batch
   200                                                 
   201   5734.4 MiB      0.0 MiB           1           gc.collect()


15.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   5734.4 MiB   5734.4 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   5734.4 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   5848.1 MiB    113.7 MiB           1       l1 = pred_graph.cpu().numpy()
   128   5848.1 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   5990.5 MiB    142.4 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   5990.5 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   5876.6 MiB   -113.9 MiB           1       del l1
   132                                             
   133   5962.0 MiB     85.4 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   5819.8 MiB   -142.2 MiB           1       del e_1
   135   5819.8 MiB      0.0 MiB           1       del e_2
   136                                             
   137   5819.8 MiB      0.0 MiB           1       if using_weights:
   138   5819.8 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   5819.8 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   5819.8 MiB      0.0 MiB           1           del weights_list
   141   5819.8 MiB      0.0 MiB           1           del l2
   142   5876.7 MiB     56.9 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   5876.7 MiB      0.0 MiB           1           del weights_sparse
   144   5876.7 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   5933.5 MiB     56.8 MiB           1       e_intersection = e_intersection.tocoo()    
   147   6047.4 MiB    113.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   6047.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   5905.2 MiB   -142.2 MiB           1       del e_intersection
   150                                             
   151   5905.2 MiB      0.0 MiB           1       if using_weights:
   152   5905.2 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   5734.4 MiB   5734.4 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   5734.4 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   5734.4 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   5734.4 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   5734.4 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   5734.4 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   5734.4 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   5734.4 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   5734.4 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   5734.4 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   5734.4 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   5734.4 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   5905.2 MiB    170.9 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   5905.2 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   5905.2 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   5905.1 MiB     -0.1 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   5905.1 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   5905.1 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   5905.1 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   5905.1 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   5905.1 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   5905.1 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   5905.1 MiB      0.0 MiB           1           del e_spatial       
   194   5905.1 MiB      0.0 MiB           1           del e_bidir
   195   5905.1 MiB      0.0 MiB           1           del weights_bidir
   196   5905.1 MiB      0.0 MiB           1           del y_cluster
   197   5905.1 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   5905.1 MiB      0.0 MiB           1           del batch
   200                                                 
   201   5905.1 MiB      0.0 MiB           1           gc.collect()


15.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   5905.1 MiB   5905.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   5905.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   6012.9 MiB    107.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   6012.9 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   6145.1 MiB    132.2 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   6145.1 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   6037.1 MiB   -108.0 MiB           1       del l1
   132                                             
   133   6064.1 MiB     27.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   5929.2 MiB   -134.9 MiB           1       del e_1
   135   5929.2 MiB      0.0 MiB           1       del e_2
   136                                             
   137   5929.2 MiB      0.0 MiB           1       if using_weights:
   138   5929.2 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   5929.2 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   5929.2 MiB      0.0 MiB           1           del weights_list
   141   5929.2 MiB      0.0 MiB           1           del l2
   142   5983.2 MiB     54.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   5983.2 MiB      0.0 MiB           1           del weights_sparse
   144   5983.2 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   6091.0 MiB    107.8 MiB           1       e_intersection = e_intersection.tocoo()    
   147   6199.3 MiB    108.3 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   6199.3 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   6064.4 MiB   -134.9 MiB           1       del e_intersection
   150                                             
   151   6064.4 MiB      0.0 MiB           1       if using_weights:
   152   6064.4 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   5905.1 MiB   5905.1 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   5905.1 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   5905.1 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   5905.1 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   5905.1 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   5905.1 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   5905.1 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   5905.1 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   5905.1 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   5905.1 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   5905.1 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   5905.1 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   6064.4 MiB    159.2 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   6064.4 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   6064.4 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   6118.2 MiB     53.9 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   6118.2 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   6118.2 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   6118.2 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   6118.2 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   6118.2 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   6118.2 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   6118.2 MiB      0.0 MiB           1           del e_spatial       
   194   6118.2 MiB      0.0 MiB           1           del e_bidir
   195   6118.2 MiB      0.0 MiB           1           del weights_bidir
   196   6118.2 MiB      0.0 MiB           1           del y_cluster
   197   5956.4 MiB   -161.8 MiB           1           del new_weights
   198                                                 
   199   5956.4 MiB      0.0 MiB           1           del batch
   200                                                 
   201   5956.4 MiB      0.0 MiB           1           gc.collect()


16.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   5956.4 MiB   5956.4 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   5956.4 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   6013.9 MiB     57.5 MiB           1       l1 = pred_graph.cpu().numpy()
   128   6013.9 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   6114.4 MiB    100.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   6114.4 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   6056.9 MiB    -57.5 MiB           1       del l1
   132                                             
   133   6099.3 MiB     42.4 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   5999.5 MiB    -99.8 MiB           1       del e_1
   135   5999.5 MiB      0.0 MiB           1       del e_2
   136                                             
   137   5999.5 MiB      0.0 MiB           1       if using_weights:
   138   5999.5 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   5999.5 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   5999.5 MiB      0.0 MiB           1           del weights_list
   141   5999.5 MiB      0.0 MiB           1           del l2
   142   6071.2 MiB     71.7 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   6071.2 MiB      0.0 MiB           1           del weights_sparse
   144   6071.2 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   6085.7 MiB     14.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   6142.9 MiB     57.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   6142.9 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   6071.3 MiB    -71.6 MiB           1       del e_intersection
   150                                             
   151   6071.3 MiB      0.0 MiB           1       if using_weights:
   152   6071.3 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   5956.4 MiB   5956.4 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   5956.4 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   5956.4 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   5956.4 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   5956.4 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   5956.4 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   5956.4 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   5956.4 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   5956.4 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   5956.4 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   5956.4 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   5956.4 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   6071.3 MiB    114.9 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   6071.3 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   6071.3 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   6114.1 MiB     42.8 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   6114.1 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   6114.1 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   6114.1 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   6114.1 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   6114.1 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   6114.3 MiB      0.3 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   6114.3 MiB      0.0 MiB           1           del e_spatial       
   194   6114.3 MiB      0.0 MiB           1           del e_bidir
   195   6114.3 MiB      0.0 MiB           1           del weights_bidir
   196   6114.3 MiB      0.0 MiB           1           del y_cluster
   197   6114.3 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   6114.3 MiB      0.0 MiB           1           del batch
   200                                                 
   201   6114.3 MiB      0.0 MiB           1           gc.collect()


17.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   6013.8 MiB   6013.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   6013.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   6129.3 MiB    115.5 MiB           1       l1 = pred_graph.cpu().numpy()
   128   6129.3 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   6273.7 MiB    144.4 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   6273.7 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   6158.1 MiB   -115.6 MiB           1       del l1
   132                                             
   133   6244.9 MiB     86.7 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   6100.5 MiB   -144.4 MiB           1       del e_1
   135   6100.5 MiB      0.0 MiB           1       del e_2
   136                                             
   137   6100.5 MiB      0.0 MiB           1       if using_weights:
   138   6100.5 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   6100.5 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   6100.5 MiB      0.0 MiB           1           del weights_list
   141   6100.5 MiB      0.0 MiB           1           del l2
   142   6165.5 MiB     65.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   6165.5 MiB      0.0 MiB           1           del weights_sparse
   144   6165.5 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   6215.9 MiB     50.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   6331.5 MiB    115.5 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   6331.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   6187.1 MiB   -144.3 MiB           1       del e_intersection
   150                                             
   151   6187.1 MiB      0.0 MiB           1       if using_weights:
   152   6187.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   6114.3 MiB   6114.3 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   6114.3 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   6114.3 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   6114.3 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   6114.3 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   6114.3 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   6114.3 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   6114.3 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   6013.8 MiB   -100.5 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   6013.8 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   6013.8 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   6013.8 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   6187.1 MiB    173.3 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   6187.1 MiB     -0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   6187.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   6331.2 MiB    144.1 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   6331.2 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   6331.2 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   6331.2 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   6331.2 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   6331.2 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   6331.4 MiB      0.2 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   6331.4 MiB      0.0 MiB           1           del e_spatial       
   194   6331.4 MiB      0.0 MiB           1           del e_bidir
   195   6187.1 MiB   -144.3 MiB           1           del weights_bidir
   196   6187.1 MiB      0.0 MiB           1           del y_cluster
   197   6187.1 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   6187.1 MiB      0.0 MiB           1           del batch
   200                                                 
   201   6187.1 MiB      0.0 MiB           1           gc.collect()


18.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   6187.1 MiB   6187.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   6187.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   6285.1 MiB     98.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   6285.2 MiB      0.1 MiB           1       l2 = truth_graph.cpu().numpy()
   129   6398.8 MiB    113.6 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   6399.0 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   6300.8 MiB    -98.1 MiB           1       del l1
   132                                             
   133   6325.4 MiB     24.5 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   6202.9 MiB   -122.5 MiB           1       del e_1
   135   6202.9 MiB      0.0 MiB           1       del e_2
   136                                             
   137   6202.9 MiB      0.0 MiB           1       if using_weights:
   138   6202.9 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   6202.9 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   6202.9 MiB      0.0 MiB           1           del weights_list
   141   6202.9 MiB      0.0 MiB           1           del l2
   142   6251.9 MiB     49.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   6251.9 MiB      0.0 MiB           1           del weights_sparse
   144   6251.9 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   6349.9 MiB     98.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   6448.1 MiB     98.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   6448.1 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   6325.7 MiB   -122.4 MiB           1       del e_intersection
   150                                             
   151   6325.7 MiB      0.0 MiB           1       if using_weights:
   152   6325.7 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   6187.1 MiB   6187.1 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   6187.1 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   6187.1 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   6187.1 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   6187.1 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   6187.1 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   6187.1 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   6187.1 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   6187.1 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   6187.1 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   6187.1 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   6187.1 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   6325.7 MiB    138.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   6325.7 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   6325.7 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   6374.4 MiB     48.7 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   6374.4 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   6374.4 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   6374.4 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   6374.4 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   6374.4 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   6374.6 MiB      0.2 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   6374.6 MiB      0.0 MiB           1           del e_spatial       
   194   6374.6 MiB      0.0 MiB           1           del e_bidir
   195   6374.6 MiB      0.0 MiB           1           del weights_bidir
   196   6374.6 MiB      0.0 MiB           1           del y_cluster
   197   6227.5 MiB   -147.0 MiB           1           del new_weights
   198                                                 
   199   6227.5 MiB      0.0 MiB           1           del batch
   200                                                 
   201   6227.5 MiB      0.0 MiB           1           gc.collect()


19.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   6227.5 MiB   6227.5 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   6227.5 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   6298.7 MiB     71.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   6298.7 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   6387.9 MiB     89.2 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   6387.9 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   6316.6 MiB    -71.3 MiB           1       del l1
   132                                             
   133   6370.1 MiB     53.5 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   6334.4 MiB    -35.7 MiB           1       del e_1
   135   6334.4 MiB      0.0 MiB           1       del e_2
   136                                             
   137   6334.4 MiB      0.0 MiB           1       if using_weights:
   138   6334.4 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   6334.4 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   6334.4 MiB      0.0 MiB           1           del weights_list
   141   6334.4 MiB      0.0 MiB           1           del l2
   142   6316.7 MiB    -17.7 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   6316.7 MiB      0.0 MiB           1           del weights_sparse
   144   6316.7 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   6352.2 MiB     35.5 MiB           1       e_intersection = e_intersection.tocoo()    
   147   6423.5 MiB     71.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   6423.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   6387.8 MiB    -35.7 MiB           1       del e_intersection
   150                                             
   151   6387.8 MiB      0.0 MiB           1       if using_weights:
   152   6387.8 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   6227.5 MiB   6227.5 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   6227.5 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   6227.5 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   6227.5 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   6227.5 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   6227.5 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   6227.5 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   6227.5 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   6227.5 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   6227.5 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   6227.5 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   6227.5 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   6387.8 MiB    160.3 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   6387.8 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   6387.8 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   6334.5 MiB    -53.3 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   6334.5 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   6334.5 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   6334.5 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   6334.5 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   6334.5 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   6334.5 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   6334.5 MiB      0.0 MiB           1           del e_spatial       
   194   6334.5 MiB      0.0 MiB           1           del e_bidir
   195   6334.5 MiB      0.0 MiB           1           del weights_bidir
   196   6334.5 MiB      0.0 MiB           1           del y_cluster
   197   6334.5 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   6334.5 MiB      0.0 MiB           1           del batch
   200                                                 
   201   6334.5 MiB      0.0 MiB           1           gc.collect()


20.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   6330.4 MiB   6330.4 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   6330.4 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   6491.0 MiB    160.6 MiB           1       l1 = pred_graph.cpu().numpy()
   128   6491.0 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   6611.6 MiB    120.7 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   6611.6 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   6450.9 MiB   -160.7 MiB           1       del l1
   132                                             
   133   6571.5 MiB    120.6 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   6450.9 MiB   -120.6 MiB           1       del e_1
   135   6450.9 MiB      0.0 MiB           1       del e_2
   136                                             
   137   6450.9 MiB      0.0 MiB           1       if using_weights:
   138   6450.9 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   6450.9 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   6450.9 MiB      0.0 MiB           1           del weights_list
   141   6450.9 MiB      0.0 MiB           1           del l2
   142   6491.1 MiB     40.2 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   6491.1 MiB      0.0 MiB           1           del weights_sparse
   144   6491.1 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   6531.3 MiB     40.2 MiB           1       e_intersection = e_intersection.tocoo()    
   147   6692.1 MiB    160.8 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   6692.1 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   6531.3 MiB   -160.7 MiB           1       del e_intersection
   150                                             
   151   6531.3 MiB      0.0 MiB           1       if using_weights:
   152   6531.3 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   6330.4 MiB   6330.4 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   6330.4 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   6330.4 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   6330.4 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   6330.4 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   6330.4 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   6330.4 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   6330.4 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   6330.4 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   6330.4 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   6330.4 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   6330.4 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   6531.3 MiB    201.0 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   6531.1 MiB     -0.2 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   6531.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   6531.2 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   6531.2 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   6531.2 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   6531.2 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   6531.2 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   6531.2 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   6531.2 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   6531.2 MiB      0.0 MiB           1           del e_spatial       
   194   6531.2 MiB      0.0 MiB           1           del e_bidir
   195   6531.2 MiB      0.0 MiB           1           del weights_bidir
   196   6531.2 MiB      0.0 MiB           1           del y_cluster
   197   6491.0 MiB    -40.2 MiB           1           del new_weights
   198                                                 
   199   6491.0 MiB      0.0 MiB           1           del batch
   200                                                 
   201   6491.0 MiB      0.0 MiB           1           gc.collect()


20.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   6491.0 MiB   6491.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   6491.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   6580.2 MiB     89.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   6580.2 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   6656.1 MiB     75.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   6656.1 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   6566.8 MiB    -89.3 MiB           1       del l1
   132                                             
   133   6633.8 MiB     67.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   6522.3 MiB   -111.5 MiB           1       del e_1
   135   6522.3 MiB      0.0 MiB           1       del e_2
   136                                             
   137   6522.3 MiB      0.0 MiB           1       if using_weights:
   138   6522.3 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   6522.3 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   6522.3 MiB      0.0 MiB           1           del weights_list
   141   6522.3 MiB      0.0 MiB           1           del l2
   142   6572.5 MiB     50.2 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   6572.5 MiB      0.0 MiB           1           del weights_sparse
   144   6572.5 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   6611.5 MiB     38.9 MiB           1       e_intersection = e_intersection.tocoo()    
   147   6700.7 MiB     89.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   6700.7 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   6589.2 MiB   -111.5 MiB           1       del e_intersection
   150                                             
   151   6589.2 MiB      0.0 MiB           1       if using_weights:
   152   6589.2 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   6491.0 MiB   6491.0 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   6491.0 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   6491.0 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   6491.0 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   6491.0 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   6491.0 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   6491.0 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   6491.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   6491.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   6491.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   6491.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   6491.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   6589.2 MiB     98.2 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   6589.4 MiB      0.2 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   6589.4 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   6589.3 MiB     -0.1 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   6589.3 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   6589.3 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   6589.3 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   6589.3 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   6589.3 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   6589.3 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   6589.3 MiB      0.0 MiB           1           del e_spatial       
   194   6589.3 MiB      0.0 MiB           1           del e_bidir
   195   6589.3 MiB      0.0 MiB           1           del weights_bidir
   196   6589.3 MiB      0.0 MiB           1           del y_cluster
   197   6589.3 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   6589.3 MiB      0.0 MiB           1           del batch
   200                                                 
   201   6589.3 MiB      0.0 MiB           1           gc.collect()


21.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   6589.3 MiB   6589.3 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   6589.3 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   6696.2 MiB    106.9 MiB           1       l1 = pred_graph.cpu().numpy()
   128   6696.2 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   6803.4 MiB    107.3 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   6803.4 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   6696.3 MiB   -107.1 MiB           1       del l1
   132                                             
   133   6776.7 MiB     80.4 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   6723.1 MiB    -53.6 MiB           1       del e_1
   135   6723.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   6723.1 MiB      0.0 MiB           1       if using_weights:
   138   6723.1 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   6723.1 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   6723.1 MiB      0.0 MiB           1           del weights_list
   141   6723.1 MiB      0.0 MiB           1           del l2
   142   6696.4 MiB    -26.7 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   6696.4 MiB      0.0 MiB           1           del weights_sparse
   144   6696.4 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   6749.9 MiB     53.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   6856.9 MiB    107.0 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   6856.9 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   6696.5 MiB   -160.4 MiB           1       del e_intersection
   150                                             
   151   6696.5 MiB      0.0 MiB           1       if using_weights:
   152   6696.5 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   6589.3 MiB   6589.3 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   6589.3 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   6589.3 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   6589.3 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   6589.3 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   6589.3 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   6589.3 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   6589.3 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   6589.3 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   6589.3 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   6589.3 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   6589.3 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   6696.5 MiB    107.2 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   6696.5 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   6696.5 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   6830.1 MiB    133.5 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   6830.1 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   6830.1 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   6830.1 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   6830.1 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   6830.1 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   6830.3 MiB      0.3 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   6830.3 MiB      0.0 MiB           1           del e_spatial       
   194   6830.3 MiB      0.0 MiB           1           del e_bidir
   195   6830.3 MiB      0.0 MiB           1           del weights_bidir
   196   6830.3 MiB      0.0 MiB           1           del y_cluster
   197   6830.3 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   6830.3 MiB      0.0 MiB           1           del batch
   200                                                 
   201   6830.3 MiB      0.0 MiB           1           gc.collect()


22.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   6826.2 MiB   6826.2 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   6826.2 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   6981.9 MiB    155.7 MiB           1       l1 = pred_graph.cpu().numpy()
   128   6981.9 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7099.1 MiB    117.2 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7099.1 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   6943.2 MiB   -155.9 MiB           1       del l1
   132                                             
   133   6943.2 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   6826.2 MiB   -116.9 MiB           1       del e_1
   135   6826.2 MiB      0.0 MiB           1       del e_2
   136                                             
   137   6826.2 MiB      0.0 MiB           1       if using_weights:
   138   6826.2 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   6826.2 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   6826.2 MiB      0.0 MiB           1           del weights_list
   141   6826.2 MiB      0.0 MiB           1           del l2
   142   6865.2 MiB     39.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   6865.2 MiB      0.0 MiB           1           del weights_sparse
   144   6865.2 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7021.2 MiB    155.9 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7176.9 MiB    155.7 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7176.9 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7021.0 MiB   -155.8 MiB           1       del e_intersection
   150                                             
   151   7021.0 MiB      0.0 MiB           1       if using_weights:
   152   7021.0 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   6826.2 MiB   6826.2 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   6826.2 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   6826.2 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   6826.2 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   6826.2 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   6826.2 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   6826.2 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   6826.2 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   6826.2 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   6826.2 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   6826.2 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   6826.2 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   7021.0 MiB    194.8 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   7021.0 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   7021.0 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   7021.0 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   7021.0 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   7021.0 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   7021.0 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   7021.0 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   7021.0 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   7021.0 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   7021.0 MiB      0.0 MiB           1           del e_spatial       
   194   7021.0 MiB      0.0 MiB           1           del e_bidir
   195   7021.0 MiB      0.0 MiB           1           del weights_bidir
   196   7021.0 MiB      0.0 MiB           1           del y_cluster
   197   6982.1 MiB    -39.0 MiB           1           del new_weights
   198                                                 
   199   6982.1 MiB      0.0 MiB           1           del batch
   200                                                 
   201   6982.1 MiB      0.0 MiB           1           gc.collect()


23.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   6982.1 MiB   6982.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   6982.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7116.9 MiB    134.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7116.9 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7218.4 MiB    101.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7218.4 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7083.3 MiB   -135.1 MiB           1       del l1
   132                                             
   133   7083.3 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   6982.1 MiB   -101.3 MiB           1       del e_1
   135   6982.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   6982.1 MiB      0.0 MiB           1       if using_weights:
   138   6982.1 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   6982.1 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   6982.1 MiB      0.0 MiB           1           del weights_list
   141   6982.1 MiB      0.0 MiB           1           del l2
   142   7015.8 MiB     33.8 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   7015.8 MiB      0.0 MiB           1           del weights_sparse
   144   7015.8 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7150.9 MiB    135.1 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7285.7 MiB    134.8 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7285.7 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7150.9 MiB   -134.8 MiB           1       del e_intersection
   150                                             
   151   7150.9 MiB      0.0 MiB           1       if using_weights:
   152   7150.9 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   6982.1 MiB   6982.1 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   6982.1 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   6982.1 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   6982.1 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   6982.1 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   6982.1 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   6982.1 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   6982.1 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   6982.1 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   6982.1 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   6982.1 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   6982.1 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   7150.9 MiB    168.8 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   7150.9 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   7150.9 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   7150.9 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   7150.9 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   7150.9 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   7150.9 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   7150.9 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   7150.9 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   7150.9 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   7150.9 MiB      0.0 MiB           1           del e_spatial       
   194   7150.9 MiB      0.0 MiB           1           del e_bidir
   195   7150.9 MiB      0.0 MiB           1           del weights_bidir
   196   7150.9 MiB      0.0 MiB           1           del y_cluster
   197   7117.1 MiB    -33.8 MiB           1           del new_weights
   198                                                 
   199   7117.1 MiB      0.0 MiB           1           del batch
   200                                                 
   201   7117.1 MiB      0.0 MiB           1           gc.collect()


24.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7117.1 MiB   7117.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7117.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7230.7 MiB    113.6 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7230.7 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7289.2 MiB     58.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7289.3 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7175.6 MiB   -113.7 MiB           1       del l1
   132                                             
   133   7175.6 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7118.8 MiB    -56.8 MiB           1       del e_1
   135   7118.8 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7118.8 MiB      0.0 MiB           1       if using_weights:
   138   7118.8 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   7118.8 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   7118.8 MiB      0.0 MiB           1           del weights_list
   141   7118.8 MiB      0.0 MiB           1           del l2
   142   7203.8 MiB     85.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   7203.8 MiB      0.0 MiB           1           del weights_sparse
   144   7118.9 MiB    -84.9 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7232.3 MiB    113.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7345.8 MiB    113.4 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7345.8 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7289.2 MiB    -56.6 MiB           1       del e_intersection
   150                                             
   151   7289.2 MiB      0.0 MiB           1       if using_weights:
   152   7289.2 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   7117.1 MiB   7117.1 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   7117.1 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   7117.1 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   7117.1 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   7117.1 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   7117.1 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   7117.1 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   7117.1 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   7117.1 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   7117.1 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   7117.1 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   7117.1 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   7289.2 MiB    172.0 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   7289.2 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   7289.2 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   7289.2 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   7289.2 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   7289.2 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   7289.2 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   7289.2 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   7289.2 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   7289.2 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   7289.2 MiB      0.0 MiB           1           del e_spatial       
   194   7289.2 MiB      0.0 MiB           1           del e_bidir
   195   7289.2 MiB      0.0 MiB           1           del weights_bidir
   196   7289.2 MiB      0.0 MiB           1           del y_cluster
   197   7204.0 MiB    -85.1 MiB           1           del new_weights
   198                                                 
   199   7204.0 MiB      0.0 MiB           1           del batch
   200                                                 
   201   7204.0 MiB      0.0 MiB           1           gc.collect()


25.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7204.0 MiB   7204.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7204.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7204.0 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7204.0 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7272.2 MiB     68.2 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7272.4 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7272.4 MiB      0.0 MiB           1       del l1
   132                                             
   133   7272.4 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7238.1 MiB    -34.2 MiB           1       del e_1
   135   7238.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7238.1 MiB      0.0 MiB           1       if using_weights:
   138   7238.1 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   7238.1 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   7238.1 MiB      0.0 MiB           1           del weights_list
   141   7238.1 MiB      0.0 MiB           1           del l2
   142   7238.1 MiB      0.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   7238.1 MiB      0.0 MiB           1           del weights_sparse
   144   7238.1 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7238.1 MiB      0.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7306.5 MiB     68.4 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7306.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7306.5 MiB      0.0 MiB           1       del e_intersection
   150                                             
   151   7306.5 MiB      0.0 MiB           1       if using_weights:
   152   7306.5 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   7204.0 MiB   7204.0 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   7204.0 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   7204.0 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   7204.0 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   7204.0 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   7204.0 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   7204.0 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   7204.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   7204.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   7204.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   7204.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   7204.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   7306.5 MiB    102.5 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   7306.5 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   7306.5 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   7306.5 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   7306.5 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   7306.5 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   7306.5 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   7306.5 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   7306.5 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   7306.6 MiB      0.1 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   7306.6 MiB      0.0 MiB           1           del e_spatial       
   194   7306.6 MiB      0.0 MiB           1           del e_bidir
   195   7306.6 MiB      0.0 MiB           1           del weights_bidir
   196   7306.6 MiB      0.0 MiB           1           del y_cluster
   197   7306.6 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   7306.6 MiB      0.0 MiB           1           del batch
   200                                                 
   201   7306.6 MiB      0.0 MiB           1           gc.collect()


25.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7306.6 MiB   7306.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7306.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7306.6 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7306.6 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7306.6 MiB      0.0 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7306.6 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7306.6 MiB      0.0 MiB           1       del l1
   132                                             
   133   7306.6 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7306.6 MiB      0.0 MiB           1       del e_1
   135   7306.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7306.6 MiB      0.0 MiB           1       if using_weights:
   138   7306.6 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   7306.6 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   7306.6 MiB      0.0 MiB           1           del weights_list
   141   7306.6 MiB      0.0 MiB           1           del l2
   142   7306.6 MiB      0.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   7306.6 MiB      0.0 MiB           1           del weights_sparse
   144   7306.6 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7306.6 MiB      0.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7360.2 MiB     53.5 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7360.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7360.2 MiB      0.0 MiB           1       del e_intersection
   150                                             
   151   7360.2 MiB      0.0 MiB           1       if using_weights:
   152   7360.2 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   7306.6 MiB   7306.6 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   7306.6 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   7306.6 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   7306.6 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   7306.6 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   7306.6 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   7306.6 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   7306.6 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   7306.6 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   7306.6 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   7306.6 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   7306.6 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   7360.2 MiB     53.5 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   7360.2 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   7360.2 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   7360.2 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   7360.2 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   7360.2 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   7360.2 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   7360.2 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   7360.2 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   7360.2 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   7360.2 MiB      0.0 MiB           1           del e_spatial       
   194   7360.2 MiB      0.0 MiB           1           del e_bidir
   195   7360.2 MiB      0.0 MiB           1           del weights_bidir
   196   7360.2 MiB      0.0 MiB           1           del y_cluster
   197   7360.2 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   7360.2 MiB      0.0 MiB           1           del batch
   200                                                 
   201   7360.2 MiB      0.0 MiB           1           gc.collect()


26.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7360.2 MiB   7360.2 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7360.2 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7468.4 MiB    108.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7468.4 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7542.3 MiB     73.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7542.4 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7434.2 MiB   -108.2 MiB           1       del l1
   132                                             
   133   7461.3 MiB     27.1 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7407.1 MiB    -54.1 MiB           1       del e_1
   135   7407.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7407.1 MiB      0.0 MiB           1       if using_weights:
   138   7407.1 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   7407.1 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   7407.1 MiB      0.0 MiB           1           del weights_list
   141   7407.1 MiB      0.0 MiB           1           del l2
   142   7461.1 MiB     53.9 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   7461.1 MiB      0.0 MiB           1           del weights_sparse
   144   7380.2 MiB    -80.9 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7488.2 MiB    108.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7596.5 MiB    108.3 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7596.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7542.4 MiB    -54.1 MiB           1       del e_intersection
   150                                             
   151   7542.4 MiB      0.0 MiB           1       if using_weights:
   152   7542.4 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   7360.2 MiB   7360.2 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   7360.2 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   7360.2 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   7360.2 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   7360.2 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   7360.2 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   7360.2 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   7360.2 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   7360.2 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   7360.2 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   7360.2 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   7360.2 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   7542.4 MiB    182.2 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   7542.4 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   7542.4 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   7542.4 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   7542.4 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   7542.4 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   7542.4 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   7542.4 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   7542.4 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   7542.4 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   7542.4 MiB      0.0 MiB           1           del e_spatial       
   194   7542.4 MiB      0.0 MiB           1           del e_bidir
   195   7542.4 MiB      0.0 MiB           1           del weights_bidir
   196   7542.4 MiB      0.0 MiB           1           del y_cluster
   197   7434.3 MiB   -108.1 MiB           1           del new_weights
   198                                                 
   199   7434.3 MiB      0.0 MiB           1           del batch
   200                                                 
   201   7434.3 MiB      0.0 MiB           1           gc.collect()


27.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7434.3 MiB   7434.3 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7434.3 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7552.8 MiB    118.4 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7552.8 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7641.3 MiB     88.6 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7641.5 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7523.1 MiB   -118.5 MiB           1       del l1
   132                                             
   133   7523.1 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7463.8 MiB    -59.2 MiB           1       del e_1
   135   7463.8 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7463.8 MiB      0.0 MiB           1       if using_weights:
   138   7463.8 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   7463.8 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   7463.8 MiB      0.0 MiB           1           del weights_list
   141   7463.8 MiB      0.0 MiB           1           del l2
   142   7552.5 MiB     88.6 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   7552.5 MiB      0.0 MiB           1           del weights_sparse
   144   7463.9 MiB    -88.5 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7582.3 MiB    118.3 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7700.4 MiB    118.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7700.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7641.3 MiB    -59.0 MiB           1       del e_intersection
   150                                             
   151   7641.3 MiB      0.0 MiB           1       if using_weights:
   152   7641.3 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   7434.3 MiB   7434.3 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   7434.3 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   7434.3 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   7434.3 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   7434.3 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   7434.3 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   7434.3 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   7434.3 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   7434.3 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   7434.3 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   7434.3 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   7434.3 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   7641.3 MiB    207.0 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   7641.3 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   7641.3 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   7641.3 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   7641.3 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   7641.3 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   7641.3 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   7641.3 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   7641.3 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   7641.3 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   7641.3 MiB      0.0 MiB           1           del e_spatial       
   194   7641.3 MiB      0.0 MiB           1           del e_bidir
   195   7641.3 MiB      0.0 MiB           1           del weights_bidir
   196   7641.3 MiB      0.0 MiB           1           del y_cluster
   197   7552.6 MiB    -88.7 MiB           1           del new_weights
   198                                                 
   199   7552.6 MiB      0.0 MiB           1           del batch
   200                                                 
   201   7552.6 MiB      0.0 MiB           1           gc.collect()


28.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7552.6 MiB   7552.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7552.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7680.9 MiB    128.3 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7680.9 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7777.2 MiB     96.3 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7777.3 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7648.9 MiB   -128.4 MiB           1       del l1
   132                                             
   133   7648.9 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7552.6 MiB    -96.3 MiB           1       del e_1
   135   7552.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7552.6 MiB      0.0 MiB           1       if using_weights:
   138   7552.6 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   7552.6 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   7552.6 MiB      0.0 MiB           1           del weights_list
   141   7552.6 MiB      0.0 MiB           1           del l2
   142   7584.7 MiB     32.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   7584.7 MiB      0.0 MiB           1           del weights_sparse
   144   7552.6 MiB    -32.1 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7681.0 MiB    128.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7809.1 MiB    128.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7809.1 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7681.0 MiB   -128.1 MiB           1       del e_intersection
   150                                             
   151   7681.0 MiB      0.0 MiB           1       if using_weights:
   152   7681.0 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   7552.6 MiB   7552.6 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   7552.6 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   7552.6 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   7552.6 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   7552.6 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   7552.6 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   7552.6 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   7552.6 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   7552.6 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   7552.6 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   7552.6 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   7552.6 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   7681.0 MiB    128.4 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   7681.2 MiB      0.2 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   7681.2 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   7681.2 MiB     -0.1 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   7681.2 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   7681.2 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   7681.2 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   7681.2 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   7681.2 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   7681.2 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   7681.2 MiB      0.0 MiB           1           del e_spatial       
   194   7681.2 MiB      0.0 MiB           1           del e_bidir
   195   7681.2 MiB      0.0 MiB           1           del weights_bidir
   196   7681.2 MiB      0.0 MiB           1           del y_cluster
   197   7681.2 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   7681.2 MiB      0.0 MiB           1           del batch
   200                                                 
   201   7681.2 MiB      0.0 MiB           1           gc.collect()


29.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7681.2 MiB   7681.2 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7681.2 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7812.0 MiB    130.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7812.0 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7910.4 MiB     98.4 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7910.4 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7779.4 MiB   -131.0 MiB           1       del l1
   132                                             
   133   7779.4 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7681.2 MiB    -98.2 MiB           1       del e_1
   135   7681.2 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7681.2 MiB      0.0 MiB           1       if using_weights:
   138   7681.2 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   7681.2 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   7681.2 MiB      0.0 MiB           1           del weights_list
   141   7681.2 MiB      0.0 MiB           1           del l2
   142   7713.9 MiB     32.7 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   7713.9 MiB      0.0 MiB           1           del weights_sparse
   144   7713.9 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7844.9 MiB    131.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7975.9 MiB    131.0 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7975.9 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7844.9 MiB   -131.0 MiB           1       del e_intersection
   150                                             
   151   7844.9 MiB      0.0 MiB           1       if using_weights:
   152   7844.9 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   7681.2 MiB   7681.2 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   7681.2 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   7681.2 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   7681.2 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   7681.2 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   7681.2 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   7681.2 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   7681.2 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   7681.2 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   7681.2 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   7681.2 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   7681.2 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   7844.9 MiB    163.7 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   7844.9 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   7844.9 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   7844.8 MiB     -0.1 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   7844.8 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   7844.8 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   7844.8 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   7844.8 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   7844.8 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   7844.8 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   7844.8 MiB      0.0 MiB           1           del e_spatial       
   194   7844.8 MiB      0.0 MiB           1           del e_bidir
   195   7844.8 MiB      0.0 MiB           1           del weights_bidir
   196   7844.8 MiB      0.0 MiB           1           del y_cluster
   197   7812.0 MiB    -32.7 MiB           1           del new_weights
   198                                                 
   199   7812.0 MiB      0.0 MiB           1           del batch
   200                                                 
   201   7812.0 MiB      0.0 MiB           1           gc.collect()


30.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7812.0 MiB   7812.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7812.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7946.1 MiB    134.1 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7946.4 MiB      0.2 MiB           1       l2 = truth_graph.cpu().numpy()
   129   8047.1 MiB    100.8 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   8047.1 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7912.8 MiB   -134.3 MiB           1       del l1
   132                                             
   133   7912.8 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7812.0 MiB   -100.8 MiB           1       del e_1
   135   7812.0 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7812.0 MiB      0.0 MiB           1       if using_weights:
   138   7812.0 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   7812.0 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   7812.0 MiB      0.0 MiB           1           del weights_list
   141   7812.0 MiB      0.0 MiB           1           del l2
   142   7845.6 MiB     33.6 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   7845.6 MiB      0.0 MiB           1           del weights_sparse
   144   7845.6 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7979.9 MiB    134.3 MiB           1       e_intersection = e_intersection.tocoo()    
   147   8114.3 MiB    134.3 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   8114.3 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7980.1 MiB   -134.2 MiB           1       del e_intersection
   150                                             
   151   7980.1 MiB      0.0 MiB           1       if using_weights:
   152   7980.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   7812.0 MiB   7812.0 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   7812.0 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   7812.0 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   7812.0 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   7812.0 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   7812.0 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   7812.0 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   7812.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   7812.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   7812.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   7812.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   7812.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   7980.1 MiB    168.0 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   7980.1 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   7980.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   7980.0 MiB     -0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   7980.0 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   7980.0 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   7980.0 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   7980.0 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   7980.0 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   7980.0 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   7980.0 MiB      0.0 MiB           1           del e_spatial       
   194   7980.0 MiB      0.0 MiB           1           del e_bidir
   195   7980.0 MiB      0.0 MiB           1           del weights_bidir
   196   7980.0 MiB      0.0 MiB           1           del y_cluster
   197   7946.4 MiB    -33.6 MiB           1           del new_weights
   198                                                 
   199   7946.4 MiB      0.0 MiB           1           del batch
   200                                                 
   201   7946.4 MiB      0.0 MiB           1           gc.collect()


30.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7946.4 MiB   7946.4 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7946.4 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   8074.8 MiB    128.4 MiB           1       l1 = pred_graph.cpu().numpy()
   128   8074.8 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   8171.4 MiB     96.6 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   8171.4 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   8042.8 MiB   -128.5 MiB           1       del l1
   132                                             
   133   8042.8 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7946.4 MiB    -96.4 MiB           1       del e_1
   135   7946.4 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7946.4 MiB      0.0 MiB           1       if using_weights:
   138   7946.4 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   7946.4 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   7946.4 MiB      0.0 MiB           1           del weights_list
   141   7946.4 MiB      0.0 MiB           1           del l2
   142   7978.6 MiB     32.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   7978.6 MiB      0.0 MiB           1           del weights_sparse
   144   7978.6 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   8107.1 MiB    128.5 MiB           1       e_intersection = e_intersection.tocoo()    
   147   8235.5 MiB    128.4 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   8235.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   8107.0 MiB   -128.5 MiB           1       del e_intersection
   150                                             
   151   8107.0 MiB      0.0 MiB           1       if using_weights:
   152   8107.0 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   7946.4 MiB   7946.4 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   7946.4 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   7946.4 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   7946.4 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   7946.4 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   7946.4 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   7946.4 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   7946.4 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   7946.4 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   7946.4 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   7946.4 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   7946.4 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   8107.0 MiB    160.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   8107.0 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   8107.0 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   8107.2 MiB      0.2 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   8107.2 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   8107.2 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   8107.2 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   8107.2 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   8107.2 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   8107.2 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   8107.2 MiB      0.0 MiB           1           del e_spatial       
   194   8107.2 MiB      0.0 MiB           1           del e_bidir
   195   8107.2 MiB      0.0 MiB           1           del weights_bidir
   196   8107.2 MiB      0.0 MiB           1           del y_cluster
   197   8075.1 MiB    -32.1 MiB           1           del new_weights
   198                                                 
   199   8075.1 MiB      0.0 MiB           1           del batch
   200                                                 
   201   8075.1 MiB      0.0 MiB           1           gc.collect()


31.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   8075.1 MiB   8075.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   8075.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   8201.1 MiB    126.1 MiB           1       l1 = pred_graph.cpu().numpy()
   128   8201.1 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   8295.8 MiB     94.6 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   8295.8 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   8169.6 MiB   -126.2 MiB           1       del l1
   132                                             
   133   8201.2 MiB     31.6 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   8138.1 MiB    -63.1 MiB           1       del e_1
   135   8138.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   8138.1 MiB      0.0 MiB           1       if using_weights:
   138   8138.1 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   8138.1 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   8138.1 MiB      0.0 MiB           1           del weights_list
   141   8138.1 MiB      0.0 MiB           1           del l2
   142   8232.7 MiB     94.6 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   8232.7 MiB      0.0 MiB           1           del weights_sparse
   144   8075.1 MiB   -157.6 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   8232.6 MiB    157.5 MiB           1       e_intersection = e_intersection.tocoo()    
   147   8358.7 MiB    126.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   8358.7 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   8209.0 MiB   -149.7 MiB           1       del e_intersection
   150                                             
   151   8209.0 MiB      0.0 MiB           1       if using_weights:
   152   8209.0 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   8075.1 MiB   8075.1 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   8075.1 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   8075.1 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   8075.1 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   8075.1 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   8075.1 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   8075.1 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   8075.1 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   8075.1 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   8075.1 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   8075.1 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   8075.1 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   8209.0 MiB    133.9 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   8209.0 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   8209.0 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   8271.9 MiB     62.9 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   8271.9 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   8271.9 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   8271.9 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   8271.9 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   8271.9 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   8271.9 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   8271.9 MiB      0.0 MiB           1           del e_spatial       
   194   8271.9 MiB      0.0 MiB           1           del e_bidir
   195   8271.9 MiB      0.0 MiB           1           del weights_bidir
   196   8201.1 MiB    -70.9 MiB           1           del y_cluster
   197   8201.1 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   8201.1 MiB      0.0 MiB           1           del batch
   200                                                 
   201   8201.1 MiB      0.0 MiB           1           gc.collect()


32.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   8201.1 MiB   8201.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   8201.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   8201.1 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   8201.1 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   8299.0 MiB     97.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   8299.2 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   8299.2 MiB      0.0 MiB           1       del l1
   132                                             
   133   8299.2 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   8259.9 MiB    -39.3 MiB           1       del e_1
   135   8259.9 MiB      0.0 MiB           1       del e_2
   136                                             
   137   8259.9 MiB      0.0 MiB           1       if using_weights:
   138   8259.9 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   8259.9 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   8259.9 MiB      0.0 MiB           1           del weights_list
   141   8259.9 MiB      0.0 MiB           1           del l2
   142   8259.9 MiB      0.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   8259.9 MiB      0.0 MiB           1           del weights_sparse
   144   8259.9 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   8259.9 MiB      0.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   8338.6 MiB     78.7 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   8338.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   8338.6 MiB      0.0 MiB           1       del e_intersection
   150                                             
   151   8338.6 MiB      0.0 MiB           1       if using_weights:
   152   8338.6 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   8201.1 MiB   8201.1 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   8201.1 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   8201.1 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   8201.1 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   8201.1 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   8201.1 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   8201.1 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   8201.1 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   8201.1 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   8201.1 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   8201.1 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   8201.1 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   8338.6 MiB    137.5 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   8338.6 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   8338.6 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   8338.6 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   8338.6 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   8338.6 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   8338.6 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   8338.6 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   8338.6 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   8338.7 MiB      0.1 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   8338.7 MiB      0.0 MiB           1           del e_spatial       
   194   8338.7 MiB      0.0 MiB           1           del e_bidir
   195   8338.7 MiB      0.0 MiB           1           del weights_bidir
   196   8338.7 MiB      0.0 MiB           1           del y_cluster
   197   8338.7 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   8338.7 MiB      0.0 MiB           1           del batch
   200                                                 
   201   8338.7 MiB      0.0 MiB           1           gc.collect()


33.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   8338.7 MiB   8338.7 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   8338.7 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   8469.9 MiB    131.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   8469.9 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   8568.4 MiB     98.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   8568.5 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   8437.2 MiB   -131.3 MiB           1       del l1
   132                                             
   133   8437.2 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   8338.7 MiB    -98.5 MiB           1       del e_1
   135   8338.7 MiB      0.0 MiB           1       del e_2
   136                                             
   137   8338.7 MiB      0.0 MiB           1       if using_weights:
   138   8338.7 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   8338.7 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   8338.7 MiB      0.0 MiB           1           del weights_list
   141   8338.7 MiB      0.0 MiB           1           del l2
   142   8371.5 MiB     32.8 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   8371.5 MiB      0.0 MiB           1           del weights_sparse
   144   8338.7 MiB    -32.8 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   8470.0 MiB    131.3 MiB           1       e_intersection = e_intersection.tocoo()    
   147   8601.2 MiB    131.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   8601.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   8470.1 MiB   -131.1 MiB           1       del e_intersection
   150                                             
   151   8470.1 MiB      0.0 MiB           1       if using_weights:
   152   8470.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   8338.7 MiB   8338.7 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   8338.7 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   8338.7 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   8338.7 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   8338.7 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   8338.7 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   8338.7 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   8338.7 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   8338.7 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   8338.7 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   8338.7 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   8338.7 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   8470.1 MiB    131.4 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   8470.1 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   8470.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   8470.0 MiB     -0.1 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   8470.0 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   8470.0 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   8470.0 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   8470.0 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   8470.0 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   8470.0 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   8470.0 MiB      0.0 MiB           1           del e_spatial       
   194   8470.0 MiB      0.0 MiB           1           del e_bidir
   195   8470.0 MiB      0.0 MiB           1           del weights_bidir
   196   8470.0 MiB      0.0 MiB           1           del y_cluster
   197   8470.0 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   8470.0 MiB      0.0 MiB           1           del batch
   200                                                 
   201   8470.0 MiB      0.0 MiB           1           gc.collect()


34.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   8470.0 MiB   8470.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   8470.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   8600.6 MiB    130.7 MiB           1       l1 = pred_graph.cpu().numpy()
   128   8600.6 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   8698.7 MiB     98.1 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   8698.8 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   8568.0 MiB   -130.8 MiB           1       del l1
   132                                             
   133   8568.0 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   8470.0 MiB    -98.1 MiB           1       del e_1
   135   8470.0 MiB      0.0 MiB           1       del e_2
   136                                             
   137   8470.0 MiB      0.0 MiB           1       if using_weights:
   138   8470.0 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   8470.0 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   8470.0 MiB      0.0 MiB           1           del weights_list
   141   8470.0 MiB      0.0 MiB           1           del l2
   142   8502.7 MiB     32.7 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   8502.7 MiB      0.0 MiB           1           del weights_sparse
   144   8470.0 MiB    -32.7 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   8600.7 MiB    130.8 MiB           1       e_intersection = e_intersection.tocoo()    
   147   8731.4 MiB    130.7 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   8731.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   8600.8 MiB   -130.6 MiB           1       del e_intersection
   150                                             
   151   8600.8 MiB      0.0 MiB           1       if using_weights:
   152   8600.8 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   8470.0 MiB   8470.0 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   8470.0 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   8470.0 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   8470.0 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   8470.0 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   8470.0 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   8470.0 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   8470.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   8470.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   8470.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   8470.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   8470.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   8600.8 MiB    130.9 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   8600.8 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   8600.8 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   8600.7 MiB     -0.1 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   8600.7 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   8600.7 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   8600.7 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   8600.7 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   8600.7 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   8600.7 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   8600.7 MiB      0.0 MiB           1           del e_spatial       
   194   8600.7 MiB      0.0 MiB           1           del e_bidir
   195   8600.7 MiB      0.0 MiB           1           del weights_bidir
   196   8600.7 MiB      0.0 MiB           1           del y_cluster
   197   8600.7 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   8600.7 MiB      0.0 MiB           1           del batch
   200                                                 
   201   8600.7 MiB      0.0 MiB           1           gc.collect()


35.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   8600.7 MiB   8600.7 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   8600.7 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   8600.7 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   8600.7 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   8662.7 MiB     62.0 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   8662.9 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   8662.9 MiB      0.0 MiB           1       del l1
   132                                             
   133   8662.9 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   8622.6 MiB    -40.4 MiB           1       del e_1
   135   8622.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   8622.6 MiB      0.0 MiB           1       if using_weights:
   138   8622.6 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   8622.6 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   8622.6 MiB      0.0 MiB           1           del weights_list
   141   8622.6 MiB      0.0 MiB           1           del l2
   142   8622.6 MiB      0.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   8622.6 MiB      0.0 MiB           1           del weights_sparse
   144   8622.6 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   8622.6 MiB      0.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   8703.2 MiB     80.7 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   8703.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   8622.8 MiB    -80.5 MiB           1       del e_intersection
   150                                             
   151   8622.8 MiB      0.0 MiB           1       if using_weights:
   152   8622.8 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   8600.7 MiB   8600.7 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   8600.7 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   8600.7 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   8600.7 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   8600.7 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   8600.7 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   8600.7 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   8600.7 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   8600.7 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   8600.7 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   8600.7 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   8600.7 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   8622.8 MiB     22.0 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   8622.8 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   8622.8 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   8622.8 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   8622.8 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   8622.8 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   8622.8 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   8622.8 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   8622.8 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   8622.8 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   8622.8 MiB      0.0 MiB           1           del e_spatial       
   194   8622.8 MiB      0.0 MiB           1           del e_bidir
   195   8622.8 MiB      0.0 MiB           1           del weights_bidir
   196   8622.8 MiB      0.0 MiB           1           del y_cluster
   197   8622.8 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   8622.8 MiB      0.0 MiB           1           del batch
   200                                                 
   201   8622.8 MiB      0.0 MiB           1           gc.collect()


35.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   8622.8 MiB   8622.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   8622.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   8622.8 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   8622.8 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   8711.1 MiB     88.4 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   8711.1 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   8711.1 MiB      0.0 MiB           1       del l1
   132                                             
   133   8711.1 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   8666.9 MiB    -44.2 MiB           1       del e_1
   135   8666.9 MiB      0.0 MiB           1       del e_2
   136                                             
   137   8666.9 MiB      0.0 MiB           1       if using_weights:
   138   8666.9 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   8666.9 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   8666.9 MiB      0.0 MiB           1           del weights_list
   141   8666.9 MiB      0.0 MiB           1           del l2
   142   8688.8 MiB     21.9 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   8688.8 MiB      0.0 MiB           1           del weights_sparse
   144   8688.8 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   8733.1 MiB     44.3 MiB           1       e_intersection = e_intersection.tocoo()    
   147   8821.6 MiB     88.4 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   8821.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   8711.1 MiB   -110.5 MiB           1       del e_intersection
   150                                             
   151   8711.1 MiB      0.0 MiB           1       if using_weights:
   152   8711.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   8622.8 MiB   8622.8 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   8622.8 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   8622.8 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   8622.8 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   8622.8 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   8622.8 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   8622.8 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   8622.8 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   8622.8 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   8622.8 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   8622.8 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   8622.8 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   8711.1 MiB     88.3 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   8711.1 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   8711.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   8733.0 MiB     21.9 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   8733.0 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   8733.0 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   8733.0 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   8733.0 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   8733.0 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   8733.1 MiB      0.1 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   8733.1 MiB      0.0 MiB           1           del e_spatial       
   194   8733.1 MiB      0.0 MiB           1           del e_bidir
   195   8733.1 MiB      0.0 MiB           1           del weights_bidir
   196   8733.1 MiB      0.0 MiB           1           del y_cluster
   197   8733.1 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   8733.1 MiB      0.0 MiB           1           del batch
   200                                                 
   201   8733.1 MiB      0.0 MiB           1           gc.collect()


36.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   8733.1 MiB   8733.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   8733.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   8733.1 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   8733.1 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   8800.3 MiB     67.2 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   8800.3 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   8800.3 MiB      0.0 MiB           1       del l1
   132                                             
   133   8800.3 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   8755.6 MiB    -44.7 MiB           1       del e_1
   135   8755.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   8755.6 MiB      0.0 MiB           1       if using_weights:
   138   8755.6 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   8755.6 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   8755.6 MiB      0.0 MiB           1           del weights_list
   141   8755.6 MiB      0.0 MiB           1           del l2
   142   8777.7 MiB     22.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   8777.7 MiB      0.0 MiB           1           del weights_sparse
   144   8777.7 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   8822.6 MiB     44.9 MiB           1       e_intersection = e_intersection.tocoo()    
   147   8912.1 MiB     89.5 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   8912.1 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   8800.6 MiB   -111.4 MiB           1       del e_intersection
   150                                             
   151   8800.6 MiB      0.0 MiB           1       if using_weights:
   152   8800.6 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   8733.1 MiB   8733.1 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   8733.1 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   8733.1 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   8733.1 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   8733.1 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   8733.1 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   8733.1 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   8733.1 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   8733.1 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   8733.1 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   8733.1 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   8733.1 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   8800.6 MiB     67.5 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   8800.6 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   8800.6 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   8822.8 MiB     22.2 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   8822.8 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   8822.8 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   8822.8 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   8822.8 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   8822.8 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   8822.8 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   8822.8 MiB      0.0 MiB           1           del e_spatial       
   194   8822.8 MiB      0.0 MiB           1           del e_bidir
   195   8822.8 MiB      0.0 MiB           1           del weights_bidir
   196   8822.8 MiB      0.0 MiB           1           del y_cluster
   197   8822.8 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   8822.8 MiB      0.0 MiB           1           del batch
   200                                                 
   201   8822.8 MiB      0.0 MiB           1           gc.collect()


37.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   8822.8 MiB   8822.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   8822.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   8919.2 MiB     96.3 MiB           1       l1 = pred_graph.cpu().numpy()
   128   8919.2 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   8968.9 MiB     49.7 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   8969.1 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   8872.8 MiB    -96.4 MiB           1       del l1
   132                                             
   133   8872.8 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   8824.6 MiB    -48.2 MiB           1       del e_1
   135   8824.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   8824.6 MiB      0.0 MiB           1       if using_weights:
   138   8824.6 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   8824.6 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   8824.6 MiB      0.0 MiB           1           del weights_list
   141   8824.6 MiB      0.0 MiB           1           del l2
   142   8896.8 MiB     72.2 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   8896.8 MiB      0.0 MiB           1           del weights_sparse
   144   8824.7 MiB    -72.1 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   8920.9 MiB     96.2 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9017.0 MiB     96.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9017.0 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   8968.9 MiB    -48.1 MiB           1       del e_intersection
   150                                             
   151   8968.9 MiB      0.0 MiB           1       if using_weights:
   152   8968.9 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   8822.8 MiB   8822.8 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   8822.8 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   8822.8 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   8822.8 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   8822.8 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   8822.8 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   8822.8 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   8822.8 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   8822.8 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   8822.8 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   8822.8 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   8822.8 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   8968.9 MiB    146.1 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   8968.9 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   8968.9 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   8968.9 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   8968.9 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   8968.9 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   8968.9 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   8968.9 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   8968.9 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   8968.9 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   8968.9 MiB      0.0 MiB           1           del e_spatial       
   194   8968.9 MiB      0.0 MiB           1           del e_bidir
   195   8968.9 MiB      0.0 MiB           1           del weights_bidir
   196   8968.9 MiB      0.0 MiB           1           del y_cluster
   197   8896.7 MiB    -72.1 MiB           1           del new_weights
   198                                                 
   199   8896.7 MiB      0.0 MiB           1           del batch
   200                                                 
   201   8896.7 MiB      0.0 MiB           1           gc.collect()


38.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   8896.7 MiB   8896.7 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   8896.7 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9006.7 MiB    110.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9006.7 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9089.0 MiB     82.3 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9089.1 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   8979.1 MiB   -110.0 MiB           1       del l1
   132                                             
   133   8979.1 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   8924.1 MiB    -55.0 MiB           1       del e_1
   135   8924.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   8924.1 MiB      0.0 MiB           1       if using_weights:
   138   8924.1 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   8924.1 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   8924.1 MiB      0.0 MiB           1           del weights_list
   141   8924.1 MiB      0.0 MiB           1           del l2
   142   9006.4 MiB     82.2 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9006.4 MiB      0.0 MiB           1           del weights_sparse
   144   8924.2 MiB    -82.1 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9034.1 MiB    109.8 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9144.2 MiB    110.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9144.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9089.3 MiB    -54.9 MiB           1       del e_intersection
   150                                             
   151   9089.3 MiB      0.0 MiB           1       if using_weights:
   152   9089.3 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   8896.7 MiB   8896.7 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   8896.7 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   8896.7 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   8896.7 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   8896.7 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   8896.7 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   8896.7 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   8896.7 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   8896.7 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   8896.7 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   8896.7 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   8896.7 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9089.3 MiB    192.5 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9089.3 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9089.3 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9089.3 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9089.3 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9089.3 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9089.3 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9089.3 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9089.3 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9089.3 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9089.3 MiB      0.0 MiB           1           del e_spatial       
   194   9089.3 MiB      0.0 MiB           1           del e_bidir
   195   9089.3 MiB      0.0 MiB           1           del weights_bidir
   196   9089.3 MiB      0.0 MiB           1           del y_cluster
   197   9006.9 MiB    -82.4 MiB           1           del new_weights
   198                                                 
   199   9006.9 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9006.9 MiB      0.0 MiB           1           gc.collect()


39.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9002.8 MiB   9002.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9002.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9159.2 MiB    156.4 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9159.2 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9276.9 MiB    117.7 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9276.9 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9120.3 MiB   -156.6 MiB           1       del l1
   132                                             
   133   9198.6 MiB     78.3 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9081.1 MiB   -117.5 MiB           1       del e_1
   135   9081.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9081.1 MiB      0.0 MiB           1       if using_weights:
   138   9081.1 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9081.1 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9081.1 MiB      0.0 MiB           1           del weights_list
   141   9081.1 MiB      0.0 MiB           1           del l2
   142   9090.6 MiB      9.5 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9090.6 MiB      0.0 MiB           1           del weights_sparse
   144   9090.6 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9168.9 MiB     78.3 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9325.6 MiB    156.7 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9325.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9169.0 MiB   -156.7 MiB           1       del e_intersection
   150                                             
   151   9169.0 MiB      0.0 MiB           1       if using_weights:
   152   9169.0 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9002.8 MiB   9002.8 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9002.8 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9002.8 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9002.8 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9002.8 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9002.8 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9002.8 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9002.8 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9002.8 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9002.8 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9002.8 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9002.8 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9169.0 MiB    166.2 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9168.8 MiB     -0.2 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9168.8 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9168.8 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9168.8 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9168.8 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9168.8 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9168.8 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9168.8 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9168.8 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9168.8 MiB      0.0 MiB           1           del e_spatial       
   194   9168.8 MiB      0.0 MiB           1           del e_bidir
   195   9168.8 MiB      0.0 MiB           1           del weights_bidir
   196   9168.8 MiB      0.0 MiB           1           del y_cluster
   197   9168.8 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9168.8 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9168.8 MiB      0.0 MiB           1           gc.collect()


40.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9168.8 MiB   9168.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9168.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9297.0 MiB    128.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9297.0 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9393.4 MiB     96.3 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9393.4 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9265.0 MiB   -128.3 MiB           1       del l1
   132                                             
   133   9329.2 MiB     64.2 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9233.0 MiB    -96.2 MiB           1       del e_1
   135   9233.0 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9233.0 MiB      0.0 MiB           1       if using_weights:
   138   9233.0 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9233.0 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9233.0 MiB      0.0 MiB           1           del weights_list
   141   9233.0 MiB      0.0 MiB           1           del l2
   142   9265.0 MiB     32.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9265.0 MiB      0.0 MiB           1           del weights_sparse
   144   9233.0 MiB    -32.1 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9297.1 MiB     64.2 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9425.5 MiB    128.4 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9425.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9297.1 MiB   -128.3 MiB           1       del e_intersection
   150                                             
   151   9297.1 MiB      0.0 MiB           1       if using_weights:
   152   9297.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9168.8 MiB   9168.8 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9168.8 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9168.8 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9168.8 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9168.8 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9168.8 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9168.8 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9168.8 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9168.8 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9168.8 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9168.8 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9168.8 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9297.1 MiB    128.4 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9297.2 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9297.2 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9297.1 MiB     -0.1 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9297.1 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9297.1 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9297.1 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9297.1 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9297.1 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9297.1 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9297.1 MiB      0.0 MiB           1           del e_spatial       
   194   9297.1 MiB      0.0 MiB           1           del e_bidir
   195   9297.1 MiB      0.0 MiB           1           del weights_bidir
   196   9297.1 MiB      0.0 MiB           1           del y_cluster
   197   9297.1 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9297.1 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9297.1 MiB      0.0 MiB           1           gc.collect()


40.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9297.1 MiB   9297.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9297.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9396.5 MiB     99.4 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9396.5 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9446.9 MiB     50.4 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9447.1 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9347.7 MiB    -99.5 MiB           1       del l1
   132                                             
   133   9372.5 MiB     24.9 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9322.8 MiB    -49.7 MiB           1       del e_1
   135   9322.8 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9322.8 MiB      0.0 MiB           1       if using_weights:
   138   9322.8 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9322.8 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9322.8 MiB      0.0 MiB           1           del weights_list
   141   9322.8 MiB      0.0 MiB           1           del l2
   142   9298.0 MiB    -24.8 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9298.0 MiB      0.0 MiB           1           del weights_sparse
   144   9298.0 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9397.3 MiB     99.3 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9496.8 MiB     99.5 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9496.8 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9347.8 MiB   -149.0 MiB           1       del e_intersection
   150                                             
   151   9347.8 MiB      0.0 MiB           1       if using_weights:
   152   9347.8 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9297.1 MiB   9297.1 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9297.1 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9297.1 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9297.1 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9297.1 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9297.1 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9297.1 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9297.1 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9297.1 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9297.1 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9297.1 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9297.1 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9347.8 MiB     50.7 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9347.8 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9347.8 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9347.7 MiB     -0.1 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9347.7 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9347.7 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9347.7 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9347.7 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9347.7 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9347.7 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9347.7 MiB      0.0 MiB           1           del e_spatial       
   194   9347.7 MiB      0.0 MiB           1           del e_bidir
   195   9347.7 MiB      0.0 MiB           1           del weights_bidir
   196   9347.7 MiB      0.0 MiB           1           del y_cluster
   197   9347.7 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9347.7 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9347.7 MiB      0.0 MiB           1           gc.collect()


41.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9347.7 MiB   9347.7 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9347.7 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9462.5 MiB    114.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9462.5 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9577.1 MiB    114.6 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9577.3 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9462.4 MiB   -114.8 MiB           1       del l1
   132                                             
   133   9491.2 MiB     28.7 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9347.7 MiB   -143.4 MiB           1       del e_1
   135   9347.7 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9347.7 MiB      0.0 MiB           1       if using_weights:
   138   9347.7 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9347.7 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9347.7 MiB      0.0 MiB           1           del weights_list
   141   9347.7 MiB      0.0 MiB           1           del l2
   142   9412.3 MiB     64.6 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9412.3 MiB      0.0 MiB           1           del weights_sparse
   144   9412.3 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9519.8 MiB    107.5 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9634.6 MiB    114.7 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9634.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9498.5 MiB   -136.0 MiB           1       del e_intersection
   150                                             
   151   9498.5 MiB      0.0 MiB           1       if using_weights:
   152   9498.5 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9347.7 MiB   9347.7 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9347.7 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9347.7 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9347.7 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9347.7 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9347.7 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9347.7 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9347.7 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9347.7 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9347.7 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9347.7 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9347.7 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9498.5 MiB    150.8 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9498.5 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9498.5 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9555.5 MiB     57.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9555.5 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9555.5 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9555.5 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9555.5 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9555.5 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9555.7 MiB      0.2 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9555.7 MiB      0.0 MiB           1           del e_spatial       
   194   9555.7 MiB      0.0 MiB           1           del e_bidir
   195   9555.7 MiB      0.0 MiB           1           del weights_bidir
   196   9491.3 MiB    -64.5 MiB           1           del y_cluster
   197   9491.3 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9491.3 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9491.3 MiB      0.0 MiB           1           gc.collect()


42.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9410.6 MiB   9410.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9410.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9514.9 MiB    104.3 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9515.1 MiB      0.2 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9590.6 MiB     75.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9590.7 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9486.3 MiB   -104.4 MiB           1       del l1
   132                                             
   133   9512.4 MiB     26.1 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9460.2 MiB    -52.2 MiB           1       del e_1
   135   9460.2 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9460.2 MiB      0.0 MiB           1       if using_weights:
   138   9460.2 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9460.2 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9460.2 MiB      0.0 MiB           1           del weights_list
   141   9460.2 MiB      0.0 MiB           1           del l2
   142   9434.2 MiB    -26.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9434.2 MiB      0.0 MiB           1           del weights_sparse
   144   9434.2 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9538.4 MiB    104.2 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9642.8 MiB    104.4 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9642.8 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9486.6 MiB   -156.2 MiB           1       del e_intersection
   150                                             
   151   9486.6 MiB      0.0 MiB           1       if using_weights:
   152   9486.6 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9491.3 MiB   9491.3 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9491.3 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9491.3 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9491.3 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9491.3 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9491.3 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9410.6 MiB    -80.7 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9410.6 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9410.6 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9410.6 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9410.6 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9410.6 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9486.6 MiB     76.0 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9486.6 MiB     -0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9486.6 MiB      0.1 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9564.7 MiB     78.1 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9564.7 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9564.7 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9564.7 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9564.7 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9564.7 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9564.9 MiB      0.2 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9564.9 MiB      0.0 MiB           1           del e_spatial       
   194   9564.9 MiB      0.0 MiB           1           del e_bidir
   195   9486.7 MiB    -78.2 MiB           1           del weights_bidir
   196   9486.7 MiB      0.0 MiB           1           del y_cluster
   197   9486.7 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9486.7 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9486.7 MiB      0.0 MiB           1           gc.collect()


43.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9419.2 MiB   9419.2 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9419.2 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9534.2 MiB    115.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9534.2 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9677.7 MiB    143.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9677.8 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9562.9 MiB   -115.0 MiB           1       del l1
   132                                             
   133   9591.6 MiB     28.8 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9448.0 MiB   -143.6 MiB           1       del e_1
   135   9448.0 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9448.0 MiB      0.0 MiB           1       if using_weights:
   138   9448.0 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9448.0 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9448.0 MiB      0.0 MiB           1           del weights_list
   141   9448.0 MiB      0.0 MiB           1           del l2
   142   9591.6 MiB    143.6 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9591.6 MiB      0.0 MiB           1           del weights_sparse
   144   9476.7 MiB   -114.8 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9620.3 MiB    143.6 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9730.5 MiB    110.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9730.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9586.9 MiB   -143.6 MiB           1       del e_intersection
   150                                             
   151   9586.9 MiB      0.0 MiB           1       if using_weights:
   152   9586.9 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9486.7 MiB   9486.7 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9486.7 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9486.7 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9486.7 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9486.7 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9486.7 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9419.2 MiB    -67.5 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9419.2 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9419.2 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9419.2 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9419.2 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9419.2 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9586.9 MiB    167.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9586.9 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9586.9 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9644.4 MiB     57.5 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9644.4 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9644.4 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9644.4 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9644.4 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9644.4 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9644.4 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9644.4 MiB      0.0 MiB           1           del e_spatial       
   194   9644.4 MiB      0.0 MiB           1           del e_bidir
   195   9644.4 MiB      0.0 MiB           1           del weights_bidir
   196   9644.4 MiB      0.0 MiB           1           del y_cluster
   197   9529.5 MiB   -114.9 MiB           1           del new_weights
   198                                                 
   199   9529.5 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9529.5 MiB      0.0 MiB           1           gc.collect()


44.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9409.8 MiB   9409.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9409.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9512.2 MiB    102.4 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9512.3 MiB      0.1 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9614.4 MiB    102.1 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9614.7 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9512.2 MiB   -102.5 MiB           1       del l1
   132                                             
   133   9537.8 MiB     25.6 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9486.6 MiB    -51.2 MiB           1       del e_1
   135   9486.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9486.6 MiB      0.0 MiB           1       if using_weights:
   138   9486.6 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9486.6 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9486.6 MiB      0.0 MiB           1           del weights_list
   141   9486.6 MiB      0.0 MiB           1           del l2
   142   9461.1 MiB    -25.5 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9461.1 MiB      0.0 MiB           1           del weights_sparse
   144   9461.1 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9563.4 MiB    102.3 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9665.5 MiB    102.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9665.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9512.1 MiB   -153.4 MiB           1       del e_intersection
   150                                             
   151   9512.1 MiB      0.0 MiB           1       if using_weights:
   152   9512.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9529.5 MiB   9529.5 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9529.5 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9529.5 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9529.5 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9529.5 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9529.5 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9409.8 MiB   -119.7 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9409.8 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9409.8 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9409.8 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9409.8 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9409.8 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9512.1 MiB    102.3 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9512.2 MiB      0.1 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9512.2 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9588.7 MiB     76.6 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9588.7 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9588.7 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9588.7 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9588.7 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9588.7 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9588.7 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9588.7 MiB      0.0 MiB           1           del e_spatial       
   194   9588.7 MiB      0.0 MiB           1           del e_bidir
   195   9588.7 MiB      0.0 MiB           1           del weights_bidir
   196   9588.7 MiB      0.0 MiB           1           del y_cluster
   197   9588.7 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9588.7 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9588.7 MiB      0.0 MiB           1           gc.collect()


45.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9402.6 MiB   9402.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9402.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9493.6 MiB     91.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9493.8 MiB      0.2 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9539.3 MiB     45.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9539.4 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9448.2 MiB    -91.2 MiB           1       del l1
   132                                             
   133   9448.2 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9402.7 MiB    -45.6 MiB           1       del e_1
   135   9402.7 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9402.7 MiB      0.0 MiB           1       if using_weights:
   138   9402.7 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9402.7 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9402.7 MiB      0.0 MiB           1           del weights_list
   141   9402.7 MiB      0.0 MiB           1           del l2
   142   9445.2 MiB     42.5 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9445.2 MiB      0.0 MiB           1           del weights_sparse
   144   9377.2 MiB    -68.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9468.2 MiB     91.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9559.2 MiB     91.0 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9559.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9513.8 MiB    -45.3 MiB           1       del e_intersection
   150                                             
   151   9513.8 MiB      0.0 MiB           1       if using_weights:
   152   9513.8 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9589.0 MiB   9589.0 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9589.0 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9589.0 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9589.0 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9589.0 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9589.0 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9402.6 MiB   -186.3 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9402.6 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9402.6 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9402.6 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9402.6 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9402.6 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9513.8 MiB    111.2 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9513.8 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9513.8 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9513.8 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9513.8 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9513.8 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9513.8 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9513.8 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9513.8 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9513.8 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9513.8 MiB      0.0 MiB           1           del e_spatial       
   194   9513.8 MiB      0.0 MiB           1           del e_bidir
   195   9513.8 MiB      0.0 MiB           1           del weights_bidir
   196   9513.8 MiB      0.0 MiB           1           del y_cluster
   197   9513.8 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9513.8 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9513.8 MiB      0.0 MiB           1           gc.collect()


45.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9399.8 MiB   9399.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9399.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9507.2 MiB    107.4 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9507.2 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9561.1 MiB     53.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9561.4 MiB      0.3 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9453.8 MiB   -107.6 MiB           1       del l1
   132                                             
   133   9453.8 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9400.0 MiB    -53.8 MiB           1       del e_1
   135   9400.0 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9400.0 MiB      0.0 MiB           1       if using_weights:
   138   9400.0 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9400.0 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9400.0 MiB      0.0 MiB           1           del weights_list
   141   9400.0 MiB      0.0 MiB           1           del l2
   142   9461.8 MiB     61.9 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9461.8 MiB      0.0 MiB           1           del weights_sparse
   144   9381.4 MiB    -80.4 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9488.6 MiB    107.2 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9596.1 MiB    107.5 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9596.1 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9542.5 MiB    -53.6 MiB           1       del e_intersection
   150                                             
   151   9542.5 MiB      0.0 MiB           1       if using_weights:
   152   9542.5 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9522.5 MiB   9522.5 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9522.5 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9522.5 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9522.5 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9522.5 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9522.5 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9399.8 MiB   -122.7 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9399.8 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9399.8 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9399.8 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9399.8 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9399.8 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9542.5 MiB    142.7 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9542.5 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9542.5 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9542.5 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9542.5 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9542.5 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9542.5 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9542.5 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9542.5 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9542.5 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9542.5 MiB      0.0 MiB           1           del e_spatial       
   194   9542.5 MiB      0.0 MiB           1           del e_bidir
   195   9542.5 MiB      0.0 MiB           1           del weights_bidir
   196   9542.5 MiB      0.0 MiB           1           del y_cluster
   197   9461.9 MiB    -80.6 MiB           1           del new_weights
   198                                                 
   199   9461.9 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9461.9 MiB      0.0 MiB           1           gc.collect()


46.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9461.9 MiB   9461.9 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9461.9 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9574.6 MiB    112.7 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9574.6 MiB      0.1 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9659.0 MiB     84.4 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9659.0 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9546.3 MiB   -112.7 MiB           1       del l1
   132                                             
   133   9574.5 MiB     28.2 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9518.2 MiB    -56.4 MiB           1       del e_1
   135   9518.2 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9518.2 MiB      0.0 MiB           1       if using_weights:
   138   9518.2 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9518.2 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9518.2 MiB      0.0 MiB           1           del weights_list
   141   9518.2 MiB      0.0 MiB           1           del l2
   142   9490.1 MiB    -28.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9490.1 MiB      0.0 MiB           1           del weights_sparse
   144   9490.1 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9602.5 MiB    112.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9715.4 MiB    112.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9715.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9581.8 MiB   -133.6 MiB           1       del e_intersection
   150                                             
   151   9581.8 MiB      0.0 MiB           1       if using_weights:
   152   9581.8 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9461.9 MiB   9461.9 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9461.9 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9461.9 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9461.9 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9461.9 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9461.9 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9461.9 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9461.9 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9461.9 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9461.9 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9461.9 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9461.9 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9581.8 MiB    119.9 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9581.9 MiB      0.1 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9581.9 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9581.9 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9581.9 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9581.9 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9581.9 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9581.9 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9581.9 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9581.9 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9581.9 MiB      0.0 MiB           1           del e_spatial       
   194   9581.9 MiB      0.0 MiB           1           del e_bidir
   195   9581.9 MiB      0.0 MiB           1           del weights_bidir
   196   9581.9 MiB      0.0 MiB           1           del y_cluster
   197   9581.9 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9581.9 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9581.9 MiB      0.0 MiB           1           gc.collect()


47.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9413.6 MiB   9413.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9413.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9413.6 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9413.6 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9450.3 MiB     36.6 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9450.5 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9450.5 MiB      0.0 MiB           1       del l1
   132                                             
   133   9450.8 MiB      0.3 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9450.8 MiB      0.0 MiB           1       del e_1
   135   9450.8 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9450.8 MiB      0.0 MiB           1       if using_weights:
   138   9450.8 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9450.8 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9450.8 MiB      0.0 MiB           1           del weights_list
   141   9450.8 MiB      0.0 MiB           1           del l2
   142   9450.8 MiB      0.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9450.8 MiB      0.0 MiB           1           del weights_sparse
   144   9450.8 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9450.8 MiB      0.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9509.2 MiB     58.5 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9509.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9509.2 MiB      0.0 MiB           1       del e_intersection
   150                                             
   151   9509.2 MiB      0.0 MiB           1       if using_weights:
   152   9509.2 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9581.9 MiB   9581.9 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9581.9 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9581.9 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9581.9 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9581.9 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9581.9 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9413.6 MiB   -168.2 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9413.6 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9413.6 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9413.6 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9413.6 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9413.6 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9509.2 MiB     95.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9509.2 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9509.2 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9509.2 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9509.2 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9509.2 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9509.2 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9509.2 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9509.2 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9509.7 MiB      0.4 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9509.7 MiB      0.0 MiB           1           del e_spatial       
   194   9414.6 MiB    -95.1 MiB           1           del e_bidir
   195   9414.6 MiB      0.0 MiB           1           del weights_bidir
   196   9414.6 MiB      0.0 MiB           1           del y_cluster
   197   9414.6 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9414.6 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9414.6 MiB      0.0 MiB           1           gc.collect()


48.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9423.0 MiB   9423.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9423.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9526.4 MiB    103.4 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9526.6 MiB      0.1 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9629.8 MiB    103.2 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9630.0 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9526.4 MiB   -103.5 MiB           1       del l1
   132                                             
   133   9552.3 MiB     25.9 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9500.6 MiB    -51.8 MiB           1       del e_1
   135   9500.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9500.6 MiB      0.0 MiB           1       if using_weights:
   138   9500.6 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9500.6 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9500.6 MiB      0.0 MiB           1           del weights_list
   141   9500.6 MiB      0.0 MiB           1           del l2
   142   9474.8 MiB    -25.8 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9474.8 MiB      0.0 MiB           1           del weights_sparse
   144   9474.8 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9578.2 MiB    103.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9681.6 MiB    103.4 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9681.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9526.6 MiB   -154.9 MiB           1       del e_intersection
   150                                             
   151   9526.6 MiB      0.0 MiB           1       if using_weights:
   152   9526.6 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9423.0 MiB   9423.0 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9423.0 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9423.0 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9423.0 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9423.0 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9423.0 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9423.0 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9423.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9423.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9423.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9423.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9423.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9526.6 MiB    103.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9526.7 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9526.7 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9578.0 MiB     51.3 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9578.0 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9578.0 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9578.0 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9578.0 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9578.0 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9578.2 MiB      0.2 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9578.2 MiB      0.0 MiB           1           del e_spatial       
   194   9578.2 MiB      0.0 MiB           1           del e_bidir
   195   9578.2 MiB      0.0 MiB           1           del weights_bidir
   196   9578.2 MiB      0.0 MiB           1           del y_cluster
   197   9578.2 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9578.2 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9578.2 MiB      0.0 MiB           1           gc.collect()


49.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9403.7 MiB   9403.7 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9403.7 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9403.7 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9403.7 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9493.6 MiB     89.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9493.8 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9493.8 MiB      0.0 MiB           1       del l1
   132                                             
   133   9493.8 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9453.3 MiB    -40.5 MiB           1       del e_1
   135   9453.3 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9453.3 MiB      0.0 MiB           1       if using_weights:
   138   9453.3 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9453.3 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9453.3 MiB      0.0 MiB           1           del weights_list
   141   9453.3 MiB      0.0 MiB           1           del l2
   142   9458.2 MiB      4.9 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9458.2 MiB      0.0 MiB           1           del weights_sparse
   144   9458.2 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9458.2 MiB      0.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9539.2 MiB     81.0 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9539.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9433.1 MiB   -106.1 MiB           1       del e_intersection
   150                                             
   151   9433.1 MiB      0.0 MiB           1       if using_weights:
   152   9433.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9585.4 MiB   9585.4 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9585.4 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9585.4 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9585.4 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9585.4 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9585.4 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9403.7 MiB   -181.7 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9403.7 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9403.7 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9403.7 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9403.7 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9403.7 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9433.1 MiB     29.4 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9433.1 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9433.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9473.6 MiB     40.5 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9473.6 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9473.6 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9473.6 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9473.6 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9473.6 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9473.6 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9473.6 MiB      0.0 MiB           1           del e_spatial       
   194   9473.6 MiB      0.0 MiB           1           del e_bidir
   195   9473.6 MiB      0.0 MiB           1           del weights_bidir
   196   9473.6 MiB      0.0 MiB           1           del y_cluster
   197   9473.6 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9473.6 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9473.6 MiB      0.0 MiB           1           gc.collect()


50.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9435.9 MiB   9435.9 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9435.9 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9549.0 MiB    113.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9549.0 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9621.7 MiB     72.6 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9621.8 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9508.6 MiB   -113.2 MiB           1       del l1
   132                                             
   133   9536.9 MiB     28.3 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9395.6 MiB   -141.4 MiB           1       del e_1
   135   9395.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9395.6 MiB      0.0 MiB           1       if using_weights:
   138   9395.6 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9395.6 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9395.6 MiB      0.0 MiB           1           del weights_list
   141   9395.6 MiB      0.0 MiB           1           del l2
   142   9459.2 MiB     63.7 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9459.2 MiB      0.0 MiB           1           del weights_sparse
   144   9459.2 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9565.2 MiB    106.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9678.4 MiB    113.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9678.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9544.2 MiB   -134.1 MiB           1       del e_intersection
   150                                             
   151   9544.2 MiB      0.0 MiB           1       if using_weights:
   152   9544.2 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9482.6 MiB   9482.6 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9482.6 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9482.6 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9482.6 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9482.6 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9482.6 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9435.9 MiB    -46.8 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9435.9 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9435.9 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9435.9 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9435.9 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9435.9 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9544.2 MiB    108.4 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9544.2 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9544.2 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9544.0 MiB     -0.2 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9544.0 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9544.0 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9544.0 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9544.0 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9544.0 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9544.0 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9544.0 MiB      0.0 MiB           1           del e_spatial       
   194   9544.0 MiB      0.0 MiB           1           del e_bidir
   195   9544.0 MiB      0.0 MiB           1           del weights_bidir
   196   9544.0 MiB      0.0 MiB           1           del y_cluster
   197   9544.0 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9544.0 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9544.0 MiB      0.0 MiB           1           gc.collect()


50.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9412.1 MiB   9412.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9412.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9412.1 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9412.1 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9489.5 MiB     77.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9489.5 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9489.5 MiB      0.0 MiB           1       del l1
   132                                             
   133   9489.5 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9444.3 MiB    -45.2 MiB           1       del e_1
   135   9444.3 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9444.3 MiB      0.0 MiB           1       if using_weights:
   138   9444.3 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9444.3 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9444.3 MiB      0.0 MiB           1           del weights_list
   141   9444.3 MiB      0.0 MiB           1           del l2
   142   9489.5 MiB     45.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9489.5 MiB      0.0 MiB           1           del weights_sparse
   144   9421.9 MiB    -67.6 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9489.4 MiB     67.5 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9579.9 MiB     90.5 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9579.9 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9534.9 MiB    -45.0 MiB           1       del e_intersection
   150                                             
   151   9534.9 MiB      0.0 MiB           1       if using_weights:
   152   9534.9 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9551.7 MiB   9551.7 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9551.7 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9551.7 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9551.7 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9551.7 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9551.7 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9412.1 MiB   -139.7 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9412.1 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9412.1 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9412.1 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9412.1 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9412.1 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9534.9 MiB    122.8 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9534.9 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9534.9 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9534.9 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9534.9 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9534.9 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9534.9 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9534.9 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9534.9 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9534.9 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9534.9 MiB      0.0 MiB           1           del e_spatial       
   194   9534.9 MiB      0.0 MiB           1           del e_bidir
   195   9534.9 MiB      0.0 MiB           1           del weights_bidir
   196   9534.9 MiB      0.0 MiB           1           del y_cluster
   197   9467.2 MiB    -67.6 MiB           1           del new_weights
   198                                                 
   199   9467.2 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9467.2 MiB      0.0 MiB           1           gc.collect()


51.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9469.5 MiB   9469.5 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9469.5 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9469.5 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9469.5 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9577.1 MiB    107.6 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9577.1 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9577.1 MiB      0.0 MiB           1       del l1
   132                                             
   133   9577.1 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9534.0 MiB    -43.1 MiB           1       del e_1
   135   9534.0 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9534.0 MiB      0.0 MiB           1       if using_weights:
   138   9534.0 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9534.0 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9534.0 MiB      0.0 MiB           1           del weights_list
   141   9534.0 MiB      0.0 MiB           1           del l2
   142   9577.1 MiB     43.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9577.1 MiB      0.0 MiB           1           del weights_sparse
   144   9512.6 MiB    -64.5 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9577.0 MiB     64.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9663.1 MiB     86.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9663.1 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9620.1 MiB    -43.0 MiB           1       del e_intersection
   150                                             
   151   9620.1 MiB      0.0 MiB           1       if using_weights:
   152   9620.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9474.8 MiB   9474.8 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9474.8 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9474.8 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9474.8 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9474.8 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9474.8 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9469.5 MiB     -5.3 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9469.5 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9469.5 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9469.5 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9469.5 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9469.5 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9620.1 MiB    150.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9620.1 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9620.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9620.1 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9620.1 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9620.1 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9620.1 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9620.1 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9620.1 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9620.2 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9620.2 MiB      0.0 MiB           1           del e_spatial       
   194   9620.2 MiB      0.0 MiB           1           del e_bidir
   195   9620.2 MiB      0.0 MiB           1           del weights_bidir
   196   9620.2 MiB      0.0 MiB           1           del y_cluster
   197   9555.6 MiB    -64.5 MiB           1           del new_weights
   198                                                 
   199   9555.6 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9555.6 MiB      0.0 MiB           1           gc.collect()


52.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9404.9 MiB   9404.9 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9404.9 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9501.8 MiB     96.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9501.8 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9598.4 MiB     96.7 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9598.6 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9501.7 MiB    -96.9 MiB           1       del l1
   132                                             
   133   9526.0 MiB     24.3 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9477.5 MiB    -48.5 MiB           1       del e_1
   135   9477.5 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9477.5 MiB      0.0 MiB           1       if using_weights:
   138   9477.5 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9477.5 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9477.5 MiB      0.0 MiB           1           del weights_list
   141   9477.5 MiB      0.0 MiB           1           del l2
   142   9453.4 MiB    -24.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9453.4 MiB      0.0 MiB           1           del weights_sparse
   144   9453.4 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9550.1 MiB     96.7 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9647.0 MiB     96.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9647.0 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9501.9 MiB   -145.1 MiB           1       del e_intersection
   150                                             
   151   9501.9 MiB      0.0 MiB           1       if using_weights:
   152   9501.9 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9563.8 MiB   9563.8 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9563.8 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9563.8 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9563.8 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9563.8 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9563.8 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9404.9 MiB   -158.9 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9404.9 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9404.9 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9404.9 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9404.9 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9404.9 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9501.9 MiB     96.9 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9501.9 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9501.9 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9501.9 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9501.9 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9501.9 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9501.9 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9501.9 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9501.9 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9501.9 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9501.9 MiB      0.0 MiB           1           del e_spatial       
   194   9501.9 MiB      0.0 MiB           1           del e_bidir
   195   9501.9 MiB      0.0 MiB           1           del weights_bidir
   196   9501.9 MiB      0.0 MiB           1           del y_cluster
   197   9501.9 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9501.9 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9501.9 MiB      0.0 MiB           1           gc.collect()


53.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9405.1 MiB   9405.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9405.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9555.7 MiB    150.6 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9555.7 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9607.5 MiB     51.8 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9607.5 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9456.8 MiB   -150.7 MiB           1       del l1
   132                                             
   133   9532.1 MiB     75.3 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9419.1 MiB   -113.0 MiB           1       del e_1
   135   9419.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9419.1 MiB      0.0 MiB           1       if using_weights:
   138   9419.1 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9419.1 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9419.1 MiB      0.0 MiB           1           del weights_list
   141   9419.1 MiB      0.0 MiB           1           del l2
   142   9475.5 MiB     56.4 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9475.5 MiB      0.0 MiB           1           del weights_sparse
   144   9437.8 MiB    -37.7 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9513.2 MiB     75.3 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9607.1 MiB     93.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9607.1 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9456.4 MiB   -150.7 MiB           1       del e_intersection
   150                                             
   151   9456.4 MiB      0.0 MiB           1       if using_weights:
   152   9456.4 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9512.3 MiB   9512.3 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9512.3 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9512.3 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9512.3 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9512.3 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9512.3 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9405.1 MiB   -107.2 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9405.1 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9405.1 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9405.1 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9405.1 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9405.1 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9456.4 MiB     51.3 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9456.4 MiB     -0.1 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9456.4 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9456.3 MiB     -0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9456.3 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9456.3 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9456.3 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9456.3 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9456.3 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9456.4 MiB      0.1 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9456.4 MiB      0.0 MiB           1           del e_spatial       
   194   9456.4 MiB      0.0 MiB           1           del e_bidir
   195   9456.4 MiB      0.0 MiB           1           del weights_bidir
   196   9456.4 MiB      0.0 MiB           1           del y_cluster
   197   9456.4 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9456.4 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9456.4 MiB      0.0 MiB           1           gc.collect()


54.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9465.7 MiB   9465.7 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9465.7 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9584.0 MiB    118.3 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9584.2 MiB      0.2 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9683.8 MiB     99.6 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9684.0 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9565.4 MiB   -118.6 MiB           1       del l1
   132                                             
   133   9624.7 MiB     59.3 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9565.4 MiB    -59.3 MiB           1       del e_1
   135   9565.4 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9565.4 MiB      0.0 MiB           1       if using_weights:
   138   9565.4 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9565.4 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9565.4 MiB      0.0 MiB           1           del weights_list
   141   9565.4 MiB      0.0 MiB           1           del l2
   142   9624.4 MiB     59.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9624.4 MiB      0.0 MiB           1           del weights_sparse
   144   9535.9 MiB    -88.6 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9565.4 MiB     29.5 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9683.7 MiB    118.3 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9683.7 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9624.7 MiB    -59.0 MiB           1       del e_intersection
   150                                             
   151   9624.7 MiB      0.0 MiB           1       if using_weights:
   152   9624.7 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9465.5 MiB   9465.5 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9465.5 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9465.5 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9465.5 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9465.5 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9465.5 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9465.7 MiB      0.2 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9465.7 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9465.7 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9465.7 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9465.7 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9465.7 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9624.7 MiB    159.0 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9624.7 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9624.7 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9654.4 MiB     29.6 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9654.4 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9654.4 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9654.4 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9654.4 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9654.4 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9654.4 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9654.4 MiB      0.0 MiB           1           del e_spatial       
   194   9654.4 MiB      0.0 MiB           1           del e_bidir
   195   9654.4 MiB      0.0 MiB           1           del weights_bidir
   196   9654.4 MiB      0.0 MiB           1           del y_cluster
   197   9565.7 MiB    -88.7 MiB           1           del new_weights
   198                                                 
   199   9565.7 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9565.7 MiB      0.0 MiB           1           gc.collect()


55.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9409.1 MiB   9409.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9409.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9529.5 MiB    120.4 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9529.5 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9680.2 MiB    150.7 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9680.3 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9559.7 MiB   -120.6 MiB           1       del l1
   132                                             
   133   9589.9 MiB     30.2 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9439.3 MiB   -150.6 MiB           1       del e_1
   135   9439.3 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9439.3 MiB      0.0 MiB           1       if using_weights:
   138   9439.3 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9439.3 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9439.3 MiB      0.0 MiB           1           del weights_list
   141   9439.3 MiB      0.0 MiB           1           del l2
   142   9589.8 MiB    150.6 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9589.8 MiB      0.0 MiB           1           del weights_sparse
   144   9469.4 MiB   -120.4 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9620.0 MiB    150.6 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9704.2 MiB     84.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9704.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9553.8 MiB   -150.4 MiB           1       del e_intersection
   150                                             
   151   9553.8 MiB      0.0 MiB           1       if using_weights:
   152   9553.8 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9574.8 MiB   9574.8 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9574.8 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9574.8 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9574.8 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9574.8 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9574.8 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9409.1 MiB   -165.7 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9409.1 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9409.1 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9409.1 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9409.1 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9409.1 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9553.8 MiB    144.7 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9553.8 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9553.8 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9613.6 MiB     59.8 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9613.6 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9613.6 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9613.6 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9613.6 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9613.6 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9613.8 MiB      0.2 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9613.8 MiB      0.0 MiB           1           del e_spatial       
   194   9613.8 MiB      0.0 MiB           1           del e_bidir
   195   9613.8 MiB      0.0 MiB           1           del weights_bidir
   196   9613.8 MiB      0.0 MiB           1           del y_cluster
   197   9493.4 MiB   -120.4 MiB           1           del new_weights
   198                                                 
   199   9493.4 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9493.4 MiB      0.0 MiB           1           gc.collect()


55.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9392.0 MiB   9392.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9392.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9392.0 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9392.0 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9462.5 MiB     70.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9462.5 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9462.5 MiB      0.0 MiB           1       del l1
   132                                             
   133   9462.7 MiB      0.2 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9427.5 MiB    -35.2 MiB           1       del e_1
   135   9427.5 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9427.5 MiB      0.0 MiB           1       if using_weights:
   138   9427.5 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9427.5 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9427.5 MiB      0.0 MiB           1           del weights_list
   141   9427.5 MiB      0.0 MiB           1           del l2
   142   9462.7 MiB     35.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9462.7 MiB      0.0 MiB           1           del weights_sparse
   144   9462.7 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9462.7 MiB      0.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9533.1 MiB     70.4 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9533.1 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9533.1 MiB      0.0 MiB           1       del e_intersection
   150                                             
   151   9533.1 MiB      0.0 MiB           1       if using_weights:
   152   9533.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9500.2 MiB   9500.2 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9500.2 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9500.2 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9500.2 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9500.2 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9500.2 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9392.0 MiB   -108.2 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9392.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9392.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9392.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9392.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9392.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9533.1 MiB    141.0 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9533.1 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9533.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9533.1 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9533.1 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9533.1 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9533.1 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9533.1 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9533.1 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9533.2 MiB      0.1 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9533.2 MiB      0.0 MiB           1           del e_spatial       
   194   9533.2 MiB      0.0 MiB           1           del e_bidir
   195   9533.2 MiB      0.0 MiB           1           del weights_bidir
   196   9533.2 MiB      0.0 MiB           1           del y_cluster
   197   9463.0 MiB    -70.2 MiB           1           del new_weights
   198                                                 
   199   9463.0 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9463.0 MiB      0.0 MiB           1           gc.collect()


56.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9435.4 MiB   9435.4 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9435.4 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9536.7 MiB    101.3 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9536.7 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9638.1 MiB    101.3 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9638.1 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9536.7 MiB   -101.4 MiB           1       del l1
   132                                             
   133   9562.1 MiB     25.4 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9511.4 MiB    -50.7 MiB           1       del e_1
   135   9511.4 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9511.4 MiB      0.0 MiB           1       if using_weights:
   138   9511.4 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9511.4 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9511.4 MiB      0.0 MiB           1           del weights_list
   141   9511.4 MiB      0.0 MiB           1           del l2
   142   9486.1 MiB    -25.2 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9486.1 MiB      0.0 MiB           1           del weights_sparse
   144   9486.1 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9587.2 MiB    101.1 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9688.5 MiB    101.3 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9688.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9536.7 MiB   -151.8 MiB           1       del e_intersection
   150                                             
   151   9536.7 MiB      0.0 MiB           1       if using_weights:
   152   9536.7 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9471.2 MiB   9471.2 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9471.2 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9471.2 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9471.2 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9471.2 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9471.2 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9435.4 MiB    -35.7 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9435.4 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9435.4 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9435.4 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9435.4 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9435.4 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9536.7 MiB    101.2 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9536.8 MiB      0.1 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9536.8 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9587.0 MiB     50.3 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9587.0 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9587.0 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9587.0 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9587.0 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9587.0 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9587.3 MiB      0.2 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9587.3 MiB      0.0 MiB           1           del e_spatial       
   194   9587.3 MiB      0.0 MiB           1           del e_bidir
   195   9587.3 MiB      0.0 MiB           1           del weights_bidir
   196   9587.3 MiB      0.0 MiB           1           del y_cluster
   197   9587.3 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9587.3 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9587.3 MiB      0.0 MiB           1           gc.collect()


57.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9401.2 MiB   9401.2 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9401.2 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9515.0 MiB    113.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9515.0 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9578.4 MiB     63.4 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9578.5 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9464.5 MiB   -114.0 MiB           1       del l1
   132                                             
   133   9493.0 MiB     28.5 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9350.6 MiB   -142.4 MiB           1       del e_1
   135   9350.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9350.6 MiB      0.0 MiB           1       if using_weights:
   138   9350.6 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9350.6 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9350.6 MiB      0.0 MiB           1           del weights_list
   141   9350.6 MiB      0.0 MiB           1           del l2
   142   9414.7 MiB     64.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9414.7 MiB      0.0 MiB           1           del weights_sparse
   144   9414.7 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9521.5 MiB    106.7 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9635.4 MiB    114.0 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9635.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9500.2 MiB   -135.2 MiB           1       del e_intersection
   150                                             
   151   9500.2 MiB      0.0 MiB           1       if using_weights:
   152   9500.2 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9596.2 MiB   9596.2 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9596.2 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9596.2 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9596.2 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9596.2 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9596.2 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9401.2 MiB   -195.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9401.2 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9401.2 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9401.2 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9401.2 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9401.2 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9500.2 MiB     99.0 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9500.2 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9500.2 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9557.2 MiB     57.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9557.2 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9557.2 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9557.2 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9557.2 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9557.2 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9557.2 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9557.2 MiB      0.0 MiB           1           del e_spatial       
   194   9557.2 MiB      0.0 MiB           1           del e_bidir
   195   9557.2 MiB      0.0 MiB           1           del weights_bidir
   196   9493.2 MiB    -64.0 MiB           1           del y_cluster
   197   9493.2 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9493.2 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9493.2 MiB      0.0 MiB           1           gc.collect()


58.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9394.0 MiB   9394.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9394.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9394.0 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9394.0 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9475.1 MiB     81.1 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9475.1 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9475.1 MiB      0.0 MiB           1       del l1
   132                                             
   133   9475.1 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9431.2 MiB    -43.9 MiB           1       del e_1
   135   9431.2 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9431.2 MiB      0.0 MiB           1       if using_weights:
   138   9431.2 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9431.2 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9431.2 MiB      0.0 MiB           1           del weights_list
   141   9431.2 MiB      0.0 MiB           1           del l2
   142   9475.0 MiB     43.8 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9475.0 MiB      0.0 MiB           1           del weights_sparse
   144   9409.4 MiB    -65.6 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9474.8 MiB     65.5 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9562.7 MiB     87.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9562.7 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9518.9 MiB    -43.9 MiB           1       del e_intersection
   150                                             
   151   9518.9 MiB      0.0 MiB           1       if using_weights:
   152   9518.9 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9500.9 MiB   9500.9 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9500.9 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9500.9 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9500.9 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9500.9 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9500.9 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9394.0 MiB   -107.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9394.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9394.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9394.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9394.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9394.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9518.9 MiB    124.9 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9518.9 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9518.9 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9518.9 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9518.9 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9518.9 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9518.9 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9518.9 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9518.9 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9518.9 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9518.9 MiB      0.0 MiB           1           del e_spatial       
   194   9518.9 MiB      0.0 MiB           1           del e_bidir
   195   9518.9 MiB      0.0 MiB           1           del weights_bidir
   196   9518.9 MiB      0.0 MiB           1           del y_cluster
   197   9453.2 MiB    -65.7 MiB           1           del new_weights
   198                                                 
   199   9453.2 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9453.2 MiB      0.0 MiB           1           gc.collect()


59.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9461.3 MiB   9461.3 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9461.3 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9556.8 MiB     95.5 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9556.8 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9628.7 MiB     71.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9628.7 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9533.0 MiB    -95.7 MiB           1       del l1
   132                                             
   133   9580.9 MiB     47.9 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9533.0 MiB    -47.9 MiB           1       del e_1
   135   9533.0 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9533.0 MiB      0.0 MiB           1       if using_weights:
   138   9533.0 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9533.0 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9533.0 MiB      0.0 MiB           1           del weights_list
   141   9533.0 MiB      0.0 MiB           1           del l2
   142   9604.7 MiB     71.7 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9604.7 MiB      0.0 MiB           1           del weights_sparse
   144   9533.1 MiB    -71.5 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9580.9 MiB     47.7 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9667.9 MiB     87.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9667.9 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9620.1 MiB    -47.9 MiB           1       del e_intersection
   150                                             
   151   9620.1 MiB      0.0 MiB           1       if using_weights:
   152   9620.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9461.2 MiB   9461.2 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9461.2 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9461.2 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9461.2 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9461.2 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9461.2 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9461.3 MiB      0.2 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9461.3 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9461.3 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9461.3 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9461.3 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9461.3 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9620.1 MiB    158.7 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9620.1 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9620.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9620.1 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9620.1 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9620.1 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9620.1 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9620.1 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9620.1 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9620.1 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9620.1 MiB      0.0 MiB           1           del e_spatial       
   194   9620.1 MiB      0.0 MiB           1           del e_bidir
   195   9620.1 MiB      0.0 MiB           1           del weights_bidir
   196   9620.1 MiB      0.0 MiB           1           del y_cluster
   197   9548.4 MiB    -71.7 MiB           1           del new_weights
   198                                                 
   199   9548.4 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9548.4 MiB      0.0 MiB           1           gc.collect()


60.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9389.7 MiB   9389.7 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9389.7 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9472.5 MiB     82.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9472.7 MiB      0.2 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9534.6 MiB     61.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9534.8 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9451.8 MiB    -83.0 MiB           1       del l1
   132                                             
   133   9451.8 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9410.3 MiB    -41.5 MiB           1       del e_1
   135   9410.3 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9410.3 MiB      0.0 MiB           1       if using_weights:
   138   9410.3 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9410.3 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9410.3 MiB      0.0 MiB           1           del weights_list
   141   9410.3 MiB      0.0 MiB           1           del l2
   142   9410.4 MiB      0.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9410.4 MiB      0.0 MiB           1           del weights_sparse
   144   9410.4 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9493.2 MiB     82.8 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9576.2 MiB     83.0 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9576.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9534.8 MiB    -41.4 MiB           1       del e_intersection
   150                                             
   151   9534.8 MiB      0.0 MiB           1       if using_weights:
   152   9534.8 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9555.7 MiB   9555.7 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9555.7 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9555.7 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9555.7 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9555.7 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9555.7 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9389.7 MiB   -166.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9389.7 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9389.7 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9389.7 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9389.7 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9389.7 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9534.8 MiB    145.1 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9534.8 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9534.8 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9534.8 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9534.8 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9534.8 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9534.8 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9534.8 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9534.8 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9534.8 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9534.8 MiB      0.0 MiB           1           del e_spatial       
   194   9534.8 MiB      0.0 MiB           1           del e_bidir
   195   9534.8 MiB      0.0 MiB           1           del weights_bidir
   196   9534.8 MiB      0.0 MiB           1           del y_cluster
   197   9534.8 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9534.8 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9534.8 MiB      0.0 MiB           1           gc.collect()


60.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9391.0 MiB   9391.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9391.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9522.7 MiB    131.7 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9522.8 MiB      0.1 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9588.8 MiB     65.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9588.8 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9456.9 MiB   -131.9 MiB           1       del l1
   132                                             
   133   9522.8 MiB     65.9 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9456.9 MiB    -65.9 MiB           1       del e_1
   135   9456.9 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9456.9 MiB      0.0 MiB           1       if using_weights:
   138   9456.9 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9456.9 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9456.9 MiB      0.0 MiB           1           del weights_list
   141   9456.9 MiB      0.0 MiB           1           del l2
   142   9489.9 MiB     33.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9489.9 MiB      0.0 MiB           1           del weights_sparse
   144   9456.9 MiB    -33.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9522.8 MiB     65.9 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9648.1 MiB    125.3 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9648.1 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9516.2 MiB   -131.9 MiB           1       del e_intersection
   150                                             
   151   9516.2 MiB      0.0 MiB           1       if using_weights:
   152   9516.2 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9544.5 MiB   9544.5 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9544.5 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9544.5 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9544.5 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9544.5 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9544.5 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9391.0 MiB   -153.5 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9391.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9391.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9391.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9391.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9391.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9516.2 MiB    125.3 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9516.0 MiB     -0.2 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9516.0 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9516.0 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9516.0 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9516.0 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9516.0 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9516.0 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9516.0 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9516.0 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9516.0 MiB      0.0 MiB           1           del e_spatial       
   194   9516.0 MiB      0.0 MiB           1           del e_bidir
   195   9516.0 MiB      0.0 MiB           1           del weights_bidir
   196   9516.0 MiB      0.0 MiB           1           del y_cluster
   197   9516.0 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9516.0 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9516.0 MiB      0.0 MiB           1           gc.collect()


61.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9394.0 MiB   9394.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9394.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9490.9 MiB     96.9 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9490.9 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9549.8 MiB     58.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9549.9 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9452.9 MiB    -97.0 MiB           1       del l1
   132                                             
   133   9452.9 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9404.4 MiB    -48.5 MiB           1       del e_1
   135   9404.4 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9404.4 MiB      0.0 MiB           1       if using_weights:
   138   9404.4 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9404.4 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9404.4 MiB      0.0 MiB           1           del weights_list
   141   9404.4 MiB      0.0 MiB           1           del l2
   142   9477.1 MiB     72.7 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9477.1 MiB      0.0 MiB           1           del weights_sparse
   144   9404.6 MiB    -72.6 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9501.2 MiB     96.7 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9598.2 MiB     96.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9598.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9549.9 MiB    -48.3 MiB           1       del e_intersection
   150                                             
   151   9549.9 MiB      0.0 MiB           1       if using_weights:
   152   9549.9 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9524.2 MiB   9524.2 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9524.2 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9524.2 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9524.2 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9524.2 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9524.2 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9394.0 MiB   -130.3 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9394.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9394.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9394.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9394.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9394.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9549.9 MiB    155.9 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9549.9 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9549.9 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9549.9 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9549.9 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9549.9 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9549.9 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9549.9 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9549.9 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9549.9 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9549.9 MiB      0.0 MiB           1           del e_spatial       
   194   9549.9 MiB      0.0 MiB           1           del e_bidir
   195   9549.9 MiB      0.0 MiB           1           del weights_bidir
   196   9549.9 MiB      0.0 MiB           1           del y_cluster
   197   9428.8 MiB   -121.1 MiB           1           del new_weights
   198                                                 
   199   9428.8 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9428.8 MiB      0.0 MiB           1           gc.collect()


62.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9436.6 MiB   9436.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9436.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9525.0 MiB     88.4 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9525.0 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9591.3 MiB     66.3 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9591.3 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9502.8 MiB    -88.5 MiB           1       del l1
   132                                             
   133   9547.0 MiB     44.2 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9502.8 MiB    -44.2 MiB           1       del e_1
   135   9502.8 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9502.8 MiB      0.0 MiB           1       if using_weights:
   138   9502.8 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9502.8 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9502.8 MiB      0.0 MiB           1           del weights_list
   141   9502.8 MiB      0.0 MiB           1           del l2
   142   9569.0 MiB     66.2 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9569.0 MiB      0.0 MiB           1           del weights_sparse
   144   9502.9 MiB    -66.1 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9547.0 MiB     44.1 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9635.6 MiB     88.6 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9635.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9591.4 MiB    -44.2 MiB           1       del e_intersection
   150                                             
   151   9591.4 MiB      0.0 MiB           1       if using_weights:
   152   9591.4 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9436.5 MiB   9436.5 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9436.5 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9436.5 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9436.5 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9436.5 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9436.5 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9436.6 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9436.6 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9436.6 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9436.6 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9436.6 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9436.6 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9591.4 MiB    154.8 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9591.4 MiB      0.1 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9591.4 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9591.4 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9591.4 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9591.4 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9591.4 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9591.4 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9591.4 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9591.4 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9591.4 MiB      0.0 MiB           1           del e_spatial       
   194   9591.4 MiB      0.0 MiB           1           del e_bidir
   195   9591.4 MiB      0.0 MiB           1           del weights_bidir
   196   9591.4 MiB      0.0 MiB           1           del y_cluster
   197   9525.2 MiB    -66.2 MiB           1           del new_weights
   198                                                 
   199   9525.2 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9525.2 MiB      0.0 MiB           1           gc.collect()


63.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9399.6 MiB   9399.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9399.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9509.1 MiB    109.6 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9509.2 MiB      0.1 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9591.3 MiB     82.1 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9591.3 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9481.7 MiB   -109.6 MiB           1       del l1
   132                                             
   133   9536.5 MiB     54.8 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9481.7 MiB    -54.8 MiB           1       del e_1
   135   9481.7 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9481.7 MiB      0.0 MiB           1       if using_weights:
   138   9481.7 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9481.7 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9481.7 MiB      0.0 MiB           1           del weights_list
   141   9481.7 MiB      0.0 MiB           1           del l2
   142   9563.6 MiB     82.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9563.6 MiB      0.0 MiB           1           del weights_sparse
   144   9481.8 MiB    -81.9 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9536.5 MiB     54.7 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9646.0 MiB    109.5 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9646.0 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9591.1 MiB    -54.8 MiB           1       del e_intersection
   150                                             
   151   9591.1 MiB      0.0 MiB           1       if using_weights:
   152   9591.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9533.8 MiB   9533.8 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9533.8 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9533.8 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9533.8 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9533.8 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9533.8 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9399.6 MiB   -134.3 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9399.6 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9399.6 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9399.6 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9399.6 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9399.6 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9591.1 MiB    191.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9591.1 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9591.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9591.1 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9591.1 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9591.1 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9591.1 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9591.1 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9591.1 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9591.1 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9591.1 MiB      0.0 MiB           1           del e_spatial       
   194   9591.1 MiB      0.0 MiB           1           del e_bidir
   195   9591.1 MiB      0.0 MiB           1           del weights_bidir
   196   9591.1 MiB      0.0 MiB           1           del y_cluster
   197   9509.0 MiB    -82.1 MiB           1           del new_weights
   198                                                 
   199   9509.0 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9509.0 MiB      0.0 MiB           1           gc.collect()


64.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9394.9 MiB   9394.9 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9394.9 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9512.8 MiB    117.9 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9512.8 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9601.2 MiB     88.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9601.2 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9483.2 MiB   -118.0 MiB           1       del l1
   132                                             
   133   9542.2 MiB     59.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9483.2 MiB    -59.0 MiB           1       del e_1
   135   9483.2 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9483.2 MiB      0.0 MiB           1       if using_weights:
   138   9483.2 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9483.2 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9483.2 MiB      0.0 MiB           1           del weights_list
   141   9483.2 MiB      0.0 MiB           1           del l2
   142   9483.4 MiB      0.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9483.4 MiB      0.0 MiB           1           del weights_sparse
   144   9483.4 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9542.2 MiB     58.9 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9654.8 MiB    112.6 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9654.8 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9507.5 MiB   -147.4 MiB           1       del e_intersection
   150                                             
   151   9507.5 MiB      0.0 MiB           1       if using_weights:
   152   9507.5 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9517.9 MiB   9517.9 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9517.9 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9517.9 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9517.9 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9517.9 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9517.9 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9394.9 MiB   -123.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9394.9 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9394.9 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9394.9 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9394.9 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9394.9 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9507.5 MiB    112.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9507.5 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9507.5 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9566.3 MiB     58.8 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9566.3 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9566.3 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9566.3 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9566.3 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9566.3 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9566.5 MiB      0.2 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9566.5 MiB      0.0 MiB           1           del e_spatial       
   194   9566.5 MiB      0.0 MiB           1           del e_bidir
   195   9566.5 MiB      0.0 MiB           1           del weights_bidir
   196   9566.5 MiB      0.0 MiB           1           del y_cluster
   197   9566.5 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9566.5 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9566.5 MiB      0.0 MiB           1           gc.collect()


65.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9390.0 MiB   9390.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9390.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9536.2 MiB    146.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9536.4 MiB      0.2 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9609.7 MiB     73.2 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9609.7 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9463.2 MiB   -146.4 MiB           1       del l1
   132                                             
   133   9536.4 MiB     73.2 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9463.2 MiB    -73.2 MiB           1       del e_1
   135   9463.2 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9463.2 MiB      0.0 MiB           1       if using_weights:
   138   9463.2 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9463.2 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9463.2 MiB      0.0 MiB           1           del weights_list
   141   9463.2 MiB      0.0 MiB           1           del l2
   142   9499.8 MiB     36.6 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9499.8 MiB      0.0 MiB           1           del weights_sparse
   144   9463.2 MiB    -36.6 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9536.4 MiB     73.2 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9582.6 MiB     46.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9582.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9436.2 MiB   -146.4 MiB           1       del e_intersection
   150                                             
   151   9436.2 MiB      0.0 MiB           1       if using_weights:
   152   9436.2 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9577.0 MiB   9577.0 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9577.0 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9577.0 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9577.0 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9577.0 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9577.0 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9390.0 MiB   -187.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9390.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9390.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9390.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9390.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9390.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9436.2 MiB     46.1 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9436.2 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9436.2 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9435.9 MiB     -0.2 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9435.9 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9435.9 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9435.9 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9435.9 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9435.9 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9436.0 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9436.0 MiB      0.0 MiB           1           del e_spatial       
   194   9436.0 MiB      0.0 MiB           1           del e_bidir
   195   9436.0 MiB      0.0 MiB           1           del weights_bidir
   196   9436.0 MiB      0.0 MiB           1           del y_cluster
   197   9436.0 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9436.0 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9436.0 MiB      0.0 MiB           1           gc.collect()


65.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9442.9 MiB   9442.9 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9442.9 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9442.9 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9442.9 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9508.4 MiB     65.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9508.5 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9508.5 MiB      0.0 MiB           1       del l1
   132                                             
   133   9508.5 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9384.0 MiB   -124.5 MiB           1       del e_1
   135   9384.0 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9384.0 MiB      0.0 MiB           1       if using_weights:
   138   9384.0 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9384.0 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9384.0 MiB      0.0 MiB           1           del weights_list
   141   9384.0 MiB      0.0 MiB           1           del l2
   142   9455.0 MiB     71.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9455.0 MiB      0.0 MiB           1           del weights_sparse
   144   9455.0 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9490.6 MiB     35.6 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9562.0 MiB     71.4 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9562.0 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9526.5 MiB    -35.6 MiB           1       del e_intersection
   150                                             
   151   9526.5 MiB      0.0 MiB           1       if using_weights:
   152   9526.5 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9442.7 MiB   9442.7 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9442.7 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9442.7 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9442.7 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9442.7 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9442.7 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9442.9 MiB      0.1 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9442.9 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9442.9 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9442.9 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9442.9 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9442.9 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9526.5 MiB     83.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9526.5 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9526.5 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9526.5 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9526.5 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9526.5 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9526.5 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9526.5 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9526.5 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9526.5 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9526.5 MiB      0.0 MiB           1           del e_spatial       
   194   9526.5 MiB      0.0 MiB           1           del e_bidir
   195   9526.5 MiB      0.0 MiB           1           del weights_bidir
   196   9526.5 MiB      0.0 MiB           1           del y_cluster
   197   9526.5 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9526.5 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9526.5 MiB      0.0 MiB           1           gc.collect()


66.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9394.9 MiB   9394.9 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9394.9 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9489.8 MiB     94.9 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9489.8 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9537.5 MiB     47.7 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9537.5 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9442.4 MiB    -95.1 MiB           1       del l1
   132                                             
   133   9460.4 MiB     17.9 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9412.8 MiB    -47.5 MiB           1       del e_1
   135   9412.8 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9412.8 MiB      0.0 MiB           1       if using_weights:
   138   9412.8 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9412.8 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9412.8 MiB      0.0 MiB           1           del weights_list
   141   9412.8 MiB      0.0 MiB           1           del l2
   142   9460.3 MiB     47.5 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9460.3 MiB      0.0 MiB           1           del weights_sparse
   144   9389.2 MiB    -71.2 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9484.0 MiB     94.9 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9578.9 MiB     94.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9578.9 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9531.6 MiB    -47.4 MiB           1       del e_intersection
   150                                             
   151   9531.6 MiB      0.0 MiB           1       if using_weights:
   152   9531.6 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9534.4 MiB   9534.4 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9534.4 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9534.4 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9534.4 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9534.4 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9534.4 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9394.9 MiB   -139.5 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9394.9 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9394.9 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9394.9 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9394.9 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9394.9 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9531.6 MiB    136.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9531.6 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9531.6 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9531.6 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9531.6 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9531.6 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9531.6 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9531.6 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9531.6 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9531.6 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9531.6 MiB      0.0 MiB           1           del e_spatial       
   194   9531.6 MiB      0.0 MiB           1           del e_bidir
   195   9531.6 MiB      0.0 MiB           1           del weights_bidir
   196   9531.6 MiB      0.0 MiB           1           del y_cluster
   197   9436.6 MiB    -95.0 MiB           1           del new_weights
   198                                                 
   199   9436.6 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9436.6 MiB      0.0 MiB           1           gc.collect()


67.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9443.4 MiB   9443.4 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9443.4 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9443.4 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9443.4 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9513.4 MiB     70.0 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9513.4 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9513.4 MiB      0.0 MiB           1       del l1
   132                                             
   133   9513.4 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9478.3 MiB    -35.1 MiB           1       del e_1
   135   9478.3 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9478.3 MiB      0.0 MiB           1       if using_weights:
   138   9478.3 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9478.3 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9478.3 MiB      0.0 MiB           1           del weights_list
   141   9478.3 MiB      0.0 MiB           1           del l2
   142   9495.9 MiB     17.5 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9495.9 MiB      0.0 MiB           1           del weights_sparse
   144   9495.9 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9530.9 MiB     35.1 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9601.0 MiB     70.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9601.0 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9566.0 MiB    -35.0 MiB           1       del e_intersection
   150                                             
   151   9566.0 MiB      0.0 MiB           1       if using_weights:
   152   9566.0 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9443.2 MiB   9443.2 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9443.2 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9443.2 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9443.2 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9443.2 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9443.2 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9443.4 MiB      0.2 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9443.4 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9443.4 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9443.4 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9443.4 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9443.4 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9566.0 MiB    122.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9566.0 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9566.0 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9566.0 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9566.0 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9566.0 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9566.0 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9566.0 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9566.0 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9566.0 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9566.0 MiB      0.0 MiB           1           del e_spatial       
   194   9566.0 MiB      0.0 MiB           1           del e_bidir
   195   9566.0 MiB      0.0 MiB           1           del weights_bidir
   196   9566.0 MiB      0.0 MiB           1           del y_cluster
   197   9566.0 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9566.0 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9566.0 MiB      0.0 MiB           1           gc.collect()


68.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9399.8 MiB   9399.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9399.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9491.6 MiB     91.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9491.6 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9537.7 MiB     46.1 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9537.8 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9445.8 MiB    -92.0 MiB           1       del l1
   132                                             
   133   9462.2 MiB     16.4 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9416.2 MiB    -46.0 MiB           1       del e_1
   135   9416.2 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9416.2 MiB      0.0 MiB           1       if using_weights:
   138   9416.2 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9416.2 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9416.2 MiB      0.0 MiB           1           del weights_list
   141   9416.2 MiB      0.0 MiB           1           del l2
   142   9462.1 MiB     45.9 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9462.1 MiB      0.0 MiB           1           del weights_sparse
   144   9393.3 MiB    -68.8 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9485.1 MiB     91.8 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9576.9 MiB     91.8 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9576.9 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9531.1 MiB    -45.8 MiB           1       del e_intersection
   150                                             
   151   9531.1 MiB      0.0 MiB           1       if using_weights:
   152   9531.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9573.8 MiB   9573.8 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9573.8 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9573.8 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9573.8 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9573.8 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9573.8 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9399.8 MiB   -174.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9399.8 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9399.8 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9399.8 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9399.8 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9399.8 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9531.1 MiB    131.2 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9531.1 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9531.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9531.1 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9531.1 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9531.1 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9531.1 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9531.1 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9531.1 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9531.1 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9531.1 MiB      0.0 MiB           1           del e_spatial       
   194   9531.1 MiB      0.0 MiB           1           del e_bidir
   195   9531.1 MiB      0.0 MiB           1           del weights_bidir
   196   9531.1 MiB      0.0 MiB           1           del y_cluster
   197   9439.2 MiB    -91.8 MiB           1           del new_weights
   198                                                 
   199   9439.2 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9439.2 MiB      0.0 MiB           1           gc.collect()


69.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9446.3 MiB   9446.3 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9446.3 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9446.3 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9446.3 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9538.5 MiB     92.2 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9538.5 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9538.5 MiB      0.0 MiB           1       del l1
   132                                             
   133   9538.5 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9501.5 MiB    -36.9 MiB           1       del e_1
   135   9501.5 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9501.5 MiB      0.0 MiB           1       if using_weights:
   138   9501.5 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9501.5 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9501.5 MiB      0.0 MiB           1           del weights_list
   141   9501.5 MiB      0.0 MiB           1           del l2
   142   9519.8 MiB     18.3 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9519.8 MiB      0.0 MiB           1           del weights_sparse
   144   9519.8 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9556.7 MiB     36.9 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9631.0 MiB     74.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9631.0 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9520.3 MiB   -110.6 MiB           1       del e_intersection
   150                                             
   151   9520.3 MiB      0.0 MiB           1       if using_weights:
   152   9520.3 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9446.1 MiB   9446.1 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9446.1 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9446.1 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9446.1 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9446.1 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9446.1 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9446.3 MiB      0.2 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9446.3 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9446.3 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9446.3 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9446.3 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9446.3 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9520.3 MiB     74.1 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9520.3 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9520.3 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9520.3 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9520.3 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9520.3 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9520.3 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9520.3 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9520.3 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9520.3 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9520.3 MiB      0.0 MiB           1           del e_spatial       
   194   9520.3 MiB      0.0 MiB           1           del e_bidir
   195   9520.3 MiB      0.0 MiB           1           del weights_bidir
   196   9520.3 MiB      0.0 MiB           1           del y_cluster
   197   9520.3 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9520.3 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9520.3 MiB      0.0 MiB           1           gc.collect()


70.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9386.9 MiB   9386.9 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9386.9 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9472.3 MiB     85.5 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9472.3 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9557.9 MiB     85.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9557.9 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9472.3 MiB    -85.6 MiB           1       del l1
   132                                             
   133   9493.6 MiB     21.3 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9451.0 MiB    -42.7 MiB           1       del e_1
   135   9451.0 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9451.0 MiB      0.0 MiB           1       if using_weights:
   138   9451.0 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9451.0 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9451.0 MiB      0.0 MiB           1           del weights_list
   141   9451.0 MiB      0.0 MiB           1           del l2
   142   9493.5 MiB     42.5 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9493.5 MiB      0.0 MiB           1           del weights_sparse
   144   9429.7 MiB    -63.8 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9515.0 MiB     85.3 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9600.6 MiB     85.6 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9600.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9557.9 MiB    -42.7 MiB           1       del e_intersection
   150                                             
   151   9557.9 MiB      0.0 MiB           1       if using_weights:
   152   9557.9 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9527.8 MiB   9527.8 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9527.8 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9527.8 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9527.8 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9527.8 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9527.8 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9386.9 MiB   -140.9 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9386.9 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9386.9 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9386.9 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9386.9 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9386.9 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9557.9 MiB    171.1 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9557.9 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9557.9 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9557.9 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9557.9 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9557.9 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9557.9 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9557.9 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9557.9 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9557.9 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9557.9 MiB      0.0 MiB           1           del e_spatial       
   194   9557.9 MiB      0.0 MiB           1           del e_bidir
   195   9557.9 MiB      0.0 MiB           1           del weights_bidir
   196   9557.9 MiB      0.0 MiB           1           del y_cluster
   197   9472.5 MiB    -85.5 MiB           1           del new_weights
   198                                                 
   199   9472.5 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9472.5 MiB      0.0 MiB           1           gc.collect()


70.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9389.8 MiB   9389.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9389.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9476.9 MiB     87.1 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9476.9 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9563.8 MiB     86.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9564.0 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9476.8 MiB    -87.2 MiB           1       del l1
   132                                             
   133   9498.7 MiB     21.8 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9455.1 MiB    -43.6 MiB           1       del e_1
   135   9455.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9455.1 MiB      0.0 MiB           1       if using_weights:
   138   9455.1 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9455.1 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9455.1 MiB      0.0 MiB           1           del weights_list
   141   9455.1 MiB      0.0 MiB           1           del l2
   142   9498.4 MiB     43.3 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9498.4 MiB      0.0 MiB           1           del weights_sparse
   144   9433.4 MiB    -65.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9520.3 MiB     86.9 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9607.4 MiB     87.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9607.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9564.0 MiB    -43.4 MiB           1       del e_intersection
   150                                             
   151   9564.0 MiB      0.0 MiB           1       if using_weights:
   152   9564.0 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9480.0 MiB   9480.0 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9480.0 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9480.0 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9480.0 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9480.0 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9480.0 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9389.8 MiB    -90.2 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9389.8 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9389.8 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9389.8 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9389.8 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9389.8 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9564.0 MiB    174.2 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9564.0 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9564.0 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9564.0 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9564.0 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9564.0 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9564.0 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9564.0 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9564.0 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9564.0 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9564.0 MiB      0.0 MiB           1           del e_spatial       
   194   9564.0 MiB      0.0 MiB           1           del e_bidir
   195   9564.0 MiB      0.0 MiB           1           del weights_bidir
   196   9564.0 MiB      0.0 MiB           1           del y_cluster
   197   9477.0 MiB    -87.0 MiB           1           del new_weights
   198                                                 
   199   9477.0 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9477.0 MiB      0.0 MiB           1           gc.collect()


71.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9387.4 MiB   9387.4 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9387.4 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9503.2 MiB    115.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9503.2 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9647.7 MiB    144.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9647.8 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9532.0 MiB   -115.8 MiB           1       del l1
   132                                             
   133   9561.0 MiB     29.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9416.4 MiB   -144.6 MiB           1       del e_1
   135   9416.4 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9416.4 MiB      0.0 MiB           1       if using_weights:
   138   9416.4 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9416.4 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9416.4 MiB      0.0 MiB           1           del weights_list
   141   9416.4 MiB      0.0 MiB           1           del l2
   142   9560.7 MiB    144.4 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9560.7 MiB      0.0 MiB           1           del weights_sparse
   144   9445.3 MiB   -115.4 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9589.7 MiB    144.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9705.4 MiB    115.8 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9705.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9560.9 MiB   -144.5 MiB           1       del e_intersection
   150                                             
   151   9560.9 MiB      0.0 MiB           1       if using_weights:
   152   9560.9 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9485.9 MiB   9485.9 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9485.9 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9485.9 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9485.9 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9485.9 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9485.9 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9387.4 MiB    -98.5 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9387.4 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9387.4 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9387.4 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9387.4 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9387.4 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9560.9 MiB    173.5 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9560.9 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9560.9 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9560.9 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9560.9 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9560.9 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9560.9 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9560.9 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9560.9 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9560.9 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9560.9 MiB      0.0 MiB           1           del e_spatial       
   194   9560.9 MiB      0.0 MiB           1           del e_bidir
   195   9560.9 MiB      0.0 MiB           1           del weights_bidir
   196   9560.9 MiB      0.0 MiB           1           del y_cluster
   197   9560.9 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9560.9 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9560.9 MiB      0.0 MiB           1           gc.collect()


72.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9395.1 MiB   9395.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9395.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9395.1 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9395.1 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9441.0 MiB     45.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9441.2 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9441.2 MiB      0.0 MiB           1       del l1
   132                                             
   133   9441.2 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9406.5 MiB    -34.7 MiB           1       del e_1
   135   9406.5 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9406.5 MiB      0.0 MiB           1       if using_weights:
   138   9406.5 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9406.5 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9406.5 MiB      0.0 MiB           1           del weights_list
   141   9406.5 MiB      0.0 MiB           1           del l2
   142   9406.5 MiB      0.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9406.5 MiB      0.0 MiB           1           del weights_sparse
   144   9406.5 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9371.9 MiB    -34.6 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9441.4 MiB     69.5 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9441.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9406.7 MiB    -34.7 MiB           1       del e_intersection
   150                                             
   151   9406.7 MiB      0.0 MiB           1       if using_weights:
   152   9406.7 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9567.7 MiB   9567.7 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9567.7 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9567.7 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9567.7 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9567.7 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9567.7 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9395.1 MiB   -172.5 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9395.1 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9395.1 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9395.1 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9395.1 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9395.1 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9406.7 MiB     11.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9406.7 MiB     -0.1 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9406.7 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9406.7 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9406.7 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9406.7 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9406.7 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9406.7 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9406.7 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9406.7 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9406.7 MiB      0.0 MiB           1           del e_spatial       
   194   9406.7 MiB      0.0 MiB           1           del e_bidir
   195   9406.7 MiB      0.0 MiB           1           del weights_bidir
   196   9406.7 MiB      0.0 MiB           1           del y_cluster
   197   9406.7 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9406.7 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9406.7 MiB      0.0 MiB           1           gc.collect()


73.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9415.4 MiB   9415.4 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9415.4 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9523.5 MiB    108.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9523.5 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9631.6 MiB    108.2 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9631.8 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9523.5 MiB   -108.2 MiB           1       del l1
   132                                             
   133   9550.6 MiB     27.1 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9496.5 MiB    -54.1 MiB           1       del e_1
   135   9496.5 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9496.5 MiB      0.0 MiB           1       if using_weights:
   138   9496.5 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9496.5 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9496.5 MiB      0.0 MiB           1           del weights_list
   141   9496.5 MiB      0.0 MiB           1           del l2
   142   9469.6 MiB    -27.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9469.6 MiB      0.0 MiB           1           del weights_sparse
   144   9469.6 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9577.6 MiB    108.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9685.9 MiB    108.3 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9685.9 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9523.7 MiB   -162.2 MiB           1       del e_intersection
   150                                             
   151   9523.7 MiB      0.0 MiB           1       if using_weights:
   152   9523.7 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9415.4 MiB   9415.4 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9415.4 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9415.4 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9415.4 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9415.4 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9415.4 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9415.4 MiB      0.1 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9415.4 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9415.4 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9415.4 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9415.4 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9415.4 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9523.7 MiB    108.2 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9523.7 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9523.7 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9604.4 MiB     80.7 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9523.6 MiB    -80.8 MiB           1           del random_flip
   180                                                 
   181   9523.6 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9523.6 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9523.6 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9523.6 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9523.6 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9523.6 MiB      0.0 MiB           1           del e_spatial       
   194   9523.6 MiB      0.0 MiB           1           del e_bidir
   195   9523.6 MiB      0.0 MiB           1           del weights_bidir
   196   9523.6 MiB      0.0 MiB           1           del y_cluster
   197   9523.6 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9523.6 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9523.6 MiB      0.0 MiB           1           gc.collect()


74.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9386.6 MiB   9386.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9386.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9505.7 MiB    119.1 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9505.7 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9654.6 MiB    148.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9654.7 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9535.5 MiB   -119.2 MiB           1       del l1
   132                                             
   133   9565.3 MiB     29.8 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9416.4 MiB   -148.9 MiB           1       del e_1
   135   9416.4 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9416.4 MiB      0.0 MiB           1       if using_weights:
   138   9416.4 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9416.4 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9416.4 MiB      0.0 MiB           1           del weights_list
   141   9416.4 MiB      0.0 MiB           1           del l2
   142   9565.2 MiB    148.8 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9565.2 MiB      0.0 MiB           1           del weights_sparse
   144   9446.2 MiB   -118.9 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9595.0 MiB    148.8 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9714.1 MiB    119.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9714.1 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9565.4 MiB   -148.7 MiB           1       del e_intersection
   150                                             
   151   9565.4 MiB      0.0 MiB           1       if using_weights:
   152   9565.4 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9532.8 MiB   9532.8 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9532.8 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9532.8 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9532.8 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9532.8 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9532.8 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9386.6 MiB   -146.2 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9386.6 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9386.6 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9386.6 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9386.6 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9386.6 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9565.4 MiB    178.8 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9565.4 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9565.4 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9565.4 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9565.4 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9565.4 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9565.4 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9565.4 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9565.4 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9565.4 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9565.4 MiB      0.0 MiB           1           del e_spatial       
   194   9565.4 MiB      0.0 MiB           1           del e_bidir
   195   9565.4 MiB      0.0 MiB           1           del weights_bidir
   196   9565.4 MiB      0.0 MiB           1           del y_cluster
   197   9565.4 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9565.4 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9565.4 MiB      0.0 MiB           1           gc.collect()


75.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9386.0 MiB   9386.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9386.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9493.0 MiB    107.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9493.0 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9546.5 MiB     53.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9546.8 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9439.6 MiB   -107.2 MiB           1       del l1
   132                                             
   133   9460.3 MiB     20.7 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9406.7 MiB    -53.6 MiB           1       del e_1
   135   9406.7 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9406.7 MiB      0.0 MiB           1       if using_weights:
   138   9406.7 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9406.7 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9406.7 MiB      0.0 MiB           1           del weights_list
   141   9406.7 MiB      0.0 MiB           1           del l2
   142   9380.0 MiB    -26.7 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9380.0 MiB      0.0 MiB           1           del weights_sparse
   144   9380.0 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9487.0 MiB    107.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9594.2 MiB    107.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9594.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9433.6 MiB   -160.6 MiB           1       del e_intersection
   150                                             
   151   9433.6 MiB      0.0 MiB           1       if using_weights:
   152   9433.6 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9574.1 MiB   9574.1 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9574.1 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9574.1 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9574.1 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9574.1 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9574.1 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9386.0 MiB   -188.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9386.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9386.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9386.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9386.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9386.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9433.6 MiB     47.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9433.6 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9433.6 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9487.0 MiB     53.4 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9487.0 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9487.0 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9487.0 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9487.0 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9487.0 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9487.1 MiB      0.1 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9487.1 MiB      0.0 MiB           1           del e_spatial       
   194   9487.1 MiB      0.0 MiB           1           del e_bidir
   195   9487.1 MiB      0.0 MiB           1           del weights_bidir
   196   9487.1 MiB      0.0 MiB           1           del y_cluster
   197   9487.1 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9487.1 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9487.1 MiB      0.0 MiB           1           gc.collect()


75.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9386.4 MiB   9386.4 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9386.4 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9386.4 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9386.4 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9465.5 MiB     79.1 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9465.7 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9465.7 MiB      0.0 MiB           1       del l1
   132                                             
   133   9465.7 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9332.9 MiB   -132.7 MiB           1       del e_1
   135   9332.9 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9332.9 MiB      0.0 MiB           1       if using_weights:
   138   9332.9 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9332.9 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9332.9 MiB      0.0 MiB           1           del weights_list
   141   9332.9 MiB      0.0 MiB           1           del l2
   142   9408.7 MiB     75.8 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9408.7 MiB      0.0 MiB           1           del weights_sparse
   144   9408.7 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9446.6 MiB     37.9 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9522.4 MiB     75.8 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9522.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9484.6 MiB    -37.8 MiB           1       del e_intersection
   150                                             
   151   9484.6 MiB      0.0 MiB           1       if using_weights:
   152   9484.6 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9494.1 MiB   9494.1 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9494.1 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9494.1 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9494.1 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9494.1 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9494.1 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9386.4 MiB   -107.7 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9386.4 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9386.4 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9386.4 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9386.4 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9386.4 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9484.6 MiB     98.2 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9484.6 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9484.6 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9484.6 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9484.6 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9484.6 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9484.6 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9484.6 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9484.6 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9484.6 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9484.6 MiB      0.0 MiB           1           del e_spatial       
   194   9484.6 MiB      0.0 MiB           1           del e_bidir
   195   9484.6 MiB      0.0 MiB           1           del weights_bidir
   196   9484.6 MiB      0.0 MiB           1           del y_cluster
   197   9408.8 MiB    -75.8 MiB           1           del new_weights
   198                                                 
   199   9408.8 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9408.8 MiB      0.0 MiB           1           gc.collect()


76.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9417.4 MiB   9417.4 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9417.4 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9519.9 MiB    102.6 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9520.0 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9622.2 MiB    102.2 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9622.5 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9519.8 MiB   -102.6 MiB           1       del l1
   132                                             
   133   9545.5 MiB     25.7 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9494.2 MiB    -51.3 MiB           1       del e_1
   135   9494.2 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9494.2 MiB      0.0 MiB           1       if using_weights:
   138   9494.2 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9494.2 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9494.2 MiB      0.0 MiB           1           del weights_list
   141   9494.2 MiB      0.0 MiB           1           del l2
   142   9545.4 MiB     51.2 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9545.4 MiB      0.0 MiB           1           del weights_sparse
   144   9468.7 MiB    -76.8 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9571.0 MiB    102.3 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9673.6 MiB    102.6 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9673.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9622.4 MiB    -51.2 MiB           1       del e_intersection
   150                                             
   151   9622.4 MiB      0.0 MiB           1       if using_weights:
   152   9622.4 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9417.2 MiB   9417.2 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9417.2 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9417.2 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9417.2 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9417.2 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9417.2 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9417.4 MiB      0.1 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9417.4 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9417.4 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9417.4 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9417.4 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9417.4 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9622.4 MiB    205.1 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9622.4 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9622.4 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9622.4 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9622.4 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9622.4 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9622.4 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9622.4 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9622.4 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9622.4 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9622.4 MiB      0.0 MiB           1           del e_spatial       
   194   9622.4 MiB      0.0 MiB           1           del e_bidir
   195   9622.4 MiB      0.0 MiB           1           del weights_bidir
   196   9622.4 MiB      0.0 MiB           1           del y_cluster
   197   9520.0 MiB   -102.5 MiB           1           del new_weights
   198                                                 
   199   9520.0 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9520.0 MiB      0.0 MiB           1           gc.collect()


77.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9388.0 MiB   9388.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9388.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9503.1 MiB    115.1 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9503.1 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9647.1 MiB    144.0 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9647.3 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9532.0 MiB   -115.3 MiB           1       del l1
   132                                             
   133   9560.9 MiB     28.9 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9416.8 MiB   -144.0 MiB           1       del e_1
   135   9416.8 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9416.8 MiB      0.0 MiB           1       if using_weights:
   138   9416.8 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9416.8 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9416.8 MiB      0.0 MiB           1           del weights_list
   141   9416.8 MiB      0.0 MiB           1           del l2
   142   9560.7 MiB    143.9 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9560.7 MiB      0.0 MiB           1           del weights_sparse
   144   9445.6 MiB   -115.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9589.5 MiB    143.9 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9705.0 MiB    115.5 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9705.0 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9561.0 MiB   -144.0 MiB           1       del e_intersection
   150                                             
   151   9561.0 MiB      0.0 MiB           1       if using_weights:
   152   9561.0 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9528.9 MiB   9528.9 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9528.9 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9528.9 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9528.9 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9528.9 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9528.9 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9388.0 MiB   -140.9 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9388.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9388.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9388.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9388.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9388.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9561.0 MiB    173.1 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9561.0 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9561.0 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9561.1 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9561.1 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9561.1 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9561.1 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9561.1 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9561.1 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9561.1 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9561.1 MiB      0.0 MiB           1           del e_spatial       
   194   9561.1 MiB      0.0 MiB           1           del e_bidir
   195   9561.1 MiB      0.0 MiB           1           del weights_bidir
   196   9561.1 MiB      0.0 MiB           1           del y_cluster
   197   9561.1 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9561.1 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9561.1 MiB      0.0 MiB           1           gc.collect()


78.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9395.9 MiB   9395.9 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9395.9 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9395.9 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9395.9 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9410.3 MiB     14.4 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9410.3 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9410.3 MiB      0.0 MiB           1       del l1
   132                                             
   133   9410.5 MiB      0.2 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9338.5 MiB    -72.0 MiB           1       del e_1
   135   9338.5 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9338.5 MiB      0.0 MiB           1       if using_weights:
   138   9338.5 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9338.5 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9338.5 MiB      0.0 MiB           1           del weights_list
   141   9338.5 MiB      0.0 MiB           1           del l2
   142   9367.1 MiB     28.6 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9367.1 MiB      0.0 MiB           1           del weights_sparse
   144   9367.1 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9381.6 MiB     14.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9439.3 MiB     57.8 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9439.3 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9439.3 MiB      0.0 MiB           1       del e_intersection
   150                                             
   151   9439.3 MiB      0.0 MiB           1       if using_weights:
   152   9439.3 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9567.2 MiB   9567.2 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9567.2 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9567.2 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9567.2 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9567.2 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9567.2 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9395.9 MiB   -171.3 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9395.9 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9395.9 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9395.9 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9395.9 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9395.9 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9439.3 MiB     43.4 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9439.3 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9439.3 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9439.3 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9439.3 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9439.3 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9439.3 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9439.3 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9439.3 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9439.5 MiB      0.1 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9439.5 MiB      0.0 MiB           1           del e_spatial       
   194   9439.5 MiB      0.0 MiB           1           del e_bidir
   195   9439.5 MiB      0.0 MiB           1           del weights_bidir
   196   9439.5 MiB      0.0 MiB           1           del y_cluster
   197   9439.5 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9439.5 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9439.5 MiB      0.0 MiB           1           gc.collect()


79.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9447.5 MiB   9447.5 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9447.5 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9540.9 MiB     93.5 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9541.2 MiB      0.2 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9591.5 MiB     50.3 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9591.6 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9497.9 MiB    -93.7 MiB           1       del l1
   132                                             
   133   9521.3 MiB     23.5 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9474.5 MiB    -46.9 MiB           1       del e_1
   135   9474.5 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9474.5 MiB      0.0 MiB           1       if using_weights:
   138   9474.5 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9474.5 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9474.5 MiB      0.0 MiB           1           del weights_list
   141   9474.5 MiB      0.0 MiB           1           del l2
   142   9521.1 MiB     46.7 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9521.1 MiB      0.0 MiB           1           del weights_sparse
   144   9451.1 MiB    -70.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9544.7 MiB     93.6 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9638.3 MiB     93.6 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9638.3 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9591.7 MiB    -46.6 MiB           1       del e_intersection
   150                                             
   151   9591.7 MiB      0.0 MiB           1       if using_weights:
   152   9591.7 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9447.3 MiB   9447.3 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9447.3 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9447.3 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9447.3 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9447.3 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9447.3 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9447.5 MiB      0.2 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9447.5 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9447.5 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9447.5 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9447.5 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9447.5 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9591.7 MiB    144.2 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9591.7 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9591.7 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9591.7 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9591.7 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9591.7 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9591.7 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9591.7 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9591.7 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9591.7 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9591.7 MiB      0.0 MiB           1           del e_spatial       
   194   9591.7 MiB      0.0 MiB           1           del e_bidir
   195   9591.7 MiB      0.0 MiB           1           del weights_bidir
   196   9591.7 MiB      0.0 MiB           1           del y_cluster
   197   9498.1 MiB    -93.6 MiB           1           del new_weights
   198                                                 
   199   9498.1 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9498.1 MiB      0.0 MiB           1           gc.collect()


80.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9386.5 MiB   9386.5 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9386.5 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9473.7 MiB     87.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9473.7 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9561.0 MiB     87.3 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9561.2 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9473.8 MiB    -87.4 MiB           1       del l1
   132                                             
   133   9495.7 MiB     21.9 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9452.0 MiB    -43.7 MiB           1       del e_1
   135   9452.0 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9452.0 MiB      0.0 MiB           1       if using_weights:
   138   9452.0 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9452.0 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9452.0 MiB      0.0 MiB           1           del weights_list
   141   9452.0 MiB      0.0 MiB           1           del l2
   142   9495.5 MiB     43.5 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9495.5 MiB      0.0 MiB           1           del weights_sparse
   144   9430.2 MiB    -65.3 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9517.3 MiB     87.1 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9604.7 MiB     87.4 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9604.7 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9561.1 MiB    -43.7 MiB           1       del e_intersection
   150                                             
   151   9561.1 MiB      0.0 MiB           1       if using_weights:
   152   9561.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9505.6 MiB   9505.6 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9505.6 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9505.6 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9505.6 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9505.6 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9505.6 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9386.5 MiB   -119.1 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9386.5 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9386.5 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9386.5 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9386.5 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9386.5 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9561.1 MiB    174.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9561.1 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9561.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9561.1 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9561.1 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9561.1 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9561.1 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9561.1 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9561.1 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9561.1 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9561.1 MiB      0.0 MiB           1           del e_spatial       
   194   9561.1 MiB      0.0 MiB           1           del e_bidir
   195   9561.1 MiB      0.0 MiB           1           del weights_bidir
   196   9561.1 MiB      0.0 MiB           1           del y_cluster
   197   9473.8 MiB    -87.3 MiB           1           del new_weights
   198                                                 
   199   9473.8 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9473.8 MiB      0.0 MiB           1           gc.collect()


80.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9390.5 MiB   9390.5 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9390.5 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9488.0 MiB     97.5 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9488.0 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9561.4 MiB     73.4 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9561.4 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9463.7 MiB    -97.8 MiB           1       del l1
   132                                             
   133   9512.6 MiB     48.9 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9463.7 MiB    -48.9 MiB           1       del e_1
   135   9463.7 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9463.7 MiB      0.0 MiB           1       if using_weights:
   138   9463.7 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9463.7 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9463.7 MiB      0.0 MiB           1           del weights_list
   141   9463.7 MiB      0.0 MiB           1           del l2
   142   9536.8 MiB     73.2 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9536.8 MiB      0.0 MiB           1           del weights_sparse
   144   9463.8 MiB    -73.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9512.6 MiB     48.8 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9610.4 MiB     97.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9610.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9561.5 MiB    -48.9 MiB           1       del e_intersection
   150                                             
   151   9561.5 MiB      0.0 MiB           1       if using_weights:
   152   9561.5 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9482.0 MiB   9482.0 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9482.0 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9482.0 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9482.0 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9482.0 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9482.0 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9390.5 MiB    -91.5 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9390.5 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9390.5 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9390.5 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9390.5 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9390.5 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9561.5 MiB    171.0 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9561.6 MiB      0.1 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9561.6 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9561.6 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9561.6 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9561.6 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9561.6 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9561.6 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9561.6 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9561.6 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9561.6 MiB      0.0 MiB           1           del e_spatial       
   194   9561.6 MiB      0.0 MiB           1           del e_bidir
   195   9561.6 MiB      0.0 MiB           1           del weights_bidir
   196   9561.6 MiB      0.0 MiB           1           del y_cluster
   197   9561.6 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9561.6 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9561.6 MiB      0.0 MiB           1           gc.collect()


81.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9388.6 MiB   9388.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9388.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9482.7 MiB     94.1 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9482.7 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9530.0 MiB     47.2 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9530.0 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9435.8 MiB    -94.2 MiB           1       del l1
   132                                             
   133   9435.8 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9388.6 MiB    -47.1 MiB           1       del e_1
   135   9388.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9388.6 MiB      0.0 MiB           1       if using_weights:
   138   9388.6 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9388.6 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9388.6 MiB      0.0 MiB           1           del weights_list
   141   9388.6 MiB      0.0 MiB           1           del l2
   142   9433.7 MiB     45.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9433.7 MiB      0.0 MiB           1           del weights_sparse
   144   9363.4 MiB    -70.3 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9457.5 MiB     94.1 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9551.6 MiB     94.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9551.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9504.7 MiB    -46.9 MiB           1       del e_intersection
   150                                             
   151   9504.7 MiB      0.0 MiB           1       if using_weights:
   152   9504.7 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9569.4 MiB   9569.4 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9569.4 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9569.4 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9569.4 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9569.4 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9569.4 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9388.6 MiB   -180.8 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9388.6 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9388.6 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9388.6 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9388.6 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9388.6 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9504.7 MiB    116.1 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9504.7 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9504.7 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9504.7 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9504.7 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9504.7 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9504.7 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9504.7 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9504.7 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9504.7 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9504.7 MiB      0.0 MiB           1           del e_spatial       
   194   9504.7 MiB      0.0 MiB           1           del e_bidir
   195   9504.7 MiB      0.0 MiB           1           del weights_bidir
   196   9504.7 MiB      0.0 MiB           1           del y_cluster
   197   9434.2 MiB    -70.6 MiB           1           del new_weights
   198                                                 
   199   9434.2 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9434.2 MiB      0.0 MiB           1           gc.collect()


82.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9442.8 MiB   9442.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9442.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9549.6 MiB    106.7 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9549.6 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9631.8 MiB     82.2 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9631.9 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9525.1 MiB   -106.8 MiB           1       del l1
   132                                             
   133   9551.8 MiB     26.7 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9498.4 MiB    -53.4 MiB           1       del e_1
   135   9498.4 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9498.4 MiB      0.0 MiB           1       if using_weights:
   138   9498.4 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9498.4 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9498.4 MiB      0.0 MiB           1           del weights_list
   141   9498.4 MiB      0.0 MiB           1           del l2
   142   9471.8 MiB    -26.6 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9471.8 MiB      0.0 MiB           1           del weights_sparse
   144   9471.8 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9578.3 MiB    106.5 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9685.0 MiB    106.7 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9685.0 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9525.2 MiB   -159.8 MiB           1       del e_intersection
   150                                             
   151   9525.2 MiB      0.0 MiB           1       if using_weights:
   152   9525.2 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9442.8 MiB   9442.8 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9442.8 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9442.8 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9442.8 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9442.8 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9442.8 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9442.8 MiB      0.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9442.8 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9442.8 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9442.8 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9442.8 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9442.8 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9525.2 MiB     82.3 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9525.1 MiB     -0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9525.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9578.2 MiB     53.1 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9578.2 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9578.2 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9578.2 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9578.2 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9578.2 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9578.2 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9578.2 MiB      0.0 MiB           1           del e_spatial       
   194   9578.2 MiB      0.0 MiB           1           del e_bidir
   195   9578.2 MiB      0.0 MiB           1           del weights_bidir
   196   9578.2 MiB      0.0 MiB           1           del y_cluster
   197   9578.2 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9578.2 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9578.2 MiB      0.0 MiB           1           gc.collect()


83.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9390.1 MiB   9390.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9390.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9508.9 MiB    118.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9508.9 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9604.2 MiB     95.3 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9604.4 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9485.4 MiB   -119.0 MiB           1       del l1
   132                                             
   133   9515.2 MiB     29.8 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9366.5 MiB   -148.6 MiB           1       del e_1
   135   9366.5 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9366.5 MiB      0.0 MiB           1       if using_weights:
   138   9366.5 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9366.5 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9366.5 MiB      0.0 MiB           1           del weights_list
   141   9366.5 MiB      0.0 MiB           1           del l2
   142   9515.0 MiB    148.5 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9515.0 MiB      0.0 MiB           1           del weights_sparse
   144   9396.3 MiB   -118.7 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9544.8 MiB    148.5 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9663.9 MiB    119.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9663.9 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9515.3 MiB   -148.6 MiB           1       del e_intersection
   150                                             
   151   9515.3 MiB      0.0 MiB           1       if using_weights:
   152   9515.3 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9587.4 MiB   9587.4 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9587.4 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9587.4 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9587.4 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9587.4 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9587.4 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9390.1 MiB   -197.3 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9390.1 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9390.1 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9390.1 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9390.1 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9390.1 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9515.3 MiB    125.3 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9515.3 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9515.3 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9515.3 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9515.3 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9515.3 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9515.3 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9515.3 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9515.3 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9515.3 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9515.3 MiB      0.0 MiB           1           del e_spatial       
   194   9515.3 MiB      0.0 MiB           1           del e_bidir
   195   9515.3 MiB      0.0 MiB           1           del weights_bidir
   196   9515.3 MiB      0.0 MiB           1           del y_cluster
   197   9515.3 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9515.3 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9515.3 MiB      0.0 MiB           1           gc.collect()


84.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9385.6 MiB   9385.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9385.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9497.3 MiB    111.7 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9497.3 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9577.9 MiB     80.6 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9577.9 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9465.9 MiB   -112.0 MiB           1       del l1
   132                                             
   133   9493.9 MiB     28.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9354.1 MiB   -139.9 MiB           1       del e_1
   135   9354.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9354.1 MiB      0.0 MiB           1       if using_weights:
   138   9354.1 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9354.1 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9354.1 MiB      0.0 MiB           1           del weights_list
   141   9354.1 MiB      0.0 MiB           1           del l2
   142   9493.8 MiB    139.7 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9493.8 MiB      0.0 MiB           1           del weights_sparse
   144   9382.1 MiB   -111.7 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9521.8 MiB    139.7 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9633.7 MiB    111.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9633.7 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9494.0 MiB   -139.7 MiB           1       del e_intersection
   150                                             
   151   9494.0 MiB      0.0 MiB           1       if using_weights:
   152   9494.0 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9524.2 MiB   9524.2 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9524.2 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9524.2 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9524.2 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9524.2 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9524.2 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9385.5 MiB   -138.7 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9385.6 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9385.6 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9385.6 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9385.6 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9385.6 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9494.0 MiB    108.4 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9494.0 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9494.0 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9494.2 MiB      0.2 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9494.2 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9494.2 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9494.2 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9494.2 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9494.2 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9494.2 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9494.2 MiB      0.0 MiB           1           del e_spatial       
   194   9494.2 MiB      0.0 MiB           1           del e_bidir
   195   9494.2 MiB      0.0 MiB           1           del weights_bidir
   196   9494.2 MiB      0.0 MiB           1           del y_cluster
   197   9494.2 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9494.2 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9494.2 MiB      0.0 MiB           1           gc.collect()


85.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9395.5 MiB   9395.5 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9395.5 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9496.3 MiB    100.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9496.3 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9546.9 MiB     50.6 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9546.9 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9446.0 MiB   -101.0 MiB           1       del l1
   132                                             
   133   9465.6 MiB     19.6 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9415.1 MiB    -50.5 MiB           1       del e_1
   135   9415.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9415.1 MiB      0.0 MiB           1       if using_weights:
   138   9415.1 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9415.1 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9415.1 MiB      0.0 MiB           1           del weights_list
   141   9415.1 MiB      0.0 MiB           1           del l2
   142   9390.0 MiB    -25.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9390.0 MiB      0.0 MiB           1           del weights_sparse
   144   9390.0 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9490.8 MiB    100.8 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9591.6 MiB    100.8 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9591.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9440.5 MiB   -151.1 MiB           1       del e_intersection
   150                                             
   151   9440.5 MiB      0.0 MiB           1       if using_weights:
   152   9440.5 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9502.4 MiB   9502.4 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9502.4 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9502.4 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9502.4 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9502.4 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9502.4 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9395.5 MiB   -106.9 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9395.5 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9395.5 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9395.5 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9395.5 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9395.5 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9440.5 MiB     45.0 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9440.3 MiB     -0.2 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9440.3 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9490.6 MiB     50.3 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9490.6 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9490.6 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9490.6 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9490.6 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9490.6 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9490.6 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9490.6 MiB      0.0 MiB           1           del e_spatial       
   194   9490.6 MiB      0.0 MiB           1           del e_bidir
   195   9490.6 MiB      0.0 MiB           1           del weights_bidir
   196   9490.6 MiB      0.0 MiB           1           del y_cluster
   197   9490.6 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9490.6 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9490.6 MiB      0.0 MiB           1           gc.collect()


85.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9392.8 MiB   9392.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9392.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9507.5 MiB    114.7 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9507.8 MiB      0.3 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9600.9 MiB     93.2 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9601.0 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9486.0 MiB   -115.0 MiB           1       del l1
   132                                             
   133   9514.8 MiB     28.8 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9371.1 MiB   -143.6 MiB           1       del e_1
   135   9371.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9371.1 MiB      0.0 MiB           1       if using_weights:
   138   9371.1 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9371.1 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9371.1 MiB      0.0 MiB           1           del weights_list
   141   9371.1 MiB      0.0 MiB           1           del l2
   142   9514.5 MiB    143.3 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9514.5 MiB      0.0 MiB           1           del weights_sparse
   144   9399.9 MiB   -114.6 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9543.2 MiB    143.3 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9658.2 MiB    115.0 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9658.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9514.9 MiB   -143.3 MiB           1       del e_intersection
   150                                             
   151   9514.9 MiB      0.0 MiB           1       if using_weights:
   152   9514.9 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9499.7 MiB   9499.7 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9499.7 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9499.7 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9499.7 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9499.7 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9499.7 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9392.8 MiB   -106.9 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9392.8 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9392.8 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9392.8 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9392.8 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9392.8 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9514.9 MiB    122.1 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9514.9 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9514.9 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9572.1 MiB     57.2 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9572.1 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9572.1 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9572.1 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9572.1 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9572.1 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9572.3 MiB      0.2 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9572.3 MiB      0.0 MiB           1           del e_spatial       
   194   9572.3 MiB      0.0 MiB           1           del e_bidir
   195   9572.3 MiB      0.0 MiB           1           del weights_bidir
   196   9572.3 MiB      0.0 MiB           1           del y_cluster
   197   9457.5 MiB   -114.9 MiB           1           del new_weights
   198                                                 
   199   9457.5 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9457.5 MiB      0.0 MiB           1           gc.collect()


86.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9421.9 MiB   9421.9 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9421.9 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9539.7 MiB    117.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9539.7 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9686.8 MiB    147.1 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9687.0 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9569.1 MiB   -117.9 MiB           1       del l1
   132                                             
   133   9598.6 MiB     29.5 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9451.3 MiB   -147.2 MiB           1       del e_1
   135   9451.3 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9451.3 MiB      0.0 MiB           1       if using_weights:
   138   9451.3 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9451.3 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9451.3 MiB      0.0 MiB           1           del weights_list
   141   9451.3 MiB      0.0 MiB           1           del l2
   142   9598.5 MiB    147.2 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9598.5 MiB      0.0 MiB           1           del weights_sparse
   144   9480.8 MiB   -117.7 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9628.0 MiB    147.2 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9648.7 MiB     20.7 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9648.7 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9501.6 MiB   -147.1 MiB           1       del e_intersection
   150                                             
   151   9501.6 MiB      0.0 MiB           1       if using_weights:
   152   9501.6 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9466.3 MiB   9466.3 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9466.3 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9466.3 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9466.3 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9466.3 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9466.3 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9421.9 MiB    -44.5 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9421.9 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9421.9 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9421.9 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9421.9 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9421.9 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9501.6 MiB     79.7 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9501.6 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9501.6 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9501.6 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9501.6 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9501.6 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9501.6 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9501.6 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9501.6 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9501.6 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9501.6 MiB      0.0 MiB           1           del e_spatial       
   194   9501.6 MiB      0.0 MiB           1           del e_bidir
   195   9501.6 MiB      0.0 MiB           1           del weights_bidir
   196   9501.6 MiB      0.0 MiB           1           del y_cluster
   197   9501.6 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9501.6 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9501.6 MiB      0.0 MiB           1           gc.collect()


87.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9391.8 MiB   9391.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9391.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9483.7 MiB     92.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9483.9 MiB      0.2 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9529.7 MiB     45.8 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9530.0 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9437.8 MiB    -92.1 MiB           1       del l1
   132                                             
   133   9448.5 MiB     10.7 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9402.5 MiB    -46.1 MiB           1       del e_1
   135   9402.5 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9402.5 MiB      0.0 MiB           1       if using_weights:
   138   9402.5 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9402.5 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9402.5 MiB      0.0 MiB           1           del weights_list
   141   9402.5 MiB      0.0 MiB           1           del l2
   142   9448.4 MiB     45.9 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9448.4 MiB      0.0 MiB           1           del weights_sparse
   144   9379.5 MiB    -68.8 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9471.3 MiB     91.8 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9563.4 MiB     92.0 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9563.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9517.4 MiB    -45.9 MiB           1       del e_intersection
   150                                             
   151   9517.4 MiB      0.0 MiB           1       if using_weights:
   152   9517.4 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9509.5 MiB   9509.5 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9509.5 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9509.5 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9509.5 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9509.5 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9509.5 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9391.8 MiB   -117.8 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9391.8 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9391.8 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9391.8 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9391.8 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9391.8 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9517.4 MiB    125.7 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9517.4 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9517.4 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9517.4 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9517.4 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9517.4 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9517.4 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9517.4 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9517.4 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9517.4 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9517.4 MiB      0.0 MiB           1           del e_spatial       
   194   9517.4 MiB      0.0 MiB           1           del e_bidir
   195   9517.4 MiB      0.0 MiB           1           del weights_bidir
   196   9517.4 MiB      0.0 MiB           1           del y_cluster
   197   9425.4 MiB    -92.0 MiB           1           del new_weights
   198                                                 
   199   9425.4 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9425.4 MiB      0.0 MiB           1           gc.collect()


88.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9434.0 MiB   9434.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9434.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9538.1 MiB    104.1 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9538.2 MiB      0.2 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9643.2 MiB    104.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9643.3 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9539.0 MiB   -104.2 MiB           1       del l1
   132                                             
   133   9591.2 MiB     52.1 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9539.0 MiB    -52.1 MiB           1       del e_1
   135   9539.0 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9539.0 MiB      0.0 MiB           1       if using_weights:
   138   9539.0 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9539.0 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9539.0 MiB      0.0 MiB           1           del weights_list
   141   9539.0 MiB      0.0 MiB           1           del l2
   142   9591.1 MiB     52.1 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9591.1 MiB      0.0 MiB           1           del weights_sparse
   144   9513.1 MiB    -78.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9539.0 MiB     25.9 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9643.5 MiB    104.5 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9643.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9591.4 MiB    -52.1 MiB           1       del e_intersection
   150                                             
   151   9591.4 MiB      0.0 MiB           1       if using_weights:
   152   9591.4 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9433.9 MiB   9433.9 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9433.9 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9433.9 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9433.9 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9433.9 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9433.9 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9434.0 MiB      0.1 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9434.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9434.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9434.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9434.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9434.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9591.4 MiB    157.4 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9591.4 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9591.4 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9617.4 MiB     26.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9539.4 MiB    -78.0 MiB           1           del random_flip
   180                                                 
   181   9539.4 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9539.4 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9539.4 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9539.4 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9539.4 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9539.4 MiB      0.0 MiB           1           del e_spatial       
   194   9539.4 MiB      0.0 MiB           1           del e_bidir
   195   9539.4 MiB      0.0 MiB           1           del weights_bidir
   196   9539.4 MiB      0.0 MiB           1           del y_cluster
   197   9539.4 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9539.4 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9539.4 MiB      0.0 MiB           1           gc.collect()


89.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9391.8 MiB   9391.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9391.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9494.9 MiB    103.1 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9494.9 MiB      0.1 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9597.9 MiB    102.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9598.0 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9494.8 MiB   -103.2 MiB           1       del l1
   132                                             
   133   9494.8 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9443.2 MiB    -51.6 MiB           1       del e_1
   135   9443.2 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9443.2 MiB      0.0 MiB           1       if using_weights:
   138   9443.2 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9444.2 MiB      1.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9444.2 MiB      0.0 MiB           1           del weights_list
   141   9444.2 MiB      0.0 MiB           1           del l2
   142   9444.5 MiB      0.3 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9444.5 MiB      0.0 MiB           1           del weights_sparse
   144   9444.5 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9547.4 MiB    102.9 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9650.5 MiB    103.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9650.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9496.1 MiB   -154.4 MiB           1       del e_intersection
   150                                             
   151   9496.1 MiB      0.0 MiB           1       if using_weights:
   152   9496.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9547.7 MiB   9547.7 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9547.7 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9547.7 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9547.7 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9547.7 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9547.7 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9391.8 MiB   -156.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9391.8 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9391.8 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9391.8 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9391.8 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9391.8 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9496.1 MiB    104.3 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9496.1 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9496.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9496.1 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9496.1 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9496.1 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9496.1 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9496.1 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9496.1 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9496.1 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9496.1 MiB      0.0 MiB           1           del e_spatial       
   194   9496.1 MiB      0.0 MiB           1           del e_bidir
   195   9496.1 MiB      0.0 MiB           1           del weights_bidir
   196   9496.1 MiB      0.0 MiB           1           del y_cluster
   197   9496.1 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9496.1 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9496.1 MiB      0.0 MiB           1           gc.collect()


90.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9381.4 MiB   9381.4 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9381.4 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9495.6 MiB    114.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9495.6 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9638.6 MiB    143.0 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9638.7 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9524.3 MiB   -114.4 MiB           1       del l1
   132                                             
   133   9552.9 MiB     28.6 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9410.0 MiB   -142.9 MiB           1       del e_1
   135   9410.0 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9410.0 MiB      0.0 MiB           1       if using_weights:
   138   9410.0 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9410.0 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9410.0 MiB      0.0 MiB           1           del weights_list
   141   9410.0 MiB      0.0 MiB           1           del l2
   142   9552.8 MiB    142.8 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9552.8 MiB      0.0 MiB           1           del weights_sparse
   144   9438.6 MiB   -114.2 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9581.4 MiB    142.8 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9695.7 MiB    114.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9695.7 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9553.0 MiB   -142.6 MiB           1       del e_intersection
   150                                             
   151   9553.0 MiB      0.0 MiB           1       if using_weights:
   152   9553.0 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9504.9 MiB   9504.9 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9504.9 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9504.9 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9504.9 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9504.9 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9504.9 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9381.4 MiB   -123.5 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9381.4 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9381.4 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9381.4 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9381.4 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9381.4 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9553.0 MiB    171.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9553.0 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9553.0 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9638.4 MiB     85.3 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9638.4 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9638.4 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9638.4 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9638.4 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9638.4 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9638.4 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9638.4 MiB      0.0 MiB           1           del e_spatial       
   194   9638.4 MiB      0.0 MiB           1           del e_bidir
   195   9552.9 MiB    -85.5 MiB           1           del weights_bidir
   196   9552.9 MiB      0.0 MiB           1           del y_cluster
   197   9552.9 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9552.9 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9552.9 MiB      0.0 MiB           1           gc.collect()


90.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9392.5 MiB   9392.5 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9392.5 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9503.8 MiB    111.4 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9503.8 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9586.0 MiB     82.1 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9586.2 MiB      0.3 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9474.6 MiB   -111.6 MiB           1       del l1
   132                                             
   133   9502.6 MiB     27.9 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9363.2 MiB   -139.4 MiB           1       del e_1
   135   9363.2 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9363.2 MiB      0.0 MiB           1       if using_weights:
   138   9363.2 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9363.2 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9363.2 MiB      0.0 MiB           1           del weights_list
   141   9363.2 MiB      0.0 MiB           1           del l2
   142   9502.4 MiB    139.2 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9502.4 MiB      0.0 MiB           1           del weights_sparse
   144   9391.1 MiB   -111.3 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9530.3 MiB    139.2 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9641.7 MiB    111.4 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9641.7 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9502.6 MiB   -139.1 MiB           1       del e_intersection
   150                                             
   151   9502.6 MiB      0.0 MiB           1       if using_weights:
   152   9502.6 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9561.6 MiB   9561.6 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9561.6 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9561.6 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9561.6 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9561.6 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9561.6 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9392.5 MiB   -169.1 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9392.5 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9392.5 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9392.5 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9392.5 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9392.5 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9502.6 MiB    110.1 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9502.6 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9502.6 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9502.8 MiB      0.2 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9502.8 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9502.8 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9502.8 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9502.8 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9502.8 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9502.8 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9502.8 MiB      0.0 MiB           1           del e_spatial       
   194   9502.8 MiB      0.0 MiB           1           del e_bidir
   195   9502.8 MiB      0.0 MiB           1           del weights_bidir
   196   9502.8 MiB      0.0 MiB           1           del y_cluster
   197   9502.8 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9502.8 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9502.8 MiB      0.0 MiB           1           gc.collect()


91.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9388.4 MiB   9388.4 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9388.4 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9513.4 MiB    125.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9513.6 MiB      0.2 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9614.1 MiB    100.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9614.2 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9489.0 MiB   -125.2 MiB           1       del l1
   132                                             
   133   9520.3 MiB     31.3 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9363.9 MiB   -156.4 MiB           1       del e_1
   135   9363.9 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9363.9 MiB      0.0 MiB           1       if using_weights:
   138   9363.9 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9363.9 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9363.9 MiB      0.0 MiB           1           del weights_list
   141   9363.9 MiB      0.0 MiB           1           del l2
   142   9520.2 MiB    156.2 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9520.2 MiB      0.0 MiB           1           del weights_sparse
   144   9395.2 MiB   -124.9 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9551.5 MiB    156.2 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9676.5 MiB    125.0 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9676.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9520.2 MiB   -156.3 MiB           1       del e_intersection
   150                                             
   151   9520.2 MiB      0.0 MiB           1       if using_weights:
   152   9520.2 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9512.1 MiB   9512.1 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9512.1 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9512.1 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9512.1 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9512.1 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9512.1 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9388.4 MiB   -123.7 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9388.4 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9388.4 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9388.4 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9388.4 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9388.4 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9520.2 MiB    131.8 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9520.2 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9520.2 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9520.3 MiB      0.1 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9520.3 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9520.3 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9520.3 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9520.3 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9520.3 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9520.3 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9520.3 MiB      0.0 MiB           1           del e_spatial       
   194   9520.3 MiB      0.0 MiB           1           del e_bidir
   195   9520.3 MiB      0.0 MiB           1           del weights_bidir
   196   9520.3 MiB      0.0 MiB           1           del y_cluster
   197   9520.3 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9520.3 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9520.3 MiB      0.0 MiB           1           gc.collect()


92.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9388.7 MiB   9388.7 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9388.7 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9468.7 MiB     80.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9468.8 MiB      0.1 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9508.6 MiB     39.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9508.8 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9428.7 MiB    -80.1 MiB           1       del l1
   132                                             
   133   9428.7 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9388.7 MiB    -40.1 MiB           1       del e_1
   135   9388.7 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9388.7 MiB      0.0 MiB           1       if using_weights:
   138   9388.7 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9388.7 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9388.7 MiB      0.0 MiB           1           del weights_list
   141   9388.7 MiB      0.0 MiB           1           del l2
   142   9426.1 MiB     37.4 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9426.1 MiB      0.0 MiB           1           del weights_sparse
   144   9426.1 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9466.0 MiB     40.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9545.9 MiB     79.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9545.9 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9506.1 MiB    -39.8 MiB           1       del e_intersection
   150                                             
   151   9506.1 MiB      0.0 MiB           1       if using_weights:
   152   9506.1 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9527.6 MiB   9527.6 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9527.6 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9527.6 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9527.6 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9527.6 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9527.6 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9388.7 MiB   -138.9 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9388.7 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9388.7 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9388.7 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9388.7 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9388.7 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9506.1 MiB    117.4 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9506.1 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9506.1 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9506.1 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9506.1 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9506.1 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9506.1 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9506.1 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9506.1 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9506.1 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9506.1 MiB      0.0 MiB           1           del e_spatial       
   194   9506.1 MiB      0.0 MiB           1           del e_bidir
   195   9506.1 MiB      0.0 MiB           1           del weights_bidir
   196   9506.1 MiB      0.0 MiB           1           del y_cluster
   197   9406.1 MiB   -100.0 MiB           1           del new_weights
   198                                                 
   199   9406.1 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9406.1 MiB      0.0 MiB           1           gc.collect()


93.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9413.3 MiB   9413.3 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9413.3 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9413.3 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9413.3 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9511.7 MiB     98.4 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9511.9 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9511.9 MiB      0.0 MiB           1       del l1
   132                                             
   133   9511.9 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9472.5 MiB    -39.4 MiB           1       del e_1
   135   9472.5 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9472.5 MiB      0.0 MiB           1       if using_weights:
   138   9472.5 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9472.5 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9472.5 MiB      0.0 MiB           1           del weights_list
   141   9472.5 MiB      0.0 MiB           1           del l2
   142   9492.1 MiB     19.6 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9492.1 MiB      0.0 MiB           1           del weights_sparse
   144   9492.1 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9531.5 MiB     39.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9610.4 MiB     78.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9610.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9492.4 MiB   -118.1 MiB           1       del e_intersection
   150                                             
   151   9492.4 MiB      0.0 MiB           1       if using_weights:
   152   9492.4 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9413.1 MiB   9413.1 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9413.1 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9413.1 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9413.1 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9413.1 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9413.1 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9413.3 MiB      0.2 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9413.3 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9413.3 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9413.3 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9413.3 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9413.3 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9492.6 MiB     79.2 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9492.6 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9492.6 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9492.6 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9492.6 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9492.6 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9492.6 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9492.6 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9492.6 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9492.6 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9492.6 MiB      0.0 MiB           1           del e_spatial       
   194   9492.6 MiB      0.0 MiB           1           del e_bidir
   195   9492.6 MiB      0.0 MiB           1           del weights_bidir
   196   9492.6 MiB      0.0 MiB           1           del y_cluster
   197   9492.6 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9492.6 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9492.6 MiB      0.0 MiB           1           gc.collect()


94.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9393.0 MiB   9393.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9393.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9497.4 MiB    104.4 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9497.6 MiB      0.2 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9628.1 MiB    130.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9628.2 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9523.6 MiB   -104.6 MiB           1       del l1
   132                                             
   133   9549.8 MiB     26.2 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9419.2 MiB   -130.6 MiB           1       del e_1
   135   9419.2 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9419.2 MiB      0.0 MiB           1       if using_weights:
   138   9419.2 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9419.2 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9419.2 MiB      0.0 MiB           1           del weights_list
   141   9419.2 MiB      0.0 MiB           1           del l2
   142   9549.6 MiB    130.4 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9549.6 MiB      0.0 MiB           1           del weights_sparse
   144   9445.3 MiB   -104.3 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9575.8 MiB    130.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9680.4 MiB    104.7 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9680.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9549.9 MiB   -130.5 MiB           1       del e_intersection
   150                                             
   151   9549.9 MiB      0.0 MiB           1       if using_weights:
   152   9549.9 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9501.0 MiB   9501.0 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9501.0 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9501.0 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9501.0 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9501.0 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9501.0 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9393.0 MiB   -108.0 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9393.0 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9393.0 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9393.0 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9393.0 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9393.0 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9549.9 MiB    156.9 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9549.9 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9549.9 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9601.8 MiB     51.8 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9601.8 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9601.8 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9601.8 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9601.8 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9601.8 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9602.0 MiB      0.3 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9602.0 MiB      0.0 MiB           1           del e_spatial       
   194   9602.0 MiB      0.0 MiB           1           del e_bidir
   195   9602.0 MiB      0.0 MiB           1           del weights_bidir
   196   9602.0 MiB      0.0 MiB           1           del y_cluster
   197   9497.5 MiB   -104.5 MiB           1           del new_weights
   198                                                 
   199   9497.5 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9497.5 MiB      0.0 MiB           1           gc.collect()


95.0% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9390.8 MiB   9390.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9390.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9505.0 MiB    114.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9505.2 MiB      0.2 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9647.8 MiB    142.7 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9648.0 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9533.6 MiB   -114.4 MiB           1       del l1
   132                                             
   133   9562.3 MiB     28.6 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9419.4 MiB   -142.9 MiB           1       del e_1
   135   9419.4 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9419.4 MiB      0.0 MiB           1       if using_weights:
   138   9419.4 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9419.4 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9419.4 MiB      0.0 MiB           1           del weights_list
   141   9419.4 MiB      0.0 MiB           1           del l2
   142   9562.2 MiB    142.8 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9562.2 MiB      0.0 MiB           1           del weights_sparse
   144   9448.0 MiB   -114.2 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9590.8 MiB    142.8 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9705.0 MiB    114.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9705.0 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9562.4 MiB   -142.6 MiB           1       del e_intersection
   150                                             
   151   9562.4 MiB      0.0 MiB           1       if using_weights:
   152   9562.4 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9506.4 MiB   9506.4 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9506.4 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9506.4 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9506.4 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9506.4 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9506.4 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9390.8 MiB   -115.6 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9390.8 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9390.8 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9390.8 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9390.8 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9390.8 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9562.4 MiB    171.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9562.4 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9562.4 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9562.5 MiB      0.1 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9562.5 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9562.5 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9562.5 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9562.5 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9562.5 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9562.5 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9562.5 MiB      0.0 MiB           1           del e_spatial       
   194   9562.5 MiB      0.0 MiB           1           del e_bidir
   195   9562.5 MiB      0.0 MiB           1           del weights_bidir
   196   9562.5 MiB      0.0 MiB           1           del y_cluster
   197   9562.5 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9562.5 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9562.5 MiB      0.0 MiB           1           gc.collect()


95.8% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9391.6 MiB   9391.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9391.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9490.9 MiB     99.3 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9490.9 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9540.6 MiB     49.7 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9540.7 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9441.3 MiB    -99.4 MiB           1       del l1
   132                                             
   133   9458.6 MiB     17.3 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9408.9 MiB    -49.7 MiB           1       del e_1
   135   9408.9 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9408.9 MiB      0.0 MiB           1       if using_weights:
   138   9408.9 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9408.9 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9408.9 MiB      0.0 MiB           1           del weights_list
   141   9408.9 MiB      0.0 MiB           1           del l2
   142   9384.1 MiB    -24.7 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9384.1 MiB      0.0 MiB           1           del weights_sparse
   144   9384.1 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9483.4 MiB     99.3 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9582.4 MiB     99.0 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9582.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9433.6 MiB   -148.8 MiB           1       del e_intersection
   150                                             
   151   9433.6 MiB      0.0 MiB           1       if using_weights:
   152   9433.6 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9570.8 MiB   9570.8 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9570.8 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9570.8 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9570.8 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9570.8 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9570.8 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9391.6 MiB   -179.2 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9391.6 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9391.6 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9391.6 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9391.6 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9391.6 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9433.6 MiB     42.0 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9433.7 MiB      0.1 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9433.7 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9483.2 MiB     49.5 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9483.2 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9483.2 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9483.2 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9483.2 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9483.2 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9483.2 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9483.2 MiB      0.0 MiB           1           del e_spatial       
   194   9483.2 MiB      0.0 MiB           1           del e_bidir
   195   9483.2 MiB      0.0 MiB           1           del weights_bidir
   196   9483.2 MiB      0.0 MiB           1           del y_cluster
   197   9483.2 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9483.2 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9483.2 MiB      0.0 MiB           1           gc.collect()


96.7% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9382.7 MiB   9382.7 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9382.7 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9382.7 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9382.7 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9462.8 MiB     80.1 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9462.9 MiB      0.1 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9462.9 MiB      0.0 MiB           1       del l1
   132                                             
   133   9462.9 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9333.1 MiB   -129.8 MiB           1       del e_1
   135   9333.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9333.1 MiB      0.0 MiB           1       if using_weights:
   138   9333.1 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9333.1 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9333.1 MiB      0.0 MiB           1           del weights_list
   141   9333.1 MiB      0.0 MiB           1           del l2
   142   9407.1 MiB     74.0 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9407.1 MiB      0.0 MiB           1           del weights_sparse
   144   9407.1 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9444.2 MiB     37.1 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9518.5 MiB     74.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9518.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9481.5 MiB    -37.0 MiB           1       del e_intersection
   150                                             
   151   9481.5 MiB      0.0 MiB           1       if using_weights:
   152   9481.5 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9490.3 MiB   9490.3 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9490.3 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9490.3 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9490.3 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9490.3 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9490.3 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9382.7 MiB   -107.6 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9382.7 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9382.7 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9382.7 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9382.7 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9382.7 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9481.5 MiB     98.8 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9481.5 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9481.5 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9481.5 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9481.5 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9481.5 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9481.5 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9481.5 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9481.5 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9481.5 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9481.5 MiB      0.0 MiB           1           del e_spatial       
   194   9481.5 MiB      0.0 MiB           1           del e_bidir
   195   9481.5 MiB      0.0 MiB           1           del weights_bidir
   196   9481.5 MiB      0.0 MiB           1           del y_cluster
   197   9407.4 MiB    -74.1 MiB           1           del new_weights
   198                                                 
   199   9407.4 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9407.4 MiB      0.0 MiB           1           gc.collect()


97.5% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9415.5 MiB   9415.5 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9415.5 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9512.3 MiB     96.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9512.3 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9609.0 MiB     96.7 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9609.2 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9512.3 MiB    -96.9 MiB           1       del l1
   132                                             
   133   9536.6 MiB     24.2 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9488.1 MiB    -48.5 MiB           1       del e_1
   135   9488.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9488.1 MiB      0.0 MiB           1       if using_weights:
   138   9488.1 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9488.1 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9488.1 MiB      0.0 MiB           1           del weights_list
   141   9488.1 MiB      0.0 MiB           1           del l2
   142   9536.3 MiB     48.2 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9536.3 MiB      0.0 MiB           1           del weights_sparse
   144   9464.0 MiB    -72.3 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9560.6 MiB     96.7 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9657.6 MiB     96.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9657.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9609.2 MiB    -48.4 MiB           1       del e_intersection
   150                                             
   151   9609.2 MiB      0.0 MiB           1       if using_weights:
   152   9609.2 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9415.4 MiB   9415.4 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9415.4 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9415.4 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9415.4 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9415.4 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9415.4 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9415.5 MiB      0.2 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9415.5 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9415.5 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9415.5 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9415.5 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9415.5 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9609.2 MiB    193.7 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9609.2 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9609.2 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9609.2 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9609.2 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9609.2 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9609.2 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9609.2 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9609.2 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9609.2 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9609.2 MiB      0.0 MiB           1           del e_spatial       
   194   9609.2 MiB      0.0 MiB           1           del e_bidir
   195   9609.2 MiB      0.0 MiB           1           del weights_bidir
   196   9609.2 MiB      0.0 MiB           1           del y_cluster
   197   9512.4 MiB    -96.8 MiB           1           del new_weights
   198                                                 
   199   9512.4 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9512.4 MiB      0.0 MiB           1           gc.collect()


98.3% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9380.6 MiB   9380.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9380.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9380.6 MiB      0.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9380.6 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9450.7 MiB     70.0 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9450.7 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9450.7 MiB      0.0 MiB           1       del l1
   132                                             
   133   9450.7 MiB      0.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9415.6 MiB    -35.1 MiB           1       del e_1
   135   9415.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9415.6 MiB      0.0 MiB           1       if using_weights:
   138   9415.6 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9415.6 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9415.6 MiB      0.0 MiB           1           del weights_list
   141   9415.6 MiB      0.0 MiB           1           del l2
   142   9433.1 MiB     17.5 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9433.1 MiB      0.0 MiB           1           del weights_sparse
   144   9433.1 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9468.2 MiB     35.1 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9538.3 MiB     70.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9538.3 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9503.3 MiB    -35.0 MiB           1       del e_intersection
   150                                             
   151   9503.3 MiB      0.0 MiB           1       if using_weights:
   152   9503.3 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9519.0 MiB   9519.0 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9519.0 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9519.0 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9519.0 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9519.0 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9519.0 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9380.6 MiB   -138.4 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9380.6 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9380.6 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9380.6 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9380.6 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9380.6 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9503.3 MiB    122.6 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9503.3 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9503.3 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9503.3 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9503.3 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9503.3 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9503.3 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9503.3 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9503.3 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9503.3 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9503.3 MiB      0.0 MiB           1           del e_spatial       
   194   9503.3 MiB      0.0 MiB           1           del e_bidir
   195   9503.3 MiB      0.0 MiB           1           del weights_bidir
   196   9503.3 MiB      0.0 MiB           1           del y_cluster
   197   9503.3 MiB      0.0 MiB           1           del new_weights
   198                                                 
   199   9503.3 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9503.3 MiB      0.0 MiB           1           gc.collect()


99.2% inference complete Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9387.1 MiB   9387.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9387.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9470.7 MiB     83.5 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9470.7 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9512.4 MiB     41.8 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9512.4 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   9428.9 MiB    -83.5 MiB           1       del l1
   132                                             
   133   9439.0 MiB     10.1 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   9397.2 MiB    -41.8 MiB           1       del e_1
   135   9397.2 MiB      0.0 MiB           1       del e_2
   136                                             
   137   9397.2 MiB      0.0 MiB           1       if using_weights:
   138   9397.2 MiB      0.0 MiB           1           weights_list = weights_bidir.cpu().numpy()
   139   9397.2 MiB      0.0 MiB           1           weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140   9397.2 MiB      0.0 MiB           1           del weights_list
   141   9397.2 MiB      0.0 MiB           1           del l2
   142   9438.7 MiB     41.5 MiB           1           new_weights = weights_sparse[e_intersection.astype('bool')]
   143   9438.7 MiB      0.0 MiB           1           del weights_sparse
   144   9438.7 MiB      0.0 MiB           1           new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9480.7 MiB     42.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9564.2 MiB     83.5 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9564.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9522.5 MiB    -41.8 MiB           1       del e_intersection
   150                                             
   151   9522.5 MiB      0.0 MiB           1       if using_weights:
   152   9522.5 MiB      0.0 MiB           1           return new_pred_graph, y, new_weights
   153                                             else:
   154                                                 return new_pred_graph, y


Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/Models/inference.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   150   9510.6 MiB   9510.6 MiB           1       @profile
   151                                             def construct_downstream(self, batch, pl_module, datatype):
   152                                         
   153   9510.6 MiB      0.0 MiB           1           if 'ci' in pl_module.hparams["regime"]:
   154   9510.6 MiB      0.0 MiB           1               spatial = pl_module(torch.cat([batch.cell_data, batch.x], axis=-1))
   155                                                 else:
   156                                                     spatial = pl_module(batch.x)
   157                                         
   158                                                 # Make truth bidirectional
   159   9510.6 MiB      0.0 MiB           1           e_bidir = torch.cat([batch.layerless_true_edges,
   160   9510.6 MiB      0.0 MiB           1                          torch.stack([batch.layerless_true_edges[1], batch.layerless_true_edges[0]], axis=1).T], axis=-1)
   161   9510.6 MiB      0.0 MiB           1           weights_bidir = torch.cat([batch.weights, batch.weights])
   162                                                 
   163                                                 # Build the radius graph with radius < r_test
   164   9387.1 MiB   -123.5 MiB           1           e_spatial = build_edges(spatial, pl_module.hparams.r_test, 300) #This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur
   165   9387.1 MiB      0.0 MiB           1           spatial = spatial.to("cpu")
   166   9387.1 MiB      0.0 MiB           1           del spatial
   167                                                 
   168                                                 # Arbitrary ordering to remove half of the duplicate edges
   169   9387.1 MiB      0.0 MiB           1           R_dist = torch.sqrt(batch.x[:,0]**2 + batch.x[:,2]**2)
   170   9387.1 MiB      0.0 MiB           1           e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]
   171   9387.1 MiB      0.0 MiB           1           del R_dist
   172                                                 
   173   9522.5 MiB    135.3 MiB           1           e_spatial, y_cluster, new_weights = graph_intersection(e_spatial, e_bidir, using_weights=True, weights_bidir=weights_bidir)
   174   9522.5 MiB      0.0 MiB           1           logging.info("Constructing with radius {}, producing {} edges, eff: {}, pur: {}".format(pl_module.hparams.r_test, e_spatial.shape[1], y_cluster.sum() / batch.layerless_true_edges.shape[1], y_cluster.sum() / y_cluster.shape[0]))
   175                                                 
   176                                                 # Re-introduce random direction, to avoid training bias
   177   9522.5 MiB      0.0 MiB           1           random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()
   178   9522.5 MiB      0.0 MiB           1           e_spatial[0, random_flip], e_spatial[1, random_flip] = e_spatial[1, random_flip], e_spatial[0, random_flip]
   179   9522.5 MiB      0.0 MiB           1           del random_flip
   180                                                 
   181   9522.5 MiB      0.0 MiB           1           batch.edge_index = e_spatial
   182                                         #         batch.y = y_cluster
   183                                         #         batch.true_weights = batch.weights
   184                                         #         batch.weights = new_weights
   185                                                 
   186   9522.5 MiB      0.0 MiB           1           e_spatial = e_spatial.to("cpu")
   187   9522.5 MiB      0.0 MiB           1           e_bidir = e_bidir.to("cpu")
   188   9522.5 MiB      0.0 MiB           1           weights_bidir = weights_bidir.to("cpu")
   189   9522.5 MiB      0.0 MiB           1           batch = batch.to("cpu")
   190                                                     
   191                                         #         self.save_downstream(batch, pl_module, datatype)
   192                                                 
   193   9522.5 MiB      0.0 MiB           1           del e_spatial       
   194   9522.5 MiB      0.0 MiB           1           del e_bidir
   195   9522.5 MiB      0.0 MiB           1           del weights_bidir
   196   9522.5 MiB      0.0 MiB           1           del y_cluster
   197   9418.2 MiB   -104.3 MiB           1           del new_weights
   198                                                 
   199   9418.2 MiB      0.0 MiB           1           del batch
   200                                                 
   201   9418.2 MiB      0.0 MiB           1           gc.collect()


Training: 0it [04:52, ?it/s]
Testing: 0it [00:00, ?it/s]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   9021.1 MiB   9021.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   9021.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   9221.3 MiB    200.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   9221.4 MiB      0.2 MiB           1       l2 = truth_graph.cpu().numpy()
   129   9163.0 MiB    -58.4 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   9163.0 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   8962.7 MiB   -200.3 MiB           1       del l1
   132                                             
   133   9062.9 MiB    100.2 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   8912.6 MiB   -150.2 MiB           1       del e_1
   135   8912.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   8912.6 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   9012.8 MiB    100.2 MiB           1       e_intersection = e_intersection.tocoo()    
   147   9213.0 MiB    200.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   9213.0 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   9012.6 MiB   -200.3 MiB           1       del e_intersection
   150                                             
   151   9012.6 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   9012.6 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:   4%|███▍                                                                                   | 1/25 [00:08<03:32,  8.86s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7822.0 MiB   7822.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7822.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   8007.3 MiB    185.3 MiB           1       l1 = pred_graph.cpu().numpy()
   128   8007.5 MiB      0.2 MiB           1       l2 = truth_graph.cpu().numpy()
   129   8146.7 MiB    139.3 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   8146.7 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7961.4 MiB   -185.4 MiB           1       del l1
   132                                             
   133   8054.1 MiB     92.8 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7915.1 MiB   -139.1 MiB           1       del e_1
   135   7915.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7915.1 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   8007.8 MiB     92.7 MiB           1       e_intersection = e_intersection.tocoo()    
   147   8193.3 MiB    185.5 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   8193.3 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   8007.9 MiB   -185.4 MiB           1       del e_intersection
   150                                             
   151   8007.9 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   8007.9 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:   8%|██████▉                                                                                | 2/25 [00:13<02:53,  7.54s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7816.4 MiB   7816.4 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7816.4 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   8025.8 MiB    209.4 MiB           1       l1 = pred_graph.cpu().numpy()
   128   8025.9 MiB      0.1 MiB           1       l2 = truth_graph.cpu().numpy()
   129   8183.0 MiB    157.1 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   8183.0 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7973.6 MiB   -209.4 MiB           1       del l1
   132                                             
   133   8091.0 MiB    117.5 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7934.0 MiB   -157.1 MiB           1       del e_1
   135   7934.0 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7934.0 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   8038.7 MiB    104.7 MiB           1       e_intersection = e_intersection.tocoo()    
   147   8248.1 MiB    209.4 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   8248.1 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   8038.6 MiB   -209.5 MiB           1       del e_intersection
   150                                             
   151   8038.6 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   8038.6 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  12%|██████████▍                                                                            | 3/25 [00:19<02:34,  7.02s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7480.5 MiB   7480.5 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7480.5 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7682.6 MiB    202.1 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7682.8 MiB      0.1 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7834.5 MiB    151.7 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7834.5 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7632.2 MiB   -202.2 MiB           1       del l1
   132                                             
   133   7783.9 MiB    151.7 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7632.2 MiB   -151.7 MiB           1       del e_1
   135   7632.2 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7632.2 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7682.8 MiB     50.6 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7885.2 MiB    202.4 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7885.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7683.0 MiB   -202.2 MiB           1       del e_intersection
   150                                             
   151   7683.0 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7683.0 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  16%|█████████████▉                                                                         | 4/25 [00:23<02:08,  6.12s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7501.8 MiB   7501.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7501.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7733.6 MiB    231.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7733.6 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7907.6 MiB    174.0 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7907.6 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7675.8 MiB   -231.8 MiB           1       del l1
   132                                             
   133   7849.7 MiB    173.9 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7675.8 MiB   -173.9 MiB           1       del e_1
   135   7675.8 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7675.8 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7733.8 MiB     58.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7965.7 MiB    231.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7965.7 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7733.9 MiB   -231.8 MiB           1       del e_intersection
   150                                             
   151   7733.9 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7733.9 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  20%|█████████████████▍                                                                     | 5/25 [00:28<01:58,  5.90s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7287.6 MiB   7287.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7287.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7550.8 MiB    263.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7550.8 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7748.3 MiB    197.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7748.3 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7485.1 MiB   -263.3 MiB           1       del l1
   132                                             
   133   7684.3 MiB    199.2 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7486.8 MiB   -197.5 MiB           1       del e_1
   135   7486.8 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7486.8 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7552.6 MiB     65.8 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7815.8 MiB    263.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7815.8 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7552.7 MiB   -263.1 MiB           1       del e_intersection
   150                                             
   151   7552.7 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7552.7 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  24%|████████████████████▉                                                                  | 6/25 [00:34<01:52,  5.94s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7143.6 MiB   7143.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7143.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7388.8 MiB    245.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7388.8 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7572.8 MiB    183.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7573.0 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7327.8 MiB   -245.1 MiB           1       del l1
   132                                             
   133   7511.7 MiB    183.9 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7327.8 MiB   -183.9 MiB           1       del e_1
   135   7327.8 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7327.8 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7389.1 MiB     61.3 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7634.2 MiB    245.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7634.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7389.0 MiB   -245.2 MiB           1       del e_intersection
   150                                             
   151   7389.0 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7389.0 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  28%|████████████████████████▎                                                              | 7/25 [00:40<01:45,  5.88s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7201.0 MiB   7201.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7201.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7418.9 MiB    217.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7418.9 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7582.7 MiB    163.8 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7582.7 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7364.6 MiB   -218.1 MiB           1       del l1
   132                                             
   133   7528.2 MiB    163.6 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7364.6 MiB   -163.6 MiB           1       del e_1
   135   7364.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7364.6 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7419.1 MiB     54.5 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7637.2 MiB    218.1 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7637.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7419.1 MiB   -218.1 MiB           1       del e_intersection
   150                                             
   151   7419.1 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7419.1 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  32%|███████████████████████████▊                                                           | 8/25 [00:44<01:30,  5.33s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7431.1 MiB   7431.1 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7431.1 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7681.4 MiB    250.3 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7681.4 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7869.3 MiB    187.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7869.3 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7619.0 MiB   -250.4 MiB           1       del l1
   132                                             
   133   7812.2 MiB    193.3 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7624.4 MiB   -187.8 MiB           1       del e_1
   135   7624.4 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7624.4 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7687.0 MiB     62.6 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7937.5 MiB    250.5 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7937.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7687.3 MiB   -250.2 MiB           1       del e_intersection
   150                                             
   151   7687.3 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7687.3 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  36%|███████████████████████████████▎                                                       | 9/25 [00:50<01:28,  5.54s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7118.8 MiB   7118.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7118.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7378.9 MiB    260.1 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7378.9 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7574.3 MiB    195.3 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7574.3 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7314.0 MiB   -260.2 MiB           1       del l1
   132                                             
   133   7516.9 MiB    202.9 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7321.7 MiB   -195.2 MiB           1       del e_1
   135   7321.7 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7321.7 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7386.8 MiB     65.1 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7647.1 MiB    260.3 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7647.1 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7387.0 MiB   -260.0 MiB           1       del e_intersection
   150                                             
   151   7387.0 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7387.0 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  40%|██████████████████████████████████▍                                                   | 10/25 [00:55<01:22,  5.49s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7174.5 MiB   7174.5 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7174.5 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7371.5 MiB    197.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7371.5 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7519.3 MiB    147.8 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7519.3 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7322.3 MiB   -197.0 MiB           1       del l1
   132                                             
   133   7470.3 MiB    148.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7322.6 MiB   -147.8 MiB           1       del e_1
   135   7322.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7322.6 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7371.8 MiB     49.2 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7568.8 MiB    197.0 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7568.8 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7371.8 MiB   -197.0 MiB           1       del e_intersection
   150                                             
   151   7371.8 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7371.8 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  44%|█████████████████████████████████████▊                                                | 11/25 [01:00<01:12,  5.15s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7384.0 MiB   7384.0 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7384.0 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7609.3 MiB    225.3 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7609.3 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7778.5 MiB    169.2 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7778.5 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7553.0 MiB   -225.4 MiB           1       del l1
   132                                             
   133   7723.7 MiB    170.6 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7554.6 MiB   -169.1 MiB           1       del e_1
   135   7554.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7554.6 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7611.0 MiB     56.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7836.3 MiB    225.4 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7836.3 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7611.1 MiB   -225.2 MiB           1       del e_intersection
   150                                             
   151   7611.1 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7611.1 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  48%|█████████████████████████████████████████▎                                            | 12/25 [01:04<01:05,  5.03s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7333.8 MiB   7333.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7333.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7556.8 MiB    223.0 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7556.8 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7724.1 MiB    167.3 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7724.1 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7501.1 MiB   -223.0 MiB           1       del l1
   132                                             
   133   7671.3 MiB    170.3 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7504.1 MiB   -167.3 MiB           1       del e_1
   135   7504.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7504.1 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7559.8 MiB     55.8 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7782.7 MiB    222.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7782.7 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7559.9 MiB   -222.8 MiB           1       del e_intersection
   150                                             
   151   7559.9 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7559.9 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  52%|████████████████████████████████████████████▋                                         | 13/25 [01:09<00:58,  4.84s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7357.4 MiB   7357.4 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7357.4 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7608.3 MiB    250.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7608.3 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7796.5 MiB    188.2 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7796.5 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7545.6 MiB   -250.9 MiB           1       del l1
   132                                             
   133   7742.3 MiB    196.7 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7554.1 MiB   -188.2 MiB           1       del e_1
   135   7554.1 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7554.1 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7616.8 MiB     62.7 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7867.6 MiB    250.7 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7867.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7616.9 MiB   -250.7 MiB           1       del e_intersection
   150                                             
   151   7616.9 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7616.9 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  56%|████████████████████████████████████████████████▏                                     | 14/25 [01:14<00:55,  5.09s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7225.8 MiB   7225.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7225.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7469.2 MiB    243.4 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7469.2 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7651.7 MiB    182.6 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7651.7 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7408.3 MiB   -243.4 MiB           1       del l1
   132                                             
   133   7593.8 MiB    185.5 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7411.3 MiB   -182.5 MiB           1       del e_1
   135   7411.3 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7411.3 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7472.1 MiB     60.8 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7715.5 MiB    243.4 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7715.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7472.3 MiB   -243.2 MiB           1       del e_intersection
   150                                             
   151   7472.3 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7472.3 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  60%|███████████████████████████████████████████████████▌                                  | 15/25 [01:20<00:52,  5.22s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7286.9 MiB   7286.9 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7286.9 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7563.2 MiB    276.4 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7563.2 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7770.6 MiB    207.3 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7770.6 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7494.2 MiB   -276.4 MiB           1       del l1
   132                                             
   133   7707.2 MiB    213.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7499.9 MiB   -207.3 MiB           1       del e_1
   135   7499.9 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7499.9 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7569.0 MiB     69.1 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7845.6 MiB    276.6 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7845.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7569.5 MiB   -276.2 MiB           1       del e_intersection
   150                                             
   151   7569.5 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7569.5 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  64%|███████████████████████████████████████████████████████                               | 16/25 [01:27<00:50,  5.64s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7048.9 MiB   7048.9 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7048.9 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7216.7 MiB    167.8 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7216.7 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7342.7 MiB    126.1 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7342.7 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7174.8 MiB   -167.9 MiB           1       del l1
   132                                             
   133   7300.8 MiB    125.9 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7174.8 MiB   -125.9 MiB           1       del e_1
   135   7174.8 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7174.8 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7216.8 MiB     42.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7384.8 MiB    168.0 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7384.8 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7216.9 MiB   -167.9 MiB           1       del e_intersection
   150                                             
   151   7216.9 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7216.9 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  68%|██████████████████████████████████████████████████████████▍                           | 17/25 [01:30<00:39,  4.97s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7224.5 MiB   7224.5 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7224.5 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7390.0 MiB    165.5 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7390.0 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7514.6 MiB    124.6 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7514.6 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7348.8 MiB   -165.7 MiB           1       del l1
   132                                             
   133   7473.1 MiB    124.3 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7348.8 MiB   -124.3 MiB           1       del e_1
   135   7348.8 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7348.8 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7390.3 MiB     41.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7555.9 MiB    165.6 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7555.9 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7390.1 MiB   -165.7 MiB           1       del e_intersection
   150                                             
   151   7390.1 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7390.1 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  72%|█████████████████████████████████████████████████████████████▉                        | 18/25 [01:33<00:30,  4.40s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7400.6 MiB   7400.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7400.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7627.4 MiB    226.9 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7627.4 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7797.7 MiB    170.2 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7797.7 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7570.8 MiB   -226.9 MiB           1       del l1
   132                                             
   133   7747.9 MiB    177.2 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7577.8 MiB   -170.2 MiB           1       del e_1
   135   7577.8 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7577.8 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7634.5 MiB     56.7 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7861.4 MiB    226.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7861.4 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7634.7 MiB   -226.7 MiB           1       del e_intersection
   150                                             
   151   7634.7 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7634.7 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  76%|█████████████████████████████████████████████████████████████████▎                    | 19/25 [01:38<00:26,  4.50s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7326.8 MiB   7326.8 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7326.8 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7578.0 MiB    251.1 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7578.0 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7766.5 MiB    188.5 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7766.5 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7515.3 MiB   -251.2 MiB           1       del l1
   132                                             
   133   7708.6 MiB    193.3 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7520.2 MiB   -188.4 MiB           1       del e_1
   135   7520.2 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7520.2 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7583.0 MiB     62.8 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7834.1 MiB    251.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7834.1 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7583.1 MiB   -251.0 MiB           1       del e_intersection
   150                                             
   151   7583.1 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7583.1 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  80%|████████████████████████████████████████████████████████████████████▊                 | 20/25 [01:43<00:24,  4.83s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7197.3 MiB   7197.3 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7197.3 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7410.5 MiB    213.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7410.5 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7570.8 MiB    160.3 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7570.8 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7357.4 MiB   -213.4 MiB           1       del l1
   132                                             
   133   7518.5 MiB    161.1 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7358.4 MiB   -160.1 MiB           1       del e_1
   135   7358.4 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7358.4 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7411.7 MiB     53.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7625.2 MiB    213.4 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7625.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7412.0 MiB   -213.2 MiB           1       del e_intersection
   150                                             
   151   7412.0 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7412.0 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  84%|████████████████████████████████████████████████████████████████████████▏             | 21/25 [01:47<00:18,  4.58s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7425.3 MiB   7425.3 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7425.3 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7579.5 MiB    154.2 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7579.5 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7695.2 MiB    115.7 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7695.2 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7541.0 MiB   -154.2 MiB           1       del l1
   132                                             
   133   7656.6 MiB    115.7 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7541.0 MiB   -115.7 MiB           1       del e_1
   135   7541.0 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7541.0 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7579.5 MiB     38.6 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7733.7 MiB    154.2 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7733.7 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7579.5 MiB   -154.2 MiB           1       del e_intersection
   150                                             
   151   7579.5 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7579.5 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  88%|███████████████████████████████████████████████████████████████████████████▋          | 22/25 [01:50<00:12,  4.08s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7588.2 MiB   7588.2 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7588.2 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7796.3 MiB    208.1 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7796.3 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7952.4 MiB    156.1 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7952.4 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7744.3 MiB   -208.1 MiB           1       del l1
   132                                             
   133   7909.6 MiB    165.3 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7753.6 MiB   -156.1 MiB           1       del e_1
   135   7753.6 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7753.6 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7805.6 MiB     52.0 MiB           1       e_intersection = e_intersection.tocoo()    
   147   8013.5 MiB    207.9 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   8013.5 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7805.6 MiB   -207.9 MiB           1       del e_intersection
   150                                             
   151   7805.6 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7805.6 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  92%|███████████████████████████████████████████████████████████████████████████████       | 23/25 [01:55<00:08,  4.16s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7544.6 MiB   7544.6 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7544.6 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7690.6 MiB    145.9 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7690.6 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   7800.4 MiB    109.9 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   7800.7 MiB      0.2 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7654.7 MiB   -146.0 MiB           1       del l1
   132                                             
   133   7764.2 MiB    109.5 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7654.7 MiB   -109.5 MiB           1       del e_1
   135   7654.7 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7654.7 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7691.2 MiB     36.5 MiB           1       e_intersection = e_intersection.tocoo()    
   147   7837.2 MiB    146.0 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   7837.2 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7691.2 MiB   -146.0 MiB           1       del e_intersection
   150                                             
   151   7691.2 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7691.2 MiB      0.0 MiB           1           return new_pred_graph, y


Testing:  96%|██████████████████████████████████████████████████████████████████████████████████▌   | 24/25 [01:58<00:03,  3.78s/it]Filename: /global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples/LightningModules/Embedding/utils.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   122   7699.7 MiB   7699.7 MiB           1   @profile
   123                                         def graph_intersection(pred_graph, truth_graph, using_weights=False, weights_bidir=None):
   124                                         
   125   7699.7 MiB      0.0 MiB           1       array_size = max(pred_graph.max().item(), truth_graph.max().item()) + 1
   126                                         
   127   7877.1 MiB    177.4 MiB           1       l1 = pred_graph.cpu().numpy()
   128   7877.1 MiB      0.0 MiB           1       l2 = truth_graph.cpu().numpy()
   129   8010.5 MiB    133.4 MiB           1       e_1 = sp.sparse.coo_matrix((np.ones(l1.shape[1]), l1), shape=(array_size, array_size)).tocsr()
   130   8010.5 MiB      0.0 MiB           1       e_2 = sp.sparse.coo_matrix((np.ones(l2.shape[1]), l2), shape=(array_size, array_size)).tocsr()
   131   7832.9 MiB   -177.5 MiB           1       del l1
   132                                             
   133   7967.9 MiB    135.0 MiB           1       e_intersection = (e_1.multiply(e_2) - ((e_1 - e_2)>0))
   134   7834.7 MiB   -133.2 MiB           1       del e_1
   135   7834.7 MiB      0.0 MiB           1       del e_2
   136                                             
   137   7834.7 MiB      0.0 MiB           1       if using_weights:
   138                                                 weights_list = weights_bidir.cpu().numpy()
   139                                                 weights_sparse = sp.sparse.coo_matrix((weights_list, l2), shape=(array_size, array_size)).tocsr()
   140                                                 del weights_list
   141                                                 del l2
   142                                                 new_weights = weights_sparse[e_intersection.astype('bool')]
   143                                                 del weights_sparse
   144                                                 new_weights = torch.from_numpy(np.array(new_weights)[0])
   145                                             
   146   7879.1 MiB     44.4 MiB           1       e_intersection = e_intersection.tocoo()    
   147   8056.6 MiB    177.5 MiB           1       new_pred_graph = torch.from_numpy(np.vstack([e_intersection.row, e_intersection.col])).long()#.to(device)
   148   8056.6 MiB      0.0 MiB           1       y = torch.from_numpy(e_intersection.data > 0)#.to(device)
   149   7879.2 MiB   -177.4 MiB           1       del e_intersection
   150                                             
   151   7879.2 MiB      0.0 MiB           1       if using_weights:
   152                                                 return new_pred_graph, y, new_weights
   153                                             else:
   154   7879.2 MiB      0.0 MiB           1           return new_pred_graph, y


Testing: 100%|██████████████████████████████████████████████████████████████████████████████████████| 25/25 [02:01<00:00,  3.62s/it]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'loss': tensor(0.9965, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 87792, 87792, 87792],
       [    8,    29,    58, ..., 87642, 87779, 87783]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[ 3067,  8316, 14351, ..., 19107, 24613, 30605],
       [ 8316, 14351, 20080, ..., 12882, 19107, 24613]])}
--------------------------------------------------------------------------------
DATALOADER:1 TEST RESULTS
{'loss': tensor(0.9966, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 84198, 84198, 84198],
       [  183,   423,   467, ..., 83217, 83893, 84185]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[40616, 40616, 40616, ..., 49724, 59858, 68825],
       [46787, 47009, 47034, ..., 36404, 49724, 59858]])}
--------------------------------------------------------------------------------
DATALOADER:2 TEST RESULTS
{'loss': tensor(0.9964, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 91313, 91313, 91313],
       [   11,   128,   174, ..., 91067, 91104, 91235]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[10222, 21289, 29977, ..., 72095, 72095, 77064],
       [21289, 29977, 39402, ..., 65822, 66036, 72095]])}
--------------------------------------------------------------------------------
DATALOADER:3 TEST RESULTS
{'loss': tensor(0.9967, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 87916, 87916, 87916],
       [    8,    24,   148, ..., 87593, 87648, 87860]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[ 1650,  1650,  6025, ..., 83888, 86253, 86253],
       [ 6025,  6239, 10550, ..., 81500, 83868, 83888]])}
--------------------------------------------------------------------------------
DATALOADER:4 TEST RESULTS
{'loss': tensor(0.9967, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 94893, 94893, 94893],
       [  177,   641,  2412, ..., 94850, 94888, 94890]]),
 'truth': array([False, False, False, ..., False, False,  True]),
 'truth_graph': array([[ 3660,  3803,  9478, ..., 22699, 29023, 37061],
       [ 9478,  9478, 16143, ..., 15971, 22699, 29023]])}
--------------------------------------------------------------------------------
DATALOADER:5 TEST RESULTS
{'loss': tensor(0.9971, device='cuda:0'),
 'preds': array([[     0,      0,      0, ..., 100744, 100744, 100744],
       [    44,    244,   2653, ..., 100626, 100653, 100733]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[ 1886,  1886,  2190, ..., 29102, 36403, 46913],
       [ 6883,  7141,  6883, ..., 23327, 29102, 36403]])}
--------------------------------------------------------------------------------
DATALOADER:6 TEST RESULTS
{'loss': tensor(0.9968, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 97200, 97200, 97200],
       [   11,    13,    20, ..., 96715, 96746, 96951]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[ 1941,  6665, 11448, ..., 46487, 63683, 86780],
       [ 6665, 11448, 16996, ..., 34453, 46487, 63683]])}
--------------------------------------------------------------------------------
DATALOADER:7 TEST RESULTS
{'loss': tensor(0.9970, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 90749, 90749, 90749],
       [    4,    16,    49, ..., 90694, 90735, 90746]]),
 'truth': array([False, False, False, ..., False, False,  True]),
 'truth_graph': array([[48815, 48815, 48815, ..., 27830, 34967, 47164],
       [56035, 56296, 56326, ..., 21995, 27830, 34967]])}
--------------------------------------------------------------------------------
DATALOADER:8 TEST RESULTS
{'loss': tensor(0.9970, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 99704, 99704, 99704],
       [  113,   114,   265, ..., 99669, 99679, 99688]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[ 1745,  1745,  1745, ..., 92451, 95390, 98148],
       [ 6429,  6505,  6717, ..., 89313, 92451, 95390]])}
--------------------------------------------------------------------------------
DATALOADER:9 TEST RESULTS
{'loss': tensor(0.9973, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 99881, 99881, 99881],
       [    7,    11,    14, ..., 99766, 99772, 99805]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[44895, 44895, 44895, ..., 86556, 86439, 86556],
       [52757, 53135, 53192, ..., 81398, 81530, 81530]])}
--------------------------------------------------------------------------------
DATALOADER:10 TEST RESULTS
{'loss': tensor(0.9969, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 86851, 86851, 86851],
       [  111,   132,   157, ..., 86712, 86766, 86767]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[ 2539,  7196, 12018, ..., 62650, 77643, 77697],
       [ 7196, 12018, 17577, ..., 48162, 62650, 62650]])}
--------------------------------------------------------------------------------
DATALOADER:11 TEST RESULTS
{'loss': tensor(0.9967, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 93887, 93887, 93887],
       [   15,    26,    35, ..., 93538, 93881, 93886]]),
 'truth': array([False, False, False, ..., False, False,  True]),
 'truth_graph': array([[ 1784,  1784,  2155, ..., 77097, 77097, 81809],
       [ 6189,  6478,  6189, ..., 70959, 71081, 77097]])}
--------------------------------------------------------------------------------
DATALOADER:12 TEST RESULTS
{'loss': tensor(0.9966, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 92622, 92622, 92622],
       [   24,    45,   113, ..., 92334, 92377, 92481]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[12887, 13359, 26098, ..., 77397, 87996, 90519],
       [26098, 26098, 35929, ..., 72184, 77397, 87996]])}
--------------------------------------------------------------------------------
DATALOADER:13 TEST RESULTS
{'loss': tensor(0.9970, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 98363, 98363, 98363],
       [    6,    22,    64, ..., 98356, 98358, 98360]]),
 'truth': array([False, False, False, ..., False,  True, False]),
 'truth_graph': array([[ 1877,  6734, 11625, ..., 63481, 63481, 80061],
       [ 6734, 11625, 17329, ..., 44183, 44739, 63481]])}
--------------------------------------------------------------------------------
DATALOADER:14 TEST RESULTS
{'loss': tensor(0.9967, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 97780, 97780, 97780],
       [   29,    32,    56, ..., 97224, 97466, 97779]]),
 'truth': array([False, False, False, ..., False, False,  True]),
 'truth_graph': array([[ 2362,  7364, 12635, ..., 64845, 79327, 79666],
       [ 7364, 12635, 18285, ..., 48805, 64845, 64845]])}
--------------------------------------------------------------------------------
DATALOADER:15 TEST RESULTS
{'loss': tensor(0.9969, device='cuda:0'),
 'preds': array([[     0,      0,      0, ..., 104939, 104939, 104939],
       [    12,     25,     45, ..., 103863, 104365, 104836]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[ 4478, 11906, 19232, ..., 73966, 81740, 81877],
       [11906, 19232, 26431, ..., 62168, 73966, 73966]])}
--------------------------------------------------------------------------------
DATALOADER:16 TEST RESULTS
{'loss': tensor(0.9960, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 81167, 81167, 81167],
       [    2,  3372,  3484, ..., 80860, 80883, 81166]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[ 5413, 13458, 20035, ..., 68003, 77072, 79275],
       [13458, 20035, 26346, ..., 57844, 68003, 77072]])}
--------------------------------------------------------------------------------
DATALOADER:17 TEST RESULTS
{'loss': tensor(0.9960, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 79285, 79285, 79285],
       [    7,    18,    78, ..., 78386, 78419, 78432]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[14801, 31278, 31278, ..., 60533, 60533, 65524],
       [31278, 44311, 44579, ..., 53321, 53472, 60533]])}
--------------------------------------------------------------------------------
DATALOADER:18 TEST RESULTS
{'loss': tensor(0.9968, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 92649, 92649, 92649],
       [   10,    19,    21, ..., 91111, 91851, 92379]]),
 'truth': array([False, False, False, ..., False,  True, False]),
 'truth_graph': array([[ 3374,  8897, 15498, ..., 61187, 74180, 82331],
       [ 8897, 15498, 21581, ..., 42224, 61187, 74180]])}
--------------------------------------------------------------------------------
DATALOADER:19 TEST RESULTS
{'loss': tensor(0.9972, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 98230, 98230, 98230],
       [   10,   155,   899, ..., 97766, 97784, 98123]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[ 1603,  2185,  6590, ..., 55460, 55460, 55460],
       [ 6590,  6590, 11437, ..., 36708, 37211, 37507]])}
--------------------------------------------------------------------------------
DATALOADER:20 TEST RESULTS
{'loss': tensor(0.9963, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 91989, 91989, 91989],
       [    2,     3,    28, ..., 91646, 91729, 91847]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[ 2476,  7206, 12314, ..., 84904, 84870, 84904],
       [ 7206, 12314, 17715, ..., 82196, 82207, 82207]])}
--------------------------------------------------------------------------------
DATALOADER:21 TEST RESULTS
{'loss': tensor(0.9960, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 77445, 77445, 77445],
       [   15,    43,   105, ..., 75387, 77051, 77103]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[41769, 41769, 41769, ..., 72348, 74537, 74537],
       [48139, 48353, 48369, ..., 69966, 72307, 72348]])}
--------------------------------------------------------------------------------
DATALOADER:22 TEST RESULTS
{'loss': tensor(0.9966, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 89400, 89400, 89400],
       [ 1033,  1176,  1259, ..., 89119, 89176, 89399]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[ 1889,  6325, 10852, ..., 25427, 32674, 32674],
       [ 6325, 10852, 16052, ..., 18860, 25175, 25427]])}
--------------------------------------------------------------------------------
DATALOADER:23 TEST RESULTS
{'loss': tensor(0.9963, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 73517, 73517, 73517],
       [    9,    86,   106, ..., 73397, 73442, 73475]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[ 2402,  6699, 11056, ..., 65311, 69769, 71729],
       [ 6699, 11056, 16035, ..., 60856, 65311, 69769]])}
--------------------------------------------------------------------------------
DATALOADER:24 TEST RESULTS
{'loss': tensor(0.9963, device='cuda:0'),
 'preds': array([[    0,     0,     0, ..., 82079, 82079, 82079],
       [    5,    78,    81, ..., 82068, 82069, 82077]]),
 'truth': array([False, False, False, ..., False, False, False]),
 'truth_graph': array([[ 3475,  3762,  9446, ..., 74246, 77137, 79289],
       [ 9446,  9446, 15123, ..., 69400, 74246, 77137]])}
--------------------------------------------------------------------------------
Testing: 100%|██████████████████████████████████████████████████████████████████████████████████████| 25/25 [02:01<00:00,  4.86s/it]

