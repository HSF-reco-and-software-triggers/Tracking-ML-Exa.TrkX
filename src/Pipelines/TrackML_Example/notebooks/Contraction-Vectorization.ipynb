{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speeding up Edge Contraction Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_scatter import scatter_add,scatter_max,scatter_mean\n",
    "from torch_sparse import coalesce\n",
    "sys.path.append(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [X] Create toy graph\n",
    "- [X] Get timings of original algorithm\n",
    "- [X] Implement CuGraph connected components\n",
    "- [X] Get CC timings\n",
    "- [ ] Implement CC into the PyGeometric function\n",
    "- [ ] Explore a vectorized version of original idea - only one edge contracted per node\n",
    "- [ ] Explore sorting vs. random choice of edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 10000\n",
    "num_edges = 100000\n",
    "x = torch.rand((num_nodes, 3), device=device).float()\n",
    "e = torch.randint(0, len(x), (2, num_edges), device=device).long()\n",
    "edge_score = torch.cat([\n",
    "    torch.rand(int(num_edges*0.9), device=device).float()*0.4,\n",
    "    torch.rand(int(num_edges*0.1), device=device).float()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_add\n",
    "from torch_sparse import coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def __merge_edges_original__(x, edge_index, batch, edge_score):\n",
    "        \n",
    "    nodes_remaining = set(range(x.size(0)))\n",
    "\n",
    "    cluster = torch.empty_like(batch, device=x.device).long()\n",
    "    edge_argsort = torch.argsort(edge_score, descending=True)\n",
    "\n",
    "    # Iterate through all edges, selecting it if it is not incident to\n",
    "    # another already chosen edge.\n",
    "    i = 0\n",
    "    new_edge_indices = []\n",
    "   # edge_index_cpu = edge_index.cpu()\n",
    "    for edge_idx in edge_argsort.tolist():\n",
    "        source = edge_index[0, edge_idx].item()\n",
    "        if source not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        target = edge_index[1, edge_idx].item()\n",
    "        if target not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        new_edge_indices.append(edge_idx)\n",
    "\n",
    "        cluster[source] = i\n",
    "        nodes_remaining.remove(source)\n",
    "\n",
    "        if source != target:\n",
    "            cluster[target] = i\n",
    "            nodes_remaining.remove(target)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # The remaining nodes are simply kept.\n",
    "    for node_idx in nodes_remaining:\n",
    "        cluster[node_idx] = i\n",
    "        i += 1\n",
    "#     cluster = cluster.to(x.device)\n",
    "\n",
    "    # We compute the new features as an addition of the old ones.\n",
    "    new_x = scatter_add(x, cluster, dim=0, dim_size=i)\n",
    "    new_edge_score = edge_score[new_edge_indices]\n",
    "    if len(nodes_remaining) > 0:\n",
    "        remaining_score = x.new_ones(\n",
    "            (new_x.size(0) - len(new_edge_indices), ))\n",
    "        new_edge_score = torch.cat([new_edge_score, remaining_score])\n",
    "    new_x = new_x * new_edge_score.view(-1, 1)\n",
    "\n",
    "    N = new_x.size(0)\n",
    "    new_edge_index, _ = coalesce(cluster[edge_index], None, N, N)\n",
    "\n",
    "    new_batch = x.new_empty(new_x.size(0), dtype=torch.long, device=device)\n",
    "#     batch = batch.to(x.device)\n",
    "    new_batch = new_batch.scatter_(0, cluster, batch)\n",
    "\n",
    "#     unpool_info = self.unpool_description(edge_index=edge_index,\n",
    "#                                           cluster=cluster, batch=batch,\n",
    "#                                           new_edge_score=new_edge_score)\n",
    "\n",
    "#     return new_x, new_edge_index, new_batch, unpool_info\n",
    "    return new_x, new_edge_index, new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def __merge_edges__(x, edge_index, batch, edge_score):\n",
    "        \n",
    "    nodes_remaining = set(range(x.size(0)))\n",
    "\n",
    "    cluster = torch.empty_like(batch, device=x.device).long()\n",
    "    edge_argsort = torch.argsort(edge_score, descending=True)\n",
    "\n",
    "    # Iterate through all edges, selecting it if it is not incident to\n",
    "    # another already chosen edge.\n",
    "    i = 0\n",
    "    new_edge_indices = []\n",
    "   # edge_index_cpu = edge_index.cpu()\n",
    "    for edge_idx in edge_argsort.tolist():\n",
    "        source = edge_index[0, edge_idx]\n",
    "        if source not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        target = edge_index[1, edge_idx]\n",
    "        if target not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        new_edge_indices.append(edge_idx)\n",
    "\n",
    "        cluster[source] = i\n",
    "        nodes_remaining.remove(source)\n",
    "\n",
    "        if source != target:\n",
    "            cluster[target] = i\n",
    "            nodes_remaining.remove(target)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # The remaining nodes are simply kept.\n",
    "    for node_idx in nodes_remaining:\n",
    "        cluster[node_idx] = i\n",
    "        i += 1\n",
    "#     cluster = cluster.to(x.device)\n",
    "    print(len(nodes_remaining)/x.size(0))\n",
    "    # We compute the new features as an addition of the old ones.\n",
    "    new_x = scatter_add(x, cluster, dim=0, dim_size=i)\n",
    "    new_edge_score = edge_score[new_edge_indices]\n",
    "    if len(nodes_remaining) > 0:\n",
    "        remaining_score = x.new_ones(\n",
    "            (new_x.size(0) - len(new_edge_indices), ))\n",
    "        new_edge_score = torch.cat([new_edge_score, remaining_score])\n",
    "    new_x = new_x * new_edge_score.view(-1, 1)\n",
    "\n",
    "    N = new_x.size(0)\n",
    "    new_edge_index, _ = coalesce(cluster[edge_index], None, N, N)\n",
    "\n",
    "    new_batch = x.new_empty(new_x.size(0), dtype=torch.long, device=device)\n",
    "#     batch = batch.to(x.device)\n",
    "    new_batch = new_batch.scatter_(0, cluster, batch)\n",
    "\n",
    "#     unpool_info = self.unpool_description(edge_index=edge_index,\n",
    "#                                           cluster=cluster, batch=batch,\n",
    "#                                           new_edge_score=new_edge_score)\n",
    "\n",
    "#     return new_x, new_edge_index, new_batch, unpool_info\n",
    "    return new_x, new_edge_index, new_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "CPU times: user 1.15 s, sys: 49.2 ms, total: 1.2 s\n",
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_x, new_edge_index, new_batch = __merge_edges__(x, e, torch.zeros(x.shape[0], device=device).long(), edge_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### CuGraph Connected Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cugraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-94515d801298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcugraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcupy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlpack\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_dlpack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_dlpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cugraph'"
     ]
    }
   ],
   "source": [
    "import cugraph\n",
    "import cudf\n",
    "import pandas as pd\n",
    "import cupy as cp\n",
    "from torch.utils.dlpack import from_dlpack, to_dlpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "passing_edges = e[:, edge_score > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "passing_edges = cudf.from_dlpack(to_dlpack(passing_edges.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "G = cugraph.Graph()\n",
    "G.from_cudf_edgelist(passing_edges, source=0, destination=1, edge_attr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "labels = cugraph.components.connectivity.weakly_connected_components(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This all seems to work fine, so let's build it into a new method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def __merge_edges__(x, edge_index, batch, edge_score):\n",
    "        \n",
    "    nodes_remaining = set(range(x.size(0)))\n",
    "\n",
    "    cluster = torch.empty_like(batch, device=x.device).long()\n",
    "    edge_argsort = torch.argsort(edge_score, descending=True)\n",
    "\n",
    "    # Iterate through all edges, selecting it if it is not incident to\n",
    "    # another already chosen edge.\n",
    "    i = 0\n",
    "    new_edge_indices = []\n",
    "   # edge_index_cpu = edge_index.cpu()\n",
    "    for edge_idx in edge_argsort.tolist():\n",
    "        source = edge_index[0, edge_idx]\n",
    "        if source not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        target = edge_index[1, edge_idx]\n",
    "        if target not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        new_edge_indices.append(edge_idx)\n",
    "\n",
    "        cluster[source] = i\n",
    "        nodes_remaining.remove(source)\n",
    "\n",
    "        if source != target:\n",
    "            cluster[target] = i\n",
    "            nodes_remaining.remove(target)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # The remaining nodes are simply kept.\n",
    "    for node_idx in nodes_remaining:\n",
    "        cluster[node_idx] = i\n",
    "        i += 1\n",
    "#     cluster = cluster.to(x.device)\n",
    "\n",
    "    # We compute the new features as an addition of the old ones.\n",
    "    new_x = scatter_add(x, cluster, dim=0, dim_size=i)\n",
    "    new_edge_score = edge_score[new_edge_indices]\n",
    "    if len(nodes_remaining) > 0:\n",
    "        remaining_score = x.new_ones(\n",
    "            (new_x.size(0) - len(new_edge_indices), ))\n",
    "        new_edge_score = torch.cat([new_edge_score, remaining_score])\n",
    "    new_x = new_x * new_edge_score.view(-1, 1)\n",
    "\n",
    "    N = new_x.size(0)\n",
    "    new_edge_index, _ = coalesce(cluster[edge_index], None, N, N)\n",
    "\n",
    "    new_batch = x.new_empty(new_x.size(0), dtype=torch.long, device=device)\n",
    "#     batch = batch.to(x.device)\n",
    "    new_batch = new_batch.scatter_(0, cluster, batch)\n",
    "\n",
    "#     unpool_info = self.unpool_description(edge_index=edge_index,\n",
    "#                                           cluster=cluster, batch=batch,\n",
    "#                                           new_edge_score=new_edge_score)\n",
    "\n",
    "#     return new_x, new_edge_index, new_batch, unpool_info\n",
    "    return new_x, new_edge_index, new_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Roommates Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 63.2 ms, sys: 7.57 ms, total: 70.7 ms\n",
      "Wall time: 71.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_score_0, max_indices_0 = scatter_max(edge_score, e[0], dim=0, dim_size=x.shape[0])\n",
    "max_score_1, max_indices_1 = scatter_max(edge_score, e[1], dim=0, dim_size=x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_score, stacked_indices = torch.stack([max_score_0, max_score_1]), torch.stack([max_indices_0, max_indices_1]).T\n",
    "top_score = torch.argmax(stacked_score, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_indices = torch.zeros(len(top_score), dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_indices[max_score_0 > max_score_1] = max_indices_0[max_score_0 > max_score_1]\n",
    "max_indices[max_score_1 > max_score_0] = max_indices_1[max_score_1 > max_score_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([919493, 990488, 718536,  ..., 208696,  13784, 941206], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get timing for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.3 ms, sys: 28.7 ms, total: 82 ms\n",
      "Wall time: 81.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_score_0, max_indices_0 = scatter_max(edge_score, e[0], dim=0, dim_size=x.shape[0])\n",
    "max_score_1, max_indices_1 = scatter_max(edge_score, e[1], dim=0, dim_size=x.shape[0])\n",
    "\n",
    "stacked_score, stacked_indices = torch.stack([max_score_0, max_score_1]), torch.stack([max_indices_0, max_indices_1]).T\n",
    "top_score = torch.argmax(stacked_score, dim=0)\n",
    "\n",
    "max_indices = torch.zeros(len(top_score), dtype=torch.long, device=device)\n",
    "\n",
    "max_indices[max_score_0 > max_score_1] = max_indices_0[max_score_0 > max_score_1]\n",
    "max_indices[max_score_1 > max_score_0] = max_indices_1[max_score_1 > max_score_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "nodes = torch.arange(1,x.shape[0]+1,device = \"cuda:0\")\n",
    "max_indices_copy = max_indices[:]\n",
    "max_indices_pairs = torch.index_select(max_indices,0,max_indices_copy-1)\n",
    "print(nodes.shape,max_indices_pairs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f021ea1e09ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_indices_matches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_indices_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "max_indices_matches = torch.eq(max_indices_pairs,nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_remaining = torch.ones(x.shape[0])\n",
    "edges_shifted = 1 + e\n",
    "nodes = torch.arange(1,x.shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(100000)\n",
      "tensor(100000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(nodes.max())\n",
    "print(edges_shifted.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 ms, sys: 0 ns, total: 3 ms\n",
      "Wall time: 2.36 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_, counts_0 = torch.unique(e[0],return_counts=True)\n",
    "_, counts_1 = torch.unique(e[1],return_counts=True)\n",
    "max_neighbors = max(counts_0.max(),counts_1.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 10\n",
    "num_edges = 100\n",
    "x_small = torch.rand((num_nodes, 3), device=device).float()\n",
    "e_small = torch.randint(0, len(x_small), (2, num_edges), device=device).long()\n",
    "edge_score_small = torch.cat([\n",
    "    torch.rand(int(num_edges*0.9), device=device).float()*0.4,\n",
    "    torch.rand(int(num_edges*0.1), device=device).float()\n",
    "])\n",
    "_, counts_0 = torch.unique(e_small[0],return_counts=True)\n",
    "_, counts_1 = torch.unique(e_small[1],return_counts=True)\n",
    "max_neighbors = max(counts_0.max(),counts_1.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "preferences = torch.zeros((x_small.shape[0],max_neighbors,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 15, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preferences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 3, 4, 5, 0, 2, 7, 6, 0, 9, 1, 4, 0, 7, 6, 9, 1, 6, 3, 3, 5, 8, 7, 6,\n",
       "        8, 7, 7, 6, 8, 2, 2, 3, 4, 6, 0, 4, 4, 1, 2, 6, 8, 0, 3, 3, 1, 4, 4, 8,\n",
       "        8, 2, 2, 1, 8, 7, 9, 7, 9, 4, 0, 8, 0, 6, 8, 5, 2, 1, 2, 4, 3, 2, 7, 2,\n",
       "        3, 9, 5, 3, 7, 4, 1, 8, 8, 7, 1, 9, 8, 1, 7, 4, 7, 1, 3, 5, 6, 2, 0, 8,\n",
       "        8, 2, 5, 9], device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preferences[:,:,0] = torch.gather(e_small[1],) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 3, 4, 5, 0, 2, 7, 6, 0, 9, 1, 4, 0, 7, 6, 9, 1, 6, 3, 3, 5, 8, 7, 6,\n",
       "         8, 7, 7, 6, 8, 2, 2, 3, 4, 6, 0, 4, 4, 1, 2, 6, 8, 0, 3, 3, 1, 4, 4, 8,\n",
       "         8, 2, 2, 1, 8, 7, 9, 7, 9, 4, 0, 8, 0, 6, 8, 5, 2, 1, 2, 4, 3, 2, 7, 2,\n",
       "         3, 9, 5, 3, 7, 4, 1, 8, 8, 7, 1, 9, 8, 1, 7, 4, 7, 1, 3, 5, 6, 2, 0, 8,\n",
       "         8, 2, 5, 9],\n",
       "        [1, 7, 9, 8, 1, 8, 6, 3, 8, 4, 9, 7, 1, 8, 1, 0, 7, 6, 6, 3, 3, 8, 2, 2,\n",
       "         8, 6, 5, 9, 6, 9, 0, 2, 9, 4, 4, 6, 4, 6, 7, 9, 2, 1, 2, 1, 8, 3, 6, 4,\n",
       "         3, 7, 7, 7, 2, 7, 7, 6, 8, 7, 0, 6, 2, 5, 3, 4, 5, 3, 2, 4, 0, 7, 1, 3,\n",
       "         9, 6, 3, 4, 7, 2, 1, 2, 7, 0, 0, 1, 5, 8, 9, 4, 7, 3, 5, 1, 3, 7, 9, 9,\n",
       "         5, 9, 4, 6]], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1, 0, 1], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "e_small = torch.tensor(\n",
    "    [[1,4,3,2,5,2,4],\n",
    "     [4,3,2,5,3,1,2]])\n",
    "scores_small = torch.tensor([1.0,0.0,0.4,0.8,])\n",
    "m = torch.tensor([4,4,5,1,4],device='cpu')\n",
    "r = ~( m[m-1] == torch.arange(1,6))\n",
    "print(r.type(torch.ByteTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "n = torch.ones_like(m)\n",
    "n = n.type(torch.ByteTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import networkx as nx\n",
    "device = \"cpu\"\n",
    "\n",
    "num_nodes = 10000\n",
    "num_edges = 100000\n",
    "G = nx.gnm_random_graph(num_nodes, num_edges, seed=None, directed=False)\n",
    "edge_index = torch.tensor(np.array(G.edges)).T.long()\n",
    "edge_index = edge_index.to(device)\n",
    "x = torch.rand((num_nodes,1),device=device).float()\n",
    "edge_score = torch.cat([\n",
    "    torch.rand(int(num_edges*0.9), device=device).float(),\n",
    "    torch.rand(int(num_edges*0.1), device=device).float()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333432674408\n",
      "0.1111111119389534\n",
      "0.1111111119389534\n",
      "0.1111111119389534\n",
      "0.1111111119389534\n",
      "0.1111111119389534\n",
      "0.1111111119389534\n",
      "0.1111111119389534\n",
      "0.1111111119389534\n",
      "0.1111111119389534\n",
      "0\n",
      "CPU times: user 56.3 ms, sys: 0 ns, total: 56.3 ms\n",
      "Wall time: 53.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "x = torch.rand((9,1),device=device).float()\n",
    "edge_index = torch.tensor([\n",
    "    [0,0,0,0,0,0,0,1,1,2,3,3,4,5,6],\n",
    "    [1,1,3,3,7,5,8,6,8,6,4,8,5,8,7]],device=device)\n",
    "edge_score = torch.tensor([0.3,0.3,0.7,0.7,0.8,0.9,0.2,0.3,1.0,1.0,0.5,0.9,1.0,0.3,0.9],device=device)\n",
    "\n",
    "#used for comparing against max_indices\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "nodes = torch.arange(x.shape[0])\n",
    "nodes = nodes.to(device)\n",
    "\n",
    "nodes_remaining = torch.ones_like(nodes,dtype = torch.bool)\n",
    "nodes_remaining = nodes_remaining.to(device)\n",
    "edges_remaining = torch.ones_like(edge_index[0],dtype=torch.bool)\n",
    "edges_remaining = edges_remaining.to(device)\n",
    "ratio = 1.0\n",
    "i = 0\n",
    "updated_edge_weights = torch.ones_like(edge_score)\n",
    "updated_edge_weights.copy_(edge_score)\n",
    "\n",
    "while i < 10 and ratio > 0.05:   \n",
    "    #get max edge score for each node and edge index where it occurs\n",
    "    max_score_0, max_indices_0 = scatter_max(updated_edge_weights, edge_index[0], dim=0, dim_size=x.shape[0])\n",
    "    max_score_1, max_indices_1 = scatter_max(updated_edge_weights, edge_index[1], dim=0, dim_size=x.shape[0])\n",
    "\n",
    "    #stack scores for each direction\n",
    "    stacked_score, stacked_indices = torch.stack([max_score_0, max_score_1]), torch.stack([max_indices_0, max_indices_1]).T\n",
    "    top_score , _ = torch.max(stacked_score, dim=0)\n",
    "    top_score = top_score.to(device)\n",
    "    \n",
    "\n",
    "    #get max neighbor for each node\n",
    "    max_indices = torch.zeros(len(top_score), dtype=torch.long, device=device)\n",
    "    max_indices[max_score_0 > max_score_1] = edge_index[1][max_indices_0[max_score_0 > max_score_1]]\n",
    "    max_indices[max_score_1 > max_score_0] = edge_index[0][max_indices_1[max_score_1 > max_score_0]]\n",
    "\n",
    "    #find edges where each node is the other's max index\n",
    "    edge_index_match_0 = max_indices[edge_index[1]] == edge_index[0]\n",
    "    edge_index_match_1 = max_indices[edge_index[0]] == edge_index[1]\n",
    "    node_0_valid = nodes_remaining[edge_index[0]]\n",
    "    node_1_valid = nodes_remaining[edge_index[1]]\n",
    "    edge_index_match = edge_index_match_0 & edge_index_match_1 & node_0_valid & node_1_valid;\n",
    "    edge_index_match &= edge_score > 0.3\n",
    "\n",
    "    #update the remaining edges based on which ones should be removed\n",
    "    edges_remaining &= ~edge_index_match\n",
    "    edges_contracted = edge_index[:,edge_index_match]\n",
    "\n",
    "    #update the remaining nodes based on which ones should be removed\n",
    "    nodes_removed = torch.flatten(edges_contracted)\n",
    "    nodes_remaining[nodes_removed] = 0.0\n",
    "\n",
    "    #zero out the edge scores of every edge that has >= 1 node being removed\n",
    "    edge_score_zero_mask = (edge_index[..., None] == nodes[nodes_removed]).any(-1).any(0)\n",
    "    updated_edge_weights *= ~edge_score_zero_mask\n",
    "    ratio = (torch.sum(nodes_remaining)/nodes_remaining.shape[0]).item()\n",
    "    print(ratio)\n",
    "    i += 1\n",
    "\n",
    "#split into edges removed and edges not removed\n",
    "edges_contracted = edge_index[:,~edges_remaining]\n",
    "new_e = edge_index[:,edges_remaining]\n",
    "\n",
    "#sort nodes into new ordering by cluster\n",
    "clustered_indices = torch.arange(edges_contracted.shape[1]).to(device)\n",
    "remaining_indices = edges_contracted.shape[1] + torch.arange(torch.sum(nodes_remaining)).to(device)\n",
    "new_node_index_map = torch.cat([\n",
    "    torch.stack([edges_contracted[0],clustered_indices]),\n",
    "    torch.stack([edges_contracted[1],clustered_indices]),\n",
    "    torch.stack([nodes[nodes_remaining],remaining_indices])],dim=-1)\n",
    "new_node_index_map = new_node_index_map[:,torch.argsort(new_node_index_map[0])]\n",
    "cluster = new_node_index_map[1,:]\n",
    "\n",
    "\n",
    "#count the number of occurences of each node to find duplicates\n",
    "_, counts = torch.unique(new_node_index_map[0], return_counts=True)\n",
    "duplicates = torch.where(counts >= 2)\n",
    "cluster_mask = torch.ones_like(cluster,dtype=torch.bool)\n",
    "\n",
    "print(duplicates[0].size(0))\n",
    "#if it finds a duplicate node, remove it from the cluster map\n",
    "if duplicates[0].size(0) > 0:\n",
    "    d = duplicates[0]\n",
    "    for i in d:\n",
    "        #find the multiple cluster indices in the node index map and get the minimum index to keep\n",
    "        duplicate_mask = (i == new_node_index_map[0])\n",
    "        duplicate_cluster_indices = cluster[duplicate_mask]\n",
    "        valid_cluster_index = torch.min(duplicate_cluster_indices)\n",
    "\n",
    "        #mask all cluster indices that need removing\n",
    "        cluster_remove_mask = ~(duplicate_mask & (cluster != valid_cluster_index))\n",
    "        cluster_mask &= cluster_remove_mask\n",
    "\n",
    "    #get all unique clusters that are being removed, and decrease all clusters greater than that index by 1 to account for each cluster removal\n",
    "    clusters_to_remove = torch.unique(cluster[~cluster_mask])\n",
    "    cluster = cluster[cluster_mask]\n",
    "    for c in clusters_to_remove:\n",
    "        cluster[cluster > c] -= 1\n",
    "\n",
    "#create new node features and edge index based on clustering\n",
    "new_x = scatter_add(x, cluster, dim=0, dim_size=torch.unique(cluster).shape[0])\n",
    "N = new_x.size(0)\n",
    "new_e = cluster[new_e]\n",
    "\n",
    "#reorder new edge index so smaller node index value is always on top\n",
    "new_e_0 = torch.min(new_e,dim=0).values\n",
    "new_e_1 = torch.max(new_e,dim=0).values\n",
    "new_e = torch.stack([new_e_0,new_e_1])\n",
    "\n",
    "#hash edge index for creating new edge scores\n",
    "base = torch.max(new_e)\n",
    "edge_index_hash = new_e[0] * base + new_e[1]\n",
    "\n",
    "#create new edge scores by averaging duplicate edges\n",
    "new_edge_score = edge_score[edges_remaining]\n",
    "new_edge_score = scatter_mean(new_edge_score,edge_index_hash)\n",
    "\n",
    "#remove duplicates and map new edge scores to averaged scores\n",
    "new_edge_index = torch.unique(new_e,dim=1)\n",
    "new_e_hash = new_edge_index[0] * base + new_edge_index[1]\n",
    "new_edge_score = new_edge_score[new_e_hash]\n",
    "\n",
    "#create node weights for keeping node features numerically stable\n",
    "contracted_weights = edge_score[~edges_remaining]\n",
    "remaining_weights = torch.ones(N - edges_contracted.size(1),device=device)\n",
    "new_node_weights = torch.cat([contracted_weights,remaining_weights])\n",
    "new_x = new_x * new_node_weights.view(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 1, 3, 3, 5, 6],\n",
      "        [1, 3, 5, 6, 4, 8, 8, 7]], device='cuda:0')\n",
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
      "        [0, 1, 2, 4, 3, 3, 2, 0, 1]], device='cuda:0')\n",
      "tensor([0, 1, 2, 4, 3, 3, 2, 0, 1], device='cuda:0')\n",
      "tensor([[0, 0, 0, 1, 2, 3, 4, 4],\n",
      "        [1, 3, 4, 2, 0, 1, 1, 3]], device='cuda:0')\n",
      "CPU times: user 5.76 ms, sys: 739 µs, total: 6.5 ms\n",
      "Wall time: 5.52 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([185921, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exatrkx-tracking",
   "language": "python",
   "name": "exatrkx-tracking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
