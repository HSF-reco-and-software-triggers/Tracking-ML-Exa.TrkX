{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speeding up Edge Contraction Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [X] Create toy graph\n",
    "- [X] Get timings of original algorithm\n",
    "- [X] Implement CuGraph connected components\n",
    "- [X] Get CC timings\n",
    "- [ ] Implement CC into the PyGeometric function\n",
    "- [ ] Explore a vectorized version of original idea - only one edge contracted per node\n",
    "- [ ] Explore sorting vs. random choice of edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 10000\n",
    "num_edges = 100000\n",
    "x = torch.rand((num_nodes, 3), device=device).float()\n",
    "e = torch.randint(0, len(x), (2, num_edges), device=device).long()\n",
    "edge_score = torch.cat([\n",
    "    torch.rand(int(num_edges*0.9), device=device).float()*0.4,\n",
    "    torch.rand(int(num_edges*0.1), device=device).float()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_add\n",
    "from torch_sparse import coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def __merge_edges_original__(x, edge_index, batch, edge_score):\n",
    "        \n",
    "    nodes_remaining = set(range(x.size(0)))\n",
    "\n",
    "    cluster = torch.empty_like(batch, device=x.device).long()\n",
    "    edge_argsort = torch.argsort(edge_score, descending=True)\n",
    "\n",
    "    # Iterate through all edges, selecting it if it is not incident to\n",
    "    # another already chosen edge.\n",
    "    i = 0\n",
    "    new_edge_indices = []\n",
    "   # edge_index_cpu = edge_index.cpu()\n",
    "    for edge_idx in edge_argsort.tolist():\n",
    "        source = edge_index[0, edge_idx].item()\n",
    "        if source not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        target = edge_index[1, edge_idx].item()\n",
    "        if target not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        new_edge_indices.append(edge_idx)\n",
    "\n",
    "        cluster[source] = i\n",
    "        nodes_remaining.remove(source)\n",
    "\n",
    "        if source != target:\n",
    "            cluster[target] = i\n",
    "            nodes_remaining.remove(target)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # The remaining nodes are simply kept.\n",
    "    for node_idx in nodes_remaining:\n",
    "        cluster[node_idx] = i\n",
    "        i += 1\n",
    "#     cluster = cluster.to(x.device)\n",
    "\n",
    "    # We compute the new features as an addition of the old ones.\n",
    "    new_x = scatter_add(x, cluster, dim=0, dim_size=i)\n",
    "    new_edge_score = edge_score[new_edge_indices]\n",
    "    if len(nodes_remaining) > 0:\n",
    "        remaining_score = x.new_ones(\n",
    "            (new_x.size(0) - len(new_edge_indices), ))\n",
    "        new_edge_score = torch.cat([new_edge_score, remaining_score])\n",
    "    new_x = new_x * new_edge_score.view(-1, 1)\n",
    "\n",
    "    N = new_x.size(0)\n",
    "    new_edge_index, _ = coalesce(cluster[edge_index], None, N, N)\n",
    "\n",
    "    new_batch = x.new_empty(new_x.size(0), dtype=torch.long, device=device)\n",
    "#     batch = batch.to(x.device)\n",
    "    new_batch = new_batch.scatter_(0, cluster, batch)\n",
    "\n",
    "#     unpool_info = self.unpool_description(edge_index=edge_index,\n",
    "#                                           cluster=cluster, batch=batch,\n",
    "#                                           new_edge_score=new_edge_score)\n",
    "\n",
    "#     return new_x, new_edge_index, new_batch, unpool_info\n",
    "    return new_x, new_edge_index, new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def __merge_edges__(x, edge_index, batch, edge_score):\n",
    "        \n",
    "    nodes_remaining = set(range(x.size(0)))\n",
    "\n",
    "    cluster = torch.empty_like(batch, device=x.device).long()\n",
    "    edge_argsort = torch.argsort(edge_score, descending=True)\n",
    "\n",
    "    # Iterate through all edges, selecting it if it is not incident to\n",
    "    # another already chosen edge.\n",
    "    i = 0\n",
    "    new_edge_indices = []\n",
    "   # edge_index_cpu = edge_index.cpu()\n",
    "    for edge_idx in edge_argsort.tolist():\n",
    "        source = edge_index[0, edge_idx]\n",
    "        if source not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        target = edge_index[1, edge_idx]\n",
    "        if target not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        new_edge_indices.append(edge_idx)\n",
    "\n",
    "        cluster[source] = i\n",
    "        nodes_remaining.remove(source)\n",
    "\n",
    "        if source != target:\n",
    "            cluster[target] = i\n",
    "            nodes_remaining.remove(target)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # The remaining nodes are simply kept.\n",
    "    for node_idx in nodes_remaining:\n",
    "        cluster[node_idx] = i\n",
    "        i += 1\n",
    "#     cluster = cluster.to(x.device)\n",
    "\n",
    "    # We compute the new features as an addition of the old ones.\n",
    "    new_x = scatter_add(x, cluster, dim=0, dim_size=i)\n",
    "    new_edge_score = edge_score[new_edge_indices]\n",
    "    if len(nodes_remaining) > 0:\n",
    "        remaining_score = x.new_ones(\n",
    "            (new_x.size(0) - len(new_edge_indices), ))\n",
    "        new_edge_score = torch.cat([new_edge_score, remaining_score])\n",
    "    new_x = new_x * new_edge_score.view(-1, 1)\n",
    "\n",
    "    N = new_x.size(0)\n",
    "    new_edge_index, _ = coalesce(cluster[edge_index], None, N, N)\n",
    "\n",
    "    new_batch = x.new_empty(new_x.size(0), dtype=torch.long, device=device)\n",
    "#     batch = batch.to(x.device)\n",
    "    new_batch = new_batch.scatter_(0, cluster, batch)\n",
    "\n",
    "#     unpool_info = self.unpool_description(edge_index=edge_index,\n",
    "#                                           cluster=cluster, batch=batch,\n",
    "#                                           new_edge_score=new_edge_score)\n",
    "\n",
    "#     return new_x, new_edge_index, new_batch, unpool_info\n",
    "    return new_x, new_edge_index, new_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 269 ms, total: 11.5 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_x, new_edge_index, new_batch = __merge_edges__(x, e, torch.zeros(x.shape[0], device=device).long(), edge_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### CuGraph Connected Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cugraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-94515d801298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcugraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcupy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlpack\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_dlpack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_dlpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cugraph'"
     ]
    }
   ],
   "source": [
    "import cugraph\n",
    "import cudf\n",
    "import pandas as pd\n",
    "import cupy as cp\n",
    "from torch.utils.dlpack import from_dlpack, to_dlpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "passing_edges = e[:, edge_score > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "passing_edges = cudf.from_dlpack(to_dlpack(passing_edges.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "G = cugraph.Graph()\n",
    "G.from_cudf_edgelist(passing_edges, source=0, destination=1, edge_attr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "labels = cugraph.components.connectivity.weakly_connected_components(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This all seems to work fine, so let's build it into a new method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def __merge_edges__(x, edge_index, batch, edge_score):\n",
    "        \n",
    "    nodes_remaining = set(range(x.size(0)))\n",
    "\n",
    "    cluster = torch.empty_like(batch, device=x.device).long()\n",
    "    edge_argsort = torch.argsort(edge_score, descending=True)\n",
    "\n",
    "    # Iterate through all edges, selecting it if it is not incident to\n",
    "    # another already chosen edge.\n",
    "    i = 0\n",
    "    new_edge_indices = []\n",
    "   # edge_index_cpu = edge_index.cpu()\n",
    "    for edge_idx in edge_argsort.tolist():\n",
    "        source = edge_index[0, edge_idx]\n",
    "        if source not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        target = edge_index[1, edge_idx]\n",
    "        if target not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        new_edge_indices.append(edge_idx)\n",
    "\n",
    "        cluster[source] = i\n",
    "        nodes_remaining.remove(source)\n",
    "\n",
    "        if source != target:\n",
    "            cluster[target] = i\n",
    "            nodes_remaining.remove(target)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # The remaining nodes are simply kept.\n",
    "    for node_idx in nodes_remaining:\n",
    "        cluster[node_idx] = i\n",
    "        i += 1\n",
    "#     cluster = cluster.to(x.device)\n",
    "\n",
    "    # We compute the new features as an addition of the old ones.\n",
    "    new_x = scatter_add(x, cluster, dim=0, dim_size=i)\n",
    "    new_edge_score = edge_score[new_edge_indices]\n",
    "    if len(nodes_remaining) > 0:\n",
    "        remaining_score = x.new_ones(\n",
    "            (new_x.size(0) - len(new_edge_indices), ))\n",
    "        new_edge_score = torch.cat([new_edge_score, remaining_score])\n",
    "    new_x = new_x * new_edge_score.view(-1, 1)\n",
    "\n",
    "    N = new_x.size(0)\n",
    "    new_edge_index, _ = coalesce(cluster[edge_index], None, N, N)\n",
    "\n",
    "    new_batch = x.new_empty(new_x.size(0), dtype=torch.long, device=device)\n",
    "#     batch = batch.to(x.device)\n",
    "    new_batch = new_batch.scatter_(0, cluster, batch)\n",
    "\n",
    "#     unpool_info = self.unpool_description(edge_index=edge_index,\n",
    "#                                           cluster=cluster, batch=batch,\n",
    "#                                           new_edge_score=new_edge_score)\n",
    "\n",
    "#     return new_x, new_edge_index, new_batch, unpool_info\n",
    "    return new_x, new_edge_index, new_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Roommates Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 63.2 ms, sys: 7.57 ms, total: 70.7 ms\n",
      "Wall time: 71.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_score_0, max_indices_0 = scatter_max(edge_score, e[0], dim=0, dim_size=x.shape[0])\n",
    "max_score_1, max_indices_1 = scatter_max(edge_score, e[1], dim=0, dim_size=x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_score, stacked_indices = torch.stack([max_score_0, max_score_1]), torch.stack([max_indices_0, max_indices_1]).T\n",
    "top_score = torch.argmax(stacked_score, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_indices = torch.zeros(len(top_score), dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_indices[max_score_0 > max_score_1] = max_indices_0[max_score_0 > max_score_1]\n",
    "max_indices[max_score_1 > max_score_0] = max_indices_1[max_score_1 > max_score_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([919493, 990488, 718536,  ..., 208696,  13784, 941206], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get timing for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.3 ms, sys: 28.7 ms, total: 82 ms\n",
      "Wall time: 81.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_score_0, max_indices_0 = scatter_max(edge_score, e[0], dim=0, dim_size=x.shape[0])\n",
    "max_score_1, max_indices_1 = scatter_max(edge_score, e[1], dim=0, dim_size=x.shape[0])\n",
    "\n",
    "stacked_score, stacked_indices = torch.stack([max_score_0, max_score_1]), torch.stack([max_indices_0, max_indices_1]).T\n",
    "top_score = torch.argmax(stacked_score, dim=0)\n",
    "\n",
    "max_indices = torch.zeros(len(top_score), dtype=torch.long, device=device)\n",
    "\n",
    "max_indices[max_score_0 > max_score_1] = max_indices_0[max_score_0 > max_score_1]\n",
    "max_indices[max_score_1 > max_score_0] = max_indices_1[max_score_1 > max_score_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "nodes = torch.arange(1,x.shape[0]+1,device = \"cuda:0\")\n",
    "max_indices_copy = max_indices[:]\n",
    "max_indices_pairs = torch.index_select(max_indices,0,max_indices_copy-1)\n",
    "print(nodes.shape,max_indices_pairs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f021ea1e09ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_indices_matches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_indices_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "max_indices_matches = torch.eq(max_indices_pairs,nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_remaining = torch.ones(x.shape[0])\n",
    "edges_shifted = 1 + e\n",
    "nodes = torch.arange(1,x.shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(100000)\n",
      "tensor(100000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(nodes.max())\n",
    "print(edges_shifted.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 ms, sys: 0 ns, total: 3 ms\n",
      "Wall time: 2.36 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_, counts_0 = torch.unique(e[0],return_counts=True)\n",
    "_, counts_1 = torch.unique(e[1],return_counts=True)\n",
    "max_neighbors = max(counts_0.max(),counts_1.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 10\n",
    "num_edges = 100\n",
    "x_small = torch.rand((num_nodes, 3), device=device).float()\n",
    "e_small = torch.randint(0, len(x_small), (2, num_edges), device=device).long()\n",
    "edge_score_small = torch.cat([\n",
    "    torch.rand(int(num_edges*0.9), device=device).float()*0.4,\n",
    "    torch.rand(int(num_edges*0.1), device=device).float()\n",
    "])\n",
    "_, counts_0 = torch.unique(e_small[0],return_counts=True)\n",
    "_, counts_1 = torch.unique(e_small[1],return_counts=True)\n",
    "max_neighbors = max(counts_0.max(),counts_1.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "preferences = torch.zeros((x_small.shape[0],max_neighbors,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 15, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preferences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 3, 4, 5, 0, 2, 7, 6, 0, 9, 1, 4, 0, 7, 6, 9, 1, 6, 3, 3, 5, 8, 7, 6,\n",
       "        8, 7, 7, 6, 8, 2, 2, 3, 4, 6, 0, 4, 4, 1, 2, 6, 8, 0, 3, 3, 1, 4, 4, 8,\n",
       "        8, 2, 2, 1, 8, 7, 9, 7, 9, 4, 0, 8, 0, 6, 8, 5, 2, 1, 2, 4, 3, 2, 7, 2,\n",
       "        3, 9, 5, 3, 7, 4, 1, 8, 8, 7, 1, 9, 8, 1, 7, 4, 7, 1, 3, 5, 6, 2, 0, 8,\n",
       "        8, 2, 5, 9], device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preferences[:,:,0] = torch.gather(e_small[1],) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 3, 4, 5, 0, 2, 7, 6, 0, 9, 1, 4, 0, 7, 6, 9, 1, 6, 3, 3, 5, 8, 7, 6,\n",
       "         8, 7, 7, 6, 8, 2, 2, 3, 4, 6, 0, 4, 4, 1, 2, 6, 8, 0, 3, 3, 1, 4, 4, 8,\n",
       "         8, 2, 2, 1, 8, 7, 9, 7, 9, 4, 0, 8, 0, 6, 8, 5, 2, 1, 2, 4, 3, 2, 7, 2,\n",
       "         3, 9, 5, 3, 7, 4, 1, 8, 8, 7, 1, 9, 8, 1, 7, 4, 7, 1, 3, 5, 6, 2, 0, 8,\n",
       "         8, 2, 5, 9],\n",
       "        [1, 7, 9, 8, 1, 8, 6, 3, 8, 4, 9, 7, 1, 8, 1, 0, 7, 6, 6, 3, 3, 8, 2, 2,\n",
       "         8, 6, 5, 9, 6, 9, 0, 2, 9, 4, 4, 6, 4, 6, 7, 9, 2, 1, 2, 1, 8, 3, 6, 4,\n",
       "         3, 7, 7, 7, 2, 7, 7, 6, 8, 7, 0, 6, 2, 5, 3, 4, 5, 3, 2, 4, 0, 7, 1, 3,\n",
       "         9, 6, 3, 4, 7, 2, 1, 2, 7, 0, 0, 1, 5, 8, 9, 4, 7, 3, 5, 1, 3, 7, 9, 9,\n",
       "         5, 9, 4, 6]], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1, 0, 1], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "e_small = torch.tensor(\n",
    "    [[1,4,3,2,5,2,4],\n",
    "     [4,3,2,5,3,1,2]])\n",
    "scores_small = torch.tensor([1.0,0.0,0.4,0.8,])\n",
    "m = torch.tensor([4,4,5,1,4],device='cpu')\n",
    "r = ~( m[m-1] == torch.arange(1,6))\n",
    "print(r.type(torch.ByteTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "n = torch.ones_like(m)\n",
    "n = n.type(torch.ByteTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_max\n",
    "device = \"cuda:0\"\n",
    "\n",
    "\n",
    "num_nodes = 10000\n",
    "num_edges = 200000\n",
    "x = torch.rand((num_nodes, 3), device=device).float()\n",
    "e = torch.randint(0, len(x), (2, num_edges), device=device).long()\n",
    "\n",
    "edge_score = torch.cat([\n",
    "    torch.rand(int(num_edges*0.9), device=device).float(),\n",
    "    torch.rand(int(num_edges*0.1), device=device).float()\n",
    "])\n",
    "edge_score = edge_score[e[0] != e[1]]\n",
    "e = e[:,e[0] != e[1]]\n",
    "\n",
    "#x = torch.rand((6,1),device=device).float()\n",
    "#e = torch.tensor([\n",
    "#    [0,1,2,3,4],\n",
    "#    [1,2,3,4,5]],device=device)\n",
    "#edge_score = torch.tensor([1.0,0.9,0.8,0.9,1.0],device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52130\n",
      "0.4966000020503998\n",
      "63460\n",
      "0.26319998502731323\n",
      "66344\n",
      "0.14739999175071716\n",
      "67125\n",
      "0.09039999544620514\n",
      "67423\n",
      "0.05639999732375145\n",
      "67571\n",
      "0.03539999946951866\n",
      "CPU times: user 86.4 ms, sys: 19.6 ms, total: 106 ms\n",
      "Wall time: 104 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#used for comparing against max_indices\n",
    "nodes = torch.arange(x.shape[0])\n",
    "nodes = nodes.to(device)\n",
    "\n",
    "nodes_remaining = torch.ones_like(nodes,dtype = torch.bool)\n",
    "ratio = 1.0\n",
    "edges_contracted = torch.empty(2,0,device=device)\n",
    "i = 0\n",
    "\n",
    "while i < 10 and ratio > 0.05:    \n",
    "    max_score_0, max_indices_0 = scatter_max(edge_score, e[0], dim=0, dim_size=x.shape[0])\n",
    "    max_score_1, max_indices_1 = scatter_max(edge_score, e[1], dim=0, dim_size=x.shape[0])\n",
    "\n",
    "    stacked_score, stacked_indices = torch.stack([max_score_0, max_score_1]), torch.stack([max_indices_0, max_indices_1]).T\n",
    "    top_score , _ = torch.max(stacked_score, dim=0)\n",
    "    top_score = top_score.to(device)\n",
    "    \n",
    "    max_indices = torch.zeros(len(top_score), dtype=torch.long, device=device)\n",
    "    max_indices[max_score_0 > max_score_1] = e[1][max_indices_0[max_score_0 > max_score_1]]\n",
    "    max_indices[max_score_1 > max_score_0] = e[0][max_indices_1[max_score_1 > max_score_0]]\n",
    "    \n",
    "    #gets the max neighbor of the max neighbor of each node\n",
    "    #if this equals the node itself, the nodes are both each other's max neighbors\n",
    "    max_indices_pairs = max_indices[max_indices]\n",
    "    max_indices_matches = (max_indices_pairs == nodes)\n",
    "    \n",
    "    #don't check any nodes who have already been contrated\n",
    "    indices_remaining = top_score > 0.0\n",
    "    max_indices_matches *= indices_remaining\n",
    "    \n",
    "    #update how many nodes are remaining\n",
    "    nodes_remaining = ~max_indices_matches * nodes_remaining\n",
    "    \n",
    "    #find all edges with >= 1 node in the nodes being contracted. This is used to zero out the edge scores\n",
    "    edge_score_zero_mask = (e[..., None] == nodes[max_indices_matches]).any(-1).any(0)\n",
    "    edge_score *= ~edge_score_zero_mask\n",
    "    \n",
    "    #find all edges with both nodes being contracted. This is used to find which edges are being contracted\n",
    "    edge_contract_mask_0 = ((e[...,None] == nodes[max_indices_matches])[0]).any(-1)\n",
    "    edge_contract_mask_1 = ((e[...,None] == nodes[max_indices_matches])[1]).any(-1)\n",
    "    edge_contract_mask = edge_contract_mask_0 * edge_contract_mask_1\n",
    "    \n",
    "    #keep track of which edges are contracted\n",
    "    new_edges_contracted = e[:,edge_contract_mask]\n",
    "    edges_contracted = torch.cat([edges_contracted,new_edges_contracted],dim=-1)\n",
    "    print(edges_contracted.shape[1])\n",
    "    \n",
    "    ratio = (torch.sum(nodes_remaining)/nodes_remaining.shape[0]).item()\n",
    "    i += 1\n",
    "    print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exatrkx-tracking",
   "language": "python",
   "name": "exatrkx-tracking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
