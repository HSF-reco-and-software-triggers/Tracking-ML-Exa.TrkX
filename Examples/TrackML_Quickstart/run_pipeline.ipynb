{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Loading faiss with AVX2 support.\n",
      "INFO:Successfully loaded faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "from Scripts import train_metric_learning, run_metric_learning_inference, train_gnn, run_gnn_inference\n",
    "import yaml\n",
    "\n",
    "import torch \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'{device} available')\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "from bokeh.io import output_notebook, show\n",
    "output_notebook()\n",
    "from bokeh.plotting import figure, row\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.palettes import viridis\n",
    "\n",
    "from Pipelines.Common_Tracking_Example.notebooks.ITk.Exploration.gnn_utils import infer_event\n",
    "from Pipelines.TrackML_Example.notebooks.build_embedding import EmbeddingInferenceBuilder\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "CONFIG = 'pipeline_config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir datasets\n",
    "!wget https://portal.nersc.gov/cfs/m3443/dtmurnane/TrackML_Example/trackml_quickstart_dataset.tar.gz -O datasets/trackml_quickstart_dataset.tar.gz\n",
    "!tar -xvf datasets/trackml_quickstart_dataset.tar.gz -C datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline configurations\n",
    "\n",
    "The configurations for the entire pipeline are defined under pipeline_config.yml. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_configs:\n",
      "  artifact_directory: artifacts\n",
      "  experiment_name: trackml_quickstart_1\n",
      "  gpus: 1\n",
      "  max_epochs: 20\n",
      "gnn_configs:\n",
      "  aggregation: sum_max\n",
      "  cell_channels: 8\n",
      "  datatype_names:\n",
      "  - train\n",
      "  - val\n",
      "  - test\n",
      "  datatype_split:\n",
      "  - 80\n",
      "  - 10\n",
      "  - 10\n",
      "  edge_cut: 0.5\n",
      "  factor: 0.3\n",
      "  hidden: 128\n",
      "  hidden_activation: SiLU\n",
      "  input_dir: datasets/quickstart_metric_learning_processed\n",
      "  layernorm: true\n",
      "  lr: 0.001\n",
      "  mask_background: true\n",
      "  n_graph_iters: 8\n",
      "  nb_edge_layer: 3\n",
      "  nb_node_layer: 3\n",
      "  noise: false\n",
      "  output_dir: datasets/quickstart_gnn_processed\n",
      "  patience: 10\n",
      "  pt_background_min: 1.0\n",
      "  pt_signal_min: 1.0\n",
      "  regime:\n",
      "  - - pid\n",
      "  spatial_channels: 3\n",
      "  truth_key: pid_signal\n",
      "  warmup: 5\n",
      "  weight: 2\n",
      "metric_learning_configs:\n",
      "  activation: Tanh\n",
      "  cell_channels: 9\n",
      "  emb_dim: 12\n",
      "  emb_hidden: 1024\n",
      "  factor: 0.5\n",
      "  input_dir: datasets/quickstart_example_1GeV\n",
      "  knn: 100\n",
      "  lr: 0.001\n",
      "  margin: 0.1\n",
      "  nb_layer: 4\n",
      "  output_dir: datasets/quickstart_metric_learning_processed\n",
      "  patience: 30\n",
      "  points_per_batch: 100000\n",
      "  pt_background_cut: 1.0\n",
      "  pt_signal_cut: 1.0\n",
      "  r_test: 0.1\n",
      "  r_train: 0.1\n",
      "  r_val: 0.1\n",
      "  randomisation: 1\n",
      "  regime:\n",
      "  - rp\n",
      "  - hnm\n",
      "  - ci\n",
      "  - norm\n",
      "  spatial_channels: 3\n",
      "  train_split:\n",
      "  - 80\n",
      "  - 10\n",
      "  - 10\n",
      "  true_edges: modulewise_true_edges\n",
      "  warmup: 5\n",
      "  weight: 1\n",
      "track_building_configs: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(CONFIG, 'r') as f:\n",
    "    configs = yaml.load(f, Loader=yaml.FullLoader)\n",
    "print(yaml.dump(configs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import argparse\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(message)s')\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "# sys.path.append('./')\n",
    "from Pipelines.TrackML_Example.LightningModules.Embedding.Models.layerless_embedding import LayerlessEmbedding\n",
    "from utils import headline\n",
    "\n",
    "from pytorch_lightning import Callback\n",
    "\n",
    "class DeviceCallback(Callback):\n",
    "\n",
    "    def on_batch_start(self, trainer, pl_module):\n",
    "        print( next(pl_module.parameters()).device.type )\n",
    "\n",
    "def train(config_file=\"pipeline_config.yaml\"):\n",
    "\n",
    "    logging.info(headline(\"Step 1: Running metric learning training\"))\n",
    "\n",
    "    with open(config_file) as file:\n",
    "        all_configs = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    \n",
    "    common_configs = all_configs[\"common_configs\"]\n",
    "    metric_learning_configs = all_configs[\"metric_learning_configs\"]\n",
    "\n",
    "    logging.info(headline(\"a) Initialising model\"))\n",
    "\n",
    "    model = LayerlessEmbedding(metric_learning_configs)\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    logging.info(headline(\"b) Running training\" ))\n",
    "\n",
    "    save_directory = os.path.join(common_configs[\"artifact_directory\"], \"metric_learning\")\n",
    "    logger = CSVLogger(save_directory, name=common_configs[\"experiment_name\"])\n",
    "\n",
    "    trainer = Trainer(\n",
    "        accelerator='gpu' if torch.cuda.is_available() else None,\n",
    "        auto_select_gpus=True,\n",
    "        gpus=1,\n",
    "        max_epochs=common_configs[\"max_epochs\"],\n",
    "        logger=logger, \n",
    "        # callbacks=[DeviceCallback()]\n",
    "    )\n",
    "\n",
    "    logging.info(headline(f\"Training model on {model.device}\"))\n",
    "\n",
    "    trainer.fit(model)\n",
    "    \n",
    "    logging.info(headline(f\"Trained model on {model.device}\"))\n",
    "\n",
    "    logging.info(headline(\"c) Saving model\") )\n",
    "\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "    trainer.save_checkpoint(os.path.join(save_directory, common_configs[\"experiment_name\"]+\".ckpt\"))\n",
    "\n",
    "    return trainer, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Train Metric Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What it does\n",
    "Broadly speaking, the first stage of our pipeline is embedding the space points on to graphs, in a way that is efficient, i.e. we miss as few points on a graph as possible. We train a MLP to transform the input feature vector of each space point $\\mathbf{u}_i$ into an N-dimensional latent space $\\mathbf{v}_i$. The graph is then constructed by connecting the space points whose Euclidean distance between the latent space points $$d_{ij} = \\left| \\mathbf{v}_i - \\mathbf{v}_j \\right| < r_{embedding}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data\n",
    "Let us take a look at the data before training. In this example pipeline, we have preprocessed the TrackML data into a more convenient form. We calculated directional information and summary statistics from the charge deposited in each spacepoints, and append them to its cyclidrical coordinates. Let us load an example data file and inspect the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[12083, 3], pid=[12083], modules=[12083], event_file='/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021045', hid=[12083], pt=[12083], weights=[10965], modulewise_true_edges=[2, 10965], layerwise_true_edges=[2, 14426], cell_data=[12083, 9], signal_true_edges=[2, 10965])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323412</td>\n",
       "      <td>2.091356</td>\n",
       "      <td>0.844154</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05625</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-2.091356</td>\n",
       "      <td>0.962261</td>\n",
       "      <td>0.051929</td>\n",
       "      <td>0.083736</td>\n",
       "      <td>-0.958000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.308704</td>\n",
       "      <td>0.884925</td>\n",
       "      <td>1.229181</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.28125</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.800960</td>\n",
       "      <td>1.972132</td>\n",
       "      <td>0.115441</td>\n",
       "      <td>0.501320</td>\n",
       "      <td>-0.198762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.312759</td>\n",
       "      <td>0.793395</td>\n",
       "      <td>1.423718</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.956851</td>\n",
       "      <td>2.072294</td>\n",
       "      <td>0.031444</td>\n",
       "      <td>0.612759</td>\n",
       "      <td>0.041935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.342820</td>\n",
       "      <td>0.772962</td>\n",
       "      <td>1.282741</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.928149</td>\n",
       "      <td>-0.127298</td>\n",
       "      <td>0.031484</td>\n",
       "      <td>-0.159847</td>\n",
       "      <td>-0.085926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.162364</td>\n",
       "      <td>1.440542</td>\n",
       "      <td>0.844154</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11250</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.348650</td>\n",
       "      <td>2.327071</td>\n",
       "      <td>0.071830</td>\n",
       "      <td>0.609832</td>\n",
       "      <td>-0.018804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3     4        5    6         7         8   \\\n",
       "0  1.0  0.323412  2.091356  0.844154  0.05  0.05625  0.3 -2.091356  0.962261   \n",
       "1  6.0  0.308704  0.884925  1.229181  0.10  0.28125  0.3  0.800960  1.972132   \n",
       "2  6.0  0.312759  0.793395  1.423718  0.05  0.33750  0.3  0.956851  2.072294   \n",
       "3  7.0  0.342820  0.772962  1.282741  0.10  0.33750  0.3  0.928149 -0.127298   \n",
       "4  3.0  0.162364  1.440542  0.844154  0.10  0.11250  0.3  0.348650  2.327071   \n",
       "\n",
       "         9         10        11  \n",
       "0  0.051929  0.083736 -0.958000  \n",
       "1  0.115441  0.501320 -0.198762  \n",
       "2  0.031444  0.612759  0.041935  \n",
       "3  0.031484 -0.159847 -0.085926  \n",
       "4  0.071830  0.609832 -0.018804  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Pipelines.TrackML_Example.LightningModules.Embedding.Models.layerless_embedding import LayerlessEmbedding\n",
    "\n",
    "metric_learning_configs = configs['metric_learning_configs']\n",
    "\n",
    "model = LayerlessEmbedding(metric_learning_configs)\n",
    "model.setup(stage='fit')\n",
    "clear_output()\n",
    "\n",
    "print(model.trainset[0])\n",
    "example_data = model.get_input_data(model.trainset[0])\n",
    "example_data_df = pd.DataFrame(example_data.numpy())\n",
    "example_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data is gotten by concatenating the cell data and cylindrical coordinate of each space point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323412</td>\n",
       "      <td>2.091356</td>\n",
       "      <td>0.844154</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05625</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-2.091356</td>\n",
       "      <td>0.962261</td>\n",
       "      <td>0.051929</td>\n",
       "      <td>0.083736</td>\n",
       "      <td>-0.958000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.308704</td>\n",
       "      <td>0.884925</td>\n",
       "      <td>1.229181</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.28125</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.800960</td>\n",
       "      <td>1.972132</td>\n",
       "      <td>0.115441</td>\n",
       "      <td>0.501320</td>\n",
       "      <td>-0.198762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.312759</td>\n",
       "      <td>0.793395</td>\n",
       "      <td>1.423718</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.956851</td>\n",
       "      <td>2.072294</td>\n",
       "      <td>0.031444</td>\n",
       "      <td>0.612759</td>\n",
       "      <td>0.041935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.342820</td>\n",
       "      <td>0.772962</td>\n",
       "      <td>1.282741</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.928149</td>\n",
       "      <td>-0.127298</td>\n",
       "      <td>0.031484</td>\n",
       "      <td>-0.159847</td>\n",
       "      <td>-0.085926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.162364</td>\n",
       "      <td>1.440542</td>\n",
       "      <td>0.844154</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11250</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.348650</td>\n",
       "      <td>2.327071</td>\n",
       "      <td>0.071830</td>\n",
       "      <td>0.609832</td>\n",
       "      <td>-0.018804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3     4        5    6         7         8   \\\n",
       "0  1.0  0.323412  2.091356  0.844154  0.05  0.05625  0.3 -2.091356  0.962261   \n",
       "1  6.0  0.308704  0.884925  1.229181  0.10  0.28125  0.3  0.800960  1.972132   \n",
       "2  6.0  0.312759  0.793395  1.423718  0.05  0.33750  0.3  0.956851  2.072294   \n",
       "3  7.0  0.342820  0.772962  1.282741  0.10  0.33750  0.3  0.928149 -0.127298   \n",
       "4  3.0  0.162364  1.440542  0.844154  0.10  0.11250  0.3  0.348650  2.327071   \n",
       "\n",
       "         9         10        11  \n",
       "0  0.051929  0.083736 -0.958000  \n",
       "1  0.115441  0.501320 -0.198762  \n",
       "2  0.031444  0.612759  0.041935  \n",
       "3  0.031484 -0.159847 -0.085926  \n",
       "4  0.071830  0.609832 -0.018804  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = [model.trainset[0].cell_data.numpy(), model.trainset[0].x.numpy()]\n",
    "input_data = np.concatenate(input_data, axis=1)\n",
    "input_data = pd.DataFrame(input_data)\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.758347</td>\n",
       "      <td>0.015815</td>\n",
       "      <td>-0.216978</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>-0.198355</td>\n",
       "      <td>-0.032176</td>\n",
       "      <td>-0.080935</td>\n",
       "      <td>-0.195768</td>\n",
       "      <td>0.440127</td>\n",
       "      <td>-0.010136</td>\n",
       "      <td>0.259614</td>\n",
       "      <td>0.176371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.224708</td>\n",
       "      <td>0.057013</td>\n",
       "      <td>-0.554482</td>\n",
       "      <td>-0.228010</td>\n",
       "      <td>-0.203369</td>\n",
       "      <td>-0.378222</td>\n",
       "      <td>0.414617</td>\n",
       "      <td>-0.000834</td>\n",
       "      <td>-0.062257</td>\n",
       "      <td>-0.112517</td>\n",
       "      <td>0.423644</td>\n",
       "      <td>-0.185710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.260113</td>\n",
       "      <td>0.091689</td>\n",
       "      <td>-0.560551</td>\n",
       "      <td>-0.232449</td>\n",
       "      <td>-0.180301</td>\n",
       "      <td>-0.381621</td>\n",
       "      <td>0.415849</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>-0.063875</td>\n",
       "      <td>-0.105468</td>\n",
       "      <td>0.406310</td>\n",
       "      <td>-0.155725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.361378</td>\n",
       "      <td>-0.026165</td>\n",
       "      <td>-0.493860</td>\n",
       "      <td>-0.010938</td>\n",
       "      <td>-0.436425</td>\n",
       "      <td>-0.254425</td>\n",
       "      <td>0.516231</td>\n",
       "      <td>0.100032</td>\n",
       "      <td>0.035344</td>\n",
       "      <td>-0.098932</td>\n",
       "      <td>0.249549</td>\n",
       "      <td>-0.140332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.103032</td>\n",
       "      <td>0.337436</td>\n",
       "      <td>-0.528402</td>\n",
       "      <td>-0.271310</td>\n",
       "      <td>-0.101918</td>\n",
       "      <td>-0.412171</td>\n",
       "      <td>0.050567</td>\n",
       "      <td>-0.036743</td>\n",
       "      <td>-0.004053</td>\n",
       "      <td>-0.002928</td>\n",
       "      <td>0.563244</td>\n",
       "      <td>0.145793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.758347  0.015815 -0.216978  0.001863 -0.198355 -0.032176 -0.080935   \n",
       "1  0.224708  0.057013 -0.554482 -0.228010 -0.203369 -0.378222  0.414617   \n",
       "2  0.260113  0.091689 -0.560551 -0.232449 -0.180301 -0.381621  0.415849   \n",
       "3  0.361378 -0.026165 -0.493860 -0.010938 -0.436425 -0.254425  0.516231   \n",
       "4 -0.103032  0.337436 -0.528402 -0.271310 -0.101918 -0.412171  0.050567   \n",
       "\n",
       "         7         8         9         10        11  \n",
       "0 -0.195768  0.440127 -0.010136  0.259614  0.176371  \n",
       "1 -0.000834 -0.062257 -0.112517  0.423644 -0.185710  \n",
       "2  0.008346 -0.063875 -0.105468  0.406310 -0.155725  \n",
       "3  0.100032  0.035344 -0.098932  0.249549 -0.140332  \n",
       "4 -0.036743 -0.004053 -0.002928  0.563244  0.145793  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    latent = model(example_data)\n",
    "\n",
    "latent_df = pd.DataFrame(latent.numpy())\n",
    "latent_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "Finally we come to model training. By default, we train the MLP for 20 epochs, which amounts to approximately 15 minutes. Feel free to adjust the epoch number in pipeline_config.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_leraning_trainer, metric_learning_model = train_metric_learning(CONFIG)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>eff</th>\n",
       "      <th>pur</th>\n",
       "      <th>current_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012257</td>\n",
       "      <td>0.009874</td>\n",
       "      <td>0.745082</td>\n",
       "      <td>0.009087</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009993</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.821396</td>\n",
       "      <td>0.010018</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.009968</td>\n",
       "      <td>0.009678</td>\n",
       "      <td>0.878741</td>\n",
       "      <td>0.010717</td>\n",
       "      <td>0.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.783437</td>\n",
       "      <td>0.009555</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.009981</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>0.847687</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  val_loss       eff       pur  current_lr\n",
       "0      0    0.012257  0.009874  0.745082  0.009087      0.0002\n",
       "1      1    0.009993  0.009858  0.821396  0.010018      0.0004\n",
       "2      2    0.009968  0.009678  0.878741  0.010717      0.0006\n",
       "3      3    0.010037  0.009856  0.783437  0.009555      0.0008\n",
       "4      4    0.009981  0.009795  0.847687  0.010338      0.0010"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_file = os.path.join(metric_leraning_trainer.logger.log_dir , 'metrics.csv')\n",
    "metrics = pd.read_csv(log_file, sep=',')\n",
    "train_metrics = metrics[ ~ metrics['train_loss'].isna() ][['epoch', 'train_loss']]\n",
    "train_metrics['epoch'] -= 1\n",
    "val_metrics = metrics[ ~ metrics['val_loss'].isna() ][['val_loss', 'eff', 'pur', 'current_lr', 'epoch']]\n",
    "metrics = pd.merge(left=train_metrics, right=val_metrics, how='inner', on='epoch')\n",
    "metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div class=\"bk-root\" id=\"3813591f-1779-48bc-abe7-805896d034ce\" data-root-id=\"1238\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"0d7b4a9c-aa1d-4b40-885c-3c1696d3d6e9\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"children\":[{\"id\":\"1003\"},{\"id\":\"1104\"},{\"id\":\"1171\"}]},\"id\":\"1238\",\"type\":\"Row\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#440154\"},\"hatch_alpha\":{\"value\":0.1},\"hatch_color\":{\"value\":\"#440154\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"train_loss\"}},\"id\":\"1039\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1116\",\"type\":\"BasicTicker\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1036\"},\"glyph\":{\"id\":\"1205\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1207\"},\"nonselection_glyph\":{\"id\":\"1206\"},\"view\":{\"id\":\"1209\"}},\"id\":\"1208\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1146\",\"type\":\"AllLabels\"},{\"attributes\":{\"axis\":{\"id\":\"1115\"},\"coordinates\":null,\"group\":null,\"ticker\":null},\"id\":\"1118\",\"type\":\"Grid\"},{\"attributes\":{\"line_color\":\"#440154\",\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"eff\"}},\"id\":\"1223\",\"type\":\"Line\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1129\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"overlay\":{\"id\":\"1129\"}},\"id\":\"1125\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1128\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1045\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#440154\"},\"hatch_alpha\":{\"value\":0.2},\"hatch_color\":{\"value\":\"#440154\"},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"eff\"}},\"id\":\"1207\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"AllLabels\"},{\"attributes\":{\"source\":{\"id\":\"1036\"}},\"id\":\"1227\",\"type\":\"CDSView\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#440154\",\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"eff\"}},\"id\":\"1224\",\"type\":\"Line\"},{\"attributes\":{\"source\":{\"id\":\"1036\"}},\"id\":\"1042\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1145\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1213\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1051\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1127\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1124\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"axis_label\":\"Purity\",\"coordinates\":null,\"formatter\":{\"id\":\"1145\"},\"group\":null,\"major_label_policy\":{\"id\":\"1146\"},\"ticker\":{\"id\":\"1120\"}},\"id\":\"1119\",\"type\":\"LinearAxis\"},{\"attributes\":{\"label\":{\"value\":\"Purity\"},\"renderers\":[{\"id\":\"1141\"},{\"id\":\"1159\"}]},\"id\":\"1154\",\"type\":\"LegendItem\"},{\"attributes\":{\"fill_color\":{\"value\":\"#440154\"},\"hatch_color\":{\"value\":\"#440154\"},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"train_loss\"}},\"id\":\"1038\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1148\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#440154\"},\"hatch_alpha\":{\"value\":0.1},\"hatch_color\":{\"value\":\"#440154\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"pur\"}},\"id\":\"1139\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1123\",\"type\":\"PanTool\"},{\"attributes\":{\"axis_label\":\"Epoch\",\"coordinates\":null,\"formatter\":{\"id\":\"1148\"},\"group\":null,\"major_label_policy\":{\"id\":\"1149\"},\"ticker\":{\"id\":\"1116\"}},\"id\":\"1115\",\"type\":\"LinearAxis\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#440154\"},\"hatch_alpha\":{\"value\":0.1},\"hatch_color\":{\"value\":\"#440154\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"eff\"}},\"id\":\"1206\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1126\",\"type\":\"SaveTool\"},{\"attributes\":{\"source\":{\"id\":\"1036\"}},\"id\":\"1142\",\"type\":\"CDSView\"},{\"attributes\":{\"label\":{\"value\":\"Efficiency\"},\"renderers\":[{\"id\":\"1208\"},{\"id\":\"1226\"}]},\"id\":\"1221\",\"type\":\"LegendItem\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"items\":[{\"id\":\"1221\"}]},\"id\":\"1220\",\"type\":\"Legend\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#440154\"},\"hatch_alpha\":{\"value\":0.2},\"hatch_color\":{\"value\":\"#440154\"},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"pur\"}},\"id\":\"1140\",\"type\":\"Circle\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#440154\",\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"eff\"}},\"id\":\"1225\",\"type\":\"Line\"},{\"attributes\":{\"tools\":[{\"id\":\"1123\"},{\"id\":\"1124\"},{\"id\":\"1125\"},{\"id\":\"1126\"},{\"id\":\"1127\"},{\"id\":\"1128\"}]},\"id\":\"1130\",\"type\":\"Toolbar\"},{\"attributes\":{\"source\":{\"id\":\"1036\"}},\"id\":\"1209\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1212\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"axis\":{\"id\":\"1119\"},\"coordinates\":null,\"dimension\":1,\"group\":null,\"ticker\":null},\"id\":\"1122\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1049\",\"type\":\"AllLabels\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1036\"},\"glyph\":{\"id\":\"1138\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1140\"},\"nonselection_glyph\":{\"id\":\"1139\"},\"view\":{\"id\":\"1142\"}},\"id\":\"1141\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1215\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1149\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1216\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1048\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1120\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1050\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"items\":[{\"id\":\"1154\"}]},\"id\":\"1153\",\"type\":\"Legend\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"text\":\"Efficiency on validation set\"},\"id\":\"1172\",\"type\":\"Title\"},{\"attributes\":{\"axis_label\":\"Efficiency\",\"coordinates\":null,\"formatter\":{\"id\":\"1212\"},\"group\":null,\"major_label_policy\":{\"id\":\"1213\"},\"ticker\":{\"id\":\"1187\"}},\"id\":\"1186\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1008\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1190\",\"type\":\"PanTool\"},{\"attributes\":{\"axis_label\":\"Epoch\",\"coordinates\":null,\"formatter\":{\"id\":\"1215\"},\"group\":null,\"major_label_policy\":{\"id\":\"1216\"},\"ticker\":{\"id\":\"1183\"}},\"id\":\"1182\",\"type\":\"LinearAxis\"},{\"attributes\":{\"label\":{\"value\":\"train_loss\"},\"renderers\":[{\"id\":\"1041\"},{\"id\":\"1059\"}]},\"id\":\"1054\",\"type\":\"LegendItem\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#440154\",\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"train_loss\"}},\"id\":\"1058\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1010\",\"type\":\"LinearScale\"},{\"attributes\":{\"line_color\":\"#208F8C\",\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"val_loss\"}},\"id\":\"1089\",\"type\":\"Line\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#440154\",\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"pur\"}},\"id\":\"1157\",\"type\":\"Line\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#208F8C\",\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"val_loss\"}},\"id\":\"1091\",\"type\":\"Line\"},{\"attributes\":{\"overlay\":{\"id\":\"1028\"}},\"id\":\"1024\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"LinearScale\"},{\"attributes\":{\"axis\":{\"id\":\"1186\"},\"coordinates\":null,\"dimension\":1,\"group\":null,\"ticker\":null},\"id\":\"1189\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1178\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1111\",\"type\":\"LinearScale\"},{\"attributes\":{\"line_color\":\"#440154\",\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"train_loss\"}},\"id\":\"1056\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"ResetTool\"},{\"attributes\":{\"axis\":{\"id\":\"1018\"},\"coordinates\":null,\"dimension\":1,\"group\":null,\"ticker\":null},\"id\":\"1021\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"1036\"}},\"id\":\"1076\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1183\",\"type\":\"BasicTicker\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#440154\"},\"hatch_alpha\":{\"value\":0.2},\"hatch_color\":{\"value\":\"#440154\"},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"train_loss\"}},\"id\":\"1040\",\"type\":\"Circle\"},{\"attributes\":{\"tools\":[{\"id\":\"1190\"},{\"id\":\"1191\"},{\"id\":\"1192\"},{\"id\":\"1193\"},{\"id\":\"1194\"},{\"id\":\"1195\"}]},\"id\":\"1197\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1191\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1036\"},\"glyph\":{\"id\":\"1223\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1225\"},\"nonselection_glyph\":{\"id\":\"1224\"},\"view\":{\"id\":\"1227\"}},\"id\":\"1226\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1028\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1196\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"label\":{\"value\":\"val_loss\"},\"renderers\":[{\"id\":\"1075\"},{\"id\":\"1092\"}]},\"id\":\"1087\",\"type\":\"LegendItem\"},{\"attributes\":{\"data\":{\"current_lr\":{\"__ndarray__\":\"MPX/3+I2Kj9k/P/f4jY6P3P9/z8qqUM/////3+I2Sj8T///fTWJQPxP//99NYlA/E///301iUD8T///fTWJQPxP//99NYlA/E///301iUD8T///fTWJQPxP//99NYlA/E///301iUD8T///fTWJQPxP//99NYlA/E///301iUD8T///fTWJQPxP//99NYlA/E///301iUD8T///fTWJQPw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[20]},\"eff\":{\"__ndarray__\":\"AAAAoLbX5z8AAACA30jqPwAAAAClHuw/AAAAAOoR6T8AAACgPyDrPwAAAMA2juw/AAAAIHYG6z8AAADg7YvsPwAAAIAliOk/AAAAAEIi7T8AAAAAehDtP////195T+0/AQAAoJCl7T////9/CVjtP////9+R9O0/AAAA4LID7j8AAAAgFXjtP////x+mXO4/AAAAIJL67T8AAAAA99ftPw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[20]},\"epoch\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"pur\":{\"__ndarray__\":\"1///3yGcgj/u//8/FoSEP+r///++8oU/yf//H1+Rgz/t//9fLiyFP+P//9+2T4Y/////vw8YhT/Z//8/8k2JP/3//78S2a0//P///wWesz8AAABARSrIP/3//183LM4/AAAAYI0x0T////9frrrRP////x9g79E/AAAAgLCP0j8AAACgYb/TPwAAAMAv+dM/AAAAAC/E0T////9fQFfUPw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[20]},\"train_loss\":{\"__ndarray__\":\"3v////QZiT/t//9/c3eEP/L//19JaoQ/9///nyuOhD/V//+fJHGEP/v//9/wSoQ/yf//v1KAhD/y//9fihKEP9r//7/6f4M/5P//H6+Jgj/6//8fbvaAP+P//x+GJ4A/3v//v6OJfj+e//+/xAp+P8D//3/Hkn0/sf//fxA3fT/D//+/MmF9P/7//7/m5Xw/m///f3ESfj/S//+/Y7t8Pw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[20]},\"val_loss\":{\"__ndarray__\":\"zv//f8c4hD/J//+fmzCEP+T//x/w0YM/+v//H1IvhD/e//9/Sg+EP+D//58qiYI/8///H1Logz/R////+WR6P5T//x9VRnA/jv//P69fcD+D//8fF1lvPy7//1+2gG8/3P//Hxgdbz+m//8fTwJvP4j//18y024/3f///yyAbj/Q//8ftMVuP/7//x/eaW4/Xf//P90Bbz8q//+fn29uPw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[20]}},\"selected\":{\"id\":\"1051\"},\"selection_policy\":{\"id\":\"1050\"}},\"id\":\"1036\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"fill_color\":{\"value\":\"#208F8C\"},\"hatch_color\":{\"value\":\"#208F8C\"},\"line_color\":{\"value\":\"#208F8C\"},\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"val_loss\"}},\"id\":\"1072\",\"type\":\"Circle\"},{\"attributes\":{\"source\":{\"id\":\"1036\"}},\"id\":\"1093\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1015\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1019\",\"type\":\"BasicTicker\"},{\"attributes\":{\"fill_color\":{\"value\":\"#440154\"},\"hatch_color\":{\"value\":\"#440154\"},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"pur\"}},\"id\":\"1138\",\"type\":\"Circle\"},{\"attributes\":{\"axis\":{\"id\":\"1182\"},\"coordinates\":null,\"group\":null,\"ticker\":null},\"id\":\"1185\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"1036\"}},\"id\":\"1060\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1193\",\"type\":\"SaveTool\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1036\"},\"glyph\":{\"id\":\"1089\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1091\"},\"nonselection_glyph\":{\"id\":\"1090\"},\"view\":{\"id\":\"1093\"}},\"id\":\"1092\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1176\",\"type\":\"DataRange1d\"},{\"attributes\":{\"line_color\":\"#440154\",\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"pur\"}},\"id\":\"1156\",\"type\":\"Line\"},{\"attributes\":{\"axis_label\":\"Loss\",\"coordinates\":null,\"formatter\":{\"id\":\"1045\"},\"group\":null,\"major_label_policy\":{\"id\":\"1046\"},\"ticker\":{\"id\":\"1019\"}},\"id\":\"1018\",\"type\":\"LinearAxis\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"text\":\"Purity on validation set\"},\"id\":\"1105\",\"type\":\"Title\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#208F8C\",\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"val_loss\"}},\"id\":\"1090\",\"type\":\"Line\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#440154\",\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"pur\"}},\"id\":\"1158\",\"type\":\"Line\"},{\"attributes\":{\"below\":[{\"id\":\"1182\"}],\"center\":[{\"id\":\"1185\"},{\"id\":\"1189\"},{\"id\":\"1220\"}],\"left\":[{\"id\":\"1186\"}],\"renderers\":[{\"id\":\"1208\"},{\"id\":\"1226\"}],\"title\":{\"id\":\"1172\"},\"toolbar\":{\"id\":\"1197\"},\"x_range\":{\"id\":\"1174\"},\"x_scale\":{\"id\":\"1178\"},\"y_range\":{\"id\":\"1176\"},\"y_scale\":{\"id\":\"1180\"}},\"id\":\"1171\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1036\"},\"glyph\":{\"id\":\"1038\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1040\"},\"nonselection_glyph\":{\"id\":\"1039\"},\"view\":{\"id\":\"1042\"}},\"id\":\"1041\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#440154\",\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"train_loss\"}},\"id\":\"1057\",\"type\":\"Line\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"items\":[{\"id\":\"1054\"},{\"id\":\"1087\"}]},\"id\":\"1053\",\"type\":\"Legend\"},{\"attributes\":{},\"id\":\"1180\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1006\",\"type\":\"DataRange1d\"},{\"attributes\":{\"axis_label\":\"Epoch\",\"coordinates\":null,\"formatter\":{\"id\":\"1048\"},\"group\":null,\"major_label_policy\":{\"id\":\"1049\"},\"ticker\":{\"id\":\"1015\"}},\"id\":\"1014\",\"type\":\"LinearAxis\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"text\":\"Training validation loss\"},\"id\":\"1004\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1195\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1022\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1113\",\"type\":\"LinearScale\"},{\"attributes\":{\"below\":[{\"id\":\"1014\"}],\"center\":[{\"id\":\"1017\"},{\"id\":\"1021\"},{\"id\":\"1053\"}],\"left\":[{\"id\":\"1018\"}],\"renderers\":[{\"id\":\"1041\"},{\"id\":\"1059\"},{\"id\":\"1075\"},{\"id\":\"1092\"}],\"title\":{\"id\":\"1004\"},\"toolbar\":{\"id\":\"1029\"},\"x_range\":{\"id\":\"1006\"},\"x_scale\":{\"id\":\"1010\"},\"y_range\":{\"id\":\"1008\"},\"y_scale\":{\"id\":\"1012\"}},\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"source\":{\"id\":\"1036\"}},\"id\":\"1160\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1187\",\"type\":\"BasicTicker\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1036\"},\"glyph\":{\"id\":\"1156\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1158\"},\"nonselection_glyph\":{\"id\":\"1157\"},\"view\":{\"id\":\"1160\"}},\"id\":\"1159\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1194\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1109\",\"type\":\"DataRange1d\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#208F8C\"},\"hatch_alpha\":{\"value\":0.2},\"hatch_color\":{\"value\":\"#208F8C\"},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":\"#208F8C\"},\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"val_loss\"}},\"id\":\"1074\",\"type\":\"Circle\"},{\"attributes\":{\"below\":[{\"id\":\"1115\"}],\"center\":[{\"id\":\"1118\"},{\"id\":\"1122\"},{\"id\":\"1153\"}],\"left\":[{\"id\":\"1119\"}],\"renderers\":[{\"id\":\"1141\"},{\"id\":\"1159\"}],\"title\":{\"id\":\"1105\"},\"toolbar\":{\"id\":\"1130\"},\"x_range\":{\"id\":\"1107\"},\"x_scale\":{\"id\":\"1111\"},\"y_range\":{\"id\":\"1109\"},\"y_scale\":{\"id\":\"1113\"}},\"id\":\"1104\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1036\"},\"glyph\":{\"id\":\"1056\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1058\"},\"nonselection_glyph\":{\"id\":\"1057\"},\"view\":{\"id\":\"1060\"}},\"id\":\"1059\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"tools\":[{\"id\":\"1022\"},{\"id\":\"1023\"},{\"id\":\"1024\"},{\"id\":\"1025\"},{\"id\":\"1026\"},{\"id\":\"1027\"}]},\"id\":\"1029\",\"type\":\"Toolbar\"},{\"attributes\":{\"overlay\":{\"id\":\"1196\"}},\"id\":\"1192\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"SaveTool\"},{\"attributes\":{\"fill_color\":{\"value\":\"#440154\"},\"hatch_color\":{\"value\":\"#440154\"},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"eff\"}},\"id\":\"1205\",\"type\":\"Circle\"},{\"attributes\":{\"axis\":{\"id\":\"1014\"},\"coordinates\":null,\"group\":null,\"ticker\":null},\"id\":\"1017\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1107\",\"type\":\"DataRange1d\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1036\"},\"glyph\":{\"id\":\"1072\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1074\"},\"nonselection_glyph\":{\"id\":\"1073\"},\"view\":{\"id\":\"1076\"}},\"id\":\"1075\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#208F8C\"},\"hatch_alpha\":{\"value\":0.1},\"hatch_color\":{\"value\":\"#208F8C\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#208F8C\"},\"x\":{\"field\":\"epoch\"},\"y\":{\"field\":\"val_loss\"}},\"id\":\"1073\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1027\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1174\",\"type\":\"DataRange1d\"}],\"root_ids\":[\"1238\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.3\"}};\n  const render_items = [{\"docid\":\"0d7b4a9c-aa1d-4b40-885c-3c1696d3d6e9\",\"root_ids\":[\"1238\"],\"roots\":{\"1238\":\"3813591f-1779-48bc-abe7-805896d034ce\"}}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1238"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 = figure(title='Training validation loss', x_axis_label='Epoch', y_axis_label='Loss')\n",
    "\n",
    "source = ColumnDataSource(metrics)\n",
    "\n",
    "cmap = viridis(3)\n",
    "\n",
    "for idx, y in enumerate(['train_loss', 'val_loss']):\n",
    "    p1.circle(y=y, x='epoch', source=source, color=cmap[idx], legend_label=y)\n",
    "    p1.line(x='epoch', y=y, source=source, color=cmap[idx], legend_label=y)\n",
    "\n",
    "\n",
    "p2 = figure(title='Purity on validation set', x_axis_label='Epoch', y_axis_label='Purity')\n",
    "p2.circle(y='pur', x='epoch', source=source, color=cmap[0], legend_label='Purity')\n",
    "p2.line(x='epoch', y='pur', source=source, color=cmap[0], legend_label='Purity')\n",
    "\n",
    "p3 = figure(title='Efficiency on validation set', x_axis_label='Epoch', y_axis_label='Efficiency')\n",
    "p3.circle(y='eff', x='epoch', source=source, color=cmap[0], legend_label='Efficiency')\n",
    "p3.line(x='epoch', y='eff', source=source, color=cmap[0], legend_label='Efficiency')\n",
    "\n",
    "show(row([p1,p2, p3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance on sample test data\n",
    "\n",
    "Here we evaluate the model performace on one sample test data. We look at how the efficiency and purity change with the embedding radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_efficiencies, all_purities, all_losses = [], [], []\n",
    "all_radius = np.arange(0.001, 0.2, 0.005)\n",
    "results = { 'eff': [], 'pur': [], 'loss': [], 'radius': all_radius }\n",
    "metric_learning_model.to(device)\n",
    "test_data = metric_learning_model.testset[0].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for r in all_radius:\n",
    "        test_results = metric_learning_model.shared_evaluation(\n",
    "            test_data, 0, r, 1000, log=False\n",
    "        )\n",
    "        for key in results:\n",
    "            if key not in test_results: continue\n",
    "            results[key].append( test_results[key].cpu().numpy() )\n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div class=\"bk-root\" id=\"f1545877-398a-4053-b6c1-458cd3a69930\" data-root-id=\"1982\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"7fd53863-f2ad-474a-a121-46bad9e05f3e\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"children\":[{\"id\":\"1781\"},{\"id\":\"1848\"},{\"id\":\"1915\"}]},\"id\":\"1982\",\"type\":\"Row\"},{\"attributes\":{\"tools\":[{\"id\":\"1800\"},{\"id\":\"1801\"},{\"id\":\"1802\"},{\"id\":\"1803\"},{\"id\":\"1804\"},{\"id\":\"1805\"}]},\"id\":\"1807\",\"type\":\"Toolbar\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"text\":\"Efficiency\"},\"id\":\"1782\",\"type\":\"Title\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1780\"},\"glyph\":{\"id\":\"1815\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1817\"},\"nonselection_glyph\":{\"id\":\"1816\"},\"view\":{\"id\":\"1819\"}},\"id\":\"1818\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1823\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1803\",\"type\":\"SaveTool\"},{\"attributes\":{\"axis\":{\"id\":\"1796\"},\"coordinates\":null,\"dimension\":1,\"group\":null,\"ticker\":null},\"id\":\"1799\",\"type\":\"Grid\"},{\"attributes\":{\"axis_label\":\"radius\",\"coordinates\":null,\"formatter\":{\"id\":\"1825\"},\"group\":null,\"major_label_policy\":{\"id\":\"1826\"},\"ticker\":{\"id\":\"1793\"}},\"id\":\"1792\",\"type\":\"LinearAxis\"},{\"attributes\":{\"below\":[{\"id\":\"1792\"}],\"center\":[{\"id\":\"1795\"},{\"id\":\"1799\"},{\"id\":\"1830\"}],\"left\":[{\"id\":\"1796\"}],\"renderers\":[{\"id\":\"1818\"},{\"id\":\"1836\"}],\"title\":{\"id\":\"1782\"},\"toolbar\":{\"id\":\"1807\"},\"x_range\":{\"id\":\"1784\"},\"x_scale\":{\"id\":\"1788\"},\"y_range\":{\"id\":\"1786\"},\"y_scale\":{\"id\":\"1790\"}},\"id\":\"1781\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1805\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1790\",\"type\":\"LinearScale\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#440154\"},\"hatch_alpha\":{\"value\":0.2},\"hatch_color\":{\"value\":\"#440154\"},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"pur\"}},\"id\":\"1884\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1793\",\"type\":\"BasicTicker\"},{\"attributes\":{\"label\":{\"value\":\"pur\"},\"renderers\":[{\"id\":\"1885\"},{\"id\":\"1903\"}]},\"id\":\"1898\",\"type\":\"LegendItem\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#440154\",\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"eff\"}},\"id\":\"1834\",\"type\":\"Line\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#440154\",\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"pur\"}},\"id\":\"1901\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1920\",\"type\":\"DataRange1d\"},{\"attributes\":{\"overlay\":{\"id\":\"1806\"}},\"id\":\"1802\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"line_color\":\"#440154\",\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"pur\"}},\"id\":\"1900\",\"type\":\"Line\"},{\"attributes\":{\"axis\":{\"id\":\"1792\"},\"coordinates\":null,\"group\":null,\"ticker\":null},\"id\":\"1795\",\"type\":\"Grid\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1780\"},\"glyph\":{\"id\":\"1882\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1884\"},\"nonselection_glyph\":{\"id\":\"1883\"},\"view\":{\"id\":\"1886\"}},\"id\":\"1885\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1853\",\"type\":\"DataRange1d\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#440154\",\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"pur\"}},\"id\":\"1902\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1786\",\"type\":\"DataRange1d\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1780\"},\"glyph\":{\"id\":\"1833\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1835\"},\"nonselection_glyph\":{\"id\":\"1834\"},\"view\":{\"id\":\"1837\"}},\"id\":\"1836\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1780\"},\"glyph\":{\"id\":\"1900\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1902\"},\"nonselection_glyph\":{\"id\":\"1901\"},\"view\":{\"id\":\"1904\"}},\"id\":\"1903\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1780\"},\"glyph\":{\"id\":\"1967\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1969\"},\"nonselection_glyph\":{\"id\":\"1968\"},\"view\":{\"id\":\"1971\"}},\"id\":\"1970\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"1780\"}},\"id\":\"1886\",\"type\":\"CDSView\"},{\"attributes\":{\"line_color\":\"#440154\",\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"eff\"}},\"id\":\"1833\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1801\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#440154\"},\"hatch_alpha\":{\"value\":0.1},\"hatch_color\":{\"value\":\"#440154\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"pur\"}},\"id\":\"1883\",\"type\":\"Circle\"},{\"attributes\":{\"source\":{\"id\":\"1780\"}},\"id\":\"1904\",\"type\":\"CDSView\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#440154\",\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"loss\"}},\"id\":\"1968\",\"type\":\"Line\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#440154\",\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"eff\"}},\"id\":\"1835\",\"type\":\"Line\"},{\"attributes\":{\"source\":{\"id\":\"1780\"}},\"id\":\"1837\",\"type\":\"CDSView\"},{\"attributes\":{\"line_color\":\"#440154\",\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"loss\"}},\"id\":\"1967\",\"type\":\"Line\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"items\":[{\"id\":\"1831\"}]},\"id\":\"1830\",\"type\":\"Legend\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#440154\",\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"loss\"}},\"id\":\"1969\",\"type\":\"Line\"},{\"attributes\":{\"source\":{\"id\":\"1780\"}},\"id\":\"1971\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1826\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1800\",\"type\":\"PanTool\"},{\"attributes\":{\"source\":{\"id\":\"1780\"}},\"id\":\"1819\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1788\",\"type\":\"LinearScale\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1806\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"axis_label\":\"eff\",\"coordinates\":null,\"formatter\":{\"id\":\"1822\"},\"group\":null,\"major_label_policy\":{\"id\":\"1823\"},\"ticker\":{\"id\":\"1797\"}},\"id\":\"1796\",\"type\":\"LinearAxis\"},{\"attributes\":{\"fill_color\":{\"value\":\"#440154\"},\"hatch_color\":{\"value\":\"#440154\"},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"eff\"}},\"id\":\"1815\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1784\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1918\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1825\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1797\",\"type\":\"BasicTicker\"},{\"attributes\":{\"below\":[{\"id\":\"1926\"}],\"center\":[{\"id\":\"1929\"},{\"id\":\"1933\"},{\"id\":\"1964\"}],\"left\":[{\"id\":\"1930\"}],\"renderers\":[{\"id\":\"1952\"},{\"id\":\"1970\"}],\"title\":{\"id\":\"1916\"},\"toolbar\":{\"id\":\"1941\"},\"x_range\":{\"id\":\"1918\"},\"x_scale\":{\"id\":\"1922\"},\"y_range\":{\"id\":\"1920\"},\"y_scale\":{\"id\":\"1924\"}},\"id\":\"1915\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1851\",\"type\":\"DataRange1d\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"items\":[{\"id\":\"1898\"}]},\"id\":\"1897\",\"type\":\"Legend\"},{\"attributes\":{\"fill_color\":{\"value\":\"#440154\"},\"hatch_color\":{\"value\":\"#440154\"},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"loss\"}},\"id\":\"1949\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1924\",\"type\":\"LinearScale\"},{\"attributes\":{\"below\":[{\"id\":\"1859\"}],\"center\":[{\"id\":\"1862\"},{\"id\":\"1866\"},{\"id\":\"1897\"}],\"left\":[{\"id\":\"1863\"}],\"renderers\":[{\"id\":\"1885\"},{\"id\":\"1903\"}],\"title\":{\"id\":\"1849\"},\"toolbar\":{\"id\":\"1874\"},\"x_range\":{\"id\":\"1851\"},\"x_scale\":{\"id\":\"1855\"},\"y_range\":{\"id\":\"1853\"},\"y_scale\":{\"id\":\"1857\"}},\"id\":\"1848\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"text\":\"Loss\"},\"id\":\"1916\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1822\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"fill_color\":{\"value\":\"#440154\"},\"hatch_color\":{\"value\":\"#440154\"},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"pur\"}},\"id\":\"1882\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1857\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1927\",\"type\":\"BasicTicker\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"text\":\"Purity\"},\"id\":\"1849\",\"type\":\"Title\"},{\"attributes\":{\"axis\":{\"id\":\"1926\"},\"coordinates\":null,\"group\":null,\"ticker\":null},\"id\":\"1929\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1922\",\"type\":\"LinearScale\"},{\"attributes\":{\"data\":{\"eff\":[0.0004481290525291115,0.04526103660464287,0.113003209233284,0.14653819799423218,0.16857121884822845,0.18851295113563538,0.20890283584594727,0.2288445681333542,0.2638733386993408,0.3276570439338684,0.42564791440963745,0.517066240310669,0.6023601293563843,0.6757039427757263,0.737321674823761,0.7872880697250366,0.8268728256225586,0.8610799908638,0.8896108865737915,0.9118679761886597,0.9306893944740295,0.9457017183303833,0.9574277400970459,0.9660168886184692,0.9728134870529175,0.9775935411453247,0.9816266894340515,0.9844648838043213,0.9874523878097534,0.9895436763763428,0.9911121129989624,0.99200838804245,0.9936515092849731,0.9951452612876892,0.9957427978515625,0.9964149594306946,0.9967136979103088,0.9973112344741821,0.9977593421936035,0.9980580806732178],\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39],\"loss\":[9.085562169275363e-07,0.0010759999277070165,0.0015577605227008462,0.0016982376109808683,0.0019522173097357154,0.0022254635114222765,0.002611562144011259,0.003020437667146325,0.003368495497852564,0.003709194716066122,0.003983301110565662,0.004238434135913849,0.004429723136126995,0.004562512040138245,0.004637668374925852,0.004655628465116024,0.0046106125228106976,0.004495473578572273,0.004304451402276754,0.00401640310883522,0.003655391512438655,0.003307507373392582,0.003011636435985565,0.0027648997493088245,0.0025482741184532642,0.0023481433745473623,0.0021702833473682404,0.002006200607866049,0.00185713404789567,0.001721296226605773,0.0015972432447597384,0.0014814636670053005,0.0013777872081845999,0.001283428049646318,0.0011945110745728016,0.0011146101169288158,0.0010390400420874357,0.0009693687898106873,0.0009050692315213382,0.0008460998069494963],\"pur\":[1.0,0.8938053250312805,0.8476190567016602,0.8352490663528442,0.81099534034729,0.7845818996429443,0.7450719475746155,0.7011441588401794,0.6658499836921692,0.6335933208465576,0.6101713180541992,0.5781210660934448,0.5477823615074158,0.5175925493240356,0.4873136579990387,0.45770734548568726,0.4272702634334564,0.39558741450309753,0.3638724386692047,0.3306163251399994,0.2994281053543091,0.2714662551879883,0.24729439616203308,0.22692422568798065,0.2089281678199768,0.1922873556613922,0.17746421694755554,0.16383478045463562,0.1513982117176056,0.14012247323989868,0.1298612356185913,0.12034721672534943,0.11173165589570999,0.103899747133255,0.09662830084562302,0.09007798880338669,0.08393239974975586,0.07822404056787491,0.07297368347644806,0.06817717850208282],\"radius\":{\"__ndarray__\":\"/Knx0k1iUD/6fmq8dJN4P7pJDAIrh4Y//Knx0k1ikD8bL90kBoGVPzq0yHa+n5o/WDm0yHa+nz8830+Nl26iP8uhRbbz/aQ/WmQ730+Npz/qJjEIrByqP3npJjEIrKw/CKwcWmQ7rz9MN4lBYOWwP5QYBFYOLbI/2/l+arx0sz8j2/l+ary0P2u8dJMYBLY/sp3vp8ZLtz/6fmq8dJO4P0Jg5dAi27k/iUFg5dAiuz/RItv5fmq8PxkEVg4tsr0/YOXQItv5vj9U46WbxCDAP/hT46WbxMA/nMQgsHJowT9ANV66SQzCP+Olm8QgsMI/hxbZzvdTwz8rhxbZzvfDP8/3U+Olm8Q/c2iR7Xw/xT8X2c73U+PFP7tJDAIrh8Y/XrpJDAIrxz8CK4cW2c7HP6abxCCwcsg/SgwCK4cWyT8=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[40]}},\"selected\":{\"id\":\"1828\"},\"selection_policy\":{\"id\":\"1827\"}},\"id\":\"1780\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1889\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"axis_label\":\"radius\",\"coordinates\":null,\"formatter\":{\"id\":\"1959\"},\"group\":null,\"major_label_policy\":{\"id\":\"1960\"},\"ticker\":{\"id\":\"1927\"}},\"id\":\"1926\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1860\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis\":{\"id\":\"1859\"},\"coordinates\":null,\"group\":null,\"ticker\":null},\"id\":\"1862\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1855\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1935\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1827\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"axis_label\":\"radius\",\"coordinates\":null,\"formatter\":{\"id\":\"1892\"},\"group\":null,\"major_label_policy\":{\"id\":\"1893\"},\"ticker\":{\"id\":\"1860\"}},\"id\":\"1859\",\"type\":\"LinearAxis\"},{\"attributes\":{\"label\":{\"value\":\"eff\"},\"renderers\":[{\"id\":\"1818\"},{\"id\":\"1836\"}]},\"id\":\"1831\",\"type\":\"LegendItem\"},{\"attributes\":{\"axis_label\":\"loss\",\"coordinates\":null,\"formatter\":{\"id\":\"1956\"},\"group\":null,\"major_label_policy\":{\"id\":\"1957\"},\"ticker\":{\"id\":\"1931\"}},\"id\":\"1930\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1890\",\"type\":\"AllLabels\"},{\"attributes\":{\"axis\":{\"id\":\"1930\"},\"coordinates\":null,\"dimension\":1,\"group\":null,\"ticker\":null},\"id\":\"1933\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1868\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1931\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis_label\":\"pur\",\"coordinates\":null,\"formatter\":{\"id\":\"1889\"},\"group\":null,\"major_label_policy\":{\"id\":\"1890\"},\"ticker\":{\"id\":\"1864\"}},\"id\":\"1863\",\"type\":\"LinearAxis\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#440154\"},\"hatch_alpha\":{\"value\":0.2},\"hatch_color\":{\"value\":\"#440154\"},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"eff\"}},\"id\":\"1817\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1892\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"axis\":{\"id\":\"1863\"},\"coordinates\":null,\"dimension\":1,\"group\":null,\"ticker\":null},\"id\":\"1866\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1864\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1939\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1893\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1934\",\"type\":\"PanTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1940\"}},\"id\":\"1936\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1828\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1804\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1872\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1937\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1867\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1938\",\"type\":\"ResetTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1873\"}},\"id\":\"1869\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1870\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1871\",\"type\":\"ResetTool\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1940\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1873\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"tools\":[{\"id\":\"1934\"},{\"id\":\"1935\"},{\"id\":\"1936\"},{\"id\":\"1937\"},{\"id\":\"1938\"},{\"id\":\"1939\"}]},\"id\":\"1941\",\"type\":\"Toolbar\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#440154\"},\"hatch_alpha\":{\"value\":0.1},\"hatch_color\":{\"value\":\"#440154\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"eff\"}},\"id\":\"1816\",\"type\":\"Circle\"},{\"attributes\":{\"tools\":[{\"id\":\"1867\"},{\"id\":\"1868\"},{\"id\":\"1869\"},{\"id\":\"1870\"},{\"id\":\"1871\"},{\"id\":\"1872\"}]},\"id\":\"1874\",\"type\":\"Toolbar\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"items\":[{\"id\":\"1965\"}]},\"id\":\"1964\",\"type\":\"Legend\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#440154\"},\"hatch_alpha\":{\"value\":0.1},\"hatch_color\":{\"value\":\"#440154\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"loss\"}},\"id\":\"1950\",\"type\":\"Circle\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#440154\"},\"hatch_alpha\":{\"value\":0.2},\"hatch_color\":{\"value\":\"#440154\"},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":\"#440154\"},\"x\":{\"field\":\"radius\"},\"y\":{\"field\":\"loss\"}},\"id\":\"1951\",\"type\":\"Circle\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1780\"},\"glyph\":{\"id\":\"1949\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1951\"},\"nonselection_glyph\":{\"id\":\"1950\"},\"view\":{\"id\":\"1953\"}},\"id\":\"1952\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"1780\"}},\"id\":\"1953\",\"type\":\"CDSView\"},{\"attributes\":{\"label\":{\"value\":\"loss\"},\"renderers\":[{\"id\":\"1952\"},{\"id\":\"1970\"}]},\"id\":\"1965\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"1956\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1957\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1959\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1960\",\"type\":\"AllLabels\"}],\"root_ids\":[\"1982\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.3\"}};\n  const render_items = [{\"docid\":\"7fd53863-f2ad-474a-a121-46bad9e05f3e\",\"root_ids\":[\"1982\"],\"roots\":{\"1982\":\"f1545877-398a-4053-b6c1-458cd3a69930\"}}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1982"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "source = ColumnDataSource(results)\n",
    "cmap = viridis(3)\n",
    "titles = ['Efficiency', 'Purity', 'Loss'] \n",
    "figures = []\n",
    "x='radius'\n",
    "for idx, y in enumerate(['eff', 'pur', 'loss']):\n",
    "    figures.append( figure(title=titles[idx], x_axis_label=x, y_axis_label=y) )\n",
    "    figures[-1].circle(y=y, x=x, source=source, color=cmap[0], legend_label=y)\n",
    "    figures[-1].line(x=x, y=y, source=source, color=cmap[0], legend_label=y)\n",
    "\n",
    "show(row(figures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Construct graphs from metric learning inference\n",
    "\n",
    "This step performs model inference on the entire input datasets (train, validation and test), to obtain input graphs to the graph neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:-------------------- Step 2: Constructing graphs from metric learning model  --------------------\n",
      "INFO:-------------------- a) Loading trained model --------------------\n",
      "INFO:-------------------- b) Running inferencing --------------------\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021000\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021001\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished, running inference to build graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 80/80 [00:30<00:00,  2.65it/s]\n",
      "100%|| 10/10 [00:03<00:00,  2.99it/s]\n",
      "100%|| 10/10 [00:03<00:00,  3.20it/s]\n"
     ]
    }
   ],
   "source": [
    "graph_builder = run_metric_learning_inference(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train graph neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:--------------------  Step 3: Running GNN training  --------------------\n",
      "INFO:-------------------- a) Initialising model --------------------\n",
      "INFO:-------------------- b) Running training --------------------\n",
      "INFO:GPU available: True, used: True\n",
      "INFO:TPU available: False, using: 0 TPU cores\n",
      "INFO:IPU available: False, using: 0 IPUs\n",
      "INFO:HPU available: False, using: 0 HPUs\n",
      "WARNING:Missing logger folder: artifacts/gnn/trackml_quickstart_1\n",
      "INFO:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:\n",
      "  | Name                   | Type       | Params\n",
      "------------------------------------------------------\n",
      "0 | node_encoder           | Sequential | 35.1 K\n",
      "1 | edge_encoder           | Sequential | 66.4 K\n",
      "2 | edge_network           | Sequential | 82.8 K\n",
      "3 | node_network           | Sequential | 82.8 K\n",
      "4 | output_edge_classifier | Sequential | 83.2 K\n",
      "------------------------------------------------------\n",
      "350 K     Trainable params\n",
      "0         Non-trainable params\n",
      "350 K     Total params\n",
      "1.401     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22d7e61d5914d83a894e60c950f8377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 15198. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 14370. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c769eb7703454a18a6f7e8a40b6660de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 16.91 GiB (GPU 0; 39.59 GiB total capacity; 28.55 GiB already allocated; 8.76 GiB free; 28.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/run_pipeline.ipynb Cell 25'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/run_pipeline.ipynb#ch0000024vscode-remote?line=0'>1</a>\u001b[0m train_gnn(CONFIG)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/Scripts/Step_3_Train_GNN.py:53\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config_file)\u001b[0m\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/Scripts/Step_3_Train_GNN.py?line=44'>45</a>\u001b[0m logger \u001b[39m=\u001b[39m CSVLogger(save_directory, name\u001b[39m=\u001b[39mcommon_configs[\u001b[39m\"\u001b[39m\u001b[39mexperiment_name\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/Scripts/Step_3_Train_GNN.py?line=46'>47</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/Scripts/Step_3_Train_GNN.py?line=47'>48</a>\u001b[0m     gpus\u001b[39m=\u001b[39mcommon_configs[\u001b[39m\"\u001b[39m\u001b[39mgpus\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/Scripts/Step_3_Train_GNN.py?line=48'>49</a>\u001b[0m     max_epochs\u001b[39m=\u001b[39mcommon_configs[\u001b[39m\"\u001b[39m\u001b[39mmax_epochs\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/Scripts/Step_3_Train_GNN.py?line=49'>50</a>\u001b[0m     logger\u001b[39m=\u001b[39mlogger\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/Scripts/Step_3_Train_GNN.py?line=50'>51</a>\u001b[0m )\n\u001b[0;32m---> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/Scripts/Step_3_Train_GNN.py?line=52'>53</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model)\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/Scripts/Step_3_Train_GNN.py?line=54'>55</a>\u001b[0m logging\u001b[39m.\u001b[39minfo(headline( \u001b[39m\"\u001b[39m\u001b[39mc) Saving model\u001b[39m\u001b[39m\"\u001b[39m ))\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/Scripts/Step_3_Train_GNN.py?line=56'>57</a>\u001b[0m os\u001b[39m.\u001b[39mmakedirs(save_directory, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:768\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=748'>749</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=749'>750</a>\u001b[0m \u001b[39mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=750'>751</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=764'>765</a>\u001b[0m \u001b[39m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=765'>766</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=766'>767</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=767'>768</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=768'>769</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=769'>770</a>\u001b[0m )\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:721\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=718'>719</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=719'>720</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=720'>721</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=721'>722</a>\u001b[0m \u001b[39m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=722'>723</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:809\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=804'>805</a>\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=805'>806</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=806'>807</a>\u001b[0m     ckpt_path, model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=807'>808</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=808'>809</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=810'>811</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=811'>812</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1234\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1229'>1230</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1231'>1232</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1233'>1234</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1235'>1236</a>\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1236'>1237</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1321\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1318'>1319</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1319'>1320</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1320'>1321</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1351\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1348'>1349</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1349'>1350</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1350'>1351</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=201'>202</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=202'>203</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=203'>204</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=204'>205</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=205'>206</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:268\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py?line=263'>264</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py?line=264'>265</a>\u001b[0m     dataloader, batch_to_device\u001b[39m=\u001b[39mpartial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_call_strategy_hook, \u001b[39m\"\u001b[39m\u001b[39mbatch_to_device\u001b[39m\u001b[39m\"\u001b[39m, dataloader_idx\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py?line=265'>266</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py?line=266'>267</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py?line=267'>268</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=201'>202</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=202'>203</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=203'>204</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=204'>205</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=205'>206</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:208\u001b[0m, in \u001b[0;36mTrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py?line=204'>205</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py?line=206'>207</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_batch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py?line=207'>208</a>\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_loop\u001b[39m.\u001b[39;49mrun(batch, batch_idx)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py?line=209'>210</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py?line=211'>212</a>\u001b[0m \u001b[39m# update non-plateau LR schedulers\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py?line=212'>213</a>\u001b[0m \u001b[39m# update epoch-interval ones only when we are at the end of training epoch\u001b[39;00m\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=201'>202</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=202'>203</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=203'>204</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=204'>205</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=205'>206</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py:88\u001b[0m, in \u001b[0;36mTrainingBatchLoop.advance\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py?line=85'>86</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mautomatic_optimization:\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py?line=86'>87</a>\u001b[0m     optimizers \u001b[39m=\u001b[39m _get_active_optimizers(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39moptimizers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39moptimizer_frequencies, batch_idx)\n\u001b[0;32m---> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py?line=87'>88</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer_loop\u001b[39m.\u001b[39;49mrun(split_batch, optimizers, batch_idx)\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py?line=88'>89</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py?line=89'>90</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_loop\u001b[39m.\u001b[39mrun(split_batch, batch_idx)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=201'>202</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=202'>203</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=203'>204</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=204'>205</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=205'>206</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:203\u001b[0m, in \u001b[0;36mOptimizerLoop.advance\u001b[0;34m(self, batch, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=201'>202</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madvance\u001b[39m(\u001b[39mself\u001b[39m, batch: Any, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=202'>203</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_optimization(\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=203'>204</a>\u001b[0m         batch,\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=204'>205</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_idx,\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=205'>206</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizers[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptim_progress\u001b[39m.\u001b[39;49moptimizer_position],\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=206'>207</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer_idx,\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=207'>208</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=208'>209</a>\u001b[0m     \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=209'>210</a>\u001b[0m         \u001b[39m# automatic optimization assumes a loss needs to be returned for extras to be considered as the batch\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=210'>211</a>\u001b[0m         \u001b[39m# would be skipped otherwise\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=211'>212</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_idx] \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39masdict()\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:256\u001b[0m, in \u001b[0;36mOptimizerLoop._run_optimization\u001b[0;34m(self, split_batch, batch_idx, optimizer, opt_idx)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=248'>249</a>\u001b[0m         closure()\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=250'>251</a>\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=251'>252</a>\u001b[0m \u001b[39m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=252'>253</a>\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=253'>254</a>\u001b[0m \u001b[39m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=254'>255</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=255'>256</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_step(optimizer, opt_idx, batch_idx, closure)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=257'>258</a>\u001b[0m result \u001b[39m=\u001b[39m closure\u001b[39m.\u001b[39mconsume_result()\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=259'>260</a>\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=260'>261</a>\u001b[0m     \u001b[39m# if no result, user decided to skip optimization\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=261'>262</a>\u001b[0m     \u001b[39m# otherwise update running loss + reset accumulated loss\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=262'>263</a>\u001b[0m     \u001b[39m# TODO: find proper way to handle updating running loss\u001b[39;00m\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:369\u001b[0m, in \u001b[0;36mOptimizerLoop._optimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=365'>366</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_ready()\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=367'>368</a>\u001b[0m \u001b[39m# model hook\u001b[39;00m\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=368'>369</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_lightning_module_hook(\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=369'>370</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39moptimizer_step\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=370'>371</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mcurrent_epoch,\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=371'>372</a>\u001b[0m     batch_idx,\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=372'>373</a>\u001b[0m     optimizer,\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=373'>374</a>\u001b[0m     opt_idx,\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=374'>375</a>\u001b[0m     train_step_and_backward_closure,\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=375'>376</a>\u001b[0m     on_tpu\u001b[39m=\u001b[39;49m\u001b[39misinstance\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49maccelerator, TPUAccelerator),\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=376'>377</a>\u001b[0m     using_native_amp\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mamp_backend \u001b[39m==\u001b[39;49m AMPType\u001b[39m.\u001b[39;49mNATIVE),\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=377'>378</a>\u001b[0m     using_lbfgs\u001b[39m=\u001b[39;49mis_lbfgs,\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=378'>379</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=380'>381</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=381'>382</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1593\u001b[0m, in \u001b[0;36mTrainer._call_lightning_module_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1589'>1590</a>\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1591'>1592</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1592'>1593</a>\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1594'>1595</a>\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1595'>1596</a>\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:248\u001b[0m, in \u001b[0;36mGNNBase.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py?line=244'>245</a>\u001b[0m         pg[\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m lr_scale \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams[\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py?line=246'>247</a>\u001b[0m \u001b[39m# update params\u001b[39;00m\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py?line=247'>248</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49moptimizer_closure)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py?line=248'>249</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py:168\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py?line=164'>165</a>\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py?line=166'>167</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py?line=167'>168</a>\u001b[0m step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strategy\u001b[39m.\u001b[39;49moptimizer_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_idx, closure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py?line=169'>170</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_after_step()\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py?line=171'>172</a>\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py:193\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=182'>183</a>\u001b[0m \u001b[39m\"\"\"Performs the actual optimizer step.\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=183'>184</a>\u001b[0m \n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=184'>185</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=189'>190</a>\u001b[0m \u001b[39m    **kwargs: Any extra arguments to ``optimizer.step``\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=190'>191</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=191'>192</a>\u001b[0m model \u001b[39m=\u001b[39m model \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=192'>193</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision_plugin\u001b[39m.\u001b[39;49moptimizer_step(model, optimizer, opt_idx, closure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:155\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[0;34m(self, model, optimizer, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=152'>153</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, pl\u001b[39m.\u001b[39mLightningModule):\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=153'>154</a>\u001b[0m     closure \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_closure, model, optimizer, optimizer_idx, closure)\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=154'>155</a>\u001b[0m \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/optim/lr_scheduler.py?line=62'>63</a>\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/optim/lr_scheduler.py?line=63'>64</a>\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/optim/lr_scheduler.py?line=64'>65</a>\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/optim/optimizer.py?line=85'>86</a>\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/optim/optimizer.py?line=86'>87</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/optim/optimizer.py?line=87'>88</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/autograd/grad_mode.py?line=26'>27</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[0;32m---> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/autograd/grad_mode.py?line=27'>28</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/optim/adamw.py:92\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/optim/adamw.py?line=89'>90</a>\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/optim/adamw.py?line=90'>91</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[0;32m---> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/optim/adamw.py?line=91'>92</a>\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/optim/adamw.py?line=93'>94</a>\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/optim/adamw.py?line=94'>95</a>\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:140\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[0;34m(self, model, optimizer, optimizer_idx, closure)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=126'>127</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_closure\u001b[39m(\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=127'>128</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=128'>129</a>\u001b[0m     model: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=131'>132</a>\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=132'>133</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=133'>134</a>\u001b[0m     \u001b[39m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=134'>135</a>\u001b[0m \u001b[39m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=135'>136</a>\u001b[0m \n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=136'>137</a>\u001b[0m \u001b[39m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=137'>138</a>\u001b[0m \u001b[39m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=138'>139</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=139'>140</a>\u001b[0m     closure_result \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=140'>141</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_closure(model, optimizer, optimizer_idx)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:148\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=146'>147</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=147'>148</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclosure(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=148'>149</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39mloss\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:134\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=132'>133</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ClosureResult:\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=133'>134</a>\u001b[0m     step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_fn()\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=135'>136</a>\u001b[0m     \u001b[39mif\u001b[39;00m step_output\u001b[39m.\u001b[39mclosure_loss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=136'>137</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarning_cache\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:427\u001b[0m, in \u001b[0;36mOptimizerLoop._training_step\u001b[0;34m(self, split_batch, batch_idx, opt_idx)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=421'>422</a>\u001b[0m step_kwargs \u001b[39m=\u001b[39m _build_training_step_kwargs(\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=422'>423</a>\u001b[0m     lightning_module, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39moptimizers, split_batch, batch_idx, opt_idx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hiddens\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=423'>424</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=425'>426</a>\u001b[0m \u001b[39m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=426'>427</a>\u001b[0m training_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(\u001b[39m\"\u001b[39;49m\u001b[39mtraining_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49mstep_kwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=427'>428</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mpost_training_step()\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py?line=429'>430</a>\u001b[0m model_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_call_lightning_module_hook(\u001b[39m\"\u001b[39m\u001b[39mtraining_step_end\u001b[39m\u001b[39m\"\u001b[39m, training_step_output)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1763\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1759'>1760</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1761'>1762</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1762'>1763</a>\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1764'>1765</a>\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1765'>1766</a>\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py:333\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=327'>328</a>\u001b[0m \u001b[39m\"\"\"The actual training step.\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=328'>329</a>\u001b[0m \n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=329'>330</a>\u001b[0m \u001b[39mSee :meth:`~pytorch_lightning.core.lightning.LightningModule.training_step` for more details\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=330'>331</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=331'>332</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mtrain_step_context():\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=332'>333</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtraining_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:128\u001b[0m, in \u001b[0;36mGNNBase.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py?line=125'>126</a>\u001b[0m edge_sample, truth_sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_directed(batch, batch\u001b[39m.\u001b[39medge_index, truth)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py?line=126'>127</a>\u001b[0m input_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_input_data(batch)\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py?line=127'>128</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(input_data, edge_sample)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py?line=129'>130</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mweighting\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams[\u001b[39m\"\u001b[39m\u001b[39mregime\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py?line=130'>131</a>\u001b[0m     manual_weights \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mweights\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/Models/interaction_gnn.py:139\u001b[0m, in \u001b[0;36mInteractionGNN.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/Models/interaction_gnn.py?line=134'>135</a>\u001b[0m \u001b[39m#         edge_outputs = []\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/Models/interaction_gnn.py?line=135'>136</a>\u001b[0m \u001b[39m# Loop over iterations of edge and node networks\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/Models/interaction_gnn.py?line=136'>137</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams[\u001b[39m\"\u001b[39m\u001b[39mn_graph_iters\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/Models/interaction_gnn.py?line=138'>139</a>\u001b[0m     x, e \u001b[39m=\u001b[39m checkpoint(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessage_step, x, start, end, e)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/Models/interaction_gnn.py?line=140'>141</a>\u001b[0m \u001b[39m# Compute final edge scores; use original edge directions only\u001b[39;00m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/Models/interaction_gnn.py?line=141'>142</a>\u001b[0m \u001b[39mreturn\u001b[39;00m checkpoint(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_step, x, start, end, e)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:211\u001b[0m, in \u001b[0;36mcheckpoint\u001b[0;34m(function, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py?line=207'>208</a>\u001b[0m \u001b[39mif\u001b[39;00m kwargs:\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py?line=208'>209</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnexpected keyword arguments: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(arg \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m kwargs))\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py?line=210'>211</a>\u001b[0m \u001b[39mreturn\u001b[39;00m CheckpointFunction\u001b[39m.\u001b[39;49mapply(function, preserve, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:90\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py?line=86'>87</a>\u001b[0m ctx\u001b[39m.\u001b[39msave_for_backward(\u001b[39m*\u001b[39mtensor_inputs)\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py?line=88'>89</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py?line=89'>90</a>\u001b[0m     outputs \u001b[39m=\u001b[39m run_function(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py?line=90'>91</a>\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/Models/interaction_gnn.py:113\u001b[0m, in \u001b[0;36mInteractionGNN.message_step\u001b[0;34m(self, x, start, end, e)\u001b[0m\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/Models/interaction_gnn.py?line=109'>110</a>\u001b[0m x_out \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m x\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/Models/interaction_gnn.py?line=111'>112</a>\u001b[0m \u001b[39m# Compute new edge features\u001b[39;00m\n\u001b[0;32m--> <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/Models/interaction_gnn.py?line=112'>113</a>\u001b[0m edge_inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([x[start], x[end], e], dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/Models/interaction_gnn.py?line=113'>114</a>\u001b[0m e_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_network(edge_inputs)\n\u001b[1;32m    <a href='file:///global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Examples/TrackML_Quickstart/../../Pipelines/TrackML_Example/LightningModules/GNN/Models/interaction_gnn.py?line=115'>116</a>\u001b[0m e_out \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m e\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.91 GiB (GPU 0; 39.59 GiB total capacity; 28.55 GiB already allocated; 8.76 GiB free; 28.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "train_gnn(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: GNN inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:-------------------- Step 4: Scoring graph edges using GNN  --------------------\n",
      "INFO:-------------------- a) Loading trained model --------------------\n",
      "INFO:-------------------- b) Running inferencing --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished, running inference to filter graphs...\n",
      "Building train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 80/80 [00:00<00:00, 59567.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:00<00:00, 10335.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:00<00:00, 10325.71it/s]\n"
     ]
    }
   ],
   "source": [
    "run_gnn_inference(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23e238e993944c70c76d26fe3e792d9ebd61de96e06ef56dc5c2723238ec1285"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('exatrkx-hsf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
