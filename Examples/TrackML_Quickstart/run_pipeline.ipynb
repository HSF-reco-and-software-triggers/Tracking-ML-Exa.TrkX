{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Loading faiss with AVX2 support.\n",
      "INFO:Successfully loaded faiss with AVX2 support.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from Scripts import train_metric_learning, run_metric_learning_inference, train_gnn, run_gnn_inference\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = 'pipeline_config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir datasets\n",
    "!wget https://portal.nersc.gov/cfs/m3443/dtmurnane/TrackML_Example/trackml_quickstart_dataset.tar.gz -O datasets/trackml_quickstart_dataset.tar.gz\n",
    "!tar -xvf datasets/trackml_quickstart_dataset.tar.gz -C datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline configurations\n",
    "\n",
    "The configurations for the entire pipeline are defined under pipeline_config.yml. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_configs:\n",
      "  artifact_directory: artifacts\n",
      "  experiment_name: trackml_quickstart_1\n",
      "  gpus: 1\n",
      "  max_epochs: 10\n",
      "gnn_configs:\n",
      "  aggregation: sum_max\n",
      "  cell_channels: 8\n",
      "  datatype_names:\n",
      "  - train\n",
      "  - val\n",
      "  - test\n",
      "  datatype_split:\n",
      "  - 80\n",
      "  - 10\n",
      "  - 10\n",
      "  edge_cut: 0.5\n",
      "  factor: 0.3\n",
      "  hidden: 128\n",
      "  hidden_activation: SiLU\n",
      "  input_dir: datasets/quickstart_metric_learning_processed\n",
      "  layernorm: true\n",
      "  lr: 0.001\n",
      "  mask_background: true\n",
      "  n_graph_iters: 8\n",
      "  nb_edge_layer: 3\n",
      "  nb_node_layer: 3\n",
      "  noise: false\n",
      "  output_dir: datasets/quickstart_gnn_processed\n",
      "  patience: 10\n",
      "  pt_background_min: 1.0\n",
      "  pt_signal_min: 1.0\n",
      "  regime:\n",
      "  - - pid\n",
      "  spatial_channels: 3\n",
      "  truth_key: pid_signal\n",
      "  warmup: 5\n",
      "  weight: 2\n",
      "metric_learning_configs:\n",
      "  activation: Tanh\n",
      "  cell_channels: 9\n",
      "  emb_dim: 12\n",
      "  emb_hidden: 1024\n",
      "  factor: 0.5\n",
      "  input_dir: datasets/quickstart_example_1GeV\n",
      "  knn: 100\n",
      "  lr: 0.001\n",
      "  margin: 0.1\n",
      "  nb_layer: 4\n",
      "  output_dir: datasets/quickstart_metric_learning_processed\n",
      "  patience: 30\n",
      "  points_per_batch: 100000\n",
      "  pt_background_cut: 1.0\n",
      "  pt_signal_cut: 1.0\n",
      "  r_test: 0.1\n",
      "  r_train: 0.1\n",
      "  r_val: 0.1\n",
      "  randomisation: 1\n",
      "  regime:\n",
      "  - rp\n",
      "  - hnm\n",
      "  - ci\n",
      "  - norm\n",
      "  spatial_channels: 3\n",
      "  train_split:\n",
      "  - 80\n",
      "  - 10\n",
      "  - 10\n",
      "  true_edges: modulewise_true_edges\n",
      "  warmup: 5\n",
      "  weight: 1\n",
      "track_building_configs: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(CONFIG, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "print(yaml.dump(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Train Metric Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:-------------------- Step 1: Running metric learning training --------------------\n",
      "INFO:-------------------- a) Initialising model --------------------\n",
      "INFO:-------------------- b) Running training --------------------\n",
      "INFO:GPU available: True, used: True\n",
      "INFO:TPU available: False, using: 0 TPU cores\n",
      "INFO:IPU available: False, using: 0 IPUs\n",
      "INFO:HPU available: False, using: 0 HPUs\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021000\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021001\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021002\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021003\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021004\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021005\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021006\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021007\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021008\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021009\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021010\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021011\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021012\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021013\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021014\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021015\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021016\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021017\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021018\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021019\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021020\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021021\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021022\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021023\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021024\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021025\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021026\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021027\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021028\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021029\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021030\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021031\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021032\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021033\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021034\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021035\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021036\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021037\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021038\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021039\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021040\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021041\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021042\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021043\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021044\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021045\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021046\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021047\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021048\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021049\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021050\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021051\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021052\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021053\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021054\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021055\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021056\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021057\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021058\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021059\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021060\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021061\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021062\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021063\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021064\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021065\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021066\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021067\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021068\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021069\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021070\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021071\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021072\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021073\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021074\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021075\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021076\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021077\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021078\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021079\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021080\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021081\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021082\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021083\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021084\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021085\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021086\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021087\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021088\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021089\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021090\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021091\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021092\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021093\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021094\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021095\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021096\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021097\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021098\n",
      "INFO:Loaded event: /global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021099\n",
      "INFO:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | network | Sequential | 3.2 M \n",
      "---------------------------------------\n",
      "3.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 M     Total params\n",
      "12.730    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c220024f96f47c8b4f0410c4db54822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 256 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/Embedding/embedding_base.py:300: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(cluster_true_positive / cluster_true)\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/Embedding/embedding_base.py:301: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(cluster_true_positive / cluster_positive)\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16922. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "INFO:Efficiency: 0.4007755517959595\n",
      "INFO:Purity: 0.014905945397913456\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021042']\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 12207. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "INFO:Efficiency: 0.4162086546421051\n",
      "INFO:Purity: 0.018342122435569763\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021014']\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 256 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f1ed4f206a4079807906d4dae3e28c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857c7ced8d474ae6a5f2dc39689f91b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Efficiency: 0.6803962588310242\n",
      "INFO:Purity: 0.00828118622303009\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021042']\n",
      "INFO:Efficiency: 0.7390756011009216\n",
      "INFO:Purity: 0.009020020253956318\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021014']\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 12892. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "INFO:Efficiency: 0.727024495601654\n",
      "INFO:Purity: 0.008870804682374\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021030']\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 11812. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "INFO:Efficiency: 0.7399869561195374\n",
      "INFO:Purity: 0.009006879292428493\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021018']\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 14226. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "INFO:Efficiency: 0.7122874855995178\n",
      "INFO:Purity: 0.008696620352566242\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021067']\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 13920. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "INFO:Efficiency: 0.708010733127594\n",
      "INFO:Purity: 0.008641904219985008\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021071']\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 11074. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "INFO:Efficiency: 0.74937903881073\n",
      "INFO:Purity: 0.00914228055626154\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021068']\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 12623. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "INFO:Efficiency: 0.7332288026809692\n",
      "INFO:Purity: 0.008949254639446735\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021027']\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 13937. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "INFO:Efficiency: 0.7166140675544739\n",
      "INFO:Purity: 0.008744527585804462\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021060']\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 14665. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "INFO:Efficiency: 0.7041988968849182\n",
      "INFO:Purity: 0.00858090166002512\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021051']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41dac4d5f12541bebf0804bf5f820175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Efficiency: 0.7705943584442139\n",
      "INFO:Purity: 0.009378998540341854\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021042']\n",
      "INFO:Efficiency: 0.8175511360168457\n",
      "INFO:Purity: 0.009977771900594234\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021014']\n",
      "INFO:Efficiency: 0.8134226202964783\n",
      "INFO:Purity: 0.009924993850290775\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021030']\n",
      "INFO:Efficiency: 0.8241527676582336\n",
      "INFO:Purity: 0.010031318292021751\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021018']\n",
      "INFO:Efficiency: 0.7955950498580933\n",
      "INFO:Purity: 0.009713757783174515\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021067']\n",
      "INFO:Efficiency: 0.7992573976516724\n",
      "INFO:Purity: 0.009755650535225868\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021071']\n",
      "INFO:Efficiency: 0.8290610909461975\n",
      "INFO:Purity: 0.01011438574641943\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021068']\n",
      "INFO:Efficiency: 0.820134162902832\n",
      "INFO:Purity: 0.010009958408772945\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021027']\n",
      "INFO:Efficiency: 0.7986977100372314\n",
      "INFO:Purity: 0.009746158495545387\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021060']\n",
      "INFO:Efficiency: 0.8003079891204834\n",
      "INFO:Purity: 0.009752023033797741\n",
      "INFO:['/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021051']\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:724: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "INFO:-------------------- c) Saving model --------------------\n"
     ]
    }
   ],
   "source": [
    "train_metric_learning(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Construct graphs from metric learning inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished, running inference to build graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]/global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/Embedding/embedding_base.py:300: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(cluster_true_positive / cluster_true)\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/Embedding/embedding_base.py:301: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(cluster_true_positive / cluster_positive)\n",
      "100%|██████████| 80/80 [00:45<00:00,  1.74it/s]\n",
      "100%|██████████| 10/10 [00:06<00:00,  1.49it/s]\n",
      "100%|██████████| 10/10 [00:05<00:00,  1.88it/s]\n"
     ]
    }
   ],
   "source": [
    "run_metric_learning_inference(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train graph neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:--------------------  Step 3: Running GNN training  --------------------\n",
      "INFO:-------------------- a) Initialising model --------------------\n",
      "INFO:-------------------- b) Running training --------------------\n",
      "INFO:GPU available: True, used: True\n",
      "INFO:TPU available: False, using: 0 TPU cores\n",
      "INFO:IPU available: False, using: 0 IPUs\n",
      "INFO:HPU available: False, using: 0 HPUs\n",
      "INFO:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:\n",
      "  | Name                   | Type       | Params\n",
      "------------------------------------------------------\n",
      "0 | node_encoder           | Sequential | 35.1 K\n",
      "1 | edge_encoder           | Sequential | 66.4 K\n",
      "2 | edge_network           | Sequential | 82.8 K\n",
      "3 | node_network           | Sequential | 82.8 K\n",
      "4 | output_edge_classifier | Sequential | 83.2 K\n",
      "------------------------------------------------------\n",
      "350 K     Trainable params\n",
      "0         Non-trainable params\n",
      "350 K     Total params\n",
      "1.401     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d45bff73cb4058879053761bb9f1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 15258. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 14240. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 256 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140f57a6da67437aa7784a308f49d53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fca62a6e6814463a94a551e574904a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 14728. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 14979. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 13424. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 15506. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 11085. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 14743. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 12151. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 14967. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c80653371d4743a6cf62b8dce11307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1a315409314d96b5e9455cede008ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f67a4d28cc48398bdf850c5ba96e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0629c432923c40c5b3e361e26c4b7e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba09a4e59ef414c95218fc4670cf991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84a5d75800c4affb783f7a0bcd5d2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8a39bc30c2420483a848901eb72c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ae4373961b43fbbc907f88106e46cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d419cd1493f4c8984eb100ecf627d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-hsf/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / max(1, edge_true))\n",
      "/global/u1/p/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/GNN/gnn_base.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / max(1, edge_positive))\n",
      "INFO:-------------------- c) Saving model --------------------\n"
     ]
    }
   ],
   "source": [
    "train_gnn(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: GNN inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:-------------------- Step 4: Scoring graph edges using GNN  --------------------\n",
      "INFO:-------------------- a) Loading trained model --------------------\n",
      "INFO:-------------------- b) Running inferencing --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished, running inference to filter graphs...\n",
      "Building train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 59567.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10335.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10325.71it/s]\n"
     ]
    }
   ],
   "source": [
    "run_gnn_inference(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23e238e993944c70c76d26fe3e792d9ebd61de96e06ef56dc5c2723238ec1285"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('exatrkx-hsf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
