{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from Scripts import train_metric_learning, run_metric_learning_inference, train_gnn\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = 'pipeline_config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir datasets\n",
    "!wget https://portal.nersc.gov/cfs/m3443/dtmurnane/TrackML_Example/trackml_quickstart_dataset.tar.gz -O datasets/trackml_quickstart_dataset.tar.gz\n",
    "!tar -xvf datasets/trackml_quickstart_dataset.tar.gz -C datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Train Metric Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common configurations:\n",
      "artifact_directory: artifacts\n",
      "experiment_name: trackml_quickstart_1\n",
      "gpus: 1\n",
      "max_epochs: 10\n",
      "\n",
      "Metric learning configurations:\n",
      "activation: Tanh\n",
      "cell_channels: 9\n",
      "emb_dim: 12\n",
      "emb_hidden: 1024\n",
      "factor: 0.5\n",
      "input_dir: datasets/quickstart_example_1GeV\n",
      "knn: 100\n",
      "lr: 0.001\n",
      "margin: 0.1\n",
      "nb_layer: 4\n",
      "output_dir: datasets/quickstart_metric_learning_processed\n",
      "patience: 30\n",
      "points_per_batch: 100000\n",
      "pt_background_cut: 1.0\n",
      "pt_signal_cut: 1.0\n",
      "r_test: 0.1\n",
      "r_train: 0.1\n",
      "r_val: 0.1\n",
      "randomisation: 1\n",
      "regime:\n",
      "- rp\n",
      "- hnm\n",
      "- ci\n",
      "- norm\n",
      "spatial_channels: 3\n",
      "train_split:\n",
      "- 80\n",
      "- 10\n",
      "- 10\n",
      "true_edges: modulewise_true_edges\n",
      "warmup: 5\n",
      "weight: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(CONFIG, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "print('Common configurations:')\n",
    "print(yaml.dump(config['common_configs']))\n",
    "print('Metric learning configurations:')\n",
    "print(yaml.dump(config['metric_learning_configs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocessing is handled by SLURM.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | network | Sequential | 3.2 M \n",
      "---------------------------------------\n",
      "3.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 M     Total params\n",
      "12.730    Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:06<00:06,  6.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/Embedding/embedding_base.py:300: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(cluster_true_positive / cluster_true)\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/Embedding/embedding_base.py:301: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(cluster_true_positive / cluster_positive)\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16922. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 12207. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  89%|████████▉ | 80/90 [00:16<00:02,  4.71it/s, loss=0.01, v_num=2239946]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 81/90 [00:17<00:01,  4.63it/s, loss=0.01, v_num=2239946]\n",
      "Epoch 0:  91%|█████████ | 82/90 [00:17<00:01,  4.61it/s, loss=0.01, v_num=2239946]\n",
      "Epoch 0:  92%|█████████▏| 83/90 [00:18<00:01,  4.59it/s, loss=0.01, v_num=2239946]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 12892. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:  93%|█████████▎| 84/90 [00:18<00:01,  4.58it/s, loss=0.01, v_num=2239946]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 11812. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:  94%|█████████▍| 85/90 [00:18<00:01,  4.57it/s, loss=0.01, v_num=2239946]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 14226. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:  96%|█████████▌| 86/90 [00:18<00:00,  4.56it/s, loss=0.01, v_num=2239946]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 13920. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:  97%|█████████▋| 87/90 [00:19<00:00,  4.56it/s, loss=0.01, v_num=2239946]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 11074. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:  98%|█████████▊| 88/90 [00:19<00:00,  4.55it/s, loss=0.01, v_num=2239946]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 12623. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:  99%|█████████▉| 89/90 [00:19<00:00,  4.54it/s, loss=0.01, v_num=2239946]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 13937. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 90/90 [00:19<00:00,  4.53it/s, loss=0.01, v_num=2239946]\n",
      "Epoch 1: 100%|██████████| 90/90 [00:19<00:00,  4.51it/s, loss=0.01, v_num=2239946]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 14665. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  89%|████████▉ | 80/90 [00:37<00:04,  2.15it/s, loss=0.00999, v_num=2239946]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 81/90 [00:37<00:04,  2.15it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 1:  91%|█████████ | 82/90 [00:37<00:03,  2.16it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 1:  92%|█████████▏| 83/90 [00:38<00:03,  2.17it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 1:  93%|█████████▎| 84/90 [00:38<00:02,  2.18it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 1:  94%|█████████▍| 85/90 [00:38<00:02,  2.19it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 1:  96%|█████████▌| 86/90 [00:39<00:01,  2.20it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 1:  97%|█████████▋| 87/90 [00:39<00:01,  2.22it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 1:  98%|█████████▊| 88/90 [00:39<00:00,  2.23it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 1:  99%|█████████▉| 89/90 [00:39<00:00,  2.24it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 1: 100%|██████████| 90/90 [00:40<00:00,  2.25it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 2:  89%|████████▉ | 80/90 [00:57<00:07,  1.39it/s, loss=0.00993, v_num=2239946] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 81/90 [00:57<00:06,  1.40it/s, loss=0.00993, v_num=2239946]\n",
      "Epoch 2:  91%|█████████ | 82/90 [00:58<00:05,  1.41it/s, loss=0.00993, v_num=2239946]\n",
      "Epoch 2:  92%|█████████▏| 83/90 [00:58<00:04,  1.42it/s, loss=0.00993, v_num=2239946]\n",
      "Epoch 2:  93%|█████████▎| 84/90 [00:58<00:04,  1.43it/s, loss=0.00993, v_num=2239946]\n",
      "Epoch 2:  94%|█████████▍| 85/90 [00:58<00:03,  1.44it/s, loss=0.00993, v_num=2239946]\n",
      "Epoch 2:  96%|█████████▌| 86/90 [00:59<00:02,  1.45it/s, loss=0.00993, v_num=2239946]\n",
      "Epoch 2:  97%|█████████▋| 87/90 [00:59<00:02,  1.47it/s, loss=0.00993, v_num=2239946]\n",
      "Epoch 2:  98%|█████████▊| 88/90 [00:59<00:01,  1.48it/s, loss=0.00993, v_num=2239946]\n",
      "Epoch 2:  99%|█████████▉| 89/90 [00:59<00:00,  1.49it/s, loss=0.00993, v_num=2239946]\n",
      "Epoch 2: 100%|██████████| 90/90 [01:00<00:00,  1.50it/s, loss=0.00993, v_num=2239946]\n",
      "Epoch 3:  89%|████████▉ | 80/90 [01:17<00:09,  1.03it/s, loss=0.00999, v_num=2239946] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 81/90 [01:17<00:08,  1.04it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 3:  91%|█████████ | 82/90 [01:18<00:07,  1.05it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 3:  92%|█████████▏| 83/90 [01:18<00:06,  1.06it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 3:  93%|█████████▎| 84/90 [01:18<00:05,  1.07it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 3:  94%|█████████▍| 85/90 [01:18<00:04,  1.08it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 3:  96%|█████████▌| 86/90 [01:19<00:03,  1.09it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 3:  97%|█████████▋| 87/90 [01:19<00:02,  1.09it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 3:  98%|█████████▊| 88/90 [01:19<00:01,  1.10it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 3:  99%|█████████▉| 89/90 [01:19<00:00,  1.11it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 3: 100%|██████████| 90/90 [01:20<00:00,  1.12it/s, loss=0.00999, v_num=2239946]\n",
      "Epoch 4:  89%|████████▉ | 80/90 [01:37<00:12,  1.22s/it, loss=0.00991, v_num=2239946] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  90%|█████████ | 81/90 [01:38<00:10,  1.21s/it, loss=0.00991, v_num=2239946]\n",
      "Epoch 4:  91%|█████████ | 82/90 [01:38<00:09,  1.20s/it, loss=0.00991, v_num=2239946]\n",
      "Epoch 4:  92%|█████████▏| 83/90 [01:38<00:08,  1.19s/it, loss=0.00991, v_num=2239946]\n",
      "Epoch 4:  93%|█████████▎| 84/90 [01:38<00:07,  1.18s/it, loss=0.00991, v_num=2239946]\n",
      "Epoch 4:  94%|█████████▍| 85/90 [01:39<00:05,  1.17s/it, loss=0.00991, v_num=2239946]\n",
      "Epoch 4:  96%|█████████▌| 86/90 [01:39<00:04,  1.16s/it, loss=0.00991, v_num=2239946]\n",
      "Epoch 4:  97%|█████████▋| 87/90 [01:39<00:03,  1.14s/it, loss=0.00991, v_num=2239946]\n",
      "Epoch 4:  98%|█████████▊| 88/90 [01:39<00:02,  1.13s/it, loss=0.00991, v_num=2239946]\n",
      "Epoch 4:  99%|█████████▉| 89/90 [01:40<00:01,  1.12s/it, loss=0.00991, v_num=2239946]\n",
      "Epoch 4: 100%|██████████| 90/90 [01:40<00:00,  1.12s/it, loss=0.00991, v_num=2239946]\n",
      "Epoch 5:  89%|████████▉ | 80/90 [01:57<00:14,  1.47s/it, loss=0.00992, v_num=2239946]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  90%|█████████ | 81/90 [01:57<00:13,  1.45s/it, loss=0.00992, v_num=2239946]\n",
      "Epoch 5:  91%|█████████ | 82/90 [01:58<00:11,  1.44s/it, loss=0.00992, v_num=2239946]\n",
      "Epoch 5:  92%|█████████▏| 83/90 [01:58<00:09,  1.43s/it, loss=0.00992, v_num=2239946]\n",
      "Epoch 5:  93%|█████████▎| 84/90 [01:58<00:08,  1.41s/it, loss=0.00992, v_num=2239946]\n",
      "Epoch 5:  94%|█████████▍| 85/90 [01:58<00:06,  1.40s/it, loss=0.00992, v_num=2239946]\n",
      "Epoch 5:  96%|█████████▌| 86/90 [01:59<00:05,  1.38s/it, loss=0.00992, v_num=2239946]\n",
      "Epoch 5:  97%|█████████▋| 87/90 [01:59<00:04,  1.37s/it, loss=0.00992, v_num=2239946]\n",
      "Epoch 5:  98%|█████████▊| 88/90 [01:59<00:02,  1.36s/it, loss=0.00992, v_num=2239946]\n",
      "Epoch 5:  99%|█████████▉| 89/90 [01:59<00:01,  1.35s/it, loss=0.00992, v_num=2239946]\n",
      "Epoch 5: 100%|██████████| 90/90 [02:00<00:00,  1.33s/it, loss=0.00992, v_num=2239946]\n",
      "Epoch 6:  89%|████████▉ | 80/90 [02:17<00:17,  1.71s/it, loss=0.00928, v_num=2239946]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  90%|█████████ | 81/90 [02:17<00:15,  1.70s/it, loss=0.00928, v_num=2239946]\n",
      "Epoch 6:  91%|█████████ | 82/90 [02:17<00:13,  1.68s/it, loss=0.00928, v_num=2239946]\n",
      "Epoch 6:  92%|█████████▏| 83/90 [02:18<00:11,  1.66s/it, loss=0.00928, v_num=2239946]\n",
      "Epoch 6:  93%|█████████▎| 84/90 [02:18<00:09,  1.65s/it, loss=0.00928, v_num=2239946]\n",
      "Epoch 6:  94%|█████████▍| 85/90 [02:18<00:08,  1.63s/it, loss=0.00928, v_num=2239946]\n",
      "Epoch 6:  96%|█████████▌| 86/90 [02:18<00:06,  1.61s/it, loss=0.00928, v_num=2239946]\n",
      "Epoch 6:  97%|█████████▋| 87/90 [02:18<00:04,  1.60s/it, loss=0.00928, v_num=2239946]\n",
      "Epoch 6:  98%|█████████▊| 88/90 [02:19<00:03,  1.58s/it, loss=0.00928, v_num=2239946]\n",
      "Epoch 6:  99%|█████████▉| 89/90 [02:19<00:01,  1.57s/it, loss=0.00928, v_num=2239946]\n",
      "Epoch 6: 100%|██████████| 90/90 [02:19<00:00,  1.55s/it, loss=0.00928, v_num=2239946]\n",
      "Epoch 7:  89%|████████▉ | 80/90 [02:34<00:19,  1.93s/it, loss=0.00956, v_num=2239946]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  90%|█████████ | 81/90 [02:34<00:17,  1.91s/it, loss=0.00956, v_num=2239946]\n",
      "Epoch 7:  91%|█████████ | 82/90 [02:34<00:15,  1.89s/it, loss=0.00956, v_num=2239946]\n",
      "Epoch 7:  92%|█████████▏| 83/90 [02:34<00:13,  1.87s/it, loss=0.00956, v_num=2239946]\n",
      "Epoch 7:  93%|█████████▎| 84/90 [02:35<00:11,  1.85s/it, loss=0.00956, v_num=2239946]\n",
      "Epoch 7:  94%|█████████▍| 85/90 [02:35<00:09,  1.83s/it, loss=0.00956, v_num=2239946]\n",
      "Epoch 7:  96%|█████████▌| 86/90 [02:35<00:07,  1.81s/it, loss=0.00956, v_num=2239946]\n",
      "Epoch 7:  97%|█████████▋| 87/90 [02:35<00:05,  1.79s/it, loss=0.00956, v_num=2239946]\n",
      "Epoch 7:  98%|█████████▊| 88/90 [02:35<00:03,  1.77s/it, loss=0.00956, v_num=2239946]\n",
      "Epoch 7:  99%|█████████▉| 89/90 [02:35<00:01,  1.75s/it, loss=0.00956, v_num=2239946]\n",
      "Epoch 7: 100%|██████████| 90/90 [02:35<00:00,  1.73s/it, loss=0.00956, v_num=2239946]\n",
      "Epoch 8:  89%|████████▉ | 80/90 [02:46<00:20,  2.09s/it, loss=0.00917, v_num=2239946]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  90%|█████████ | 81/90 [02:47<00:18,  2.07s/it, loss=0.00917, v_num=2239946]\n",
      "Epoch 8:  91%|█████████ | 82/90 [02:47<00:16,  2.04s/it, loss=0.00917, v_num=2239946]\n",
      "Epoch 8:  92%|█████████▏| 83/90 [02:47<00:14,  2.02s/it, loss=0.00917, v_num=2239946]\n",
      "Epoch 8:  93%|█████████▎| 84/90 [02:47<00:11,  2.00s/it, loss=0.00917, v_num=2239946]\n",
      "Epoch 8:  94%|█████████▍| 85/90 [02:47<00:09,  1.97s/it, loss=0.00917, v_num=2239946]\n",
      "Epoch 8:  96%|█████████▌| 86/90 [02:47<00:07,  1.95s/it, loss=0.00917, v_num=2239946]\n",
      "Epoch 8:  97%|█████████▋| 87/90 [02:48<00:05,  1.93s/it, loss=0.00917, v_num=2239946]\n",
      "Epoch 8:  98%|█████████▊| 88/90 [02:48<00:03,  1.91s/it, loss=0.00917, v_num=2239946]\n",
      "Epoch 8:  99%|█████████▉| 89/90 [02:48<00:01,  1.89s/it, loss=0.00917, v_num=2239946]\n",
      "Epoch 8: 100%|██████████| 90/90 [02:48<00:00,  1.87s/it, loss=0.00917, v_num=2239946]\n",
      "Epoch 9:  89%|████████▉ | 80/90 [02:59<00:22,  2.24s/it, loss=0.00834, v_num=2239946]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  90%|█████████ | 81/90 [02:59<00:19,  2.22s/it, loss=0.00834, v_num=2239946]\n",
      "Epoch 9:  91%|█████████ | 82/90 [02:59<00:17,  2.19s/it, loss=0.00834, v_num=2239946]\n",
      "Epoch 9:  92%|█████████▏| 83/90 [02:59<00:15,  2.17s/it, loss=0.00834, v_num=2239946]\n",
      "Epoch 9:  93%|█████████▎| 84/90 [02:59<00:12,  2.14s/it, loss=0.00834, v_num=2239946]\n",
      "Epoch 9:  94%|█████████▍| 85/90 [03:00<00:10,  2.12s/it, loss=0.00834, v_num=2239946]\n",
      "Epoch 9:  96%|█████████▌| 86/90 [03:00<00:08,  2.09s/it, loss=0.00834, v_num=2239946]\n",
      "Epoch 9:  97%|█████████▋| 87/90 [03:00<00:06,  2.07s/it, loss=0.00834, v_num=2239946]\n",
      "Epoch 9:  98%|█████████▊| 88/90 [03:00<00:04,  2.05s/it, loss=0.00834, v_num=2239946]\n",
      "Epoch 9:  99%|█████████▉| 89/90 [03:00<00:02,  2.03s/it, loss=0.00834, v_num=2239946]\n",
      "Epoch 9: 100%|██████████| 90/90 [03:00<00:00,  2.01s/it, loss=0.00834, v_num=2239946]\n",
      "Epoch 9: 100%|██████████| 90/90 [03:00<00:00,  2.01s/it, loss=0.00834, v_num=2239946]\n"
     ]
    }
   ],
   "source": [
    "train_metric_learning(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Construct graphs from metric learning inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished, running inference to build graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]/global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/Embedding/embedding_base.py:300: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(cluster_true_positive / cluster_true)\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/Embedding/embedding_base.py:301: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(cluster_true_positive / cluster_positive)\n",
      "100%|██████████| 80/80 [00:45<00:00,  1.74it/s]\n",
      "100%|██████████| 10/10 [00:06<00:00,  1.49it/s]\n",
      "100%|██████████| 10/10 [00:05<00:00,  1.88it/s]\n"
     ]
    }
   ],
   "source": [
    "run_metric_learning_inference(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train graph neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | network | Sequential | 3.2 M \n",
      "---------------------------------------\n",
      "3.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 M     Total params\n",
      "12.730    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 256 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/Embedding/embedding_base.py:300: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(cluster_true_positive / cluster_true)\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example/LightningModules/Embedding/embedding_base.py:301: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(cluster_true_positive / cluster_positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:01<00:01,  1.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16922. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 12207. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 256 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  92%|█████████▏| 83/90 [00:37<00:03,  2.23it/s, loss=0.01, v_num=2239949]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 12892. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  93%|█████████▎| 84/90 [00:37<00:02,  2.22it/s, loss=0.01, v_num=2239949]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 11812. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  94%|█████████▍| 85/90 [00:38<00:02,  2.21it/s, loss=0.01, v_num=2239949]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 14226. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  96%|█████████▌| 86/90 [00:38<00:01,  2.21it/s, loss=0.01, v_num=2239949]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 13920. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  97%|█████████▋| 87/90 [00:39<00:01,  2.21it/s, loss=0.01, v_num=2239949]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 11074. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  98%|█████████▊| 88/90 [00:39<00:00,  2.21it/s, loss=0.01, v_num=2239949]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 12623. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  99%|█████████▉| 89/90 [00:40<00:00,  2.21it/s, loss=0.01, v_num=2239949]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 13937. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 90/90 [00:40<00:00,  2.21it/s, loss=0.01, v_num=2239949]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx-cori/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 14665. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 90/90 [06:13<00:00,  4.15s/it, loss=0.00849, v_num=2239949]  \n"
     ]
    }
   ],
   "source": [
    "train_gnn(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d39ef2eb9ae11bd9e6af699887a383c5ad20d05dfc942a410d80659e8e5ab6e1"
  },
  "kernelspec": {
   "display_name": "ExaTrk",
   "language": "python",
   "name": "exatrk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
