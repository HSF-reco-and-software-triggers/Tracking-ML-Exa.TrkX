{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('../../../Pipelines/TrackML_Example_Full')\n",
    "sys.path.append('..')\n",
    "from LightningModules.Embedding.multi_embedding_base import EmbeddingBase\n",
    "from LightningModules.Embedding.utils import make_mlp\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimapEmbedding(EmbeddingBase):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__(hparams)\n",
    "\n",
    "        in_channels = hparams['spatial_channels'] + hparams['cell_channels']\n",
    "        self.head_network = make_mlp(in_channels, [hparams[\"emb_hidden\"]] * hparams[\"nb_layer\"] + [hparams[\"emb_dim\"]],\n",
    "            hidden_activation=hparams[\"activation\"],\n",
    "            output_activation=None,\n",
    "            layer_norm=True,\n",
    "        )\n",
    "\n",
    "        self.tail_network = make_mlp(in_channels, [hparams[\"emb_hidden\"]] * hparams[\"nb_layer\"] + [hparams[\"emb_dim\"]],\n",
    "            hidden_activation=hparams[\"activation\"],\n",
    "            output_activation=None,\n",
    "            layer_norm=True,\n",
    "        )\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        head_out = self.head_network(x)\n",
    "        tail_out = self.tail_network(x)\n",
    "\n",
    "        if \"norm\" in self.hparams[\"regime\"]:\n",
    "            return F.normalize(head_out), F.normalize(tail_out)\n",
    "        else:\n",
    "            return head_out, tail_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultimapEmbedding(\n",
       "  (head_network): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=1024, bias=True)\n",
       "    (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Tanh()\n",
       "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (4): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (7): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (8): Tanh()\n",
       "    (9): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (10): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (11): Tanh()\n",
       "    (12): Linear(in_features=1024, out_features=12, bias=True)\n",
       "  )\n",
       "  (tail_network): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=1024, bias=True)\n",
       "    (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Tanh()\n",
       "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (4): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (7): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (8): Tanh()\n",
       "    (9): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (10): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (11): Tanh()\n",
       "    (12): Linear(in_features=1024, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = '../pipeline_config_local.yaml'\n",
    "\n",
    "with open(config, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "common_configs = config['common_configs']\n",
    "metric_learning_config = config['metric_learning_configs']\n",
    "model = MultimapEmbedding(metric_learning_config)\n",
    "model.setup(stage='fit')\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = model.get_input_data( model.trainset[0] ).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    head_latent, tail_latent = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_spatial = torch.empty([2, 0], dtype=torch.int64, device=model.device)\n",
    "query_indices, query = model.get_query_points(batch, head_latent)\n",
    "\n",
    "e_spatial = model.append_hnm_pairs(e_spatial, query, query_indices, head_latent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 563794])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_spatial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12053]), torch.Size([12053, 12]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape, query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hparams['points_per_batch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([     2,      9,     17,  ..., 103232, 103234, 103239]),\n",
       " tensor([36744, 42619, 74811,  ...,  3775, 11978, 61769]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = model.trainset[0]\n",
    "\n",
    "indices = batch.signal_true_edges.unique()\n",
    "\n",
    "indices, indices[torch.randperm(len(indices))][: 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12053])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[torch.randperm(len(indices))][: 100000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[103241, 3], pid=[103241], modules=[103241], event_file='datasets/full_data/21045', hid=[103241], pt=[103241], weights=[76942], modulewise_true_edges=[2, 76942], cell_data=[103241, 9], signal_true_edges=[2, 10963])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('exatrkx-hsf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23e238e993944c70c76d26fe3e792d9ebd61de96e06ef56dc5c2723238ec1285"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
