{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44f9a128-f88a-49bb-b07c-655645c6a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, torch\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX')\n",
    "\n",
    "from Pipelines.TrackML_Example.LightningModules.GNN.Models.interaction_gnn import InteractionGNN\n",
    "from Pipelines.TrackML_Example.notebooks.build_gnn import GNNInferenceBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3661ab3d-7fbd-4818-a1da-7efa0f40d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNInferenceBuilder:\n",
    "    def __init__(self, model, overwrite=None):\n",
    "        self.model = model\n",
    "        self.output_dir = model.hparams[\"output_dir\"]\n",
    "        if overwrite is not None: \n",
    "            self.overwrite = overwrite\n",
    "        elif \"overwrite\" in model.hparams:\n",
    "            self.overwrite = model.hparams[\"overwrite\"]\n",
    "        else:\n",
    "            self.overwrite = False\n",
    "\n",
    "        # Prep the directory to produce inference data to\n",
    "        self.datatypes = [\"train\", \"val\", \"test\"]\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        [\n",
    "            os.makedirs(os.path.join(self.output_dir, datatype), exist_ok=True)\n",
    "            for datatype in self.datatypes\n",
    "        ]\n",
    "\n",
    "    def infer(self):\n",
    "        print(\"Training finished, running inference to filter graphs...\")\n",
    "\n",
    "        # By default, the set of examples propagated through the pipeline will be train+val+test set\n",
    "        datasets = {\n",
    "            \"train\": self.model.trainset,\n",
    "            \"val\": self.model.valset,\n",
    "            \"test\": self.model.testset,\n",
    "        }\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for set_idx, (datatype, dataset) in enumerate(datasets.items()):\n",
    "                print(f\"Building {datatype}\")\n",
    "                for batch in tqdm(dataset[:2]):\n",
    "                    batch = batch.to(self.model.device)\n",
    "                    batch = self.construct_downstream(batch)\n",
    "                    self.save_downstream(batch, datatype)\n",
    "\n",
    "\n",
    "    def construct_downstream(self, batch):\n",
    "        print(batch)\n",
    "\n",
    "        output = self.model.shared_evaluation(batch, 0, log=False)\n",
    "        \n",
    "        batch.scores = output[\"score\"][: int(len(output[\"score\"]) / 2)]\n",
    "        print(batch)\n",
    "        return batch\n",
    "    \n",
    "    def save_downstream(self, batch, datatype):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "495e326b-bcb8-4d67-8649-b82cce87952f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished, running inference to filter graphs...\n",
      "Building train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 46121.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 40148.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 40868.21it/s]\n"
     ]
    }
   ],
   "source": [
    "load_model = \"/global/cfs/cdirs/m3443/usr/pmtuan/Tracking-ML-Exa.TrkX/run/gnn/models/trackml_wobbly-oath-197_version_23.ckpt\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = InteractionGNN.load_from_checkpoint(load_model).to(device)\n",
    "model.setup_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa827ff8-9a9a-448a-98ad-0ee45afce9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished, running inference to filter graphs...\n",
      "Building train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[125576, 3], pid=[125576], modules=[125576], event_file='/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021000', hid=[125576], pt=[125576], weights=[96834], modulewise_true_edges=[2, 96834], cell_data=[125576, 9], signal_true_edges=[2, 13819], edge_index=[2, 93287], y=[93287], y_pid=[93287])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[125576, 3], pid=[125576], modules=[125576], event_file='/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021000', hid=[125576], pt=[125576], weights=[96834], modulewise_true_edges=[2, 96834], cell_data=[125576, 9], signal_true_edges=[2, 13819], edge_index=[2, 93287], y=[93287], y_pid=[93287], scores=[93287])\n",
      "Data(x=[120844, 3], pid=[120844], modules=[120844], event_file='/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021001', hid=[120844], pt=[120844], weights=[92848], modulewise_true_edges=[2, 92848], cell_data=[120844, 9], signal_true_edges=[2, 13039], edge_index=[2, 88508], y=[88508], y_pid=[88508])\n",
      "Data(x=[120844, 3], pid=[120844], modules=[120844], event_file='/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021001', hid=[120844], pt=[120844], weights=[92848], modulewise_true_edges=[2, 92848], cell_data=[120844, 9], signal_true_edges=[2, 13039], edge_index=[2, 88508], y=[88508], y_pid=[88508], scores=[88508])\n",
      "Building val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 14.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[116176, 3], pid=[116176], modules=[116176], event_file='/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021002', hid=[116176], pt=[116176], weights=[88801], modulewise_true_edges=[2, 88801], cell_data=[116176, 9], signal_true_edges=[2, 13854], edge_index=[2, 84407], y=[84407], y_pid=[84407])\n",
      "Data(x=[116176, 3], pid=[116176], modules=[116176], event_file='/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021002', hid=[116176], pt=[116176], weights=[88801], modulewise_true_edges=[2, 88801], cell_data=[116176, 9], signal_true_edges=[2, 13854], edge_index=[2, 84407], y=[84407], y_pid=[84407], scores=[84407])\n",
      "Data(x=[122332, 3], pid=[122332], modules=[122332], event_file='/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021007', hid=[122332], pt=[122332], weights=[94101], modulewise_true_edges=[2, 94101], cell_data=[122332, 9], signal_true_edges=[2, 13026], edge_index=[2, 89287], y=[89287], y_pid=[89287])\n",
      "Data(x=[122332, 3], pid=[122332], modules=[122332], event_file='/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021007', hid=[122332], pt=[122332], weights=[94101], modulewise_true_edges=[2, 94101], cell_data=[122332, 9], signal_true_edges=[2, 13026], edge_index=[2, 89287], y=[89287], y_pid=[89287], scores=[89287])\n",
      "Building test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[100511, 3], pid=[100511], modules=[100511], event_file='/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021005', hid=[100511], pt=[100511], weights=[74374], modulewise_true_edges=[2, 74374], cell_data=[100511, 9], signal_true_edges=[2, 10886], edge_index=[2, 63905], y=[63905], y_pid=[63905])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 18.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[100511, 3], pid=[100511], modules=[100511], event_file='/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021005', hid=[100511], pt=[100511], weights=[74374], modulewise_true_edges=[2, 74374], cell_data=[100511, 9], signal_true_edges=[2, 10886], edge_index=[2, 63905], y=[63905], y_pid=[63905], scores=[63905])\n",
      "Data(x=[88019, 3], pid=[88019], modules=[88019], event_file='/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021019', hid=[88019], pt=[88019], weights=[63061], modulewise_true_edges=[2, 63061], cell_data=[88019, 9], signal_true_edges=[2, 8365], edge_index=[2, 49670], y=[49670], y_pid=[49670])\n",
      "Data(x=[88019, 3], pid=[88019], modules=[88019], event_file='/global/cfs/cdirs/m3443/data/trackml-codalab/train_all/event000021019', hid=[88019], pt=[88019], weights=[63061], modulewise_true_edges=[2, 63061], cell_data=[88019, 9], signal_true_edges=[2, 8365], edge_index=[2, 49670], y=[49670], y_pid=[49670], scores=[49670])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "graph_scorer = GNNInferenceBuilder(model)\n",
    "graph_scorer.infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe752a11-1224-4a63-a8a7-6361ce85a7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "extrkx_hsf",
   "language": "python",
   "name": "extrkx_hsf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
