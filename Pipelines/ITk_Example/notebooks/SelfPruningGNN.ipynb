{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Pruning Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "# External imports\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import auc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "\n",
    "sys.path.append('..')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"selfpruning_gnn.yaml\") as f:\n",
    "        hparams = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 s, sys: 2.22 s, total: 22.2 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = model.trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9523)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.y.sum()/sample.modulewise_true_edges.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "edges = sample.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pid = sample.pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([154102])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pid[pid > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([341982])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 457686])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(136479)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample.pid[edges[0]] == sample.pid[edges[1]]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Memory Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.2 s, sys: 2.62 s, total: 28.8 s\n",
      "Wall time: 18.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = model.trainset[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "y = sample.pid[sample.edge_index[0]] == sample.pid[sample.edge_index[1]]\n",
    "output = model(sample.x.to(device), sample.edge_index.to(device), y.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9535369873046875 Gb\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.max_memory_allocated()/1024**3, \"Gb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Train GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmurnanedaniel\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.9<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">devoted-music-11</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/murnanedaniel/ITk_1GeV_GNN\" target=\"_blank\">https://wandb.ai/murnanedaniel/ITk_1GeV_GNN</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/murnanedaniel/ITk_1GeV_GNN/runs/huxrz4hl\" target=\"_blank\">https://wandb.ai/murnanedaniel/ITk_1GeV_GNN/runs/huxrz4hl</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20210813_173510-huxrz4hl</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name          | Type        | Params\n",
      "----------------------------------------------\n",
      "0 | input_network | Sequential  | 2.4 K \n",
      "1 | edge_network  | EdgeNetwork | 4.4 K \n",
      "2 | node_network  | NodeNetwork | 4.3 K \n",
      "----------------------------------------------\n",
      "11.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 K    Total params\n",
      "0.045     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:103: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n",
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "../LightningModules/GNN/gnn_base.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(edge_true_positive / edge_true)\n",
      "../LightningModules/GNN/gnn_base.py:157: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(edge_true_positive / edge_positive)\n",
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:103: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baea84fc6e45428abf325562da032b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba32f13371043e6a0183995382cdfad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:897: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn('Detected KeyboardInterrupt, attempting graceful shutdown...')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-93a2a62ee9b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWandbLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ITk_1GeV_GNN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"InitialTest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    458\u001b[0m         )\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mpost_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu.py\u001b[0m in \u001b[0;36mteardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# clean up memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \"\"\"\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logger = WandbLogger(project=\"ITk_1GeV_GNN\", group=\"InitialTest\")\n",
    "trainer = Trainer(gpus=1, max_epochs=10, logger=logger)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LightningModules.GNN.utils import load_dataset, random_edge_slice_v2, make_mlp\n",
    "from LightningModules.GNN.Models.agnn import EdgeNetwork, NodeNetwork\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch.utils.checkpoint import checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     1,
     10,
     25,
     31,
     37,
     43
    ]
   },
   "outputs": [],
   "source": [
    "class GNNBase(LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Initialise the Lightning Module that can scan over different GNN training regimes\n",
    "        \"\"\"\n",
    "        # Assign hyperparameters\n",
    "        self.save_hyperparameters(hparams)\n",
    "        self.hparams[\"posted_alert\"] = False\n",
    "\n",
    "    def setup(self, stage):\n",
    "        # Handle any subset of [train, val, test] data split, assuming that ordering\n",
    "        input_dirs = [None, None, None]\n",
    "        input_dirs[: len(self.hparams[\"datatype_names\"])] = [\n",
    "            os.path.join(self.hparams[\"input_dir\"], datatype)\n",
    "            for datatype in self.hparams[\"datatype_names\"]\n",
    "        ]\n",
    "        self.trainset, self.valset, self.testset = [\n",
    "            load_dataset(\n",
    "                input_dir, self.hparams[\"datatype_split\"][i], \n",
    "                self.hparams[\"pt_min\"], self.hparams[\"noise\"]\n",
    "            )\n",
    "            for i, input_dir in enumerate(input_dirs)\n",
    "        ]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        if self.trainset is not None:\n",
    "            return DataLoader(self.trainset, batch_size=1, num_workers=1)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        if self.valset is not None:\n",
    "            return DataLoader(self.valset, batch_size=1, num_workers=1)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        if self.testset is not None:\n",
    "            return DataLoader(self.testset, batch_size=1, num_workers=1)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = [\n",
    "            torch.optim.AdamW(\n",
    "                self.parameters(),\n",
    "                lr=(self.hparams[\"lr\"]),\n",
    "                betas=(0.9, 0.999),\n",
    "                eps=1e-08,\n",
    "                amsgrad=True,\n",
    "            )\n",
    "        ]\n",
    "        scheduler = [\n",
    "            {\n",
    "                \"scheduler\": torch.optim.lr_scheduler.StepLR(\n",
    "                    optimizer[0],\n",
    "                    step_size=self.hparams[\"patience\"],\n",
    "                    gamma=self.hparams[\"factor\"],\n",
    "                ),\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            }\n",
    "        ]\n",
    "        return optimizer, scheduler\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        weight = (\n",
    "            torch.tensor(self.hparams[\"weight\"])\n",
    "            if (\"weight\" in self.hparams)\n",
    "            else torch.tensor((~batch.y_pid.bool()).sum() / batch.y_pid.sum())\n",
    "        )\n",
    "\n",
    "        if \"pid\" in self.hparams[\"regime\"]:\n",
    "            y = (\n",
    "                batch.pid[batch.edge_index[0]] == batch.pid[batch.edge_index[1]]\n",
    "            )\n",
    "        else:\n",
    "            y = batch.y\n",
    "            \n",
    "        output = (\n",
    "            self(\n",
    "                torch.cat([batch.cell_data, batch.x], axis=-1), batch.edge_index\n",
    "            ).squeeze()\n",
    "            if (\"ci\" in self.hparams[\"regime\"])\n",
    "            else self(batch.x, batch.edge_index, y)\n",
    "        )\n",
    "        \n",
    "        output = torch.cat(output)\n",
    "                \n",
    "\n",
    "        if \"weighting\" in self.hparams[\"regime\"]:\n",
    "            manual_weights = batch.weights\n",
    "        else:\n",
    "            manual_weights = None\n",
    "\n",
    "#         print(output.shape, torch.repeat_interleave(y.float(), self.hparams[\"n_graph_iters\"]+1).shape)\n",
    "        \n",
    "        loss = F.binary_cross_entropy_with_logits(\n",
    "            output, y.float().repeat(self.hparams[\"n_graph_iters\"]), \n",
    "            weight=torch.repeat_interleave(((torch.arange(self.hparams[\"n_graph_iters\"])+1)/self.hparams[\"n_graph_iters\"]).to(self.device), len(y)), pos_weight=weight\n",
    "        )\n",
    "    \n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def shared_evaluation(self, batch, batch_idx):\n",
    "\n",
    "        weight = (\n",
    "            torch.tensor(self.hparams[\"weight\"])\n",
    "            if (\"weight\" in self.hparams)\n",
    "            else torch.tensor((~batch.y_pid.bool()).sum() / batch.y_pid.sum())\n",
    "        )\n",
    "        \n",
    "        if \"pid\" in self.hparams[\"regime\"]:\n",
    "            y = (\n",
    "                batch.pid[batch.edge_index[0]] == batch.pid[batch.edge_index[1]]\n",
    "            )\n",
    "        else:\n",
    "            y = batch.y\n",
    "\n",
    "        output = (\n",
    "            self(\n",
    "                torch.cat([batch.cell_data, batch.x], axis=-1), batch.edge_index\n",
    "            ).squeeze()\n",
    "            if (\"ci\" in self.hparams[\"regime\"])\n",
    "            else self(batch.x, batch.edge_index, y)\n",
    "        )\n",
    "        \n",
    "        output = output[-1]\n",
    "\n",
    "        truth = (\n",
    "            (batch.pid[batch.edge_index[0]] == batch.pid[batch.edge_index[1]]).float()\n",
    "            if \"pid\" in self.hparams[\"regime\"]\n",
    "            else batch.y\n",
    "        )\n",
    "\n",
    "        if \"weighting\" in self.hparams[\"regime\"]:\n",
    "            manual_weights = batch.weights\n",
    "        else:\n",
    "            manual_weights = None\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(\n",
    "            output, truth.float(), weight=manual_weights, pos_weight=weight\n",
    "        )\n",
    "\n",
    "        # Edge filter performance\n",
    "        preds = F.sigmoid(output) > self.hparams[\"edge_cut\"]\n",
    "        edge_positive = preds.sum().float()\n",
    "\n",
    "        edge_true = truth.sum().float()\n",
    "        edge_true_positive = (truth.bool() & preds).sum().float()\n",
    "\n",
    "        eff = torch.tensor(edge_true_positive / edge_true)\n",
    "        pur = torch.tensor(edge_true_positive / edge_positive)\n",
    "\n",
    "        current_lr = self.optimizers().param_groups[0][\"lr\"]\n",
    "        self.log_dict(\n",
    "            {\"val_loss\": loss, \"eff\": eff, \"pur\": pur, \"current_lr\": current_lr}\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"preds\": preds.cpu().numpy(),\n",
    "            \"truth\": truth.cpu().numpy(),\n",
    "        }\n",
    "\n",
    "    #         return {\"loss\": loss, \"preds\": preds, \"truth\": truth}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        outputs = self.shared_evaluation(batch, batch_idx)\n",
    "\n",
    "        return outputs[\"loss\"]\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "\n",
    "        outputs = self.shared_evaluation(batch, batch_idx)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def test_step_end(self, output_results):\n",
    "\n",
    "        print(\"Step:\", output_results)\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "\n",
    "        print(\"Epoch:\", outputs)\n",
    "\n",
    "    def optimizer_step(\n",
    "        self,\n",
    "        epoch,\n",
    "        batch_idx,\n",
    "        optimizer,\n",
    "        optimizer_idx,\n",
    "        optimizer_closure=None,\n",
    "        on_tpu=False,\n",
    "        using_native_amp=False,\n",
    "        using_lbfgs=False,\n",
    "    ):\n",
    "        # warm up lr\n",
    "        if (self.hparams[\"warmup\"] is not None) and (\n",
    "            self.trainer.global_step < self.hparams[\"warmup\"]\n",
    "        ):\n",
    "            lr_scale = min(\n",
    "                1.0, float(self.trainer.global_step + 1) / self.hparams[\"warmup\"]\n",
    "            )\n",
    "            for pg in optimizer.param_groups:\n",
    "                pg[\"lr\"] = lr_scale * self.hparams[\"lr\"]\n",
    "\n",
    "        # update params\n",
    "        optimizer.step(closure=optimizer_closure)\n",
    "        optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class PrunedAGNN(GNNBase):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__(hparams)\n",
    "        \"\"\"\n",
    "        Initialise the Lightning Module that can scan over different GNN training regimes\n",
    "        \"\"\"\n",
    "\n",
    "        # Setup input network\n",
    "        self.input_network = make_mlp(hparams[\"in_channels\"], [hparams[\"hidden\"]]*hparams[\"nb_node_layer\"],\n",
    "                                      output_activation=hparams[\"hidden_activation\"],\n",
    "                                      layer_norm=hparams[\"layernorm\"])\n",
    "\n",
    "        \n",
    "        # Setup the edge network\n",
    "        self.edge_network = EdgeNetwork(\n",
    "            hparams[\"hidden\"],\n",
    "            hparams[\"hidden\"],\n",
    "            hparams[\"nb_edge_layer\"],\n",
    "            hparams[\"hidden_activation\"],\n",
    "            hparams[\"layernorm\"],\n",
    "        )\n",
    "        \n",
    "        self.output_network = [EdgeNetwork(\n",
    "            hparams[\"hidden\"],\n",
    "            hparams[\"hidden\"],\n",
    "            hparams[\"nb_edge_layer\"],\n",
    "            hparams[\"hidden_activation\"],\n",
    "            hparams[\"layernorm\"],\n",
    "        ).to(device) for i in range(hparams[\"n_graph_iters\"])]\n",
    "        \n",
    "        # Setup the node layers\n",
    "        self.node_network = NodeNetwork(\n",
    "            hparams[\"hidden\"],\n",
    "            hparams[\"hidden\"],\n",
    "            hparams[\"nb_node_layer\"],\n",
    "            hparams[\"hidden_activation\"],\n",
    "            hparams[\"layernorm\"],\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, y):\n",
    "        input_x = x\n",
    "\n",
    "        x = self.input_network(x)\n",
    "\n",
    "        output_list = []\n",
    "        \n",
    "        # Loop over iterations of edge and node networks\n",
    "        for i in range(self.hparams[\"n_graph_iters\"]):\n",
    "            x_inital = x\n",
    "\n",
    "            # Apply edge network\n",
    "            \n",
    "            e_attention = torch.sigmoid(checkpoint(self.edge_network, x, edge_index))\n",
    "            \n",
    "            # Apply node network\n",
    "            x = checkpoint(self.node_network, x, e_attention, edge_index)\n",
    "\n",
    "            # Residual connection\n",
    "            x = x_inital + x\n",
    "            \n",
    "            e_output = checkpoint(self.output_network[i], x, edge_index)\n",
    "            output_list.append(e_output)\n",
    "            \n",
    "            precut_mask = torch.sigmoid(e_output) > self.hparams[\"precut\"]\n",
    "\n",
    "            self.log_dict(\n",
    "                {f\"precut_eff_{i}\": (precut_mask & y).sum()/y.sum(), f\"precut_pur_{i}\": (precut_mask & y).sum()/precut_mask.sum()}\n",
    "            )\n",
    "            \n",
    "#         e_output = self.output_network[-1](x, edge_index)\n",
    "#         output_list.append(e_output)\n",
    "        \n",
    "        return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MultistepAGNN(GNNBase):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__(hparams)\n",
    "        \"\"\"\n",
    "        Initialise the Lightning Module that can scan over different GNN training regimes\n",
    "        \"\"\"\n",
    "\n",
    "        # Setup input network\n",
    "        self.input_network = make_mlp(hparams[\"in_channels\"], [hparams[\"hidden\"]]*hparams[\"nb_node_layer\"],\n",
    "                                      output_activation=hparams[\"hidden_activation\"],\n",
    "                                      layer_norm=hparams[\"layernorm\"])\n",
    "\n",
    "        \n",
    "        # Setup the edge network\n",
    "        self.edge_network = EdgeNetwork(\n",
    "            hparams[\"hidden\"],\n",
    "            hparams[\"hidden\"],\n",
    "            hparams[\"nb_edge_layer\"],\n",
    "            hparams[\"hidden_activation\"],\n",
    "            hparams[\"layernorm\"],\n",
    "        )\n",
    "        \n",
    "        self.output_network = EdgeNetwork(\n",
    "            hparams[\"hidden\"],\n",
    "            hparams[\"hidden\"],\n",
    "            hparams[\"nb_edge_layer\"],\n",
    "            hparams[\"hidden_activation\"],\n",
    "            hparams[\"layernorm\"],\n",
    "        )\n",
    "        \n",
    "        # Setup the node layers\n",
    "        self.node_network = NodeNetwork(\n",
    "            hparams[\"hidden\"],\n",
    "            hparams[\"hidden\"],\n",
    "            hparams[\"nb_node_layer\"],\n",
    "            hparams[\"hidden_activation\"],\n",
    "            hparams[\"layernorm\"],\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, y):\n",
    "        input_x = x\n",
    "\n",
    "        x = self.input_network(x)\n",
    "\n",
    "        output_list = []\n",
    "        \n",
    "        # Loop over iterations of edge and node networks\n",
    "        for i in range(self.hparams[\"n_graph_iters\"]):\n",
    "            x_inital = x\n",
    "\n",
    "            # Apply edge network\n",
    "            \n",
    "            e_attention = torch.sigmoid(checkpoint(self.edge_network, x, edge_index))\n",
    "            \n",
    "            # Apply node network\n",
    "            x = checkpoint(self.node_network, x, e_attention, edge_index)\n",
    "\n",
    "            # Residual connection\n",
    "            x = x_inital + x\n",
    "            \n",
    "            e_output = checkpoint(self.output_network, x, edge_index)\n",
    "            output_list.append(e_output)\n",
    "            \n",
    "            precut_mask = torch.sigmoid(e_output) > self.hparams[\"precut\"]\n",
    "\n",
    "            self.log_dict(\n",
    "                {f\"precut_eff_{i}\": (precut_mask & y).sum()/y.sum(), f\"precut_pur_{i}\": (precut_mask & y).sum()/precut_mask.sum()}\n",
    "            )\n",
    "            \n",
    "#         e_output = self.output_network[-1](x, edge_index)\n",
    "#         output_list.append(e_output)\n",
    "        \n",
    "        return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = MultistepAGNN(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmurnanedaniel\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.9<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">electric-morning-12</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/murnanedaniel/Selfpruning_ITk_1GeV_GNN\" target=\"_blank\">https://wandb.ai/murnanedaniel/Selfpruning_ITk_1GeV_GNN</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/murnanedaniel/Selfpruning_ITk_1GeV_GNN/runs/o0fmx2s3\" target=\"_blank\">https://wandb.ai/murnanedaniel/Selfpruning_ITk_1GeV_GNN/runs/o0fmx2s3</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20210817_140559-o0fmx2s3</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name           | Type        | Params\n",
      "-----------------------------------------------\n",
      "0 | input_network  | Sequential  | 9.0 K \n",
      "1 | edge_network   | EdgeNetwork | 17.0 K\n",
      "2 | output_network | EdgeNetwork | 17.0 K\n",
      "3 | node_network   | NodeNetwork | 16.8 K\n",
      "-----------------------------------------------\n",
      "59.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "59.8 K    Total params\n",
      "0.239     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:103: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n",
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/global/homes/d/danieltm/.local/lib/python3.7/site-packages/ipykernel_launcher.py:158: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/global/homes/d/danieltm/.local/lib/python3.7/site-packages/ipykernel_launcher.py:159: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:103: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce149589d62d4a6f8971781ba5dfc117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: LightningDeprecationWarning: Relying on `self.log('val_loss', ...)` to set the ModelCheckpoint monitor is deprecated in v1.2 and will be removed in v1.4. Please, create your own `mc = ModelCheckpoint(monitor='your_monitor')` and use it as `Trainer(callbacks=[mc])`.\n",
      "  \"Relying on `self.log('val_loss', ...)` to set the ModelCheckpoint monitor is deprecated in v1.2\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:897: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn('Detected KeyboardInterrupt, attempting graceful shutdown...')\n"
     ]
    }
   ],
   "source": [
    "logger = WandbLogger(project=\"Selfpruning_ITk_1GeV_GNN\", group=\"RecurrentMultistep\")\n",
    "trainer = Trainer(gpus=1, max_epochs=20, logger=logger)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExatrkxTest",
   "language": "python",
   "name": "exatrkx-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
