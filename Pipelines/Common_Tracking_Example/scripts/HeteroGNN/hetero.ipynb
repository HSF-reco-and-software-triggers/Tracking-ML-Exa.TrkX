{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/usr/pmtuan/conda/extrkx_hsf_clone/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import yaml, os\n",
    "import matplotlib, seaborn as sns\n",
    "from torch_geometric.data import HeteroData\n",
    "from pytorch_lightning import LightningModule\n",
    "from itertools import combinations_with_replacement, product\n",
    "from typing import Dict, Optional\n",
    "from torch import Tensor\n",
    "from torch_geometric.typing import Adj, EdgeType, NodeType\n",
    "import pdb\n",
    "%matplotlib inline\n",
    "\n",
    "CONFIGFILE = \"hetero_reg3_lev3.yaml\"\n",
    "with open(CONFIGFILE, 'r') as f: config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "# data_dir = config['input_dir'] + '/train'\n",
    "# data = torch.load(os.path.join(data_dir, os.listdir(data_dir)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_dataset, LargeDataset, background_cut_event, make_mlp\n",
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region(model):\n",
    "    return 'volume_' + '_'.join([str(i) for i in model['volume_ids']])\n",
    "\n",
    "class LargeHeteroDataset(LargeDataset):\n",
    "    def __init__(self, root, subdir, num_events, hparams, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, subdir, num_events, hparams, transform, pre_transform, pre_filter)\n",
    "\n",
    "    # def get_region(self, model):\n",
    "    #     return 'region_' + '_'.join([str(i) for i in model['volume_ids']])\n",
    "\n",
    "    def get(self, idx):\n",
    "        \n",
    "        event = torch.load(self.input_paths[idx], map_location=torch.device('cpu'))\n",
    "\n",
    "        # Process event with pt cuts\n",
    "        if self.hparams[\"pt_background_cut\"] > 0:\n",
    "            event = background_cut_event(event, self.hparams[\"pt_background_cut\"], self.hparams[\"pt_signal_cut\"])\n",
    "        \n",
    "        # Ensure PID definition is correct\n",
    "        event.y_pid = (event.pid[event.edge_index[0]] == event.pid[event.edge_index[1]]) & event.pid[event.edge_index[0]].bool()\n",
    "        event.pid_signal = torch.isin(event.edge_index, event.signal_true_edges).all(0) & event.y_pid\n",
    "\n",
    "        # create new hit map\n",
    "        models = config['model_ids']\n",
    "        map = torch.ones_like(event.hid) * -1\n",
    "        for model in self.hparams['model_ids']:\n",
    "            volume_id = model['volume_ids']\n",
    "            homo_ids = event.hid[ torch.isin( event.volume_id, torch.tensor(volume_id) ) ]\n",
    "            # print(homo_ids)\n",
    "            # map = torch.ones((torch.max(homo_ids)+1,), dtype=torch.long) * -1\n",
    "            # print(map)\n",
    "            map[homo_ids] = torch.arange(homo_ids.shape[0])\n",
    "            # print(map)\n",
    "        \n",
    "\n",
    "        data = HeteroData()\n",
    "        for _, model in enumerate(self.hparams['model_ids']):\n",
    "            region = get_region(model)\n",
    "            mask = torch.isin( event.volume_id, torch.tensor(model['volume_ids']) )\n",
    "            for attr in ['x', 'cell_data', 'pid', 'hid', 'pt', 'primary', 'nhits', 'modules', 'volume_id']:\n",
    "                data[region][attr] = event[attr][mask]\n",
    "            data[region]['mask'] = mask\n",
    "        \n",
    "        for model1, model2 in product(self.hparams['model_ids'], self.hparams['model_ids']):\n",
    "            # ids = torch.tensor([model1['volume_ids'], model2['volume_ids']])\n",
    "            id0, id1 = torch.tensor([model1['volume_ids']]), torch.tensor([model2['volume_ids']])\n",
    "            region1, region2 = get_region(model1), get_region(model2)\n",
    "            mask1 = torch.isin(event.volume_id[event.edge_index[0]], id0)\n",
    "            mask2 = torch.isin(event.volume_id[event.edge_index[1]], id1)\n",
    "            mask = mask1 * mask2 #+ torch.isin(event.volume_id[event.edge_index[0]], id2) * torch.isin(event.volume_id[event.edge_index[1]],id1)\n",
    "            edge_index = event.edge_index.T[mask].T\n",
    "            edge_index = map[edge_index]\n",
    "            data[region1, 'connected_to', region2].edge_index = edge_index\n",
    "            data[region1, 'connected_to', region2].y = event.y[mask]\n",
    "            data[region1, 'connected_to', region2].y_pid = event.y_pid[mask]\n",
    "            for truth_edge in ['modulewise_true_edges', 'signal_true_edges']:\n",
    "                mask = torch.isin(event.volume_id[event[truth_edge][0]], id0) * torch.isin(event.volume_id[event[truth_edge][1]], id1) #+ torch.isin(event.volume_id[event[truth_edge][0]], id2) * torch.isin(event.volume_id[event[truth_edge][1]], id1)\n",
    "                data[region1, 'connected_to', region2][truth_edge] = event[truth_edge].T[mask].T\n",
    "        return data, self.input_paths[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LargeHeteroDataset(root=config['input_dir'], subdir='train', num_events=1, hparams=config)\n",
    "data, input_dir = dataset.get(0)\n",
    "homo_data = torch.load(input_dir)\n",
    "# undirected_data = T.ToUndirected()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mvolume_0_1\u001b[0m={\n",
       "    x=[248396, 9],\n",
       "    cell_data=[248396, 11],\n",
       "    pid=[248396],\n",
       "    hid=[248396],\n",
       "    pt=[248396],\n",
       "    primary=[248396],\n",
       "    nhits=[248396],\n",
       "    modules=[248396],\n",
       "    volume_id=[248396],\n",
       "    mask=[326917]\n",
       "  },\n",
       "  \u001b[1mvolume_2\u001b[0m={\n",
       "    x=[40883, 9],\n",
       "    cell_data=[40883, 11],\n",
       "    pid=[40883],\n",
       "    hid=[40883],\n",
       "    pt=[40883],\n",
       "    primary=[40883],\n",
       "    nhits=[40883],\n",
       "    modules=[40883],\n",
       "    volume_id=[40883],\n",
       "    mask=[326917]\n",
       "  },\n",
       "  \u001b[1mvolume_3\u001b[0m={\n",
       "    x=[37638, 9],\n",
       "    cell_data=[37638, 11],\n",
       "    pid=[37638],\n",
       "    hid=[37638],\n",
       "    pt=[37638],\n",
       "    primary=[37638],\n",
       "    nhits=[37638],\n",
       "    modules=[37638],\n",
       "    volume_id=[37638],\n",
       "    mask=[326917]\n",
       "  },\n",
       "  \u001b[1m(volume_0_1, connected_to, volume_0_1)\u001b[0m={\n",
       "    edge_index=[2, 292516],\n",
       "    y=[292516],\n",
       "    y_pid=[292516],\n",
       "    modulewise_true_edges=[2, 104922],\n",
       "    signal_true_edges=[2, 11008]\n",
       "  },\n",
       "  \u001b[1m(volume_0_1, connected_to, volume_2)\u001b[0m={\n",
       "    edge_index=[2, 22346],\n",
       "    y=[22346],\n",
       "    y_pid=[22346],\n",
       "    modulewise_true_edges=[2, 3695],\n",
       "    signal_true_edges=[2, 653]\n",
       "  },\n",
       "  \u001b[1m(volume_0_1, connected_to, volume_3)\u001b[0m={\n",
       "    edge_index=[2, 10604],\n",
       "    y=[10604],\n",
       "    y_pid=[10604],\n",
       "    modulewise_true_edges=[2, 3045],\n",
       "    signal_true_edges=[2, 197]\n",
       "  },\n",
       "  \u001b[1m(volume_2, connected_to, volume_0_1)\u001b[0m={\n",
       "    edge_index=[2, 24792],\n",
       "    y=[24792],\n",
       "    y_pid=[24792],\n",
       "    modulewise_true_edges=[2, 57],\n",
       "    signal_true_edges=[2, 0]\n",
       "  },\n",
       "  \u001b[1m(volume_2, connected_to, volume_2)\u001b[0m={\n",
       "    edge_index=[2, 66930],\n",
       "    y=[66930],\n",
       "    y_pid=[66930],\n",
       "    modulewise_true_edges=[2, 6563],\n",
       "    signal_true_edges=[2, 1318]\n",
       "  },\n",
       "  \u001b[1m(volume_2, connected_to, volume_3)\u001b[0m={\n",
       "    edge_index=[2, 7323],\n",
       "    y=[7323],\n",
       "    y_pid=[7323],\n",
       "    modulewise_true_edges=[2, 1123],\n",
       "    signal_true_edges=[2, 205]\n",
       "  },\n",
       "  \u001b[1m(volume_3, connected_to, volume_0_1)\u001b[0m={\n",
       "    edge_index=[2, 11243],\n",
       "    y=[11243],\n",
       "    y_pid=[11243],\n",
       "    modulewise_true_edges=[2, 5],\n",
       "    signal_true_edges=[2, 0]\n",
       "  },\n",
       "  \u001b[1m(volume_3, connected_to, volume_2)\u001b[0m={\n",
       "    edge_index=[2, 7207],\n",
       "    y=[7207],\n",
       "    y_pid=[7207],\n",
       "    modulewise_true_edges=[2, 3],\n",
       "    signal_true_edges=[2, 0]\n",
       "  },\n",
       "  \u001b[1m(volume_3, connected_to, volume_3)\u001b[0m={\n",
       "    edge_index=[2, 27402],\n",
       "    y=[27402],\n",
       "    y_pid=[27402],\n",
       "    modulewise_true_edges=[2, 7766],\n",
       "    signal_true_edges=[2, 931]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import HeteroConv, HeteroLinear, MLP, GCNConv, MessagePassing, to_hetero\n",
    "from torch.nn import Module, ModuleDict\n",
    "from collections import defaultdict\n",
    "\n",
    "class NodeEncoder(torch.nn.Module):\n",
    "    def __init__(self, hparams, model) -> None:\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "\n",
    "        self.network = make_mlp(\n",
    "            model['num_features'],\n",
    "            [hparams[\"hidden\"]] * hparams[\"nb_node_layer\"],\n",
    "            output_activation=hparams[\"output_activation\"],\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "            layer_norm=hparams[\"layernorm\"],\n",
    "            batch_norm=hparams[\"batchnorm\"],\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return  self.network( x.float() )\n",
    "    \n",
    "class HeteroNodeEncoder(torch.nn.Module):\n",
    "    def __init__(self, hparams) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.hparams = hparams\n",
    "\n",
    "        self.encoders = torch.nn.ModuleDict()\n",
    "        for model in self.hparams['model_ids']:\n",
    "            region = get_region(model)\n",
    "            self.encoders[region] = NodeEncoder(self.hparams, model)\n",
    "        \n",
    "    def forward(self, x_dict):\n",
    "        for model in self.hparams['model_ids']:\n",
    "            region = get_region(model)\n",
    "            print(region)\n",
    "            x_dict[region] = self.encoders[region](x_dict[region][:, : model['num_features']])\n",
    "        \n",
    "        return x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'volume_0_1': tensor([[ 0.4559, -0.6419, -0.2931,  ...,  0.0601,  0.2524,  0.7009],\n",
       "         [ 0.4751, -0.6559, -0.3046,  ...,  0.0529,  0.2268,  0.7113],\n",
       "         [ 0.4322, -0.6406, -0.2763,  ...,  0.0861,  0.2159,  0.7096],\n",
       "         ...,\n",
       "         [-0.9515, -0.9330, -0.9221,  ..., -0.2887,  0.8334, -0.8976],\n",
       "         [-0.9532, -0.9333, -0.9220,  ..., -0.2904,  0.8344, -0.8974],\n",
       "         [-0.9538, -0.9331, -0.9231,  ..., -0.2832,  0.8338, -0.8953]],\n",
       "        grad_fn=<TanhBackward0>),\n",
       " 'volume_2': tensor([[ 0.5418,  0.9371,  0.8508,  ..., -0.9120,  0.1569,  0.0486],\n",
       "         [ 0.5762,  0.9358,  0.8506,  ..., -0.9064,  0.1539,  0.0734],\n",
       "         [ 0.4515,  0.9366,  0.8540,  ..., -0.9223,  0.1309, -0.0043],\n",
       "         ...,\n",
       "         [ 0.3760, -0.8509, -0.4800,  ..., -0.7841,  0.7006, -0.4799],\n",
       "         [ 0.3826, -0.8437, -0.4772,  ..., -0.7881,  0.7012, -0.4746],\n",
       "         [ 0.4670, -0.7989, -0.5056,  ..., -0.8094,  0.7284, -0.4121]],\n",
       "        grad_fn=<TanhBackward0>),\n",
       " 'volume_3': tensor([[ 0.9449, -0.5705, -0.1779,  ..., -0.8334, -0.7380, -0.6303],\n",
       "         [ 0.9434, -0.5818, -0.1685,  ..., -0.8169, -0.7216, -0.6515],\n",
       "         [-0.9647, -0.7614, -0.7734,  ...,  0.6438,  0.8145,  0.9178],\n",
       "         ...,\n",
       "         [-0.6866,  0.5762,  0.2488,  ...,  0.1966,  0.4573, -0.2291],\n",
       "         [-0.6867,  0.5768,  0.2484,  ...,  0.1968,  0.4576, -0.2287],\n",
       "         [-0.6844,  0.5716,  0.2501,  ...,  0.2090,  0.4463, -0.2421]],\n",
       "        grad_fn=<TanhBackward0>)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = HeteroNodeEncoder(hparams=config)\n",
    "\n",
    "encoder(data.x_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeEncoder(torch.nn.Module):\n",
    "    def __init__(self, hparams) -> None:\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "\n",
    "        self.network = make_mlp(\n",
    "            2 * hparams['hidden'],\n",
    "            [hparams[\"hidden\"]] * hparams[\"nb_node_layer\"],\n",
    "            output_activation=hparams[\"output_activation\"],\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "            layer_norm=hparams[\"layernorm\"],\n",
    "            batch_norm=hparams[\"batchnorm\"],\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        src, dst = edge_index\n",
    "        print(\"Encoding edges\")\n",
    "        if isinstance(x, tuple):\n",
    "            x1, x2 = x\n",
    "            x_in = torch.cat([x1[src], x2[dst]], dim=-1)\n",
    "        else:\n",
    "            x_in = torch.cat([x[src], x[dst]], dim=-1)\n",
    "\n",
    "        return  self.network( x_in )\n",
    "\n",
    "class HeteroEdgeConv(HeteroConv):\n",
    "\n",
    "    def __init__(self, convs: dict, aggr: str = \"sum\"):\n",
    "        super().__init__(convs, aggr)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_dict: dict,\n",
    "        edge_index_dict: dict,\n",
    "        *args_dict,\n",
    "        **kwargs_dict,\n",
    "    ) -> dict :\n",
    "\n",
    "        out_dict = {}\n",
    "        for edge_type, edge_index in edge_index_dict.items():\n",
    "            print(edge_type)\n",
    "            src, rel, dst = edge_type\n",
    "\n",
    "            str_edge_type = '__'.join(edge_type)\n",
    "            if str_edge_type not in self.convs:\n",
    "                continue\n",
    "\n",
    "            args = []\n",
    "            for value_dict in args_dict:\n",
    "                if edge_type in value_dict:\n",
    "                    args.append(value_dict[edge_type])\n",
    "                elif src == dst and src in value_dict:\n",
    "                    args.append(value_dict[src])\n",
    "                elif src in value_dict or dst in value_dict:\n",
    "                    args.append(\n",
    "                        (value_dict.get(src, None), value_dict.get(dst, None)))\n",
    "\n",
    "            kwargs = {}\n",
    "            for arg, value_dict in kwargs_dict.items():\n",
    "                arg = arg[:-5]  # `{*}_dict`\n",
    "                if edge_type in value_dict:\n",
    "                    kwargs[arg] = value_dict[edge_type]\n",
    "                elif src == dst and src in value_dict:\n",
    "                    kwargs[arg] = value_dict[src]\n",
    "                elif src in value_dict or dst in value_dict:\n",
    "                    kwargs[arg] = (value_dict.get(src, None),\n",
    "                                value_dict.get(dst, None))\n",
    "\n",
    "            conv = self.convs[str_edge_type]\n",
    "            print(kwargs)\n",
    "\n",
    "            if src == dst:\n",
    "                out = conv(x_dict[src], edge_index, *args, **kwargs)\n",
    "            else:\n",
    "                out = conv((x_dict[src], x_dict[dst]), edge_index, *args, **kwargs)\n",
    "\n",
    "            out_dict[edge_type] = out\n",
    "\n",
    "        return out_dict\n",
    "\n",
    "class EdgeClassifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = make_mlp(\n",
    "            3 * hparams[\"hidden\"],\n",
    "            [hparams[\"hidden\"]] * hparams[\"nb_edge_layer\"] + [1],\n",
    "            layer_norm=hparams[\"layernorm\"],\n",
    "            batch_norm=hparams[\"batchnorm\"],\n",
    "            output_activation=hparams['output_activation'],\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge):\n",
    "        src, dst = edge_index\n",
    "        if isinstance(x, tuple):\n",
    "            x1, x2 = x\n",
    "            classifier_input = torch.cat([x1[src], x2[dst], edge], dim=-1)\n",
    "        else:\n",
    "            classifier_input = torch.cat([x[src], x[dst], edge], dim=-1)\n",
    "        # classifier_input = torch.cat([x[src], x[dst], edge], dim=-1)\n",
    "        return self.network(classifier_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionMessagePassing(MessagePassing):\n",
    "    def __init__(self, hparams, aggr: str = \"add\", flow: str = \"source_to_target\", node_dim: int = -2, decomposed_layers: int = 1):\n",
    "        super().__init__(aggr, flow=flow, node_dim=node_dim, decomposed_layers=decomposed_layers)\n",
    "\n",
    "        self.hparams=hparams\n",
    "\n",
    "        # The edge network computes new edge features from connected nodes\n",
    "        self.edge_encoder = make_mlp(\n",
    "            2 * (hparams[\"hidden\"]),\n",
    "            [hparams[\"hidden\"]] * hparams[\"nb_edge_layer\"],\n",
    "            layer_norm=hparams[\"layernorm\"],\n",
    "            batch_norm=hparams[\"batchnorm\"],\n",
    "            output_activation=hparams[\"output_activation\"],\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "        )\n",
    "\n",
    "        # The edge network computes new edge features from connected nodes\n",
    "        self.edge_network = make_mlp(\n",
    "            3 * hparams[\"hidden\"],\n",
    "            [hparams[\"hidden\"]] * hparams[\"nb_edge_layer\"],\n",
    "            layer_norm=hparams[\"layernorm\"],\n",
    "            batch_norm=hparams[\"batchnorm\"],\n",
    "            output_activation=hparams[\"output_activation\"],\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "        )\n",
    "\n",
    "        # The node network computes new node features\n",
    "        self.node_network = make_mlp(\n",
    "            2 * hparams[\"hidden\"],\n",
    "            [hparams[\"hidden\"]] * hparams[\"nb_node_layer\"],\n",
    "            layer_norm=hparams[\"layernorm\"],\n",
    "            batch_norm=hparams[\"batchnorm\"],\n",
    "            output_activation=hparams[\"output_activation\"],\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "        )\n",
    "\n",
    "    def message(self, edge):\n",
    "        return edge\n",
    "\n",
    "    def aggregate(self, out, edge_index):\n",
    "\n",
    "        src, dst = edge_index\n",
    "        return self.aggr_module(out, dst)[dst.unique()]\n",
    "    \n",
    "    def update(self, agg_message, x, edge_index):\n",
    "        src, dst = edge_index\n",
    "        indices_to_add = torch.arange(agg_message.shape[0])\n",
    "        print(dst.unique())\n",
    "        print(x)\n",
    "        x[dst.unique()] += agg_message\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def edge_update(self, x, edge, edge_index, *args, **kwargs):\n",
    "        src, dst = edge_index\n",
    "        if isinstance(x, tuple):\n",
    "            x_src, x_dst = x[0][src], x[1][dst]\n",
    "        else:\n",
    "            x_src, x_dst = x[src], x[dst]\n",
    "        out = self.edge_network(torch.cat([x_src, x_dst, edge], dim=-1))\n",
    "        return out\n",
    "\n",
    "    def forward(self, x, edge_index, edge):\n",
    "\n",
    "        if isinstance(x, tuple):\n",
    "            x_src, x_dst = x\n",
    "        else:\n",
    "            x_src, x_dst = x, x\n",
    "\n",
    "        x_dst = self.propagate(edge_index, x=x_dst, edge=edge)\n",
    "\n",
    "        return x_dst\n",
    "\n",
    "class InteractionHeteroConv(HeteroConv):\n",
    "    def __init__(self, convs: Dict[EdgeType, Module], aggr: Optional[str] = \"sum\"):\n",
    "        super().__init__(convs, aggr)\n",
    "\n",
    "    def edge_forward(self,x_dict: Dict[NodeType, Tensor],\n",
    "        edge_index_dict: Dict[EdgeType, Adj],\n",
    "        edge_dict,\n",
    "        *args_dict,\n",
    "        **kwargs_dict,\n",
    "    ) -> Dict[NodeType, Tensor]:\n",
    "\n",
    "        out_dict = {}\n",
    "        for edge_type, edge_index in edge_index_dict.items():\n",
    "            print(edge_type)\n",
    "            src, rel, dst = edge_type\n",
    "\n",
    "            str_edge_type = '__'.join(edge_type)\n",
    "            if str_edge_type not in self.convs:\n",
    "                continue\n",
    "\n",
    "            args = []\n",
    "            for value_dict in args_dict:\n",
    "                if edge_type in value_dict:\n",
    "                    args.append(value_dict[edge_type])\n",
    "                elif src == dst and src in value_dict:\n",
    "                    args.append(value_dict[src])\n",
    "                elif src in value_dict or dst in value_dict:\n",
    "                    args.append(\n",
    "                        (value_dict.get(src, None), value_dict.get(dst, None)))\n",
    "\n",
    "            kwargs = {}\n",
    "            for arg, value_dict in kwargs_dict.items():\n",
    "                arg = arg[:-5]  # `{*}_dict`\n",
    "                if edge_type in value_dict:\n",
    "                    kwargs[arg] = value_dict[edge_type]\n",
    "                elif src == dst and src in value_dict:\n",
    "                    kwargs[arg] = value_dict[src]\n",
    "                elif src in value_dict or dst in value_dict:\n",
    "                    kwargs[arg] = (value_dict.get(src, None),\n",
    "                                value_dict.get(dst, None))\n",
    "\n",
    "            conv = self.convs[str_edge_type]\n",
    "            edge = edge_dict[edge_type]\n",
    "\n",
    "            out = conv.edge_update((x_dict[src], x_dict[dst]), edge, edge_index, *args, **kwargs)\n",
    "\n",
    "            # if src == dst:\n",
    "            #     out = conv.edge_updater(x_dict[src], edge_index, *args, **kwargs)\n",
    "            # else:\n",
    "            #     out = conv.edge_update((x_dict[src], x_dict[dst]), edge_index, *args,\n",
    "            #             **kwargs)\n",
    "\n",
    "            out_dict[edge_type] = out\n",
    "\n",
    "        return out_dict\n",
    "\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        self.node_encoders = HeteroNodeEncoder(self.hparams)\n",
    "        self.edge_encoders = HeteroEdgeConv({\n",
    "            (get_region(model0), 'connected_to', get_region(model1)): EdgeEncoder(self.hparams)\n",
    "            for model0, model1 in product(self.hparams['model_ids'], self.hparams['model_ids'])\n",
    "        })\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "\n",
    "        for _ in range(1):\n",
    "            conv = InteractionHeteroConv({\n",
    "                (get_region(model0), 'connected_to', get_region(model1)): InteractionMessagePassing(hparams=self.hparams)\n",
    "                for model0, model1 in product(self.hparams['model_ids'], self.hparams['model_ids'])\n",
    "            }, aggr='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.edge_classifiers = HeteroEdgeConv({\n",
    "            (get_region(model0), 'connected_to', get_region(model1)): EdgeClassifier(self.hparams)\n",
    "            for model0, model1 in combinations_with_replacement(self.hparams['model_ids'], 2)\n",
    "        })\n",
    "\n",
    "\n",
    "    def forward(self, x_dict: dict, edge_index_dict: dict):\n",
    "        x_dict = self.node_encoders(x_dict)  \n",
    "        edge_dict = self.edge_encoders(x_dict, edge_index_dict) \n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict, edge_dict=edge_dict)\n",
    "            edge_dict = conv.edge_forward(x_dict, edge_index_dict, edge_dict)\n",
    "\n",
    "        out = self.edge_classifiers(x_dict, edge_index_dict, edge_dict=edge_dict)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume_0_1\n",
      "volume_2\n",
      "volume_3\n",
      "('volume_0_1', 'connected_to', 'volume_0_1')\n",
      "{}\n",
      "Encoding edges\n",
      "('volume_0_1', 'connected_to', 'volume_2')\n",
      "{}\n",
      "Encoding edges\n",
      "('volume_0_1', 'connected_to', 'volume_3')\n",
      "{}\n",
      "Encoding edges\n",
      "('volume_2', 'connected_to', 'volume_0_1')\n",
      "{}\n",
      "Encoding edges\n",
      "('volume_2', 'connected_to', 'volume_2')\n",
      "{}\n",
      "Encoding edges\n",
      "('volume_2', 'connected_to', 'volume_3')\n",
      "{}\n",
      "Encoding edges\n",
      "('volume_3', 'connected_to', 'volume_0_1')\n",
      "{}\n",
      "Encoding edges\n",
      "('volume_3', 'connected_to', 'volume_2')\n",
      "{}\n",
      "Encoding edges\n",
      "('volume_3', 'connected_to', 'volume_3')\n",
      "{}\n",
      "Encoding edges\n",
      "tensor([     0,      1,      7,  ..., 248383, 248392, 248393])\n",
      "tensor([[-0.7312, -0.8284,  0.6658,  ...,  0.5697, -0.7187,  0.6371],\n",
      "        [-0.7490, -0.8317,  0.6773,  ...,  0.5903, -0.7170,  0.6186],\n",
      "        [-0.7228, -0.8311,  0.6851,  ...,  0.5611, -0.7352,  0.6047],\n",
      "        ...,\n",
      "        [-0.0284,  0.5865, -0.4600,  ..., -0.0034, -0.4285, -0.6854],\n",
      "        [-0.0325,  0.5808, -0.4714,  ...,  0.0044, -0.4312, -0.6718],\n",
      "        [-0.0323,  0.5804, -0.4669,  ...,  0.0028, -0.4338, -0.6771]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "tensor([    0,     1,     2,  ..., 29669, 29683, 38114])\n",
      "tensor([[ 0.1814,  0.9176,  0.5984,  ...,  0.0336,  0.3571,  0.9838],\n",
      "        [ 0.1547,  0.9182,  0.6008,  ...,  0.0276,  0.3535,  0.9846],\n",
      "        [ 0.2559,  0.9166,  0.5776,  ...,  0.0560,  0.3830,  0.9804],\n",
      "        ...,\n",
      "        [-0.6197, -0.5166, -0.9759,  ..., -0.7613, -0.6849, -0.3590],\n",
      "        [-0.6221, -0.5096, -0.9762,  ..., -0.7587, -0.6812, -0.3597],\n",
      "        [-0.6756, -0.4891, -0.9785,  ..., -0.7720, -0.6649, -0.3556]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "tensor([    1,     2,     3,  ..., 36743, 36744, 36745])\n",
      "tensor([[ 0.0340, -0.1822,  0.7388,  ..., -0.8632,  0.2089,  0.9547],\n",
      "        [-0.0552, -0.2036,  0.7231,  ..., -0.8776,  0.1110,  0.9480],\n",
      "        [ 0.8863, -0.3789, -0.2497,  ...,  0.5101,  0.6395, -0.5048],\n",
      "        ...,\n",
      "        [-0.2224,  0.7990, -0.5803,  ...,  0.7784, -0.9003, -0.9637],\n",
      "        [-0.2223,  0.7988, -0.5804,  ...,  0.7785, -0.9003, -0.9637],\n",
      "        [-0.2359,  0.8000, -0.5721,  ...,  0.7766, -0.8995, -0.9628]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "tensor([ 89143, 120150, 120153,  ..., 161140, 161143, 161160])\n",
      "tensor([[-1.7063, -0.6340, -0.3610,  ...,  2.4751,  0.2613, -1.0903],\n",
      "        [-0.7977, -0.9204, -0.1898,  ...,  1.4238, -0.1067, -0.2911],\n",
      "        [-0.7228, -0.8311,  0.6851,  ...,  0.5611, -0.7352,  0.6047],\n",
      "        ...,\n",
      "        [ 0.6775,  0.6788, -0.5529,  ..., -0.4357, -0.9795, -0.9343],\n",
      "        [-0.0325,  0.5808, -0.4714,  ...,  0.0044, -0.4312, -0.6718],\n",
      "        [-0.0323,  0.5804, -0.4669,  ...,  0.0028, -0.4338, -0.6771]],\n",
      "       grad_fn=<IndexPutBackward0>)\n",
      "tensor([   88,    89,    90,  ..., 40878, 40879, 40882])\n",
      "tensor([[-0.6589,  0.1428,  0.2648,  ...,  0.5268, -0.4797,  1.6115],\n",
      "        [-1.5695, -0.5946,  0.0908,  ...,  0.9878, -1.1994,  2.2528],\n",
      "        [-1.3649, -0.7882, -0.2333,  ...,  0.9635, -1.3492,  2.1813],\n",
      "        ...,\n",
      "        [-0.6197, -0.5166, -0.9759,  ..., -0.7613, -0.6849, -0.3590],\n",
      "        [-0.6221, -0.5096, -0.9762,  ..., -0.7587, -0.6812, -0.3597],\n",
      "        [-0.6756, -0.4891, -0.9785,  ..., -0.7720, -0.6649, -0.3556]],\n",
      "       grad_fn=<IndexPutBackward0>)\n",
      "tensor([    6,    13,    14,  ..., 24807, 26094, 26222])\n",
      "tensor([[ 0.0340, -0.1822,  0.7388,  ..., -0.8632,  0.2089,  0.9547],\n",
      "        [ 0.8024,  0.2778,  0.3149,  ..., -0.2433,  0.5942,  0.8303],\n",
      "        [ 1.4961,  0.4998,  0.2129,  ..., -0.3357,  1.5609,  0.4122],\n",
      "        ...,\n",
      "        [-0.2224,  0.7990, -0.5803,  ...,  0.7784, -0.9003, -0.9637],\n",
      "        [-0.2223,  0.7988, -0.5804,  ...,  0.7785, -0.9003, -0.9637],\n",
      "        [-0.2359,  0.8000, -0.5721,  ...,  0.7766, -0.8995, -0.9628]],\n",
      "       grad_fn=<IndexPutBackward0>)\n",
      "tensor([ 77036,  78203,  78204,  ..., 248349, 248352, 248358])\n",
      "tensor([[-1.7063, -0.6340, -0.3610,  ...,  2.4751,  0.2613, -1.0903],\n",
      "        [-0.7977, -0.9204, -0.1898,  ...,  1.4238, -0.1067, -0.2911],\n",
      "        [-0.7228, -0.8311,  0.6851,  ...,  0.5611, -0.7352,  0.6047],\n",
      "        ...,\n",
      "        [ 0.6775,  0.6788, -0.5529,  ..., -0.4357, -0.9795, -0.9343],\n",
      "        [-0.0325,  0.5808, -0.4714,  ...,  0.0044, -0.4312, -0.6718],\n",
      "        [-0.0323,  0.5804, -0.4669,  ...,  0.0028, -0.4338, -0.6771]],\n",
      "       grad_fn=<IndexPutBackward0>)\n",
      "tensor([    2,     3,     4,  ..., 35087, 35093, 35094])\n",
      "tensor([[-0.6589,  0.1428,  0.2648,  ...,  0.5268, -0.4797,  1.6115],\n",
      "        [-1.5695, -0.5946,  0.0908,  ...,  0.9878, -1.1994,  2.2528],\n",
      "        [-1.3649, -0.7882, -0.2333,  ...,  0.9635, -1.3492,  2.1813],\n",
      "        ...,\n",
      "        [-0.6197, -0.5166, -0.9759,  ..., -0.7613, -0.6849, -0.3590],\n",
      "        [-0.6221, -0.5096, -0.9762,  ..., -0.7587, -0.6812, -0.3597],\n",
      "        [-3.7118,  1.9994,  2.6913,  ...,  0.8954,  0.2900,  3.5230]],\n",
      "       grad_fn=<IndexPutBackward0>)\n",
      "tensor([    1,     2,     4,  ..., 37605, 37611, 37632])\n",
      "tensor([[ 0.0340, -0.1822,  0.7388,  ..., -0.8632,  0.2089,  0.9547],\n",
      "        [ 0.8024,  0.2778,  0.3149,  ..., -0.2433,  0.5942,  0.8303],\n",
      "        [ 1.4961,  0.4998,  0.2129,  ..., -0.3357,  1.5609,  0.4122],\n",
      "        ...,\n",
      "        [-0.2224,  0.7990, -0.5803,  ...,  0.7784, -0.9003, -0.9637],\n",
      "        [-0.2223,  0.7988, -0.5804,  ...,  0.7785, -0.9003, -0.9637],\n",
      "        [-0.2359,  0.8000, -0.5721,  ...,  0.7766, -0.8995, -0.9628]],\n",
      "       grad_fn=<IndexPutBackward0>)\n",
      "('volume_0_1', 'connected_to', 'volume_0_1')\n",
      "('volume_0_1', 'connected_to', 'volume_2')\n",
      "('volume_0_1', 'connected_to', 'volume_3')\n",
      "('volume_2', 'connected_to', 'volume_0_1')\n",
      "('volume_2', 'connected_to', 'volume_2')\n",
      "('volume_2', 'connected_to', 'volume_3')\n",
      "('volume_3', 'connected_to', 'volume_0_1')\n",
      "('volume_3', 'connected_to', 'volume_2')\n",
      "('volume_3', 'connected_to', 'volume_3')\n",
      "('volume_0_1', 'connected_to', 'volume_0_1')\n",
      "{'edge': tensor([[-0.2077, -0.1954,  0.0662,  ...,  0.8359,  0.2107, -0.1661],\n",
      "        [-0.4911, -0.6690,  0.1470,  ...,  0.6301,  0.3104, -0.7842],\n",
      "        [-0.1681, -0.5688,  0.4230,  ...,  0.0459,  0.7038, -0.5169],\n",
      "        ...,\n",
      "        [ 0.8819, -0.9262,  0.6750,  ..., -0.2596,  0.0891,  0.8033],\n",
      "        [ 0.9525, -0.9369,  0.7228,  ..., -0.2142,  0.3545,  0.6904],\n",
      "        [ 0.3748, -0.7931,  0.3140,  ..., -0.1453, -0.0030,  0.8939]],\n",
      "       grad_fn=<TanhBackward0>)}\n",
      "('volume_0_1', 'connected_to', 'volume_2')\n",
      "{'edge': tensor([[-0.4335, -0.2534, -0.0632,  ..., -0.0286, -0.8837, -0.7101],\n",
      "        [ 0.7011, -0.7066, -0.1247,  ...,  0.9535,  0.7473,  0.8183],\n",
      "        [ 0.7954,  0.6943, -0.1126,  ..., -0.3327, -0.7537, -0.0798],\n",
      "        ...,\n",
      "        [ 0.3655, -0.6555,  0.9412,  ...,  0.7454,  0.1968,  0.1384],\n",
      "        [ 0.9324, -0.2765, -0.8465,  ...,  0.9870, -0.4309,  0.2819],\n",
      "        [ 0.9185, -0.2205,  0.4788,  ...,  0.9716, -0.4730,  0.4959]],\n",
      "       grad_fn=<TanhBackward0>)}\n",
      "('volume_0_1', 'connected_to', 'volume_3')\n",
      "{'edge': tensor([[ 0.6729,  0.8030,  0.8093,  ...,  0.1225,  0.4292, -0.5751],\n",
      "        [ 0.8310, -0.3876,  0.9585,  ..., -0.4975, -0.2867, -0.1449],\n",
      "        [ 0.8802, -0.7391,  0.9738,  ..., -0.7147, -0.3574,  0.8650],\n",
      "        ...,\n",
      "        [-0.0506, -0.1291, -0.4768,  ...,  0.6920,  0.8117, -0.0485],\n",
      "        [ 0.1316, -0.3290, -0.7386,  ...,  0.8184,  0.8219,  0.1873],\n",
      "        [ 0.1491,  0.3521, -0.6794,  ...,  0.6337,  0.8740,  0.0093]],\n",
      "       grad_fn=<TanhBackward0>)}\n",
      "('volume_2', 'connected_to', 'volume_0_1')\n",
      "('volume_2', 'connected_to', 'volume_2')\n",
      "{'edge': tensor([[ 0.6745, -0.8591, -0.6320,  ..., -0.9425, -0.2393,  0.8469],\n",
      "        [ 0.2258, -0.6836,  0.4015,  ..., -0.6468, -0.5938, -0.0062],\n",
      "        [-0.6881, -0.6520,  0.8811,  ..., -0.7885,  0.6226, -0.4321],\n",
      "        ...,\n",
      "        [-0.3611,  0.6875,  0.7972,  ..., -0.3908, -0.6193,  0.1475],\n",
      "        [ 0.6005, -0.0811,  0.2757,  ...,  0.4199,  0.2539, -0.1842],\n",
      "        [ 0.5644, -0.3440,  0.5299,  ...,  0.1117,  0.0582, -0.3177]],\n",
      "       grad_fn=<TanhBackward0>)}\n",
      "('volume_2', 'connected_to', 'volume_3')\n",
      "{'edge': tensor([[-0.3476, -0.8108, -0.0744,  ...,  0.8461,  0.1978,  0.8080],\n",
      "        [ 0.8226, -0.5400, -0.6985,  ...,  0.9191,  0.9301,  0.0672],\n",
      "        [ 0.9038, -0.5937, -0.4608,  ...,  0.9464,  0.8788,  0.0522],\n",
      "        ...,\n",
      "        [ 0.5403,  0.7665,  0.2834,  ...,  0.3945,  0.7476, -0.7041],\n",
      "        [ 0.7193,  0.8718,  0.2073,  ...,  0.5344,  0.6874, -0.6845],\n",
      "        [ 0.8893,  0.0670, -0.0141,  ...,  0.7679,  0.8496, -0.4291]],\n",
      "       grad_fn=<TanhBackward0>)}\n",
      "('volume_3', 'connected_to', 'volume_0_1')\n",
      "('volume_3', 'connected_to', 'volume_2')\n",
      "('volume_3', 'connected_to', 'volume_3')\n",
      "{'edge': tensor([[-0.2986, -0.9911, -0.4798,  ..., -0.8576,  0.0410, -0.3437],\n",
      "        [ 0.1113,  0.4772, -0.5603,  ..., -0.4550, -0.9834, -0.9355],\n",
      "        [-0.6170, -0.8145,  0.1279,  ...,  0.5648, -0.9762, -0.8614],\n",
      "        ...,\n",
      "        [ 0.6511, -0.6839,  0.8891,  ..., -0.5923,  0.2191,  0.7226],\n",
      "        [ 0.6298, -0.6790,  0.8992,  ..., -0.6337,  0.2894,  0.7324],\n",
      "        [-0.5623,  0.9733,  0.5730,  ..., -0.5858,  0.4169,  0.9198]],\n",
      "       grad_fn=<TanhBackward0>)}\n",
      "{('volume_0_1', 'connected_to', 'volume_0_1'): tensor([[ 4.5934e-04],\n",
      "        [-9.8414e-04],\n",
      "        [-7.4277e-05],\n",
      "        ...,\n",
      "        [ 1.9299e-03],\n",
      "        [-1.3564e-03],\n",
      "        [ 4.2247e-04]], grad_fn=<TanhBackward0>), ('volume_0_1', 'connected_to', 'volume_2'): tensor([[-3.8626e-04],\n",
      "        [ 2.7735e-04],\n",
      "        [ 4.0616e-05],\n",
      "        ...,\n",
      "        [ 7.7291e-05],\n",
      "        [ 1.2613e-05],\n",
      "        [-4.4283e-04]], grad_fn=<TanhBackward0>), ('volume_0_1', 'connected_to', 'volume_3'): tensor([[-0.0001],\n",
      "        [-0.0001],\n",
      "        [-0.0006],\n",
      "        ...,\n",
      "        [-0.0012],\n",
      "        [-0.0005],\n",
      "        [-0.0015]], grad_fn=<TanhBackward0>), ('volume_2', 'connected_to', 'volume_2'): tensor([[ 0.0018],\n",
      "        [-0.0005],\n",
      "        [ 0.0005],\n",
      "        ...,\n",
      "        [ 0.0003],\n",
      "        [ 0.0007],\n",
      "        [ 0.0018]], grad_fn=<TanhBackward0>), ('volume_2', 'connected_to', 'volume_3'): tensor([[-0.0004],\n",
      "        [ 0.0011],\n",
      "        [-0.0003],\n",
      "        ...,\n",
      "        [ 0.0003],\n",
      "        [-0.0002],\n",
      "        [ 0.0002]], grad_fn=<TanhBackward0>), ('volume_3', 'connected_to', 'volume_3'): tensor([[-2.5250e-04],\n",
      "        [ 2.6590e-04],\n",
      "        [ 9.3977e-05],\n",
      "        ...,\n",
      "        [ 7.6090e-04],\n",
      "        [-8.0038e-04],\n",
      "        [ 7.8909e-04]], grad_fn=<TanhBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "gnn = HeteroGNN(config)\n",
    "\n",
    "# x_dict, edge_dict= gnn(data.x_dict, data.edge_index_dict, data.mask_dict)\n",
    "out = gnn(data.x_dict, data.edge_index_dict)\n",
    "print(out)\n",
    "# for region, x in edge_dict.items():\n",
    "#     print(region, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('volume_0_1', 'connected_to', 'volume_0_1'): tensor([[-0.0951],\n",
      "        [-0.1666],\n",
      "        [ 0.1289],\n",
      "        ...,\n",
      "        [ 0.3235],\n",
      "        [ 0.2870],\n",
      "        [ 0.0448]], grad_fn=<AddmmBackward0>), ('volume_0_1', 'connected_to', 'volume_2'): tensor([[ 0.3332],\n",
      "        [-0.1639],\n",
      "        [-0.1021],\n",
      "        ...,\n",
      "        [ 0.1369],\n",
      "        [-0.0543],\n",
      "        [-0.0602]], grad_fn=<AddmmBackward0>), ('volume_0_1', 'connected_to', 'volume_3'): tensor([[ 0.3072],\n",
      "        [ 0.0244],\n",
      "        [-0.6064],\n",
      "        ...,\n",
      "        [ 0.0584],\n",
      "        [ 0.1134],\n",
      "        [ 0.2005]], grad_fn=<AddmmBackward0>), ('volume_2', 'connected_to', 'volume_2'): tensor([[0.4536],\n",
      "        [0.6040],\n",
      "        [0.6297],\n",
      "        ...,\n",
      "        [0.7279],\n",
      "        [0.7474],\n",
      "        [0.7390]], grad_fn=<AddmmBackward0>), ('volume_2', 'connected_to', 'volume_3'): tensor([[0.3646],\n",
      "        [0.7339],\n",
      "        [0.6230],\n",
      "        ...,\n",
      "        [0.0788],\n",
      "        [0.3085],\n",
      "        [0.4047]], grad_fn=<AddmmBackward0>), ('volume_3', 'connected_to', 'volume_3'): tensor([[-0.2100],\n",
      "        [-0.2240],\n",
      "        [-0.4441],\n",
      "        ...,\n",
      "        [-0.5685],\n",
      "        [-0.5484],\n",
      "        [ 0.4259]], grad_fn=<AddmmBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = InteractionMessagePassing(config)\n",
    "\n",
    "imp.__dict__\n",
    "\n",
    "imp.message(edge_dict[('volume_0_1', 'connected_to', 'volume_2')])\n",
    "\n",
    "agg_mess =  imp.aggregate(edge_dict[('volume_0_1', 'connected_to', 'volume_2')], data.edge_index_dict[('volume_0_1', 'connected_to', 'volume_2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([44901, 9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x_dict['volume_2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    3,     9,    10,  ..., 32679, 32682, 32706])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index_dict[('volume_0_1', 'connected_to', 'volume_2')][1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32707, 64])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_mess.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.2172,  0.2139,  0.7973,  0.5595,  0.6907, -0.1025,  0.8380, -0.8767,\n",
       "          0.6852, -0.2419, -0.5343, -0.3155, -0.8071, -0.8822, -0.8435, -0.1221,\n",
       "         -0.9178, -0.0342,  0.9332, -0.4804, -0.9798,  0.9193,  0.0914, -0.7186,\n",
       "          0.9954,  0.3603, -0.2618,  0.4908,  0.7446,  0.1564,  0.4808, -0.2528,\n",
       "          0.8234, -0.8981, -0.8134,  0.8633,  0.3379,  0.7493, -0.8564,  0.0854,\n",
       "         -0.2980,  0.8694, -0.7680, -0.9496, -0.2677,  0.0066,  0.6150, -0.9630,\n",
       "         -0.6399,  0.4512, -0.9669,  0.2664, -0.5042,  0.4415, -0.7914,  0.1718,\n",
       "          0.0780, -0.8166, -0.0536,  0.5492,  0.6580,  0.5869,  0.9228,  0.6665]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_mess[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_encoder = NodeEncoder(config)\n",
    "edge_encoder = EdgeEncoder\n",
    "# het_encoder = to_hetero(encoder, data.metadata())\n",
    "\n",
    "node_encoder(data['region_2'].x, data['region_2'].mask)[data['region_2'].mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_encoder = to_hetero(node_encoder, metadata=data.metadata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.dense.linear import HeteroLinear\n",
    "\n",
    "encoder = HeteroLinear(in_channels=9, out_channels=64, num_types=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1403,  0.2397,  0.2695,  ..., -0.0816,  0.3613,  0.1801],\n",
       "        [-0.1321,  0.2312,  0.2651,  ..., -0.0746,  0.3529,  0.1808],\n",
       "        [-0.1614,  0.2399,  0.2729,  ..., -0.1022,  0.3619,  0.1883],\n",
       "        ...,\n",
       "        [ 0.3059, -0.2536, -1.3117,  ..., -0.7055, -1.2227, -0.5551],\n",
       "        [ 0.3078, -0.2565, -1.3183,  ..., -0.7088, -1.2038, -0.5388],\n",
       "        [ 0.3069, -0.2540, -1.3174,  ..., -0.7057, -1.2094, -0.5426]],\n",
       "       grad_fn=<IndexPutBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(homo_data.x.float(), torch.where(homo_data.volume_id==1, homo_data.volume_id, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[349642, 9], cell_data=[349642, 11], pid=[349642], event_file='/global/cfs/cdirs/m3443/data/ITk-upgrade/processed/full_events_v4/event000014840', hid=[349642], pt=[349642], primary=[349642], nhits=[349642], modules=[349642], modulewise_true_edges=[2, 138249], signal_true_edges=[2, 16298], edge_index=[2, 772775], y=[772775], y_pid=[772775], volume_id=[349642])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([     0,      1,      2,  ..., 264913, 264914, 264915])\n",
      "tensor([ 0,  1,  2,  ..., -1, -1, -1])\n",
      "tensor([285245, 285246, 285247,  ..., 328489, 328490, 328491])\n",
      "tensor([ 0,  1,  2,  ..., -1, -1, -1])\n",
      "tensor([264916, 264917, 264918,  ..., 349639, 349640, 349641])\n",
      "tensor([    0,     1,     2,  ..., 41476, 41477, 41478])\n"
     ]
    }
   ],
   "source": [
    "models = config['model_ids']\n",
    "map = torch.ones_like(homo_data.hid) * -1\n",
    "for model in models:\n",
    "    volume_id = model['volume_ids']\n",
    "    homo_ids = homo_data.hid[ torch.isin( homo_data.volume_id, torch.tensor(volume_id) ) ]\n",
    "    print(homo_ids)\n",
    "    # map = torch.ones((torch.max(homo_ids)+1,), dtype=torch.long) * -1\n",
    "    # print(map)\n",
    "    map[homo_ids] = torch.arange(homo_ids.shape[0])\n",
    "    print(map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid, counts = map.unique(return_counts=True)\n",
    "counts.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([349641])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map = torch.zeros(torch.max(homo_ids))\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0,      1,      2,  ..., 349639, 349640, 349641])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homo_data.hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.4'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric\n",
    "\n",
    "\n",
    "torch_geometric.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('extrkx_hsf_clone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "771d61ecd5a3184c4db4d548640adff250f79a9f92b9bacc068bde90a3f9bd55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
