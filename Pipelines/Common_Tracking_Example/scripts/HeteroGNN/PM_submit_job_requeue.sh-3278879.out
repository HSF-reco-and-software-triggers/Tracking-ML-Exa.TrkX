
Starting sweeps

Running main
Wed Sep 28 19:42:39 2022
Running main
Wed Sep 28 19:42:39 2022
Running main
Wed Sep 28 19:42:39 2022
Running main
Wed Sep 28 19:42:39 2022
Using config file: homo_config.yaml
Using config file: homo_config.yaml
Using config file: homo_config.yaml
Using config file: homo_config.yaml
Initialising model
Wed Sep 28 19:42:39 2022
Initialising model
Wed Sep 28 19:42:39 2022
Initialising model
Wed Sep 28 19:42:39 2022
Initialising model
Wed Sep 28 19:42:39 2022
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
wandb: Currently logged in as: pmtuan. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.13.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.21
wandb: Run data is saved locally in /global/cfs/cdirs/m3443/data/lightning_models/lightning_checkpoints/wandb/run-20220928_194243-soshypmf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-haze-19
wandb: ‚≠êÔ∏è View project at https://wandb.ai/pmtuan/ITk_Toy_HeteroGNN
wandb: üöÄ View run at https://wandb.ai/pmtuan/ITk_Toy_HeteroGNN/runs/soshypmf
wandb: logging graph, to disable use `wandb.watch(log_graph=False)`
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
  rank_zero_deprecation(
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

nid002232:43615:43615 [0] NCCL INFO Bootstrap : Using nmn0:10.100.16.95<0>
nid002232:43615:43615 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
nid002232:43615:43615 [0] NCCL INFO NET/IB : No device found.
nid002232:43615:43615 [0] NCCL INFO NET/Socket : Using [0]nmn0:10.100.16.95<0> [1]hsn0:10.249.12.243<0> [2]hsn1:10.249.12.244<0> [3]hsn2:10.249.35.222<0> [4]hsn3:10.249.33.222<0>
nid002232:43615:43615 [0] NCCL INFO Using network Socket
NCCL version 2.10.3+cuda11.3
nid002232:43616:43616 [1] NCCL INFO Bootstrap : Using nmn0:10.100.16.95<0>
nid002232:43618:43618 [3] NCCL INFO Bootstrap : Using nmn0:10.100.16.95<0>
nid002232:43616:43616 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
nid002232:43618:43618 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
nid002232:43616:43616 [1] NCCL INFO NET/IB : No device found.
nid002232:43618:43618 [3] NCCL INFO NET/IB : No device found.
nid002232:43616:43616 [1] NCCL INFO NET/Socket : Using [0]nmn0:10.100.16.95<0> [1]hsn0:10.249.12.243<0> [2]hsn1:10.249.12.244<0> [3]hsn2:10.249.35.222<0> [4]hsn3:10.249.33.222<0>
nid002232:43616:43616 [1] NCCL INFO Using network Socket
nid002232:43618:43618 [3] NCCL INFO NET/Socket : Using [0]nmn0:10.100.16.95<0> [1]hsn0:10.249.12.243<0> [2]hsn1:10.249.12.244<0> [3]hsn2:10.249.35.222<0> [4]hsn3:10.249.33.222<0>
nid002232:43618:43618 [3] NCCL INFO Using network Socket
nid002232:43617:43617 [2] NCCL INFO Bootstrap : Using nmn0:10.100.16.95<0>
nid002232:43617:43617 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
nid002232:43617:43617 [2] NCCL INFO NET/IB : No device found.
nid002232:43617:43617 [2] NCCL INFO NET/Socket : Using [0]nmn0:10.100.16.95<0> [1]hsn0:10.249.12.243<0> [2]hsn1:10.249.12.244<0> [3]hsn2:10.249.35.222<0> [4]hsn3:10.249.33.222<0>
nid002232:43617:43617 [2] NCCL INFO Using network Socket
nid002232:43615:43985 [0] NCCL INFO Channel 00/24 :    0   1   2   3
nid002232:43615:43985 [0] NCCL INFO Channel 01/24 :    0   1   3   2
nid002232:43615:43985 [0] NCCL INFO Channel 02/24 :    0   2   3   1
nid002232:43615:43985 [0] NCCL INFO Channel 03/24 :    0   2   1   3
nid002232:43615:43985 [0] NCCL INFO Channel 04/24 :    0   3   1   2
nid002232:43615:43985 [0] NCCL INFO Channel 05/24 :    0   3   2   1
nid002232:43615:43985 [0] NCCL INFO Channel 06/24 :    0   1   2   3
nid002232:43615:43985 [0] NCCL INFO Channel 07/24 :    0   1   3   2
nid002232:43615:43985 [0] NCCL INFO Channel 08/24 :    0   2   3   1
nid002232:43615:43985 [0] NCCL INFO Channel 09/24 :    0   2   1   3
nid002232:43615:43985 [0] NCCL INFO Channel 10/24 :    0   3   1   2
nid002232:43615:43985 [0] NCCL INFO Channel 11/24 :    0   3   2   1
nid002232:43615:43985 [0] NCCL INFO Channel 12/24 :    0   1   2   3
nid002232:43615:43985 [0] NCCL INFO Channel 13/24 :    0   1   3   2
nid002232:43615:43985 [0] NCCL INFO Channel 14/24 :    0   2   3   1
nid002232:43615:43985 [0] NCCL INFO Channel 15/24 :    0   2   1   3
nid002232:43615:43985 [0] NCCL INFO Channel 16/24 :    0   3   1   2
nid002232:43615:43985 [0] NCCL INFO Channel 17/24 :    0   3   2   1
nid002232:43615:43985 [0] NCCL INFO Channel 18/24 :    0   1   2   3
nid002232:43615:43985 [0] NCCL INFO Channel 19/24 :    0   1   3   2
nid002232:43615:43985 [0] NCCL INFO Channel 20/24 :    0   2   3   1
nid002232:43615:43985 [0] NCCL INFO Channel 21/24 :    0   2   1   3
nid002232:43615:43985 [0] NCCL INFO Channel 22/24 :    0   3   1   2
nid002232:43615:43985 [0] NCCL INFO Channel 23/24 :    0   3   2   1
nid002232:43615:43985 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 2/-1/-1->0->3 [3] 2/-1/-1->0->3 [4] 3/-1/-1->0->2 [5] 3/-1/-1->0->2 [6] -1/-1/-1->0->1 [7] -1/-1/-1->0->1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 2/-1/-1->0->3 [11] 2/-1/-1->0->3 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 2/-1/-1->0->3 [15] 2/-1/-1->0->3 [16] 3/-1/-1->0->2 [17] 3/-1/-1->0->2 [18] -1/-1/-1->0->1 [19] -1/-1/-1->0->1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 2/-1/-1->0->3 [23] 2/-1/-1->0->3
nid002232:43616:43986 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 3/-1/-1->1->-1 [3] 3/-1/-1->1->-1 [4] -1/-1/-1->1->3 [5] -1/-1/-1->1->3 [6] 0/-1/-1->1->2 [7] 0/-1/-1->1->2 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 3/-1/-1->1->-1 [11] 3/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 3/-1/-1->1->-1 [15] 3/-1/-1->1->-1 [16] -1/-1/-1->1->3 [17] -1/-1/-1->1->3 [18] 0/-1/-1->1->2 [19] 0/-1/-1->1->2 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 3/-1/-1->1->-1 [23] 3/-1/-1->1->-1
nid002232:43617:43988 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] -1/-1/-1->2->0 [3] -1/-1/-1->2->0 [4] 0/-1/-1->2->-1 [5] 0/-1/-1->2->-1 [6] 1/-1/-1->2->3 [7] 1/-1/-1->2->3 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] -1/-1/-1->2->0 [11] -1/-1/-1->2->0 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] -1/-1/-1->2->0 [15] -1/-1/-1->2->0 [16] 0/-1/-1->2->-1 [17] 0/-1/-1->2->-1 [18] 1/-1/-1->2->3 [19] 1/-1/-1->2->3 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] -1/-1/-1->2->0 [23] -1/-1/-1->2->0
nid002232:43618:43987 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] 0/-1/-1->3->1 [3] 0/-1/-1->3->1 [4] 1/-1/-1->3->0 [5] 1/-1/-1->3->0 [6] 2/-1/-1->3->-1 [7] 2/-1/-1->3->-1 [8] -1/-1/-1->3->2 [9] -1/-1/-1->3->2 [10] 0/-1/-1->3->1 [11] 0/-1/-1->3->1 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] 0/-1/-1->3->1 [15] 0/-1/-1->3->1 [16] 1/-1/-1->3->0 [17] 1/-1/-1->3->0 [18] 2/-1/-1->3->-1 [19] 2/-1/-1->3->-1 [20] -1/-1/-1->3->2 [21] -1/-1/-1->3->2 [22] 0/-1/-1->3->1 [23] 0/-1/-1->3->1
nid002232:43617:43988 [2] NCCL INFO Channel 00 : 2[82000] -> 3[c1000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 02 : 2[82000] -> 3[c1000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 00 : 0[3000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 00 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 06 : 2[82000] -> 3[c1000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 01 : 0[3000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 03 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 08 : 2[82000] -> 3[c1000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 06 : 0[3000] -> 1[41000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 00 : 1[41000] -> 2[82000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 06 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 12 : 2[82000] -> 3[c1000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 04 : 1[41000] -> 2[82000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 07 : 0[3000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 09 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 14 : 2[82000] -> 3[c1000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 06 : 1[41000] -> 2[82000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 12 : 0[3000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 12 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 18 : 2[82000] -> 3[c1000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 13 : 0[3000] -> 1[41000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 10 : 1[41000] -> 2[82000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 15 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 20 : 2[82000] -> 3[c1000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 12 : 1[41000] -> 2[82000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 18 : 0[3000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 18 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 16 : 1[41000] -> 2[82000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 19 : 0[3000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 21 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 18 : 1[41000] -> 2[82000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 22 : 1[41000] -> 2[82000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 02 : 3[c1000] -> 1[41000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 02 : 0[3000] -> 2[82000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 01 : 2[82000] -> 0[3000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 01 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 04 : 3[c1000] -> 1[41000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 03 : 0[3000] -> 2[82000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 04 : 2[82000] -> 0[3000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 03 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 08 : 3[c1000] -> 1[41000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 08 : 0[3000] -> 2[82000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 07 : 2[82000] -> 0[3000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 07 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 10 : 3[c1000] -> 1[41000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 09 : 0[3000] -> 2[82000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 10 : 2[82000] -> 0[3000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 09 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 14 : 3[c1000] -> 1[41000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 14 : 0[3000] -> 2[82000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 13 : 2[82000] -> 0[3000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 13 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 16 : 3[c1000] -> 1[41000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 15 : 0[3000] -> 2[82000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 16 : 2[82000] -> 0[3000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 15 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 20 : 3[c1000] -> 1[41000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 20 : 0[3000] -> 2[82000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 19 : 2[82000] -> 0[3000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 19 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 22 : 3[c1000] -> 1[41000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 21 : 0[3000] -> 2[82000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 22 : 2[82000] -> 0[3000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 21 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 04 : 0[3000] -> 3[c1000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 03 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 01 : 3[c1000] -> 2[82000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 02 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 05 : 0[3000] -> 3[c1000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 05 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 05 : 3[c1000] -> 2[82000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 05 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 10 : 0[3000] -> 3[c1000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 09 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 07 : 3[c1000] -> 2[82000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 08 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 11 : 0[3000] -> 3[c1000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 11 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 11 : 3[c1000] -> 2[82000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 11 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 16 : 0[3000] -> 3[c1000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 15 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 13 : 3[c1000] -> 2[82000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 14 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 17 : 0[3000] -> 3[c1000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 17 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 17 : 3[c1000] -> 2[82000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 17 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 22 : 0[3000] -> 3[c1000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 21 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 19 : 3[c1000] -> 2[82000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 20 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 23 : 0[3000] -> 3[c1000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 23 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 23 : 3[c1000] -> 2[82000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 23 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Connected all rings
nid002232:43618:43987 [3] NCCL INFO Connected all rings
nid002232:43615:43985 [0] NCCL INFO Connected all rings
nid002232:43616:43986 [1] NCCL INFO Connected all rings
nid002232:43616:43986 [1] NCCL INFO Channel 01 : 1[41000] -> 2[82000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 07 : 1[41000] -> 2[82000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 02 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 08 : 1[41000] -> 2[82000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 04 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 09 : 1[41000] -> 2[82000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 01 : 2[82000] -> 3[c1000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 05 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 13 : 1[41000] -> 2[82000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 07 : 2[82000] -> 3[c1000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 10 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 19 : 1[41000] -> 2[82000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 09 : 2[82000] -> 3[c1000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 11 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 08 : 0[3000] -> 1[41000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 20 : 1[41000] -> 2[82000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 13 : 2[82000] -> 3[c1000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 14 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 09 : 0[3000] -> 1[41000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 21 : 1[41000] -> 2[82000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 19 : 2[82000] -> 3[c1000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 16 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 20 : 0[3000] -> 1[41000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 21 : 2[82000] -> 3[c1000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 17 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 21 : 0[3000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 22 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 23 : 3[c1000] -> 0[3000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 02 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 04 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 05 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 10 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 11 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 02 : 2[82000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 04 : 0[3000] -> 2[82000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 14 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 03 : 2[82000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 05 : 0[3000] -> 2[82000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 16 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 05 : 2[82000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 10 : 0[3000] -> 2[82000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 17 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 11 : 2[82000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 11 : 0[3000] -> 2[82000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 03 : 3[c1000] -> 1[41000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 22 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 14 : 2[82000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 16 : 0[3000] -> 2[82000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 05 : 3[c1000] -> 1[41000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 23 : 1[41000] -> 3[c1000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 15 : 2[82000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 17 : 0[3000] -> 2[82000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 11 : 3[c1000] -> 1[41000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 17 : 2[82000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 22 : 0[3000] -> 2[82000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 15 : 3[c1000] -> 1[41000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 23 : 2[82000] -> 0[3000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 23 : 0[3000] -> 2[82000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 17 : 3[c1000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 23 : 3[c1000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 00 : 3[c1000] -> 2[82000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 06 : 3[c1000] -> 2[82000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 08 : 3[c1000] -> 2[82000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 09 : 3[c1000] -> 2[82000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 00 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 12 : 3[c1000] -> 2[82000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 01 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 18 : 3[c1000] -> 2[82000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 02 : 0[3000] -> 3[c1000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 06 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 00 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 20 : 3[c1000] -> 2[82000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 03 : 0[3000] -> 3[c1000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 07 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 01 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Channel 21 : 3[c1000] -> 2[82000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 08 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 14 : 0[3000] -> 3[c1000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 06 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 12 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43615:43985 [0] NCCL INFO Channel 15 : 0[3000] -> 3[c1000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 07 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 13 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 09 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 18 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 12 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 19 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 13 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43617:43988 [2] NCCL INFO Channel 20 : 2[82000] -> 1[41000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 18 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 19 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43616:43986 [1] NCCL INFO Channel 21 : 1[41000] -> 0[3000] via P2P/IPC/read
nid002232:43618:43987 [3] NCCL INFO Connected all trees
nid002232:43618:43987 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
nid002232:43615:43985 [0] NCCL INFO Connected all trees
nid002232:43615:43985 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
nid002232:43618:43987 [3] NCCL INFO 24 coll channels, 32 p2p channels, 8 p2p channels per peer
nid002232:43617:43988 [2] NCCL INFO Connected all trees
nid002232:43617:43988 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
nid002232:43616:43986 [1] NCCL INFO Connected all trees
nid002232:43616:43986 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
nid002232:43615:43985 [0] NCCL INFO 24 coll channels, 32 p2p channels, 8 p2p channels per peer
nid002232:43617:43988 [2] NCCL INFO 24 coll channels, 32 p2p channels, 8 p2p channels per peer
nid002232:43616:43986 [1] NCCL INFO 24 coll channels, 32 p2p channels, 8 p2p channels per peer
nid002232:43616:43986 [1] NCCL INFO comm 0x148b80003010 rank 1 nranks 4 cudaDev 1 busId 41000 - Init COMPLETE
nid002232:43617:43988 [2] NCCL INFO comm 0x151d34003010 rank 2 nranks 4 cudaDev 2 busId 82000 - Init COMPLETE
nid002232:43618:43987 [3] NCCL INFO comm 0x145610003010 rank 3 nranks 4 cudaDev 3 busId c1000 - Init COMPLETE
nid002232:43615:43985 [0] NCCL INFO comm 0x14deec003010 rank 0 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
nid002232:43615:43615 [0] NCCL INFO Launch mode Parallel
Restoring states from the checkpoint path at 3278879/hpc_ckpt_10.ckpt
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:342: UserWarning: The dirpath has changed from '/global/cfs/cdirs/m3443/data/lightning_models/lightning_checkpoints/ITk_Toy_HeteroGNN/1jqpd3rq/checkpoints' to '/global/cfs/cdirs/m3443/data/lightning_models/lightning_checkpoints/ITk_Toy_HeteroGNN/soshypmf/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.
  warnings.warn(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:342: UserWarning: The dirpath has changed from '/global/cfs/cdirs/m3443/data/lightning_models/lightning_checkpoints/ITk_Toy_HeteroGNN/1jqpd3rq/checkpoints' to '/global/cfs/cdirs/m3443/data/lightning_models/lightning_checkpoints/ITk_Toy_HeteroGNN/soshypmf/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.
  warnings.warn(
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:342: UserWarning: The dirpath has changed from '/global/cfs/cdirs/m3443/data/lightning_models/lightning_checkpoints/ITk_Toy_HeteroGNN/1jqpd3rq/checkpoints' to '/global/cfs/cdirs/m3443/data/lightning_models/lightning_checkpoints/ITk_Toy_HeteroGNN/soshypmf/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.
  warnings.warn(
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:342: UserWarning: The dirpath has changed from '/global/cfs/cdirs/m3443/data/lightning_models/lightning_checkpoints/ITk_Toy_HeteroGNN/1jqpd3rq/checkpoints' to '/global/cfs/cdirs/m3443/data/lightning_models/lightning_checkpoints/ITk_Toy_HeteroGNN/soshypmf/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.
  warnings.warn(
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name    | Type        | Params
----------------------------------------
0 | encoder | HomoEncoder | 25.2 K
1 | conv    | ModuleList  | 41.3 K
2 | decoder | HomoDecoder | 20.7 K
----------------------------------------
87.2 K    Trainable params
0         Non-trainable params
87.2 K    Total params
0.349     Total estimated model params size (MB)
Restored all states from the checkpoint file at 3278879/hpc_ckpt_10.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: 241it [00:00, ?it/s]Training:   0% 0/270 [00:00<00:00, -14440389.49it/s]Epoch 187:   0% 0/270 [00:00<00:00, -2863533.33it/s]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:135: UserWarning: You're resuming from a checkpoint that ended before the epoch ended. This can cause unreliable results if further training is done. Consider using an end-of-epoch checkpoint or enabling fault-tolerant training: https://pytorch-lightning.readthedocs.io/en/stable/advanced/fault_tolerant_training.html
  rank_zero_warn(
Epoch 187:   0% 1/270 [00:04<-1:59:56, -57.50it/s]  Epoch 187:   0% 1/270 [00:04<-1:59:56, -57.50it/s]Epoch 187:   0% 1/270 [00:04<-1:59:56, -54.89it/s, loss=0.017, v_num=ypmf]Epoch 187:   1% 2/270 [00:04<-1:59:55, -50.82it/s, loss=0.017, v_num=ypmf]Epoch 187:   1% 2/270 [00:04<-1:59:55, -50.82it/s, loss=0.017, v_num=ypmf]Epoch 187:   1% 2/270 [00:04<-1:59:55, -48.44it/s, loss=0.0166, v_num=ypmf]Epoch 187:   1% 3/270 [00:05<-1:59:55, -45.04it/s, loss=0.0166, v_num=ypmf]Epoch 187:   1% 3/270 [00:05<-1:59:55, -45.04it/s, loss=0.0166, v_num=ypmf]Epoch 187:   1% 3/270 [00:05<-1:59:54, -42.92it/s, loss=0.0172, v_num=ypmf]Epoch 187:   1% 4/270 [00:05<-1:59:54, -39.65it/s, loss=0.0172, v_num=ypmf]Epoch 187:   1% 4/270 [00:05<-1:59:54, -39.64it/s, loss=0.0172, v_num=ypmf]Epoch 187:   1% 4/270 [00:06<-1:59:54, -38.72it/s, loss=0.0172, v_num=ypmf]Epoch 187:   2% 5/270 [00:06<-1:59:53, -35.99it/s, loss=0.0172, v_num=ypmf]Epoch 187:   2% 5/270 [00:06<-1:59:53, -35.98it/s, loss=0.0172, v_num=ypmf]Epoch 187:   2% 5/270 [00:06<-1:59:53, -35.23it/s, loss=0.017, v_num=ypmf] Epoch 187:   2% 6/270 [00:06<-1:59:53, -33.67it/s, loss=0.017, v_num=ypmf]Epoch 187:   2% 6/270 [00:06<-1:59:53, -33.67it/s, loss=0.017, v_num=ypmf]Epoch 187:   2% 6/270 [00:07<-1:59:52, -31.76it/s, loss=0.0172, v_num=ypmf]Epoch 187:   3% 7/270 [00:07<-1:59:52, -30.02it/s, loss=0.0172, v_num=ypmf]Epoch 187:   3% 7/270 [00:07<-1:59:52, -30.02it/s, loss=0.0172, v_num=ypmf]Epoch 187:   3% 7/270 [00:08<-1:59:51, -28.84it/s, loss=0.0171, v_num=ypmf]Epoch 187:   3% 8/270 [00:08<-1:59:51, -27.47it/s, loss=0.0171, v_num=ypmf]Epoch 187:   3% 8/270 [00:08<-1:59:51, -27.47it/s, loss=0.0171, v_num=ypmf]Epoch 187:   3% 8/270 [00:08<-1:59:51, -26.83it/s, loss=0.017, v_num=ypmf] Epoch 187:   3% 9/270 [00:09<-1:59:50, -25.69it/s, loss=0.017, v_num=ypmf]Epoch 187:   3% 9/270 [00:09<-1:59:50, -25.69it/s, loss=0.017, v_num=ypmf]Epoch 187:   3% 9/270 [00:09<-1:59:50, -25.28it/s, loss=0.017, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 299904. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 286335. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 298239. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 340421. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 333632. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 241985. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 309078. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 305106. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 281005. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(

Validation: 0it [00:00, ?it/s][A
Validation:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.23it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.23it/s][AEpoch 187:   4% 10/270 [00:11<-1:59:48, -20.80it/s, loss=0.017, v_num=ypmf]Epoch 187:   4% 10/270 [00:11<-1:59:48, -20.80it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  10% 2/20 [00:02<00:19,  1.10s/it][A
Validation DataLoader 0:  10% 2/20 [00:02<00:19,  1.10s/it][AEpoch 187:   4% 11/270 [00:12<-1:59:46, -18.15it/s, loss=0.017, v_num=ypmf]Epoch 187:   4% 11/270 [00:12<-1:59:46, -18.15it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  15% 3/20 [00:04<00:26,  1.54s/it][A
Validation DataLoader 0:  15% 3/20 [00:04<00:26,  1.54s/it][AEpoch 187:   4% 12/270 [00:14<-1:59:44, -15.54it/s, loss=0.017, v_num=ypmf]Epoch 187:   4% 12/270 [00:14<-1:59:44, -15.54it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  20% 4/20 [00:04<00:19,  1.21s/it][A
Validation DataLoader 0:  20% 4/20 [00:04<00:19,  1.21s/it][AEpoch 187:   5% 13/270 [00:15<-1:59:43, -14.78it/s, loss=0.017, v_num=ypmf]Epoch 187:   5% 13/270 [00:15<-1:59:43, -14.78it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  25% 5/20 [00:06<00:20,  1.34s/it][A
Validation DataLoader 0:  25% 5/20 [00:06<00:20,  1.34s/it][AEpoch 187:   5% 14/270 [00:16<-1:59:41, -13.36it/s, loss=0.017, v_num=ypmf]Epoch 187:   5% 14/270 [00:16<-1:59:41, -13.36it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  30% 6/20 [00:07<00:19,  1.36s/it][A
Validation DataLoader 0:  30% 6/20 [00:07<00:19,  1.36s/it][AEpoch 187:   6% 15/270 [00:18<-1:59:40, -12.27it/s, loss=0.017, v_num=ypmf]Epoch 187:   6% 15/270 [00:18<-1:59:40, -12.27it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  35% 7/20 [00:09<00:20,  1.58s/it][A
Validation DataLoader 0:  35% 7/20 [00:09<00:20,  1.58s/it][AEpoch 187:   6% 16/270 [00:20<-1:59:37, -11.02it/s, loss=0.017, v_num=ypmf]Epoch 187:   6% 16/270 [00:20<-1:59:37, -11.02it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  40% 8/20 [00:11<00:19,  1.62s/it][A
Validation DataLoader 0:  40% 8/20 [00:11<00:19,  1.62s/it][AEpoch 187:   6% 17/270 [00:22<-1:59:35, -10.11it/s, loss=0.017, v_num=ypmf]Epoch 187:   6% 17/270 [00:22<-1:59:35, -10.11it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  45% 9/20 [00:12<00:14,  1.35s/it][A
Validation DataLoader 0:  45% 9/20 [00:12<00:14,  1.35s/it][AEpoch 187:   7% 18/270 [00:22<-1:59:35, -9.74it/s, loss=0.017, v_num=ypmf] Epoch 187:   7% 18/270 [00:22<-1:59:35, -9.74it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  50% 10/20 [00:13<00:13,  1.33s/it][A
Validation DataLoader 0:  50% 10/20 [00:13<00:13,  1.33s/it][AEpoch 187:   7% 19/270 [00:24<-1:59:33, -9.18it/s, loss=0.017, v_num=ypmf]Epoch 187:   7% 19/270 [00:24<-1:59:33, -9.18it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  55% 11/20 [00:14<00:10,  1.15s/it][A
Validation DataLoader 0:  55% 11/20 [00:14<00:10,  1.15s/it][AEpoch 187:   7% 20/270 [00:24<-1:59:32, -8.87it/s, loss=0.017, v_num=ypmf]Epoch 187:   7% 20/270 [00:24<-1:59:32, -8.87it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  60% 12/20 [00:16<00:10,  1.34s/it][A
Validation DataLoader 0:  60% 12/20 [00:16<00:10,  1.34s/it][AEpoch 187:   8% 21/270 [00:26<-1:59:30, -8.25it/s, loss=0.017, v_num=ypmf]Epoch 187:   8% 21/270 [00:26<-1:59:30, -8.25it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  65% 13/20 [00:16<00:08,  1.19s/it][A
Validation DataLoader 0:  65% 13/20 [00:16<00:08,  1.19s/it][AEpoch 187:   8% 22/270 [00:27<-1:59:29, -7.96it/s, loss=0.017, v_num=ypmf]Epoch 187:   8% 22/270 [00:27<-1:59:29, -7.96it/s, loss=0.017, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 259909. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 344211. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 329330. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 314700. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 307471. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301684. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308802. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 331218. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 324586. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 281641. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 324981. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 320890. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 346585. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 317690. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(

Validation DataLoader 0:  70% 14/20 [00:17<00:06,  1.04s/it][A
Validation DataLoader 0:  70% 14/20 [00:17<00:06,  1.04s/it][AEpoch 187:   9% 23/270 [00:28<-1:59:29, -7.72it/s, loss=0.017, v_num=ypmf]Epoch 187:   9% 23/270 [00:28<-1:59:29, -7.72it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  75% 15/20 [00:18<00:05,  1.06s/it][A
Validation DataLoader 0:  75% 15/20 [00:18<00:05,  1.06s/it][AEpoch 187:   9% 24/270 [00:29<-1:59:27, -7.40it/s, loss=0.017, v_num=ypmf]Epoch 187:   9% 24/270 [00:29<-1:59:27, -7.40it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  80% 16/20 [00:19<00:04,  1.06s/it][A
Validation DataLoader 0:  80% 16/20 [00:19<00:04,  1.06s/it][AEpoch 187:   9% 25/270 [00:30<-1:59:26, -7.11it/s, loss=0.017, v_num=ypmf]Epoch 187:   9% 25/270 [00:30<-1:59:26, -7.11it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  85% 17/20 [00:21<00:03,  1.18s/it][A
Validation DataLoader 0:  85% 17/20 [00:21<00:03,  1.18s/it][AEpoch 187:  10% 26/270 [00:31<-1:59:24, -6.75it/s, loss=0.017, v_num=ypmf]Epoch 187:  10% 26/270 [00:31<-1:59:24, -6.75it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  90% 18/20 [00:21<00:02,  1.03s/it][A
Validation DataLoader 0:  90% 18/20 [00:21<00:02,  1.03s/it][AEpoch 187:  10% 27/270 [00:32<-1:59:24, -6.58it/s, loss=0.017, v_num=ypmf]Epoch 187:  10% 27/270 [00:32<-1:59:24, -6.58it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  95% 19/20 [00:23<00:01,  1.12s/it][A
Validation DataLoader 0:  95% 19/20 [00:23<00:01,  1.12s/it][AEpoch 187:  10% 28/270 [00:33<-1:59:22, -6.29it/s, loss=0.017, v_num=ypmf]Epoch 187:  10% 28/270 [00:33<-1:59:22, -6.29it/s, loss=0.017, v_num=ypmf]
Validation DataLoader 0: 100% 20/20 [00:23<00:00,  1.02s/it][A
Validation DataLoader 0: 100% 20/20 [00:23<00:00,  1.02s/it][AEpoch 187:  11% 29/270 [00:34<-1:59:21, -6.12it/s, loss=0.017, v_num=ypmf]Epoch 187:  11% 29/270 [00:34<-1:59:21, -6.12it/s, loss=0.017, v_num=ypmf]Epoch 187:  11% 29/270 [00:37<-1:59:18, -5.70it/s, loss=0.017, v_num=ypmf]
                                                            [AEpoch 187:  11% 29/270 [00:37<-1:59:18, -5.70it/s, loss=0.017, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 187:   0% 0/270 [00:00<00:00, -6479661.95it/s, loss=0.017, v_num=ypmf]Epoch 188:   0% 0/270 [00:00<00:00, -1733837.50it/s, loss=0.017, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 302996. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 296757. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 284098. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308178. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 338406. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 281251. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 188:   0% 1/270 [00:01<-1:59:58, -130.18it/s, loss=0.017, v_num=ypmf] Epoch 188:   0% 1/270 [00:01<-1:59:58, -130.17it/s, loss=0.017, v_num=ypmf]Epoch 188:   0% 1/270 [00:01<-1:59:58, -122.00it/s, loss=0.0169, v_num=ypmf]Epoch 188:   1% 2/270 [00:02<-1:59:58, -102.60it/s, loss=0.0169, v_num=ypmf]Epoch 188:   1% 2/270 [00:02<-1:59:58, -102.60it/s, loss=0.0169, v_num=ypmf]Epoch 188:   1% 2/270 [00:02<-1:59:58, -92.65it/s, loss=0.017, v_num=ypmf]  Epoch 188:   1% 3/270 [00:03<-1:59:57, -69.52it/s, loss=0.017, v_num=ypmf]Epoch 188:   1% 3/270 [00:03<-1:59:57, -69.51it/s, loss=0.017, v_num=ypmf]Epoch 188:   1% 3/270 [00:03<-1:59:57, -67.18it/s, loss=0.0169, v_num=ypmf]Epoch 188:   1% 4/270 [00:04<-1:59:55, -49.76it/s, loss=0.0169, v_num=ypmf]Epoch 188:   1% 4/270 [00:04<-1:59:55, -49.76it/s, loss=0.0169, v_num=ypmf]Epoch 188:   1% 4/270 [00:04<-1:59:55, -48.42it/s, loss=0.0168, v_num=ypmf]Epoch 188:   2% 5/270 [00:05<-1:59:54, -44.00it/s, loss=0.0168, v_num=ypmf]Epoch 188:   2% 5/270 [00:05<-1:59:54, -44.00it/s, loss=0.0168, v_num=ypmf]Epoch 188:   2% 5/270 [00:05<-1:59:54, -42.75it/s, loss=0.0167, v_num=ypmf]Epoch 188:   2% 6/270 [00:06<-1:59:53, -36.36it/s, loss=0.0167, v_num=ypmf]Epoch 188:   2% 6/270 [00:06<-1:59:53, -36.36it/s, loss=0.0167, v_num=ypmf]Epoch 188:   2% 6/270 [00:06<-1:59:53, -35.56it/s, loss=0.0168, v_num=ypmf]Epoch 188:   3% 7/270 [00:06<-1:59:53, -33.74it/s, loss=0.0168, v_num=ypmf]Epoch 188:   3% 7/270 [00:06<-1:59:53, -33.74it/s, loss=0.0168, v_num=ypmf]Epoch 188:   3% 7/270 [00:07<-1:59:53, -33.15it/s, loss=0.0169, v_num=ypmf]Epoch 188:   3% 8/270 [00:07<-1:59:52, -30.04it/s, loss=0.0169, v_num=ypmf]Epoch 188:   3% 8/270 [00:07<-1:59:52, -30.04it/s, loss=0.0169, v_num=ypmf]Epoch 188:   3% 8/270 [00:07<-1:59:52, -29.49it/s, loss=0.0169, v_num=ypmf]Epoch 188:   3% 9/270 [00:08<-1:59:51, -28.08it/s, loss=0.0169, v_num=ypmf]Epoch 188:   3% 9/270 [00:08<-1:59:51, -28.08it/s, loss=0.0169, v_num=ypmf]Epoch 188:   3% 9/270 [00:08<-1:59:51, -27.32it/s, loss=0.0169, v_num=ypmf]Epoch 188:   4% 10/270 [00:08<-1:59:51, -26.09it/s, loss=0.0169, v_num=ypmf]Epoch 188:   4% 10/270 [00:08<-1:59:51, -26.09it/s, loss=0.0169, v_num=ypmf]Epoch 188:   4% 10/270 [00:09<-1:59:50, -25.49it/s, loss=0.017, v_num=ypmf] Epoch 188:   4% 11/270 [00:09<-1:59:50, -24.67it/s, loss=0.017, v_num=ypmf]Epoch 188:   4% 11/270 [00:09<-1:59:50, -24.67it/s, loss=0.017, v_num=ypmf]Epoch 188:   4% 11/270 [00:09<-1:59:50, -23.77it/s, loss=0.0171, v_num=ypmf]Epoch 188:   4% 12/270 [00:10<-1:59:49, -22.71it/s, loss=0.0171, v_num=ypmf]Epoch 188:   4% 12/270 [00:10<-1:59:49, -22.71it/s, loss=0.0171, v_num=ypmf]Epoch 188:   4% 12/270 [00:10<-1:59:49, -22.39it/s, loss=0.0172, v_num=ypmf]Epoch 188:   5% 13/270 [00:10<-1:59:49, -21.46it/s, loss=0.0172, v_num=ypmf]Epoch 188:   5% 13/270 [00:10<-1:59:49, -21.46it/s, loss=0.0172, v_num=ypmf]Epoch 188:   5% 13/270 [00:10<-1:59:48, -21.20it/s, loss=0.0172, v_num=ypmf]Epoch 188:   5% 14/270 [00:11<-1:59:48, -20.37it/s, loss=0.0172, v_num=ypmf]Epoch 188:   5% 14/270 [00:11<-1:59:48, -20.37it/s, loss=0.0172, v_num=ypmf]Epoch 188:   5% 14/270 [00:11<-1:59:48, -20.07it/s, loss=0.0171, v_num=ypmf]Epoch 188:   6% 15/270 [00:11<-1:59:47, -19.31it/s, loss=0.0171, v_num=ypmf]Epoch 188:   6% 15/270 [00:11<-1:59:47, -19.31it/s, loss=0.0171, v_num=ypmf]Epoch 188:   6% 15/270 [00:11<-1:59:47, -19.09it/s, loss=0.0171, v_num=ypmf]Epoch 188:   6% 16/270 [00:12<-1:59:47, -18.17it/s, loss=0.0171, v_num=ypmf]Epoch 188:   6% 16/270 [00:12<-1:59:47, -18.17it/s, loss=0.0171, v_num=ypmf]Epoch 188:   6% 16/270 [00:12<-1:59:46, -18.07it/s, loss=0.0172, v_num=ypmf]Epoch 188:   6% 17/270 [00:12<-1:59:46, -17.59it/s, loss=0.0172, v_num=ypmf]Epoch 188:   6% 17/270 [00:12<-1:59:46, -17.59it/s, loss=0.0172, v_num=ypmf]Epoch 188:   6% 17/270 [00:12<-1:59:46, -17.35it/s, loss=0.0171, v_num=ypmf]Epoch 188:   7% 18/270 [00:13<-1:59:45, -16.79it/s, loss=0.0171, v_num=ypmf]Epoch 188:   7% 18/270 [00:13<-1:59:45, -16.79it/s, loss=0.0171, v_num=ypmf]Epoch 188:   7% 18/270 [00:13<-1:59:45, -16.01it/s, loss=0.0172, v_num=ypmf]Epoch 188:   7% 19/270 [00:14<-1:59:44, -15.53it/s, loss=0.0172, v_num=ypmf]Epoch 188:   7% 19/270 [00:14<-1:59:44, -15.53it/s, loss=0.0172, v_num=ypmf]Epoch 188:   7% 19/270 [00:14<-1:59:44, -15.35it/s, loss=0.0171, v_num=ypmf]Epoch 188:   7% 20/270 [00:14<-1:59:44, -14.92it/s, loss=0.0171, v_num=ypmf]Epoch 188:   7% 20/270 [00:14<-1:59:44, -14.92it/s, loss=0.0171, v_num=ypmf]Epoch 188:   7% 20/270 [00:15<-1:59:43, -14.70it/s, loss=0.0171, v_num=ypmf]Epoch 188:   8% 21/270 [00:15<-1:59:43, -14.24it/s, loss=0.0171, v_num=ypmf]Epoch 188:   8% 21/270 [00:15<-1:59:43, -14.24it/s, loss=0.0171, v_num=ypmf]Epoch 188:   8% 21/270 [00:15<-1:59:43, -14.12it/s, loss=0.0171, v_num=ypmf]Epoch 188:   8% 22/270 [00:16<-1:59:42, -13.66it/s, loss=0.0171, v_num=ypmf]Epoch 188:   8% 22/270 [00:16<-1:59:42, -13.66it/s, loss=0.0171, v_num=ypmf]Epoch 188:   8% 22/270 [00:16<-1:59:42, -13.53it/s, loss=0.0171, v_num=ypmf]Epoch 188:   9% 23/270 [00:16<-1:59:42, -13.17it/s, loss=0.0171, v_num=ypmf]Epoch 188:   9% 23/270 [00:16<-1:59:42, -13.17it/s, loss=0.0171, v_num=ypmf]Epoch 188:   9% 23/270 [00:16<-1:59:42, -13.03it/s, loss=0.0171, v_num=ypmf]Epoch 188:   9% 24/270 [00:17<-1:59:41, -12.69it/s, loss=0.0171, v_num=ypmf]Epoch 188:   9% 24/270 [00:17<-1:59:41, -12.69it/s, loss=0.0171, v_num=ypmf]Epoch 188:   9% 24/270 [00:17<-1:59:41, -12.60it/s, loss=0.0172, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 307156. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293285. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301055. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 324013. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 354746. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 341168. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 281676. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 339205. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 303284. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 288162. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 241711. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 260715. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 320529. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 306250. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 324202. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 331191. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 247158. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 298061. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 310035. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 290525. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319118. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 342088. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 296341. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 299920. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 315282. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 188:   9% 25/270 [00:17<-1:59:41, -12.27it/s, loss=0.0172, v_num=ypmf]Epoch 188:   9% 25/270 [00:17<-1:59:41, -12.27it/s, loss=0.0172, v_num=ypmf]Epoch 188:   9% 25/270 [00:17<-1:59:40, -12.12it/s, loss=0.0172, v_num=ypmf]Epoch 188:  10% 26/270 [00:18<-1:59:40, -11.78it/s, loss=0.0172, v_num=ypmf]Epoch 188:  10% 26/270 [00:18<-1:59:40, -11.78it/s, loss=0.0172, v_num=ypmf]Epoch 188:  10% 26/270 [00:18<-1:59:40, -11.69it/s, loss=0.0172, v_num=ypmf]Epoch 188:  10% 27/270 [00:18<-1:59:39, -11.39it/s, loss=0.0172, v_num=ypmf]Epoch 188:  10% 27/270 [00:18<-1:59:39, -11.39it/s, loss=0.0172, v_num=ypmf]Epoch 188:  10% 27/270 [00:18<-1:59:39, -11.31it/s, loss=0.0171, v_num=ypmf]Epoch 188:  10% 28/270 [00:19<-1:59:39, -11.06it/s, loss=0.0171, v_num=ypmf]Epoch 188:  10% 28/270 [00:19<-1:59:39, -11.06it/s, loss=0.0171, v_num=ypmf]Epoch 188:  10% 28/270 [00:19<-1:59:38, -10.92it/s, loss=0.0171, v_num=ypmf]Epoch 188:  11% 29/270 [00:19<-1:59:38, -10.71it/s, loss=0.0171, v_num=ypmf]Epoch 188:  11% 29/270 [00:19<-1:59:38, -10.71it/s, loss=0.0171, v_num=ypmf]Epoch 188:  11% 29/270 [00:19<-1:59:38, -10.60it/s, loss=0.0171, v_num=ypmf]Epoch 188:  11% 30/270 [00:20<-1:59:37, -10.38it/s, loss=0.0171, v_num=ypmf]Epoch 188:  11% 30/270 [00:20<-1:59:37, -10.38it/s, loss=0.0171, v_num=ypmf]Epoch 188:  11% 30/270 [00:20<-1:59:37, -10.19it/s, loss=0.0171, v_num=ypmf]Epoch 188:  11% 31/270 [00:21<-1:59:37, -9.98it/s, loss=0.0171, v_num=ypmf] Epoch 188:  11% 31/270 [00:21<-1:59:37, -9.98it/s, loss=0.0171, v_num=ypmf]Epoch 188:  11% 31/270 [00:21<-1:59:36, -9.88it/s, loss=0.017, v_num=ypmf] Epoch 188:  12% 32/270 [00:21<-1:59:36, -9.68it/s, loss=0.017, v_num=ypmf]Epoch 188:  12% 32/270 [00:21<-1:59:36, -9.68it/s, loss=0.017, v_num=ypmf]Epoch 188:  12% 32/270 [00:21<-1:59:36, -9.57it/s, loss=0.017, v_num=ypmf]Epoch 188:  12% 33/270 [00:22<-1:59:35, -9.32it/s, loss=0.017, v_num=ypmf]Epoch 188:  12% 33/270 [00:22<-1:59:35, -9.32it/s, loss=0.017, v_num=ypmf]Epoch 188:  12% 33/270 [00:22<-1:59:35, -9.26it/s, loss=0.0169, v_num=ypmf]Epoch 188:  13% 34/270 [00:22<-1:59:34, -9.07it/s, loss=0.0169, v_num=ypmf]Epoch 188:  13% 34/270 [00:22<-1:59:34, -9.07it/s, loss=0.0169, v_num=ypmf]Epoch 188:  13% 34/270 [00:23<-1:59:34, -9.00it/s, loss=0.0169, v_num=ypmf]Epoch 188:  13% 35/270 [00:23<-1:59:34, -8.81it/s, loss=0.0169, v_num=ypmf]Epoch 188:  13% 35/270 [00:23<-1:59:34, -8.81it/s, loss=0.0169, v_num=ypmf]Epoch 188:  13% 35/270 [00:23<-1:59:34, -8.76it/s, loss=0.0169, v_num=ypmf]Epoch 188:  13% 36/270 [00:23<-1:59:33, -8.59it/s, loss=0.0169, v_num=ypmf]Epoch 188:  13% 36/270 [00:23<-1:59:33, -8.59it/s, loss=0.0169, v_num=ypmf]Epoch 188:  13% 36/270 [00:24<-1:59:33, -8.50it/s, loss=0.0169, v_num=ypmf]Epoch 188:  14% 37/270 [00:24<-1:59:33, -8.33it/s, loss=0.0169, v_num=ypmf]Epoch 188:  14% 37/270 [00:24<-1:59:33, -8.33it/s, loss=0.0169, v_num=ypmf]Epoch 188:  14% 37/270 [00:25<-1:59:32, -8.04it/s, loss=0.0169, v_num=ypmf]Epoch 188:  14% 38/270 [00:25<-1:59:31, -7.91it/s, loss=0.0169, v_num=ypmf]Epoch 188:  14% 38/270 [00:25<-1:59:31, -7.91it/s, loss=0.0169, v_num=ypmf]Epoch 188:  14% 38/270 [00:25<-1:59:31, -7.84it/s, loss=0.0168, v_num=ypmf]Epoch 188:  14% 39/270 [00:26<-1:59:30, -7.67it/s, loss=0.0168, v_num=ypmf]Epoch 188:  14% 39/270 [00:26<-1:59:30, -7.67it/s, loss=0.0168, v_num=ypmf]Epoch 188:  14% 39/270 [00:26<-1:59:30, -7.63it/s, loss=0.0168, v_num=ypmf]Epoch 188:  15% 40/270 [00:26<-1:59:30, -7.46it/s, loss=0.0168, v_num=ypmf]Epoch 188:  15% 40/270 [00:26<-1:59:30, -7.46it/s, loss=0.0168, v_num=ypmf]Epoch 188:  15% 40/270 [00:27<-1:59:29, -7.38it/s, loss=0.0168, v_num=ypmf]Epoch 188:  15% 41/270 [00:27<-1:59:29, -7.20it/s, loss=0.0168, v_num=ypmf]Epoch 188:  15% 41/270 [00:27<-1:59:29, -7.20it/s, loss=0.0168, v_num=ypmf]Epoch 188:  15% 41/270 [00:27<-1:59:29, -7.20it/s, loss=0.0169, v_num=ypmf]Epoch 188:  16% 42/270 [00:28<-1:59:28, -7.07it/s, loss=0.0169, v_num=ypmf]Epoch 188:  16% 42/270 [00:28<-1:59:28, -7.07it/s, loss=0.0169, v_num=ypmf]Epoch 188:  16% 42/270 [00:28<-1:59:28, -7.01it/s, loss=0.0169, v_num=ypmf]Epoch 188:  16% 43/270 [00:28<-1:59:28, -6.89it/s, loss=0.0169, v_num=ypmf]Epoch 188:  16% 43/270 [00:28<-1:59:28, -6.89it/s, loss=0.0169, v_num=ypmf]Epoch 188:  16% 43/270 [00:28<-1:59:27, -6.83it/s, loss=0.0169, v_num=ypmf]Epoch 188:  16% 44/270 [00:29<-1:59:27, -6.71it/s, loss=0.0169, v_num=ypmf]Epoch 188:  16% 44/270 [00:29<-1:59:27, -6.71it/s, loss=0.0169, v_num=ypmf]Epoch 188:  16% 44/270 [00:29<-1:59:27, -6.65it/s, loss=0.0169, v_num=ypmf]Epoch 188:  17% 45/270 [00:30<-1:59:26, -6.53it/s, loss=0.0169, v_num=ypmf]Epoch 188:  17% 45/270 [00:30<-1:59:26, -6.53it/s, loss=0.0169, v_num=ypmf]Epoch 188:  17% 45/270 [00:30<-1:59:26, -6.48it/s, loss=0.0168, v_num=ypmf]Epoch 188:  17% 46/270 [00:30<-1:59:25, -6.36it/s, loss=0.0168, v_num=ypmf]Epoch 188:  17% 46/270 [00:30<-1:59:25, -6.36it/s, loss=0.0168, v_num=ypmf]Epoch 188:  17% 46/270 [00:30<-1:59:25, -6.32it/s, loss=0.0168, v_num=ypmf]Epoch 188:  17% 47/270 [00:31<-1:59:25, -6.22it/s, loss=0.0168, v_num=ypmf]Epoch 188:  17% 47/270 [00:31<-1:59:25, -6.22it/s, loss=0.0168, v_num=ypmf]Epoch 188:  17% 47/270 [00:31<-1:59:24, -6.19it/s, loss=0.0168, v_num=ypmf]Epoch 188:  18% 48/270 [00:31<-1:59:24, -6.08it/s, loss=0.0168, v_num=ypmf]Epoch 188:  18% 48/270 [00:31<-1:59:24, -6.08it/s, loss=0.0168, v_num=ypmf]Epoch 188:  18% 48/270 [00:31<-1:59:24, -6.04it/s, loss=0.0168, v_num=ypmf]Epoch 188:  18% 49/270 [00:32<-1:59:23, -5.93it/s, loss=0.0168, v_num=ypmf]Epoch 188:  18% 49/270 [00:32<-1:59:23, -5.93it/s, loss=0.0168, v_num=ypmf]Epoch 188:  18% 49/270 [00:32<-1:59:23, -5.91it/s, loss=0.0168, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 334726. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 316818. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 266399. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 260652. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 294056. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 303640. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 286171. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 354691. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 304558. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 299407. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 304908. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 304411. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 272407. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 339113. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 339716. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 315051. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 284571. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 304059. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 309275. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 321344. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 335570. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 300671. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301636. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 331222. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 304100. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 188:  19% 50/270 [00:32<-1:59:23, -5.81it/s, loss=0.0168, v_num=ypmf]Epoch 188:  19% 50/270 [00:32<-1:59:23, -5.81it/s, loss=0.0168, v_num=ypmf]Epoch 188:  19% 50/270 [00:33<-1:59:22, -5.77it/s, loss=0.0167, v_num=ypmf]Epoch 188:  19% 51/270 [00:33<-1:59:22, -5.67it/s, loss=0.0167, v_num=ypmf]Epoch 188:  19% 51/270 [00:33<-1:59:22, -5.67it/s, loss=0.0167, v_num=ypmf]Epoch 188:  19% 51/270 [00:33<-1:59:22, -5.64it/s, loss=0.0167, v_num=ypmf]Epoch 188:  19% 52/270 [00:34<-1:59:21, -5.54it/s, loss=0.0167, v_num=ypmf]Epoch 188:  19% 52/270 [00:34<-1:59:21, -5.54it/s, loss=0.0167, v_num=ypmf]Epoch 188:  19% 52/270 [00:34<-1:59:21, -5.52it/s, loss=0.0166, v_num=ypmf]Epoch 188:  20% 53/270 [00:34<-1:59:21, -5.44it/s, loss=0.0166, v_num=ypmf]Epoch 188:  20% 53/270 [00:34<-1:59:21, -5.44it/s, loss=0.0166, v_num=ypmf]Epoch 188:  20% 53/270 [00:35<-1:59:20, -5.34it/s, loss=0.0167, v_num=ypmf]Epoch 188:  20% 54/270 [00:35<-1:59:19, -5.26it/s, loss=0.0167, v_num=ypmf]Epoch 188:  20% 54/270 [00:35<-1:59:19, -5.26it/s, loss=0.0167, v_num=ypmf]Epoch 188:  20% 54/270 [00:35<-1:59:19, -5.21it/s, loss=0.0168, v_num=ypmf]Epoch 188:  20% 55/270 [00:36<-1:59:19, -5.14it/s, loss=0.0168, v_num=ypmf]Epoch 188:  20% 55/270 [00:36<-1:59:19, -5.14it/s, loss=0.0168, v_num=ypmf]Epoch 188:  20% 55/270 [00:36<-1:59:18, -5.10it/s, loss=0.0168, v_num=ypmf]Epoch 188:  21% 56/270 [00:36<-1:59:18, -5.02it/s, loss=0.0168, v_num=ypmf]Epoch 188:  21% 56/270 [00:36<-1:59:18, -5.02it/s, loss=0.0168, v_num=ypmf]Epoch 188:  21% 56/270 [00:37<-1:59:18, -4.99it/s, loss=0.0169, v_num=ypmf]Epoch 188:  21% 57/270 [00:37<-1:59:17, -4.92it/s, loss=0.0169, v_num=ypmf]Epoch 188:  21% 57/270 [00:37<-1:59:17, -4.92it/s, loss=0.0169, v_num=ypmf]Epoch 188:  21% 57/270 [00:37<-1:59:17, -4.90it/s, loss=0.0168, v_num=ypmf]Epoch 188:  21% 58/270 [00:38<-1:59:16, -4.81it/s, loss=0.0168, v_num=ypmf]Epoch 188:  21% 58/270 [00:38<-1:59:16, -4.81it/s, loss=0.0168, v_num=ypmf]Epoch 188:  21% 58/270 [00:38<-1:59:16, -4.79it/s, loss=0.0168, v_num=ypmf]Epoch 188:  22% 59/270 [00:38<-1:59:16, -4.73it/s, loss=0.0168, v_num=ypmf]Epoch 188:  22% 59/270 [00:38<-1:59:16, -4.73it/s, loss=0.0168, v_num=ypmf]Epoch 188:  22% 59/270 [00:38<-1:59:16, -4.71it/s, loss=0.0169, v_num=ypmf]Epoch 188:  22% 60/270 [00:38<-1:59:15, -4.64it/s, loss=0.0169, v_num=ypmf]Epoch 188:  22% 60/270 [00:38<-1:59:15, -4.64it/s, loss=0.0169, v_num=ypmf]Epoch 188:  22% 60/270 [00:39<-1:59:15, -4.59it/s, loss=0.0169, v_num=ypmf]Epoch 188:  23% 61/270 [00:39<-1:59:14, -4.51it/s, loss=0.0169, v_num=ypmf]Epoch 188:  23% 61/270 [00:39<-1:59:14, -4.51it/s, loss=0.0169, v_num=ypmf]Epoch 188:  23% 61/270 [00:40<-1:59:14, -4.49it/s, loss=0.0169, v_num=ypmf]Epoch 188:  23% 62/270 [00:40<-1:59:13, -4.42it/s, loss=0.0169, v_num=ypmf]Epoch 188:  23% 62/270 [00:40<-1:59:13, -4.42it/s, loss=0.0169, v_num=ypmf]Epoch 188:  23% 62/270 [00:41<-1:59:13, -4.35it/s, loss=0.0169, v_num=ypmf]Epoch 188:  23% 63/270 [00:41<-1:59:12, -4.28it/s, loss=0.0169, v_num=ypmf]Epoch 188:  23% 63/270 [00:41<-1:59:12, -4.28it/s, loss=0.0169, v_num=ypmf]Epoch 188:  23% 63/270 [00:41<-1:59:12, -4.27it/s, loss=0.0169, v_num=ypmf]Epoch 188:  24% 64/270 [00:42<-1:59:12, -4.21it/s, loss=0.0169, v_num=ypmf]Epoch 188:  24% 64/270 [00:42<-1:59:12, -4.21it/s, loss=0.0169, v_num=ypmf]Epoch 188:  24% 64/270 [00:42<-1:59:11, -4.19it/s, loss=0.0169, v_num=ypmf]Epoch 188:  24% 65/270 [00:42<-1:59:11, -4.13it/s, loss=0.0169, v_num=ypmf]Epoch 188:  24% 65/270 [00:42<-1:59:11, -4.13it/s, loss=0.0169, v_num=ypmf]Epoch 188:  24% 65/270 [00:42<-1:59:11, -4.11it/s, loss=0.017, v_num=ypmf] Epoch 188:  24% 66/270 [00:43<-1:59:10, -4.04it/s, loss=0.017, v_num=ypmf]Epoch 188:  24% 66/270 [00:43<-1:59:10, -4.04it/s, loss=0.017, v_num=ypmf]Epoch 188:  24% 66/270 [00:43<-1:59:10, -4.02it/s, loss=0.017, v_num=ypmf]Epoch 188:  25% 67/270 [00:43<-1:59:09, -3.96it/s, loss=0.017, v_num=ypmf]Epoch 188:  25% 67/270 [00:43<-1:59:09, -3.96it/s, loss=0.017, v_num=ypmf]Epoch 188:  25% 67/270 [00:44<-1:59:09, -3.95it/s, loss=0.0169, v_num=ypmf]Epoch 188:  25% 68/270 [00:44<-1:59:09, -3.89it/s, loss=0.0169, v_num=ypmf]Epoch 188:  25% 68/270 [00:44<-1:59:09, -3.89it/s, loss=0.0169, v_num=ypmf]Epoch 188:  25% 68/270 [00:44<-1:59:08, -3.88it/s, loss=0.0169, v_num=ypmf]Epoch 188:  26% 69/270 [00:45<-1:59:08, -3.80it/s, loss=0.0169, v_num=ypmf]Epoch 188:  26% 69/270 [00:45<-1:59:08, -3.80it/s, loss=0.0169, v_num=ypmf]Epoch 188:  26% 69/270 [00:45<-1:59:07, -3.79it/s, loss=0.0168, v_num=ypmf]Epoch 188:  26% 70/270 [00:45<-1:59:07, -3.73it/s, loss=0.0168, v_num=ypmf]Epoch 188:  26% 70/270 [00:45<-1:59:07, -3.73it/s, loss=0.0168, v_num=ypmf]Epoch 188:  26% 70/270 [00:46<-1:59:07, -3.71it/s, loss=0.0168, v_num=ypmf]Epoch 188:  26% 71/270 [00:47<-1:59:04, -3.55it/s, loss=0.0168, v_num=ypmf]Epoch 188:  26% 71/270 [00:47<-1:59:04, -3.55it/s, loss=0.0168, v_num=ypmf]Epoch 188:  26% 71/270 [00:47<-1:59:04, -3.54it/s, loss=0.0168, v_num=ypmf]Epoch 188:  27% 72/270 [00:48<-1:59:04, -3.50it/s, loss=0.0168, v_num=ypmf]Epoch 188:  27% 72/270 [00:48<-1:59:04, -3.50it/s, loss=0.0168, v_num=ypmf]Epoch 188:  27% 72/270 [00:48<-1:59:04, -3.49it/s, loss=0.0169, v_num=ypmf]Epoch 188:  27% 73/270 [00:49<-1:59:03, -3.43it/s, loss=0.0169, v_num=ypmf]Epoch 188:  27% 73/270 [00:49<-1:59:03, -3.43it/s, loss=0.0169, v_num=ypmf]Epoch 188:  27% 73/270 [00:49<-1:59:03, -3.42it/s, loss=0.0167, v_num=ypmf]Epoch 188:  27% 74/270 [00:49<-1:59:02, -3.37it/s, loss=0.0167, v_num=ypmf]Epoch 188:  27% 74/270 [00:49<-1:59:02, -3.37it/s, loss=0.0167, v_num=ypmf]Epoch 188:  27% 74/270 [00:49<-1:59:02, -3.36it/s, loss=0.0167, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 325063. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 331459. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 257957. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 299885. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 267067. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 294640. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 276818. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 350657. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 269889. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 282240. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 343908. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 352627. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 318617. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 289876. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 277314. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 323542. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 330357. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 324048. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 421311. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 324425. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 302045. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 307587. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 377637. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 282293. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 259583. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 188:  28% 75/270 [00:49<-1:59:02, -3.32it/s, loss=0.0167, v_num=ypmf]Epoch 188:  28% 75/270 [00:49<-1:59:02, -3.32it/s, loss=0.0167, v_num=ypmf]Epoch 188:  28% 75/270 [00:50<-1:59:02, -3.31it/s, loss=0.0168, v_num=ypmf]Epoch 188:  28% 76/270 [00:50<-1:59:01, -3.27it/s, loss=0.0168, v_num=ypmf]Epoch 188:  28% 76/270 [00:50<-1:59:01, -3.27it/s, loss=0.0168, v_num=ypmf]Epoch 188:  28% 76/270 [00:50<-1:59:01, -3.26it/s, loss=0.0168, v_num=ypmf]Epoch 188:  29% 77/270 [00:51<-1:59:00, -3.21it/s, loss=0.0168, v_num=ypmf]Epoch 188:  29% 77/270 [00:51<-1:59:00, -3.21it/s, loss=0.0168, v_num=ypmf]Epoch 188:  29% 77/270 [00:51<-1:59:00, -3.21it/s, loss=0.0169, v_num=ypmf]Epoch 188:  29% 78/270 [00:51<-1:59:00, -3.16it/s, loss=0.0169, v_num=ypmf]Epoch 188:  29% 78/270 [00:51<-1:59:00, -3.16it/s, loss=0.0169, v_num=ypmf]Epoch 188:  29% 78/270 [00:52<-1:58:59, -3.12it/s, loss=0.0169, v_num=ypmf]Epoch 188:  29% 79/270 [00:52<-1:58:58, -3.08it/s, loss=0.0169, v_num=ypmf]Epoch 188:  29% 79/270 [00:52<-1:58:58, -3.08it/s, loss=0.0169, v_num=ypmf]Epoch 188:  29% 79/270 [00:52<-1:58:58, -3.06it/s, loss=0.0169, v_num=ypmf]Epoch 188:  30% 80/270 [00:53<-1:58:58, -3.02it/s, loss=0.0169, v_num=ypmf]Epoch 188:  30% 80/270 [00:53<-1:58:58, -3.02it/s, loss=0.0169, v_num=ypmf]Epoch 188:  30% 80/270 [00:53<-1:58:57, -3.01it/s, loss=0.0168, v_num=ypmf]Epoch 188:  30% 81/270 [00:53<-1:58:57, -2.98it/s, loss=0.0168, v_num=ypmf]Epoch 188:  30% 81/270 [00:53<-1:58:57, -2.98it/s, loss=0.0168, v_num=ypmf]Epoch 188:  30% 81/270 [00:53<-1:58:57, -2.96it/s, loss=0.0168, v_num=ypmf]Epoch 188:  30% 82/270 [00:54<-1:58:56, -2.93it/s, loss=0.0168, v_num=ypmf]Epoch 188:  30% 82/270 [00:54<-1:58:56, -2.93it/s, loss=0.0168, v_num=ypmf]Epoch 188:  30% 82/270 [00:54<-1:58:56, -2.92it/s, loss=0.0168, v_num=ypmf]Epoch 188:  31% 83/270 [00:54<-1:58:56, -2.88it/s, loss=0.0168, v_num=ypmf]Epoch 188:  31% 83/270 [00:54<-1:58:56, -2.88it/s, loss=0.0168, v_num=ypmf]Epoch 188:  31% 83/270 [00:55<-1:58:55, -2.87it/s, loss=0.0168, v_num=ypmf]Epoch 188:  31% 84/270 [00:55<-1:58:55, -2.83it/s, loss=0.0168, v_num=ypmf]Epoch 188:  31% 84/270 [00:55<-1:58:55, -2.83it/s, loss=0.0168, v_num=ypmf]Epoch 188:  31% 84/270 [00:55<-1:58:55, -2.83it/s, loss=0.0167, v_num=ypmf]Epoch 188:  31% 85/270 [00:55<-1:58:54, -2.79it/s, loss=0.0167, v_num=ypmf]Epoch 188:  31% 85/270 [00:55<-1:58:54, -2.79it/s, loss=0.0167, v_num=ypmf]Epoch 188:  31% 85/270 [00:56<-1:58:54, -2.78it/s, loss=0.0167, v_num=ypmf]Epoch 188:  32% 86/270 [00:56<-1:58:53, -2.74it/s, loss=0.0167, v_num=ypmf]Epoch 188:  32% 86/270 [00:56<-1:58:53, -2.74it/s, loss=0.0167, v_num=ypmf]Epoch 188:  32% 86/270 [00:56<-1:58:53, -2.74it/s, loss=0.0167, v_num=ypmf]Epoch 188:  32% 87/270 [00:56<-1:58:53, -2.71it/s, loss=0.0167, v_num=ypmf]Epoch 188:  32% 87/270 [00:56<-1:58:53, -2.71it/s, loss=0.0167, v_num=ypmf]Epoch 188:  32% 87/270 [00:57<-1:58:52, -2.67it/s, loss=0.0168, v_num=ypmf]Epoch 188:  33% 88/270 [00:58<-1:58:51, -2.63it/s, loss=0.0168, v_num=ypmf]Epoch 188:  33% 88/270 [00:58<-1:58:51, -2.63it/s, loss=0.0168, v_num=ypmf]Epoch 188:  33% 88/270 [00:58<-1:58:51, -2.63it/s, loss=0.0168, v_num=ypmf]Epoch 188:  33% 89/270 [00:58<-1:58:51, -2.59it/s, loss=0.0168, v_num=ypmf]Epoch 188:  33% 89/270 [00:58<-1:58:51, -2.59it/s, loss=0.0168, v_num=ypmf]Epoch 188:  33% 89/270 [00:59<-1:58:50, -2.55it/s, loss=0.0168, v_num=ypmf]Epoch 188:  33% 90/270 [00:59<-1:58:49, -2.52it/s, loss=0.0168, v_num=ypmf]Epoch 188:  33% 90/270 [00:59<-1:58:49, -2.52it/s, loss=0.0168, v_num=ypmf]Epoch 188:  33% 90/270 [01:00<-1:58:49, -2.51it/s, loss=0.0169, v_num=ypmf]Epoch 188:  34% 91/270 [01:01<-1:58:47, -2.45it/s, loss=0.0169, v_num=ypmf]Epoch 188:  34% 91/270 [01:01<-1:58:47, -2.45it/s, loss=0.0169, v_num=ypmf]Epoch 188:  34% 91/270 [01:01<-1:58:47, -2.45it/s, loss=0.0168, v_num=ypmf]Epoch 188:  34% 92/270 [01:01<-1:58:47, -2.42it/s, loss=0.0168, v_num=ypmf]Epoch 188:  34% 92/270 [01:01<-1:58:47, -2.42it/s, loss=0.0168, v_num=ypmf]Epoch 188:  34% 92/270 [01:01<-1:58:47, -2.41it/s, loss=0.0168, v_num=ypmf]Epoch 188:  34% 93/270 [01:02<-1:58:46, -2.38it/s, loss=0.0168, v_num=ypmf]Epoch 188:  34% 93/270 [01:02<-1:58:46, -2.38it/s, loss=0.0168, v_num=ypmf]Epoch 188:  34% 93/270 [01:02<-1:58:46, -2.37it/s, loss=0.0169, v_num=ypmf]Epoch 188:  35% 94/270 [01:02<-1:58:45, -2.34it/s, loss=0.0169, v_num=ypmf]Epoch 188:  35% 94/270 [01:02<-1:58:45, -2.34it/s, loss=0.0169, v_num=ypmf]Epoch 188:  35% 94/270 [01:03<-1:58:45, -2.33it/s, loss=0.0168, v_num=ypmf]Epoch 188:  35% 95/270 [01:03<-1:58:44, -2.30it/s, loss=0.0168, v_num=ypmf]Epoch 188:  35% 95/270 [01:03<-1:58:44, -2.30it/s, loss=0.0168, v_num=ypmf]Epoch 188:  35% 95/270 [01:03<-1:58:44, -2.29it/s, loss=0.0167, v_num=ypmf]Epoch 188:  36% 96/270 [01:04<-1:58:44, -2.26it/s, loss=0.0167, v_num=ypmf]Epoch 188:  36% 96/270 [01:04<-1:58:44, -2.26it/s, loss=0.0167, v_num=ypmf]Epoch 188:  36% 96/270 [01:04<-1:58:43, -2.26it/s, loss=0.0166, v_num=ypmf]Epoch 188:  36% 97/270 [01:04<-1:58:43, -2.23it/s, loss=0.0166, v_num=ypmf]Epoch 188:  36% 97/270 [01:04<-1:58:43, -2.23it/s, loss=0.0166, v_num=ypmf]Epoch 188:  36% 97/270 [01:04<-1:58:43, -2.22it/s, loss=0.0169, v_num=ypmf]Epoch 188:  36% 98/270 [01:05<-1:58:42, -2.20it/s, loss=0.0169, v_num=ypmf]Epoch 188:  36% 98/270 [01:05<-1:58:42, -2.20it/s, loss=0.0169, v_num=ypmf]Epoch 188:  36% 98/270 [01:05<-1:58:42, -2.19it/s, loss=0.0168, v_num=ypmf]Epoch 188:  37% 99/270 [01:05<-1:58:42, -2.16it/s, loss=0.0168, v_num=ypmf]Epoch 188:  37% 99/270 [01:05<-1:58:42, -2.16it/s, loss=0.0168, v_num=ypmf]Epoch 188:  37% 99/270 [01:05<-1:58:41, -2.16it/s, loss=0.0167, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 294281. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319046. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 355950. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 292969. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 317375. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 264761. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 271738. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 369365. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 297777. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 300917. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 302087. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 262220. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308712. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 311812. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 315254. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 300058. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 325672. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 287268. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 295620. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293974. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 338407. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 294176. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301420. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 290409. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 332073. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 188:  37% 100/270 [01:06<-1:58:41, -2.13it/s, loss=0.0167, v_num=ypmf]Epoch 188:  37% 100/270 [01:06<-1:58:41, -2.13it/s, loss=0.0167, v_num=ypmf]Epoch 188:  37% 100/270 [01:06<-1:58:41, -2.13it/s, loss=0.0167, v_num=ypmf]Epoch 188:  37% 101/270 [01:06<-1:58:40, -2.10it/s, loss=0.0167, v_num=ypmf]Epoch 188:  37% 101/270 [01:06<-1:58:40, -2.10it/s, loss=0.0167, v_num=ypmf]Epoch 188:  37% 101/270 [01:06<-1:58:40, -2.09it/s, loss=0.0167, v_num=ypmf]Epoch 188:  38% 102/270 [01:07<-1:58:39, -2.07it/s, loss=0.0167, v_num=ypmf]Epoch 188:  38% 102/270 [01:07<-1:58:39, -2.07it/s, loss=0.0167, v_num=ypmf]Epoch 188:  38% 102/270 [01:07<-1:58:39, -2.06it/s, loss=0.0167, v_num=ypmf]Epoch 188:  38% 103/270 [01:07<-1:58:38, -2.03it/s, loss=0.0167, v_num=ypmf]Epoch 188:  38% 103/270 [01:07<-1:58:38, -2.03it/s, loss=0.0167, v_num=ypmf]Epoch 188:  38% 103/270 [01:07<-1:58:38, -2.03it/s, loss=0.0168, v_num=ypmf]Epoch 188:  39% 104/270 [01:08<-1:58:38, -2.00it/s, loss=0.0168, v_num=ypmf]Epoch 188:  39% 104/270 [01:08<-1:58:38, -2.00it/s, loss=0.0168, v_num=ypmf]Epoch 188:  39% 104/270 [01:08<-1:58:37, -2.00it/s, loss=0.0169, v_num=ypmf]Epoch 188:  39% 105/270 [01:08<-1:58:37, -1.97it/s, loss=0.0169, v_num=ypmf]Epoch 188:  39% 105/270 [01:08<-1:58:37, -1.97it/s, loss=0.0169, v_num=ypmf]Epoch 188:  39% 105/270 [01:09<-1:58:36, -1.96it/s, loss=0.017, v_num=ypmf] Epoch 188:  39% 106/270 [01:09<-1:58:36, -1.94it/s, loss=0.017, v_num=ypmf]Epoch 188:  39% 106/270 [01:09<-1:58:36, -1.94it/s, loss=0.017, v_num=ypmf]Epoch 188:  39% 106/270 [01:09<-1:58:36, -1.93it/s, loss=0.017, v_num=ypmf]Epoch 188:  40% 107/270 [01:10<-1:58:35, -1.90it/s, loss=0.017, v_num=ypmf]Epoch 188:  40% 107/270 [01:10<-1:58:35, -1.90it/s, loss=0.017, v_num=ypmf]Epoch 188:  40% 107/270 [01:11<-1:58:33, -1.87it/s, loss=0.017, v_num=ypmf]Epoch 188:  40% 108/270 [01:11<-1:58:33, -1.85it/s, loss=0.017, v_num=ypmf]Epoch 188:  40% 108/270 [01:11<-1:58:33, -1.85it/s, loss=0.017, v_num=ypmf]Epoch 188:  40% 108/270 [01:12<-1:58:32, -1.84it/s, loss=0.0171, v_num=ypmf]Epoch 188:  40% 109/270 [01:12<-1:58:32, -1.82it/s, loss=0.0171, v_num=ypmf]Epoch 188:  40% 109/270 [01:12<-1:58:32, -1.82it/s, loss=0.0171, v_num=ypmf]Epoch 188:  40% 109/270 [01:13<-1:58:31, -1.80it/s, loss=0.017, v_num=ypmf] Epoch 188:  41% 110/270 [01:13<-1:58:30, -1.77it/s, loss=0.017, v_num=ypmf]Epoch 188:  41% 110/270 [01:13<-1:58:30, -1.77it/s, loss=0.017, v_num=ypmf]Epoch 188:  41% 110/270 [01:14<-1:58:30, -1.77it/s, loss=0.0169, v_num=ypmf]Epoch 188:  41% 111/270 [01:14<-1:58:29, -1.74it/s, loss=0.0169, v_num=ypmf]Epoch 188:  41% 111/270 [01:14<-1:58:29, -1.74it/s, loss=0.0169, v_num=ypmf]Epoch 188:  41% 111/270 [01:14<-1:58:29, -1.74it/s, loss=0.0169, v_num=ypmf]Epoch 188:  41% 112/270 [01:15<-1:58:29, -1.72it/s, loss=0.0169, v_num=ypmf]Epoch 188:  41% 112/270 [01:15<-1:58:29, -1.72it/s, loss=0.0169, v_num=ypmf]Epoch 188:  41% 112/270 [01:15<-1:58:28, -1.71it/s, loss=0.0169, v_num=ypmf]Epoch 188:  42% 113/270 [01:15<-1:58:28, -1.69it/s, loss=0.0169, v_num=ypmf]Epoch 188:  42% 113/270 [01:15<-1:58:28, -1.69it/s, loss=0.0169, v_num=ypmf]Epoch 188:  42% 113/270 [01:15<-1:58:27, -1.68it/s, loss=0.0169, v_num=ypmf]Epoch 188:  42% 114/270 [01:16<-1:58:27, -1.66it/s, loss=0.0169, v_num=ypmf]Epoch 188:  42% 114/270 [01:16<-1:58:27, -1.66it/s, loss=0.0169, v_num=ypmf]Epoch 188:  42% 114/270 [01:16<-1:58:27, -1.66it/s, loss=0.0169, v_num=ypmf]Epoch 188:  43% 115/270 [01:16<-1:58:26, -1.64it/s, loss=0.0169, v_num=ypmf]Epoch 188:  43% 115/270 [01:16<-1:58:26, -1.64it/s, loss=0.0169, v_num=ypmf]Epoch 188:  43% 115/270 [01:17<-1:58:25, -1.62it/s, loss=0.0168, v_num=ypmf]Epoch 188:  43% 116/270 [01:18<-1:58:24, -1.60it/s, loss=0.0168, v_num=ypmf]Epoch 188:  43% 116/270 [01:18<-1:58:24, -1.60it/s, loss=0.0168, v_num=ypmf]Epoch 188:  43% 116/270 [01:18<-1:58:24, -1.60it/s, loss=0.0168, v_num=ypmf]Epoch 188:  43% 117/270 [01:18<-1:58:23, -1.58it/s, loss=0.0168, v_num=ypmf]Epoch 188:  43% 117/270 [01:18<-1:58:23, -1.58it/s, loss=0.0168, v_num=ypmf]Epoch 188:  43% 117/270 [01:18<-1:58:23, -1.57it/s, loss=0.0166, v_num=ypmf]Epoch 188:  44% 118/270 [01:19<-1:58:23, -1.55it/s, loss=0.0166, v_num=ypmf]Epoch 188:  44% 118/270 [01:19<-1:58:23, -1.55it/s, loss=0.0166, v_num=ypmf]Epoch 188:  44% 118/270 [01:19<-1:58:22, -1.55it/s, loss=0.0166, v_num=ypmf]Epoch 188:  44% 119/270 [01:19<-1:58:22, -1.53it/s, loss=0.0166, v_num=ypmf]Epoch 188:  44% 119/270 [01:19<-1:58:22, -1.53it/s, loss=0.0166, v_num=ypmf]Epoch 188:  44% 119/270 [01:20<-1:58:21, -1.52it/s, loss=0.0167, v_num=ypmf]Epoch 188:  44% 120/270 [01:20<-1:58:21, -1.51it/s, loss=0.0167, v_num=ypmf]Epoch 188:  44% 120/270 [01:20<-1:58:21, -1.51it/s, loss=0.0167, v_num=ypmf]Epoch 188:  44% 120/270 [01:20<-1:58:21, -1.50it/s, loss=0.0167, v_num=ypmf]Epoch 188:  45% 121/270 [01:21<-1:58:20, -1.48it/s, loss=0.0167, v_num=ypmf]Epoch 188:  45% 121/270 [01:21<-1:58:20, -1.48it/s, loss=0.0167, v_num=ypmf]Epoch 188:  45% 121/270 [01:21<-1:58:20, -1.48it/s, loss=0.0167, v_num=ypmf]Epoch 188:  45% 122/270 [01:21<-1:58:19, -1.46it/s, loss=0.0167, v_num=ypmf]Epoch 188:  45% 122/270 [01:21<-1:58:19, -1.46it/s, loss=0.0167, v_num=ypmf]Epoch 188:  45% 122/270 [01:21<-1:58:19, -1.46it/s, loss=0.0168, v_num=ypmf]Epoch 188:  46% 123/270 [01:22<-1:58:18, -1.44it/s, loss=0.0168, v_num=ypmf]Epoch 188:  46% 123/270 [01:22<-1:58:18, -1.44it/s, loss=0.0168, v_num=ypmf]Epoch 188:  46% 123/270 [01:22<-1:58:18, -1.43it/s, loss=0.0167, v_num=ypmf]Epoch 188:  46% 124/270 [01:22<-1:58:18, -1.42it/s, loss=0.0167, v_num=ypmf]Epoch 188:  46% 124/270 [01:22<-1:58:18, -1.42it/s, loss=0.0167, v_num=ypmf]Epoch 188:  46% 124/270 [01:22<-1:58:17, -1.41it/s, loss=0.0168, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 264731. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 350962. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 300495. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 310782. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 314936. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 264162. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 331444. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 255767. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 322048. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 390427. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 318226. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293693. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 314046. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319822. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 348537. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 313603. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 284034. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 309943. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 292086. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 277222. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 346709. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 255243. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 312984. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 251212. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 350759. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 188:  46% 125/270 [01:23<-1:58:16, -1.39it/s, loss=0.0168, v_num=ypmf]Epoch 188:  46% 125/270 [01:23<-1:58:16, -1.39it/s, loss=0.0168, v_num=ypmf]Epoch 188:  46% 125/270 [01:23<-1:58:16, -1.39it/s, loss=0.0167, v_num=ypmf]Epoch 188:  47% 126/270 [01:24<-1:58:15, -1.37it/s, loss=0.0167, v_num=ypmf]Epoch 188:  47% 126/270 [01:24<-1:58:15, -1.37it/s, loss=0.0167, v_num=ypmf]Epoch 188:  47% 126/270 [01:24<-1:58:15, -1.37it/s, loss=0.0167, v_num=ypmf]Epoch 188:  47% 127/270 [01:24<-1:58:14, -1.35it/s, loss=0.0167, v_num=ypmf]Epoch 188:  47% 127/270 [01:24<-1:58:14, -1.35it/s, loss=0.0167, v_num=ypmf]Epoch 188:  47% 127/270 [01:24<-1:58:14, -1.34it/s, loss=0.0167, v_num=ypmf]Epoch 188:  47% 128/270 [01:25<-1:58:13, -1.33it/s, loss=0.0167, v_num=ypmf]Epoch 188:  47% 128/270 [01:25<-1:58:13, -1.33it/s, loss=0.0167, v_num=ypmf]Epoch 188:  47% 128/270 [01:25<-1:58:13, -1.32it/s, loss=0.0166, v_num=ypmf]Epoch 188:  48% 129/270 [01:25<-1:58:12, -1.30it/s, loss=0.0166, v_num=ypmf]Epoch 188:  48% 129/270 [01:25<-1:58:12, -1.30it/s, loss=0.0166, v_num=ypmf]Epoch 188:  48% 129/270 [01:26<-1:58:12, -1.30it/s, loss=0.0166, v_num=ypmf]Epoch 188:  48% 130/270 [01:32<-1:58:04, -1.20it/s, loss=0.0166, v_num=ypmf]Epoch 188:  48% 130/270 [01:32<-1:58:04, -1.20it/s, loss=0.0166, v_num=ypmf]Epoch 188:  48% 130/270 [01:32<-1:58:04, -1.20it/s, loss=0.0167, v_num=ypmf]Epoch 188:  49% 131/270 [01:33<-1:58:03, -1.18it/s, loss=0.0167, v_num=ypmf]Epoch 188:  49% 131/270 [01:33<-1:58:03, -1.18it/s, loss=0.0167, v_num=ypmf]Epoch 188:  49% 131/270 [01:33<-1:58:03, -1.18it/s, loss=0.0167, v_num=ypmf]Epoch 188:  49% 132/270 [01:34<-1:58:01, -1.16it/s, loss=0.0167, v_num=ypmf]Epoch 188:  49% 132/270 [01:34<-1:58:01, -1.16it/s, loss=0.0167, v_num=ypmf]Epoch 188:  49% 132/270 [01:34<-1:58:01, -1.16it/s, loss=0.0167, v_num=ypmf]Epoch 188:  49% 133/270 [01:34<-1:58:01, -1.14it/s, loss=0.0167, v_num=ypmf]Epoch 188:  49% 133/270 [01:34<-1:58:01, -1.14it/s, loss=0.0167, v_num=ypmf]Epoch 188:  49% 133/270 [01:34<-1:58:00, -1.14it/s, loss=0.0167, v_num=ypmf]Epoch 188:  50% 134/270 [01:35<-1:57:59, -1.12it/s, loss=0.0167, v_num=ypmf]Epoch 188:  50% 134/270 [01:35<-1:57:59, -1.12it/s, loss=0.0167, v_num=ypmf]Epoch 188:  50% 134/270 [01:35<-1:57:59, -1.12it/s, loss=0.0167, v_num=ypmf]Epoch 188:  50% 135/270 [01:35<-1:57:59, -1.11it/s, loss=0.0167, v_num=ypmf]Epoch 188:  50% 135/270 [01:35<-1:57:59, -1.11it/s, loss=0.0167, v_num=ypmf]Epoch 188:  50% 135/270 [01:36<-1:57:58, -1.10it/s, loss=0.0167, v_num=ypmf]Epoch 188:  50% 136/270 [01:36<-1:57:57, -1.09it/s, loss=0.0167, v_num=ypmf]Epoch 188:  50% 136/270 [01:36<-1:57:57, -1.09it/s, loss=0.0167, v_num=ypmf]Epoch 188:  50% 136/270 [01:36<-1:57:57, -1.09it/s, loss=0.0168, v_num=ypmf]Epoch 188:  51% 137/270 [01:37<-1:57:56, -1.07it/s, loss=0.0168, v_num=ypmf]Epoch 188:  51% 137/270 [01:37<-1:57:56, -1.07it/s, loss=0.0168, v_num=ypmf]Epoch 188:  51% 137/270 [01:37<-1:57:56, -1.07it/s, loss=0.0167, v_num=ypmf]Epoch 188:  51% 138/270 [01:37<-1:57:55, -1.05it/s, loss=0.0167, v_num=ypmf]Epoch 188:  51% 138/270 [01:37<-1:57:55, -1.05it/s, loss=0.0167, v_num=ypmf]Epoch 188:  51% 138/270 [01:37<-1:57:55, -1.05it/s, loss=0.0167, v_num=ypmf]Epoch 188:  51% 139/270 [01:38<-1:57:54, -1.04it/s, loss=0.0167, v_num=ypmf]Epoch 188:  51% 139/270 [01:38<-1:57:54, -1.04it/s, loss=0.0167, v_num=ypmf]Epoch 188:  51% 139/270 [01:39<-1:57:53, -1.03it/s, loss=0.0166, v_num=ypmf]Epoch 188:  52% 140/270 [01:39<-1:57:52, -1.01it/s, loss=0.0166, v_num=ypmf]Epoch 188:  52% 140/270 [01:39<-1:57:52, -1.01it/s, loss=0.0166, v_num=ypmf]Epoch 188:  52% 140/270 [01:40<-1:57:52, -1.01it/s, loss=0.0167, v_num=ypmf]Epoch 188:  52% 141/270 [01:40<-1:57:50, -0.99it/s, loss=0.0167, v_num=ypmf]Epoch 188:  52% 141/270 [01:40<-1:57:50, -0.99it/s, loss=0.0167, v_num=ypmf]Epoch 188:  52% 141/270 [01:40<-1:57:50, -0.99it/s, loss=0.0167, v_num=ypmf]Epoch 188:  53% 142/270 [01:41<-1:57:49, -0.98it/s, loss=0.0167, v_num=ypmf]Epoch 188:  53% 142/270 [01:41<-1:57:49, -0.98it/s, loss=0.0167, v_num=ypmf]Epoch 188:  53% 142/270 [01:41<-1:57:49, -0.98it/s, loss=0.0167, v_num=ypmf]Epoch 188:  53% 143/270 [01:41<-1:57:48, -0.96it/s, loss=0.0167, v_num=ypmf]Epoch 188:  53% 143/270 [01:41<-1:57:48, -0.96it/s, loss=0.0167, v_num=ypmf]Epoch 188:  53% 143/270 [01:42<-1:57:47, -0.95it/s, loss=0.0167, v_num=ypmf]Epoch 188:  53% 144/270 [01:43<-1:57:47, -0.94it/s, loss=0.0167, v_num=ypmf]Epoch 188:  53% 144/270 [01:43<-1:57:47, -0.94it/s, loss=0.0167, v_num=ypmf]Epoch 188:  53% 144/270 [01:43<-1:57:46, -0.94it/s, loss=0.0166, v_num=ypmf]Epoch 188:  54% 145/270 [01:43<-1:57:46, -0.93it/s, loss=0.0166, v_num=ypmf]Epoch 188:  54% 145/270 [01:43<-1:57:46, -0.93it/s, loss=0.0166, v_num=ypmf]Epoch 188:  54% 145/270 [01:43<-1:57:45, -0.92it/s, loss=0.0166, v_num=ypmf]Epoch 188:  54% 146/270 [01:44<-1:57:44, -0.91it/s, loss=0.0166, v_num=ypmf]Epoch 188:  54% 146/270 [01:44<-1:57:44, -0.91it/s, loss=0.0166, v_num=ypmf]Epoch 188:  54% 146/270 [01:44<-1:57:44, -0.91it/s, loss=0.0166, v_num=ypmf]Epoch 188:  54% 147/270 [01:44<-1:57:43, -0.90it/s, loss=0.0166, v_num=ypmf]Epoch 188:  54% 147/270 [01:44<-1:57:43, -0.90it/s, loss=0.0166, v_num=ypmf]Epoch 188:  54% 147/270 [01:45<-1:57:43, -0.89it/s, loss=0.0166, v_num=ypmf]Epoch 188:  55% 148/270 [01:45<-1:57:42, -0.88it/s, loss=0.0166, v_num=ypmf]Epoch 188:  55% 148/270 [01:45<-1:57:42, -0.88it/s, loss=0.0166, v_num=ypmf]Epoch 188:  55% 148/270 [01:45<-1:57:42, -0.88it/s, loss=0.0167, v_num=ypmf]Epoch 188:  55% 149/270 [01:46<-1:57:41, -0.87it/s, loss=0.0167, v_num=ypmf]Epoch 188:  55% 149/270 [01:46<-1:57:41, -0.87it/s, loss=0.0167, v_num=ypmf]Epoch 188:  55% 149/270 [01:46<-1:57:40, -0.86it/s, loss=0.0168, v_num=ypmf]Epoch 188:  56% 150/270 [01:46<-1:57:40, -0.85it/s, loss=0.0168, v_num=ypmf]Epoch 188:  56% 150/270 [01:46<-1:57:40, -0.85it/s, loss=0.0168, v_num=ypmf]Epoch 188:  56% 150/270 [01:47<-1:57:39, -0.85it/s, loss=0.0169, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 314087. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 306188. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 298912. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 371416. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 322349. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 329647. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 303396. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 273050. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301129. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 257419. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 320940. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 329652. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 314153. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308344. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 310923. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 385444. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 300612. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 327918. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 309094. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 340915. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 270937. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 255837. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301171. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 246542. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 277846. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 188:  56% 151/270 [01:47<-1:57:38, -0.84it/s, loss=0.0169, v_num=ypmf]Epoch 188:  56% 151/270 [01:47<-1:57:38, -0.84it/s, loss=0.0169, v_num=ypmf]Epoch 188:  56% 151/270 [01:47<-1:57:38, -0.84it/s, loss=0.0169, v_num=ypmf]Epoch 188:  56% 152/270 [01:48<-1:57:37, -0.82it/s, loss=0.0169, v_num=ypmf]Epoch 188:  56% 152/270 [01:48<-1:57:37, -0.82it/s, loss=0.0169, v_num=ypmf]Epoch 188:  56% 152/270 [01:48<-1:57:37, -0.82it/s, loss=0.017, v_num=ypmf] Epoch 188:  57% 153/270 [01:48<-1:57:36, -0.81it/s, loss=0.017, v_num=ypmf]Epoch 188:  57% 153/270 [01:48<-1:57:36, -0.81it/s, loss=0.017, v_num=ypmf]Epoch 188:  57% 153/270 [01:48<-1:57:36, -0.81it/s, loss=0.0169, v_num=ypmf]Epoch 188:  57% 154/270 [01:49<-1:57:35, -0.80it/s, loss=0.0169, v_num=ypmf]Epoch 188:  57% 154/270 [01:49<-1:57:35, -0.80it/s, loss=0.0169, v_num=ypmf]Epoch 188:  57% 154/270 [01:49<-1:57:35, -0.80it/s, loss=0.0169, v_num=ypmf]Epoch 188:  57% 155/270 [01:49<-1:57:34, -0.78it/s, loss=0.0169, v_num=ypmf]Epoch 188:  57% 155/270 [01:49<-1:57:34, -0.78it/s, loss=0.0169, v_num=ypmf]Epoch 188:  57% 155/270 [01:49<-1:57:34, -0.78it/s, loss=0.0169, v_num=ypmf]Epoch 188:  58% 156/270 [01:50<-1:57:32, -0.77it/s, loss=0.0169, v_num=ypmf]Epoch 188:  58% 156/270 [01:50<-1:57:32, -0.77it/s, loss=0.0169, v_num=ypmf]Epoch 188:  58% 156/270 [01:50<-1:57:32, -0.77it/s, loss=0.0168, v_num=ypmf]Epoch 188:  58% 157/270 [01:51<-1:57:31, -0.76it/s, loss=0.0168, v_num=ypmf]Epoch 188:  58% 157/270 [01:51<-1:57:31, -0.76it/s, loss=0.0168, v_num=ypmf]Epoch 188:  58% 157/270 [01:51<-1:57:31, -0.75it/s, loss=0.0168, v_num=ypmf]Epoch 188:  59% 158/270 [01:51<-1:57:30, -0.74it/s, loss=0.0168, v_num=ypmf]Epoch 188:  59% 158/270 [01:51<-1:57:30, -0.74it/s, loss=0.0168, v_num=ypmf]Epoch 188:  59% 158/270 [01:51<-1:57:30, -0.74it/s, loss=0.017, v_num=ypmf] Epoch 188:  59% 159/270 [01:52<-1:57:29, -0.73it/s, loss=0.017, v_num=ypmf]Epoch 188:  59% 159/270 [01:52<-1:57:29, -0.73it/s, loss=0.017, v_num=ypmf]Epoch 188:  59% 159/270 [01:52<-1:57:28, -0.73it/s, loss=0.017, v_num=ypmf]Epoch 188:  59% 160/270 [01:52<-1:57:27, -0.72it/s, loss=0.017, v_num=ypmf]Epoch 188:  59% 160/270 [01:52<-1:57:27, -0.72it/s, loss=0.017, v_num=ypmf]Epoch 188:  59% 160/270 [01:52<-1:57:27, -0.72it/s, loss=0.017, v_num=ypmf]Epoch 188:  60% 161/270 [01:53<-1:57:26, -0.71it/s, loss=0.017, v_num=ypmf]Epoch 188:  60% 161/270 [01:53<-1:57:26, -0.71it/s, loss=0.017, v_num=ypmf]Epoch 188:  60% 161/270 [01:53<-1:57:26, -0.71it/s, loss=0.017, v_num=ypmf]Epoch 188:  60% 162/270 [01:53<-1:57:25, -0.69it/s, loss=0.017, v_num=ypmf]Epoch 188:  60% 162/270 [01:53<-1:57:25, -0.69it/s, loss=0.017, v_num=ypmf]Epoch 188:  60% 162/270 [01:54<-1:57:25, -0.69it/s, loss=0.017, v_num=ypmf]Epoch 188:  60% 163/270 [01:54<-1:57:24, -0.68it/s, loss=0.017, v_num=ypmf]Epoch 188:  60% 163/270 [01:54<-1:57:24, -0.68it/s, loss=0.017, v_num=ypmf]Epoch 188:  60% 163/270 [01:54<-1:57:23, -0.68it/s, loss=0.017, v_num=ypmf]Epoch 188:  61% 164/270 [01:54<-1:57:22, -0.67it/s, loss=0.017, v_num=ypmf]Epoch 188:  61% 164/270 [01:54<-1:57:22, -0.67it/s, loss=0.017, v_num=ypmf]Epoch 188:  61% 164/270 [01:55<-1:57:22, -0.67it/s, loss=0.017, v_num=ypmf]Epoch 188:  61% 165/270 [01:55<-1:57:21, -0.66it/s, loss=0.017, v_num=ypmf]Epoch 188:  61% 165/270 [01:55<-1:57:21, -0.66it/s, loss=0.017, v_num=ypmf]Epoch 188:  61% 165/270 [01:55<-1:57:21, -0.66it/s, loss=0.017, v_num=ypmf]Epoch 188:  61% 166/270 [01:56<-1:57:19, -0.65it/s, loss=0.017, v_num=ypmf]Epoch 188:  61% 166/270 [01:56<-1:57:19, -0.65it/s, loss=0.017, v_num=ypmf]Epoch 188:  61% 166/270 [01:56<-1:57:18, -0.64it/s, loss=0.0169, v_num=ypmf]Epoch 188:  62% 167/270 [01:57<-1:57:17, -0.63it/s, loss=0.0169, v_num=ypmf]Epoch 188:  62% 167/270 [01:57<-1:57:17, -0.63it/s, loss=0.0169, v_num=ypmf]Epoch 188:  62% 167/270 [01:57<-1:57:17, -0.63it/s, loss=0.017, v_num=ypmf] Epoch 188:  62% 168/270 [01:57<-1:57:16, -0.62it/s, loss=0.017, v_num=ypmf]Epoch 188:  62% 168/270 [01:57<-1:57:16, -0.62it/s, loss=0.017, v_num=ypmf]Epoch 188:  62% 168/270 [01:58<-1:57:15, -0.62it/s, loss=0.0169, v_num=ypmf]Epoch 188:  63% 169/270 [01:58<-1:57:14, -0.61it/s, loss=0.0169, v_num=ypmf]Epoch 188:  63% 169/270 [01:58<-1:57:14, -0.61it/s, loss=0.0169, v_num=ypmf]Epoch 188:  63% 169/270 [01:58<-1:57:14, -0.61it/s, loss=0.0169, v_num=ypmf]Epoch 188:  63% 170/270 [01:59<-1:57:13, -0.60it/s, loss=0.0169, v_num=ypmf]Epoch 188:  63% 170/270 [01:59<-1:57:13, -0.60it/s, loss=0.0169, v_num=ypmf]Epoch 188:  63% 170/270 [01:59<-1:57:12, -0.60it/s, loss=0.0167, v_num=ypmf]Epoch 188:  63% 171/270 [01:59<-1:57:11, -0.58it/s, loss=0.0167, v_num=ypmf]Epoch 188:  63% 171/270 [01:59<-1:57:11, -0.58it/s, loss=0.0167, v_num=ypmf]Epoch 188:  63% 171/270 [01:59<-1:57:11, -0.58it/s, loss=0.0167, v_num=ypmf]Epoch 188:  64% 172/270 [02:00<-1:57:10, -0.57it/s, loss=0.0167, v_num=ypmf]Epoch 188:  64% 172/270 [02:00<-1:57:10, -0.57it/s, loss=0.0167, v_num=ypmf]Epoch 188:  64% 172/270 [02:00<-1:57:09, -0.57it/s, loss=0.0166, v_num=ypmf]Epoch 188:  64% 173/270 [02:00<-1:57:08, -0.56it/s, loss=0.0166, v_num=ypmf]Epoch 188:  64% 173/270 [02:00<-1:57:08, -0.56it/s, loss=0.0166, v_num=ypmf]Epoch 188:  64% 173/270 [02:01<-1:57:08, -0.56it/s, loss=0.0167, v_num=ypmf]Epoch 188:  64% 174/270 [02:01<-1:57:06, -0.55it/s, loss=0.0167, v_num=ypmf]Epoch 188:  64% 174/270 [02:01<-1:57:06, -0.55it/s, loss=0.0167, v_num=ypmf]Epoch 188:  64% 174/270 [02:01<-1:57:06, -0.55it/s, loss=0.0167, v_num=ypmf]Epoch 188:  65% 175/270 [02:01<-1:57:05, -0.54it/s, loss=0.0167, v_num=ypmf]Epoch 188:  65% 175/270 [02:01<-1:57:05, -0.54it/s, loss=0.0167, v_num=ypmf]Epoch 188:  65% 175/270 [02:02<-1:57:04, -0.54it/s, loss=0.0167, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 311056. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 317039. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 345004. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 289228. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 350331. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 313252. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 273770. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 310130. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 289096. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 259792. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 296812. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 254046. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 298125. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 296435. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319713. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 264676. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 295704. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 268871. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 345428. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293027. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 270558. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 318718. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 309990. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 254542. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 252154. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 188:  65% 176/270 [02:02<-1:57:03, -0.53it/s, loss=0.0167, v_num=ypmf]Epoch 188:  65% 176/270 [02:02<-1:57:03, -0.53it/s, loss=0.0167, v_num=ypmf]Epoch 188:  65% 176/270 [02:03<-1:57:03, -0.53it/s, loss=0.0169, v_num=ypmf]Epoch 188:  66% 177/270 [02:03<-1:57:01, -0.52it/s, loss=0.0169, v_num=ypmf]Epoch 188:  66% 177/270 [02:03<-1:57:01, -0.52it/s, loss=0.0169, v_num=ypmf]Epoch 188:  66% 177/270 [02:03<-1:57:01, -0.52it/s, loss=0.017, v_num=ypmf] Epoch 188:  66% 178/270 [02:04<-1:56:59, -0.51it/s, loss=0.017, v_num=ypmf]Epoch 188:  66% 178/270 [02:04<-1:56:59, -0.51it/s, loss=0.017, v_num=ypmf]Epoch 188:  66% 178/270 [02:04<-1:56:59, -0.51it/s, loss=0.017, v_num=ypmf]Epoch 188:  66% 179/270 [02:04<-1:56:57, -0.50it/s, loss=0.017, v_num=ypmf]Epoch 188:  66% 179/270 [02:04<-1:56:57, -0.50it/s, loss=0.017, v_num=ypmf]Epoch 188:  66% 179/270 [02:04<-1:56:57, -0.50it/s, loss=0.0169, v_num=ypmf]Epoch 188:  67% 180/270 [02:05<-1:56:56, -0.49it/s, loss=0.0169, v_num=ypmf]Epoch 188:  67% 180/270 [02:05<-1:56:56, -0.49it/s, loss=0.0169, v_num=ypmf]Epoch 188:  67% 180/270 [02:05<-1:56:55, -0.49it/s, loss=0.0169, v_num=ypmf]Epoch 188:  67% 181/270 [02:05<-1:56:54, -0.48it/s, loss=0.0169, v_num=ypmf]Epoch 188:  67% 181/270 [02:05<-1:56:54, -0.48it/s, loss=0.0169, v_num=ypmf]Epoch 188:  67% 181/270 [02:06<-1:56:53, -0.48it/s, loss=0.0168, v_num=ypmf]Epoch 188:  67% 182/270 [02:06<-1:56:52, -0.47it/s, loss=0.0168, v_num=ypmf]Epoch 188:  67% 182/270 [02:06<-1:56:52, -0.47it/s, loss=0.0168, v_num=ypmf]Epoch 188:  67% 182/270 [02:06<-1:56:52, -0.47it/s, loss=0.0167, v_num=ypmf]Epoch 188:  68% 183/270 [02:07<-1:56:50, -0.46it/s, loss=0.0167, v_num=ypmf]Epoch 188:  68% 183/270 [02:07<-1:56:50, -0.46it/s, loss=0.0167, v_num=ypmf]Epoch 188:  68% 183/270 [02:07<-1:56:50, -0.46it/s, loss=0.0167, v_num=ypmf]Epoch 188:  68% 184/270 [02:07<-1:56:48, -0.45it/s, loss=0.0167, v_num=ypmf]Epoch 188:  68% 184/270 [02:07<-1:56:48, -0.45it/s, loss=0.0167, v_num=ypmf]Epoch 188:  68% 184/270 [02:07<-1:56:48, -0.45it/s, loss=0.0167, v_num=ypmf]Epoch 188:  69% 185/270 [02:08<-1:56:46, -0.44it/s, loss=0.0167, v_num=ypmf]Epoch 188:  69% 185/270 [02:08<-1:56:46, -0.44it/s, loss=0.0167, v_num=ypmf]Epoch 188:  69% 185/270 [02:09<-1:56:44, -0.43it/s, loss=0.0167, v_num=ypmf]Epoch 188:  69% 186/270 [02:09<-1:56:42, -0.42it/s, loss=0.0167, v_num=ypmf]Epoch 188:  69% 186/270 [02:09<-1:56:42, -0.42it/s, loss=0.0167, v_num=ypmf]Epoch 188:  69% 186/270 [02:09<-1:56:42, -0.42it/s, loss=0.0167, v_num=ypmf]Epoch 188:  69% 187/270 [02:10<-1:56:40, -0.41it/s, loss=0.0167, v_num=ypmf]Epoch 188:  69% 187/270 [02:10<-1:56:40, -0.41it/s, loss=0.0167, v_num=ypmf]Epoch 188:  69% 187/270 [02:10<-1:56:40, -0.41it/s, loss=0.0167, v_num=ypmf]Epoch 188:  70% 188/270 [02:11<-1:56:38, -0.40it/s, loss=0.0167, v_num=ypmf]Epoch 188:  70% 188/270 [02:11<-1:56:38, -0.40it/s, loss=0.0167, v_num=ypmf]Epoch 188:  70% 188/270 [02:11<-1:56:38, -0.40it/s, loss=0.0167, v_num=ypmf]Epoch 188:  70% 189/270 [02:11<-1:56:36, -0.40it/s, loss=0.0167, v_num=ypmf]Epoch 188:  70% 189/270 [02:11<-1:56:36, -0.40it/s, loss=0.0167, v_num=ypmf]Epoch 188:  70% 189/270 [02:12<-1:56:34, -0.39it/s, loss=0.0166, v_num=ypmf]Epoch 188:  70% 190/270 [02:13<-1:56:32, -0.38it/s, loss=0.0166, v_num=ypmf]Epoch 188:  70% 190/270 [02:13<-1:56:32, -0.38it/s, loss=0.0166, v_num=ypmf]Epoch 188:  70% 190/270 [02:13<-1:56:32, -0.38it/s, loss=0.0167, v_num=ypmf]Epoch 188:  71% 191/270 [02:13<-1:56:29, -0.37it/s, loss=0.0167, v_num=ypmf]Epoch 188:  71% 191/270 [02:13<-1:56:29, -0.37it/s, loss=0.0167, v_num=ypmf]Epoch 188:  71% 191/270 [02:13<-1:56:29, -0.37it/s, loss=0.0167, v_num=ypmf]Epoch 188:  71% 192/270 [02:14<-1:56:27, -0.37it/s, loss=0.0167, v_num=ypmf]Epoch 188:  71% 192/270 [02:14<-1:56:27, -0.37it/s, loss=0.0167, v_num=ypmf]Epoch 188:  71% 192/270 [02:14<-1:56:27, -0.36it/s, loss=0.0167, v_num=ypmf]Epoch 188:  71% 193/270 [02:14<-1:56:24, -0.36it/s, loss=0.0167, v_num=ypmf]Epoch 188:  71% 193/270 [02:14<-1:56:24, -0.36it/s, loss=0.0167, v_num=ypmf]Epoch 188:  71% 193/270 [02:15<-1:56:24, -0.36it/s, loss=0.0167, v_num=ypmf]Epoch 188:  72% 194/270 [02:15<-1:56:21, -0.35it/s, loss=0.0167, v_num=ypmf]Epoch 188:  72% 194/270 [02:15<-1:56:21, -0.35it/s, loss=0.0167, v_num=ypmf]Epoch 188:  72% 194/270 [02:15<-1:56:21, -0.35it/s, loss=0.0167, v_num=ypmf]Epoch 188:  72% 195/270 [02:15<-1:56:19, -0.34it/s, loss=0.0167, v_num=ypmf]Epoch 188:  72% 195/270 [02:15<-1:56:19, -0.34it/s, loss=0.0167, v_num=ypmf]Epoch 188:  72% 195/270 [02:16<-1:56:18, -0.34it/s, loss=0.0167, v_num=ypmf]Epoch 188:  73% 196/270 [02:16<-1:56:16, -0.33it/s, loss=0.0167, v_num=ypmf]Epoch 188:  73% 196/270 [02:16<-1:56:16, -0.33it/s, loss=0.0167, v_num=ypmf]Epoch 188:  73% 196/270 [02:16<-1:56:15, -0.33it/s, loss=0.0165, v_num=ypmf]Epoch 188:  73% 197/270 [02:17<-1:56:13, -0.32it/s, loss=0.0165, v_num=ypmf]Epoch 188:  73% 197/270 [02:17<-1:56:13, -0.32it/s, loss=0.0165, v_num=ypmf]Epoch 188:  73% 197/270 [02:17<-1:56:12, -0.32it/s, loss=0.0164, v_num=ypmf]Epoch 188:  73% 198/270 [02:17<-1:56:10, -0.31it/s, loss=0.0164, v_num=ypmf]Epoch 188:  73% 198/270 [02:17<-1:56:10, -0.31it/s, loss=0.0164, v_num=ypmf]Epoch 188:  73% 198/270 [02:18<-1:56:09, -0.31it/s, loss=0.0164, v_num=ypmf]Epoch 188:  74% 199/270 [02:18<-1:56:06, -0.30it/s, loss=0.0164, v_num=ypmf]Epoch 188:  74% 199/270 [02:18<-1:56:06, -0.30it/s, loss=0.0164, v_num=ypmf]Epoch 188:  74% 199/270 [02:18<-1:56:06, -0.30it/s, loss=0.0165, v_num=ypmf]Epoch 188:  74% 200/270 [02:19<-1:56:03, -0.29it/s, loss=0.0165, v_num=ypmf]Epoch 188:  74% 200/270 [02:19<-1:56:03, -0.29it/s, loss=0.0165, v_num=ypmf]Epoch 188:  74% 200/270 [02:19<-1:56:03, -0.29it/s, loss=0.0165, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 294588. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293681. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 351533. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 310138. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301411. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 269424. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 335306. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 283766. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 369663. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293796. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 268199. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 360363. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 318688. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293125. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 366986. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 283021. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 282183. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 330753. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 296129. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 306735. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 345771. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 294112. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 343383. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 280635. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 326691. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 188:  74% 201/270 [02:19<-1:56:00, -0.29it/s, loss=0.0165, v_num=ypmf]Epoch 188:  74% 201/270 [02:19<-1:56:00, -0.29it/s, loss=0.0165, v_num=ypmf]Epoch 188:  74% 201/270 [02:20<-1:55:59, -0.29it/s, loss=0.0166, v_num=ypmf]Epoch 188:  75% 202/270 [02:20<-1:55:55, -0.28it/s, loss=0.0166, v_num=ypmf]Epoch 188:  75% 202/270 [02:20<-1:55:55, -0.28it/s, loss=0.0166, v_num=ypmf]Epoch 188:  75% 202/270 [02:20<-1:55:55, -0.28it/s, loss=0.0166, v_num=ypmf]Epoch 188:  75% 203/270 [02:21<-1:55:52, -0.27it/s, loss=0.0166, v_num=ypmf]Epoch 188:  75% 203/270 [02:21<-1:55:52, -0.27it/s, loss=0.0166, v_num=ypmf]Epoch 188:  75% 203/270 [02:21<-1:55:51, -0.27it/s, loss=0.0167, v_num=ypmf]Epoch 188:  76% 204/270 [02:21<-1:55:48, -0.26it/s, loss=0.0167, v_num=ypmf]Epoch 188:  76% 204/270 [02:21<-1:55:48, -0.26it/s, loss=0.0167, v_num=ypmf]Epoch 188:  76% 204/270 [02:21<-1:55:47, -0.26it/s, loss=0.0167, v_num=ypmf]Epoch 188:  76% 205/270 [02:22<-1:55:44, -0.25it/s, loss=0.0167, v_num=ypmf]Epoch 188:  76% 205/270 [02:22<-1:55:44, -0.25it/s, loss=0.0167, v_num=ypmf]Epoch 188:  76% 205/270 [02:22<-1:55:43, -0.25it/s, loss=0.0166, v_num=ypmf]Epoch 188:  76% 206/270 [02:22<-1:55:39, -0.24it/s, loss=0.0166, v_num=ypmf]Epoch 188:  76% 206/270 [02:22<-1:55:39, -0.24it/s, loss=0.0166, v_num=ypmf]Epoch 188:  76% 206/270 [02:23<-1:55:39, -0.24it/s, loss=0.0166, v_num=ypmf]Epoch 188:  77% 207/270 [02:23<-1:55:35, -0.24it/s, loss=0.0166, v_num=ypmf]Epoch 188:  77% 207/270 [02:23<-1:55:35, -0.24it/s, loss=0.0166, v_num=ypmf]Epoch 188:  77% 207/270 [02:23<-1:55:34, -0.24it/s, loss=0.0165, v_num=ypmf]Epoch 188:  77% 208/270 [02:24<-1:55:30, -0.23it/s, loss=0.0165, v_num=ypmf]Epoch 188:  77% 208/270 [02:24<-1:55:30, -0.23it/s, loss=0.0165, v_num=ypmf]Epoch 188:  77% 208/270 [02:24<-1:55:29, -0.23it/s, loss=0.0165, v_num=ypmf]Epoch 188:  77% 209/270 [02:24<-1:55:25, -0.22it/s, loss=0.0165, v_num=ypmf]Epoch 188:  77% 209/270 [02:24<-1:55:25, -0.22it/s, loss=0.0165, v_num=ypmf]Epoch 188:  77% 209/270 [02:24<-1:55:24, -0.22it/s, loss=0.0166, v_num=ypmf]Epoch 188:  78% 210/270 [02:25<-1:55:19, -0.21it/s, loss=0.0166, v_num=ypmf]Epoch 188:  78% 210/270 [02:25<-1:55:19, -0.21it/s, loss=0.0166, v_num=ypmf]Epoch 188:  78% 210/270 [02:25<-1:55:19, -0.21it/s, loss=0.0166, v_num=ypmf]Epoch 188:  78% 211/270 [02:25<-1:55:14, -0.21it/s, loss=0.0166, v_num=ypmf]Epoch 188:  78% 211/270 [02:25<-1:55:14, -0.21it/s, loss=0.0166, v_num=ypmf]Epoch 188:  78% 211/270 [02:26<-1:55:13, -0.21it/s, loss=0.0166, v_num=ypmf]Epoch 188:  79% 212/270 [02:26<-1:55:08, -0.20it/s, loss=0.0166, v_num=ypmf]Epoch 188:  79% 212/270 [02:26<-1:55:08, -0.20it/s, loss=0.0166, v_num=ypmf]Epoch 188:  79% 212/270 [02:26<-1:55:07, -0.20it/s, loss=0.0165, v_num=ypmf]Epoch 188:  79% 213/270 [02:26<-1:55:01, -0.19it/s, loss=0.0165, v_num=ypmf]Epoch 188:  79% 213/270 [02:26<-1:55:01, -0.19it/s, loss=0.0165, v_num=ypmf]Epoch 188:  79% 213/270 [02:27<-1:55:01, -0.19it/s, loss=0.0165, v_num=ypmf]Epoch 188:  79% 214/270 [02:27<-1:54:55, -0.18it/s, loss=0.0165, v_num=ypmf]Epoch 188:  79% 214/270 [02:27<-1:54:55, -0.18it/s, loss=0.0165, v_num=ypmf]Epoch 188:  79% 214/270 [02:27<-1:54:54, -0.18it/s, loss=0.0166, v_num=ypmf]Epoch 188:  80% 215/270 [02:28<-1:54:47, -0.18it/s, loss=0.0166, v_num=ypmf]Epoch 188:  80% 215/270 [02:28<-1:54:47, -0.18it/s, loss=0.0166, v_num=ypmf]Epoch 188:  80% 215/270 [02:28<-1:54:47, -0.18it/s, loss=0.0167, v_num=ypmf]Epoch 188:  80% 216/270 [02:28<-1:54:39, -0.17it/s, loss=0.0167, v_num=ypmf]Epoch 188:  80% 216/270 [02:28<-1:54:39, -0.17it/s, loss=0.0167, v_num=ypmf]Epoch 188:  80% 216/270 [02:28<-1:54:39, -0.17it/s, loss=0.0167, v_num=ypmf]Epoch 188:  80% 217/270 [02:29<-1:54:31, -0.16it/s, loss=0.0167, v_num=ypmf]Epoch 188:  80% 217/270 [02:29<-1:54:31, -0.16it/s, loss=0.0167, v_num=ypmf]Epoch 188:  80% 217/270 [02:30<-1:54:29, -0.16it/s, loss=0.0168, v_num=ypmf]Epoch 188:  81% 218/270 [02:30<-1:54:21, -0.15it/s, loss=0.0168, v_num=ypmf]Epoch 188:  81% 218/270 [02:30<-1:54:21, -0.15it/s, loss=0.0168, v_num=ypmf]Epoch 188:  81% 218/270 [02:30<-1:54:20, -0.15it/s, loss=0.0169, v_num=ypmf]Epoch 188:  81% 219/270 [02:30<-1:54:10, -0.15it/s, loss=0.0169, v_num=ypmf]Epoch 188:  81% 219/270 [02:30<-1:54:10, -0.15it/s, loss=0.0169, v_num=ypmf]Epoch 188:  81% 219/270 [02:31<-1:54:10, -0.15it/s, loss=0.0168, v_num=ypmf]Epoch 188:  81% 220/270 [02:31<-1:54:00, -0.14it/s, loss=0.0168, v_num=ypmf]Epoch 188:  81% 220/270 [02:31<-1:54:00, -0.14it/s, loss=0.0168, v_num=ypmf]Epoch 188:  81% 220/270 [02:31<-1:53:59, -0.14it/s, loss=0.017, v_num=ypmf] Epoch 188:  82% 221/270 [02:32<-1:53:48, -0.13it/s, loss=0.017, v_num=ypmf]Epoch 188:  82% 221/270 [02:32<-1:53:48, -0.13it/s, loss=0.017, v_num=ypmf]Epoch 188:  82% 221/270 [02:32<-1:53:47, -0.13it/s, loss=0.0169, v_num=ypmf]Epoch 188:  82% 222/270 [02:32<-1:53:34, -0.12it/s, loss=0.0169, v_num=ypmf]Epoch 188:  82% 222/270 [02:32<-1:53:34, -0.12it/s, loss=0.0169, v_num=ypmf]Epoch 188:  82% 222/270 [02:33<-1:53:33, -0.12it/s, loss=0.017, v_num=ypmf] Epoch 188:  83% 223/270 [02:33<-1:53:19, -0.12it/s, loss=0.017, v_num=ypmf]Epoch 188:  83% 223/270 [02:33<-1:53:19, -0.12it/s, loss=0.017, v_num=ypmf]Epoch 188:  83% 223/270 [02:34<-1:53:18, -0.12it/s, loss=0.017, v_num=ypmf]Epoch 188:  83% 224/270 [02:34<-1:53:02, -0.11it/s, loss=0.017, v_num=ypmf]Epoch 188:  83% 224/270 [02:34<-1:53:02, -0.11it/s, loss=0.017, v_num=ypmf]Epoch 188:  83% 224/270 [02:34<-1:53:02, -0.11it/s, loss=0.017, v_num=ypmf]Epoch 188:  83% 225/270 [02:35<-1:52:44, -0.10it/s, loss=0.017, v_num=ypmf]Epoch 188:  83% 225/270 [02:35<-1:52:44, -0.10it/s, loss=0.017, v_num=ypmf]Epoch 188:  83% 225/270 [02:35<-1:52:43, -0.10it/s, loss=0.0171, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 297231. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 287881. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 332663. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 320228. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 309256. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 298232. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 394541. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 316559. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 325241. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 306283. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 332535. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301049. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 310673. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 315975. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 303870. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 281888. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 290522. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 325071. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 281171. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293969. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 306680. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 347516. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 349829. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 303665. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 342070. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 188:  84% 226/270 [02:36<-1:52:23, -0.10it/s, loss=0.0171, v_num=ypmf]Epoch 188:  84% 226/270 [02:36<-1:52:23, -0.10it/s, loss=0.0171, v_num=ypmf]Epoch 188:  84% 226/270 [02:36<-1:52:22, -0.10it/s, loss=0.0171, v_num=ypmf]Epoch 188:  84% 227/270 [02:36<-1:52:00, -0.09it/s, loss=0.0171, v_num=ypmf]Epoch 188:  84% 227/270 [02:36<-1:52:00, -0.09it/s, loss=0.0171, v_num=ypmf]Epoch 188:  84% 227/270 [02:36<-1:51:58, -0.09it/s, loss=0.0171, v_num=ypmf]Epoch 188:  84% 228/270 [02:37<-1:51:32, -0.08it/s, loss=0.0171, v_num=ypmf]Epoch 188:  84% 228/270 [02:37<-1:51:32, -0.08it/s, loss=0.0171, v_num=ypmf]Epoch 188:  84% 228/270 [02:37<-1:51:31, -0.08it/s, loss=0.0171, v_num=ypmf]Epoch 188:  85% 229/270 [02:38<-1:51:00, -0.08it/s, loss=0.0171, v_num=ypmf]Epoch 188:  85% 229/270 [02:38<-1:51:00, -0.08it/s, loss=0.0171, v_num=ypmf]Epoch 188:  85% 229/270 [02:38<-1:50:59, -0.08it/s, loss=0.0171, v_num=ypmf]Epoch 188:  85% 230/270 [02:38<-1:50:23, -0.07it/s, loss=0.0171, v_num=ypmf]Epoch 188:  85% 230/270 [02:38<-1:50:23, -0.07it/s, loss=0.0171, v_num=ypmf]Epoch 188:  85% 230/270 [02:38<-1:50:23, -0.07it/s, loss=0.0172, v_num=ypmf]Epoch 188:  86% 231/270 [02:39<-1:49:39, -0.06it/s, loss=0.0172, v_num=ypmf]Epoch 188:  86% 231/270 [02:39<-1:49:39, -0.06it/s, loss=0.0172, v_num=ypmf]Epoch 188:  86% 231/270 [02:39<-1:49:37, -0.06it/s, loss=0.0172, v_num=ypmf]Epoch 188:  86% 232/270 [02:40<-1:48:44, -0.06it/s, loss=0.0172, v_num=ypmf]Epoch 188:  86% 232/270 [02:40<-1:48:44, -0.06it/s, loss=0.0172, v_num=ypmf]Epoch 188:  86% 232/270 [02:40<-1:48:43, -0.06it/s, loss=0.0173, v_num=ypmf]Epoch 188:  86% 233/270 [02:40<-1:47:37, -0.05it/s, loss=0.0173, v_num=ypmf]Epoch 188:  86% 233/270 [02:40<-1:47:37, -0.05it/s, loss=0.0173, v_num=ypmf]Epoch 188:  86% 233/270 [02:40<-1:47:36, -0.05it/s, loss=0.0173, v_num=ypmf]Epoch 188:  87% 234/270 [02:41<-1:46:11, -0.04it/s, loss=0.0173, v_num=ypmf]Epoch 188:  87% 234/270 [02:41<-1:46:11, -0.04it/s, loss=0.0173, v_num=ypmf]Epoch 188:  87% 234/270 [02:41<-1:46:10, -0.04it/s, loss=0.0172, v_num=ypmf]Epoch 188:  87% 235/270 [02:41<-1:44:16, -0.04it/s, loss=0.0172, v_num=ypmf]Epoch 188:  87% 235/270 [02:41<-1:44:16, -0.04it/s, loss=0.0172, v_num=ypmf]Epoch 188:  87% 235/270 [02:42<-1:44:15, -0.04it/s, loss=0.0171, v_num=ypmf]Epoch 188:  87% 236/270 [02:42<-1:41:35, -0.03it/s, loss=0.0171, v_num=ypmf]Epoch 188:  87% 236/270 [02:42<-1:41:35, -0.03it/s, loss=0.0171, v_num=ypmf]Epoch 188:  87% 236/270 [02:42<-1:41:34, -0.03it/s, loss=0.0171, v_num=ypmf]Epoch 188:  88% 237/270 [02:43<-1:37:36, -0.02it/s, loss=0.0171, v_num=ypmf]Epoch 188:  88% 237/270 [02:43<-1:37:36, -0.02it/s, loss=0.0171, v_num=ypmf]Epoch 188:  88% 237/270 [02:43<-1:37:34, -0.02it/s, loss=0.0172, v_num=ypmf]Epoch 188:  88% 238/270 [02:43<-1:30:55, -0.02it/s, loss=0.0172, v_num=ypmf]Epoch 188:  88% 238/270 [02:43<-1:30:55, -0.02it/s, loss=0.0172, v_num=ypmf]Epoch 188:  88% 238/270 [02:43<-1:30:54, -0.02it/s, loss=0.017, v_num=ypmf] Epoch 188:  89% 239/270 [02:44<-1:17:36, -0.01it/s, loss=0.017, v_num=ypmf]Epoch 188:  89% 239/270 [02:44<-1:17:36, -0.01it/s, loss=0.017, v_num=ypmf]Epoch 188:  89% 239/270 [02:44<-1:17:24, -0.01it/s, loss=0.017, v_num=ypmf]Epoch 188:  89% 240/270 [02:45<-2:37:20, -0.01it/s, loss=0.017, v_num=ypmf]Epoch 188:  89% 240/270 [02:45<-2:37:20, -0.01it/s, loss=0.017, v_num=ypmf]Epoch 188:  89% 240/270 [02:45<-2:37:15, -0.01it/s, loss=0.0169, v_num=ypmf]Epoch 188:  89% 241/270 [02:45<?, ?it/s, loss=0.0169, v_num=ypmf]           Epoch 188:  89% 241/270 [02:45<?, ?it/s, loss=0.0169, v_num=ypmf]Epoch 188:  89% 241/270 [02:45<?, ?it/s, loss=0.0168, v_num=ypmf]Epoch 188:  90% 242/270 [02:46<1:17:40, 166.45s/it, loss=0.0168, v_num=ypmf]Epoch 188:  90% 242/270 [02:46<1:17:40, 166.45s/it, loss=0.0168, v_num=ypmf]Epoch 188:  90% 242/270 [02:46<1:17:44, 166.60s/it, loss=0.0167, v_num=ypmf]Epoch 188:  90% 243/270 [02:46<37:32, 83.44s/it, loss=0.0167, v_num=ypmf]   Epoch 188:  90% 243/270 [02:46<37:32, 83.44s/it, loss=0.0167, v_num=ypmf]Epoch 188:  90% 243/270 [02:47<37:35, 83.54s/it, loss=0.0167, v_num=ypmf]Epoch 188:  90% 244/270 [02:47<24:12, 55.85s/it, loss=0.0167, v_num=ypmf]Epoch 188:  90% 244/270 [02:47<24:12, 55.85s/it, loss=0.0167, v_num=ypmf]Epoch 188:  90% 244/270 [02:47<24:13, 55.90s/it, loss=0.0167, v_num=ypmf]Epoch 188:  91% 245/270 [02:48<17:30, 42.01s/it, loss=0.0167, v_num=ypmf]Epoch 188:  91% 245/270 [02:48<17:30, 42.01s/it, loss=0.0167, v_num=ypmf]Epoch 188:  91% 245/270 [02:48<17:32, 42.11s/it, loss=0.0168, v_num=ypmf]Epoch 188:  91% 246/270 [02:48<13:30, 33.77s/it, loss=0.0168, v_num=ypmf]Epoch 188:  91% 246/270 [02:48<13:30, 33.77s/it, loss=0.0168, v_num=ypmf]Epoch 188:  91% 246/270 [02:49<13:31, 33.80s/it, loss=0.0168, v_num=ypmf]Epoch 188:  91% 247/270 [02:49<10:49, 28.24s/it, loss=0.0168, v_num=ypmf]Epoch 188:  91% 247/270 [02:49<10:49, 28.24s/it, loss=0.0168, v_num=ypmf]Epoch 188:  91% 247/270 [02:49<10:49, 28.26s/it, loss=0.0169, v_num=ypmf]Epoch 188:  92% 248/270 [02:50<08:54, 24.29s/it, loss=0.0169, v_num=ypmf]Epoch 188:  92% 248/270 [02:50<08:54, 24.29s/it, loss=0.0169, v_num=ypmf]Epoch 188:  92% 248/270 [02:50<08:54, 24.32s/it, loss=0.0169, v_num=ypmf]Epoch 188:  92% 249/270 [02:50<07:27, 21.32s/it, loss=0.0169, v_num=ypmf]Epoch 188:  92% 249/270 [02:50<07:27, 21.32s/it, loss=0.0169, v_num=ypmf]Epoch 188:  92% 249/270 [02:50<07:28, 21.34s/it, loss=0.0169, v_num=ypmf]Epoch 188:  93% 250/270 [02:51<06:20, 19.01s/it, loss=0.0169, v_num=ypmf]Epoch 188:  93% 250/270 [02:51<06:20, 19.01s/it, loss=0.0169, v_num=ypmf]Epoch 188:  93% 250/270 [02:51<06:20, 19.03s/it, loss=0.0168, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 279673. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 385273. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 342346. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 291323. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301394. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 356441. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308388. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 272234. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 313025. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 332201. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 265465. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 314501. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch
_size` from an ambiguous collection. The batch size we found is 308555. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 333265. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 276093. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 363200. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 264931. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 348744. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 273277. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 316523. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 330700. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 365224. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 304471. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 323910. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Validation: 0it [00:00, ?it/s][A
Validation:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.27it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.27it/s][AEpoch 188:  93% 251/270 [02:51<05:26, 17.19s/it, loss=0.0168, v_num=ypmf]Epoch 188:  93% 251/270 [02:51<05:26, 17.19s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  10% 2/20 [00:01<00:16,  1.08it/s][A
Validation DataLoader 0:  10% 2/20 [00:01<00:16,  1.08it/s][AEpoch 188:  93% 252/270 [02:53<04:43, 15.74s/it, loss=0.0168, v_num=ypmf]Epoch 188:  93% 252/270 [02:53<04:43, 15.74s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  15% 3/20 [00:02<00:16,  1.04it/s][A
Validation DataLoader 0:  15% 3/20 [00:02<00:16,  1.04it/s][AEpoch 188:  94% 253/270 [02:54<04:06, 14.51s/it, loss=0.0168, v_num=ypmf]Epoch 188:  94% 253/270 [02:54<04:06, 14.51s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  20% 4/20 [00:03<00:13,  1.16it/s][A
Validation DataLoader 0:  20% 4/20 [00:03<00:13,  1.16it/s][AEpoch 188:  94% 254/270 [02:54<03:35, 13.45s/it, loss=0.0168, v_num=ypmf]Epoch 188:  94% 254/270 [02:54<03:35, 13.45s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  25% 5/20 [00:04<00:13,  1.10it/s][A
Validation DataLoader 0:  25% 5/20 [00:04<00:13,  1.10it/s][AEpoch 188:  94% 255/270 [02:55<03:08, 12.56s/it, loss=0.0168, v_num=ypmf]Epoch 188:  94% 255/270 [02:55<03:08, 12.56s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  30% 6/20 [00:05<00:15,  1.14s/it][A
Validation DataLoader 0:  30% 6/20 [00:05<00:15,  1.14s/it][AEpoch 188:  95% 256/270 [02:57<02:45, 11.83s/it, loss=0.0168, v_num=ypmf]Epoch 188:  95% 256/270 [02:57<02:45, 11.83s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  35% 7/20 [00:07<00:15,  1.17s/it][A
Validation DataLoader 0:  35% 7/20 [00:07<00:15,  1.17s/it][AEpoch 188:  95% 257/270 [02:58<02:25, 11.17s/it, loss=0.0168, v_num=ypmf]Epoch 188:  95% 257/270 [02:58<02:25, 11.17s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  40% 8/20 [00:08<00:15,  1.25s/it][A
Validation DataLoader 0:  40% 8/20 [00:08<00:15,  1.25s/it][AEpoch 188:  96% 258/270 [03:00<02:07, 10.59s/it, loss=0.0168, v_num=ypmf]Epoch 188:  96% 258/270 [03:00<02:07, 10.59s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  45% 9/20 [00:09<00:11,  1.09s/it][A
Validation DataLoader 0:  45% 9/20 [00:09<00:11,  1.09s/it][AEpoch 188:  96% 259/270 [03:00<01:50, 10.04s/it, loss=0.0168, v_num=ypmf]Epoch 188:  96% 259/270 [03:00<01:50, 10.04s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  50% 10/20 [00:10<00:09,  1.00it/s][A
Validation DataLoader 0:  50% 10/20 [00:10<00:09,  1.00it/s][AEpoch 188:  96% 260/270 [03:01<01:35,  9.56s/it, loss=0.0168, v_num=ypmf]Epoch 188:  96% 260/270 [03:01<01:35,  9.56s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  55% 11/20 [00:10<00:08,  1.09it/s][A
Validation DataLoader 0:  55% 11/20 [00:10<00:08,  1.09it/s][AEpoch 188:  97% 261/270 [03:02<01:22,  9.12s/it, loss=0.0168, v_num=ypmf]Epoch 188:  97% 261/270 [03:02<01:22,  9.12s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  60% 12/20 [00:12<00:09,  1.13s/it][A
Validation DataLoader 0:  60% 12/20 [00:12<00:09,  1.13s/it][AEpoch 188:  97% 262/270 [03:03<01:10,  8.76s/it, loss=0.0168, v_num=ypmf]Epoch 188:  97% 262/270 [03:03<01:10,  8.76s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  65% 13/20 [00:13<00:07,  1.04s/it][A
Validation DataLoader 0:  65% 13/20 [00:13<00:07,  1.04s/it][AEpoch 188:  97% 263/270 [03:04<00:58,  8.40s/it, loss=0.0168, v_num=ypmf]Epoch 188:  97% 263/270 [03:04<00:58,  8.40s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  70% 14/20 [00:14<00:05,  1.05it/s][A
Validation DataLoader 0:  70% 14/20 [00:14<00:05,  1.05it/s][AEpoch 188:  98% 264/270 [03:05<00:48,  8.07s/it, loss=0.0168, v_num=ypmf]Epoch 188:  98% 264/270 [03:05<00:48,  8.07s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  75% 15/20 [00:15<00:05,  1.14s/it][A
Validation DataLoader 0:  75% 15/20 [00:15<00:05,  1.14s/it][AEpoch 188:  98% 265/270 [03:07<00:38,  7.80s/it, loss=0.0168, v_num=ypmf]Epoch 188:  98% 265/270 [03:07<00:38,  7.80s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  80% 16/20 [00:16<00:04,  1.18s/it][A
Validation DataLoader 0:  80% 16/20 [00:16<00:04,  1.18s/it][AEpoch 188:  99% 266/270 [03:08<00:30,  7.54s/it, loss=0.0168, v_num=ypmf]Epoch 188:  99% 266/270 [03:08<00:30,  7.54s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  85% 17/20 [00:17<00:03,  1.08s/it][A
Validation DataLoader 0:  85% 17/20 [00:17<00:03,  1.08s/it][AEpoch 188:  99% 267/270 [03:09<00:21,  7.28s/it, loss=0.0168, v_num=ypmf]Epoch 188:  99% 267/270 [03:09<00:21,  7.28s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  90% 18/20 [00:18<00:01,  1.05it/s][A
Validation DataLoader 0:  90% 18/20 [00:18<00:01,  1.05it/s][AEpoch 188:  99% 268/270 [03:09<00:14,  7.03s/it, loss=0.0168, v_num=ypmf]Epoch 188:  99% 268/270 [03:09<00:14,  7.03s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  95% 19/20 [00:21<00:01,  1.43s/it][A
Validation DataLoader 0:  95% 19/20 [00:21<00:01,  1.43s/it][AEpoch 188: 100% 269/270 [03:12<00:06,  6.87s/it, loss=0.0168, v_num=ypmf]Epoch 188: 100% 269/270 [03:12<00:06,  6.87s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0: 100% 20/20 [00:21<00:00,  1.17s/it][A
Validation DataLoader 0: 100% 20/20 [00:21<00:00,  1.17s/it][AEpoch 188: 100% 270/270 [03:12<00:00,  6.66s/it, loss=0.0168, v_num=ypmf]Epoch 188: 100% 270/270 [03:12<00:00,  6.66s/it, loss=0.0168, v_num=ypmf]Epoch 188: 100% 270/270 [03:13<00:00,  6.67s/it, loss=0.0168, v_num=ypmf]
                                                            [AEpoch 188: 100% 270/270 [03:13<00:00,  6.67s/it, loss=0.0168, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 188:   0% 0/270 [00:00<00:00, -6563813.40it/s, loss=0.0168, v_num=ypmf]Epoch 189:   0% 0/270 [00:00<00:00, -1668031.79it/s, loss=0.0168, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 189:   0% 1/270 [00:01<-1:59:59, -172.90it/s, loss=0.0168, v_num=ypmf] Epoch 189:   0% 1/270 [00:01<-1:59:59, -172.88it/s, loss=0.0168, v_num=ypmf]Epoch 189:   0% 1/270 [00:01<-1:59:59, -156.38it/s, loss=0.0167, v_num=ypmf]Epoch 189:   1% 2/270 [00:01<-1:59:58, -124.06it/s, loss=0.0167, v_num=ypmf]Epoch 189:   1% 2/270 [00:01<-1:59:58, -124.05it/s, loss=0.0167, v_num=ypmf]Epoch 189:   1% 2/270 [00:02<-1:59:58, -115.53it/s, loss=0.0166, v_num=ypmf]Epoch 189:   1% 3/270 [00:02<-1:59:58, -95.12it/s, loss=0.0166, v_num=ypmf] Epoch 189:   1% 3/270 [00:02<-1:59:58, -95.11it/s, loss=0.0166, v_num=ypmf]Epoch 189:   1% 3/270 [00:02<-1:59:58, -90.30it/s, loss=0.0167, v_num=ypmf]Epoch 189:   1% 4/270 [00:03<-1:59:57, -75.11it/s, loss=0.0167, v_num=ypmf]Epoch 189:   1% 4/270 [00:03<-1:59:57, -75.11it/s, loss=0.0167, v_num=ypmf]Epoch 189:   1% 4/270 [00:03<-1:59:57, -71.39it/s, loss=0.0166, v_num=ypmf]Epoch 189:   2% 5/270 [00:03<-1:59:56, -64.66it/s, loss=0.0166, v_num=ypmf]Epoch 189:   2% 5/270 [00:03<-1:59:56, -64.66it/s, loss=0.0166, v_num=ypmf]Epoch 189:   2% 5/270 [00:03<-1:59:56, -62.79it/s, loss=0.0169, v_num=ypmf]Epoch 189:   2% 6/270 [00:04<-1:59:56, -55.91it/s, loss=0.0169, v_num=ypmf]Epoch 189:   2% 6/270 [00:04<-1:59:56, -55.91it/s, loss=0.0169, v_num=ypmf]Epoch 189:   2% 6/270 [00:04<-1:59:56, -54.08it/s, loss=0.0169, v_num=ypmf]Epoch 189:   3% 7/270 [00:04<-1:59:55, -49.10it/s, loss=0.0169, v_num=ypmf]Epoch 189:   3% 7/270 [00:04<-1:59:55, -49.09it/s, loss=0.0169, v_num=ypmf]Epoch 189:   3% 7/270 [00:04<-1:59:55, -47.76it/s, loss=0.0168, v_num=ypmf]Epoch 189:   3% 8/270 [00:05<-1:59:55, -44.35it/s, loss=0.0168, v_num=ypmf]Epoch 189:   3% 8/270 [00:05<-1:59:55, -44.35it/s, loss=0.0168, v_num=ypmf]Epoch 189:   3% 8/270 [00:05<-1:59:54, -43.27it/s, loss=0.0168, v_num=ypmf]Epoch 189:   3% 9/270 [00:05<-1:59:54, -40.20it/s, loss=0.0168, v_num=ypmf]Epoch 189:   3% 9/270 [00:05<-1:59:54, -40.20it/s, loss=0.0168, v_num=ypmf]Epoch 189:   3% 9/270 [00:05<-1:59:54, -39.18it/s, loss=0.0169, v_num=ypmf]Epoch 189:   4% 10/270 [00:06<-1:59:53, -36.78it/s, loss=0.0169, v_num=ypmf]Epoch 189:   4% 10/270 [00:06<-1:59:53, -36.77it/s, loss=0.0169, v_num=ypmf]Epoch 189:   4% 10/270 [00:06<-1:59:53, -35.58it/s, loss=0.0169, v_num=ypmf]Epoch 189:   4% 11/270 [00:06<-1:59:53, -33.51it/s, loss=0.0169, v_num=ypmf]Epoch 189:   4% 11/270 [00:06<-1:59:53, -33.51it/s, loss=0.0169, v_num=ypmf]Epoch 189:   4% 11/270 [00:06<-1:59:53, -32.92it/s, loss=0.0169, v_num=ypmf]Epoch 189:   4% 12/270 [00:07<-1:59:52, -31.06it/s, loss=0.0169, v_num=ypmf]Epoch 189:   4% 12/270 [00:07<-1:59:52, -31.06it/s, loss=0.0169, v_num=ypmf]Epoch 189:   4% 12/270 [00:07<-1:59:52, -30.54it/s, loss=0.0169, v_num=ypmf]Epoch 189:   5% 13/270 [00:07<-1:59:52, -29.20it/s, loss=0.0169, v_num=ypmf]Epoch 189:   5% 13/270 [00:07<-1:59:52, -29.20it/s, loss=0.0169, v_num=ypmf]Epoch 189:   5% 13/270 [00:08<-1:59:51, -28.33it/s, loss=0.017, v_num=ypmf] Epoch 189:   5% 14/270 [00:08<-1:59:51, -27.17it/s, loss=0.017, v_num=ypmf]Epoch 189:   5% 14/270 [00:08<-1:59:51, -27.17it/s, loss=0.017, v_num=ypmf]Epoch 189:   5% 14/270 [00:08<-1:59:51, -26.44it/s, loss=0.017, v_num=ypmf]Epoch 189:   6% 15/270 [00:09<-1:59:50, -24.64it/s, loss=0.017, v_num=ypmf]Epoch 189:   6% 15/270 [00:09<-1:59:50, -24.64it/s, loss=0.017, v_num=ypmf]Epoch 189:   6% 15/270 [00:09<-1:59:50, -24.33it/s, loss=0.017, v_num=ypmf]Epoch 189:   6% 16/270 [00:09<-1:59:49, -22.82it/s, loss=0.017, v_num=ypmf]Epoch 189:   6% 16/270 [00:09<-1:59:49, -22.82it/s, loss=0.017, v_num=ypmf]Epoch 189:   6% 16/270 [00:09<-1:59:49, -22.79it/s, loss=0.0169, v_num=ypmf]Epoch 189:   6% 17/270 [00:10<-1:59:48, -20.72it/s, loss=0.0169, v_num=ypmf]Epoch 189:   6% 17/270 [00:10<-1:59:48, -20.71it/s, loss=0.0169, v_num=ypmf]Epoch 189:   6% 17/270 [00:10<-1:59:48, -20.41it/s, loss=0.0169, v_num=ypmf]Epoch 189:   7% 18/270 [00:11<-1:59:48, -19.60it/s, loss=0.0169, v_num=ypmf]Epoch 189:   7% 18/270 [00:11<-1:59:48, -19.60it/s, loss=0.0169, v_num=ypmf]Epoch 189:   7% 18/270 [00:11<-1:59:47, -19.22it/s, loss=0.0169, v_num=ypmf]Epoch 189:   7% 19/270 [00:12<-1:59:47, -18.44it/s, loss=0.0169, v_num=ypmf]Epoch 189:   7% 19/270 [00:12<-1:59:47, -18.44it/s, loss=0.0169, v_num=ypmf]Epoch 189:   7% 19/270 [00:12<-1:59:47, -18.22it/s, loss=0.0169, v_num=ypmf]Epoch 189:   7% 20/270 [00:12<-1:59:46, -17.59it/s, loss=0.0169, v_num=ypmf]Epoch 189:   7% 20/270 [00:12<-1:59:46, -17.59it/s, loss=0.0169, v_num=ypmf]Epoch 189:   7% 20/270 [00:12<-1:59:46, -17.39it/s, loss=0.017, v_num=ypmf] Epoch 189:   8% 21/270 [00:13<-1:59:46, -16.87it/s, loss=0.017, v_num=ypmf]Epoch 189:   8% 21/270 [00:13<-1:59:46, -16.87it/s, loss=0.017, v_num=ypmf]Epoch 189:   8% 21/270 [00:13<-1:59:45, -16.56it/s, loss=0.017, v_num=ypmf]Epoch 189:   8% 22/270 [00:13<-1:59:45, -16.07it/s, loss=0.017, v_num=ypmf]Epoch 189:   8% 22/270 [00:13<-1:59:45, -16.07it/s, loss=0.017, v_num=ypmf]Epoch 189:   8% 22/270 [00:13<-1:59:45, -15.86it/s, loss=0.017, v_num=ypmf]Epoch 189:   9% 23/270 [00:14<-1:59:44, -15.34it/s, loss=0.017, v_num=ypmf]Epoch 189:   9% 23/270 [00:14<-1:59:44, -15.34it/s, loss=0.017, v_num=ypmf]Epoch 189:   9% 23/270 [00:14<-1:59:44, -15.21it/s, loss=0.0169, v_num=ypmf]Epoch 189:   9% 24/270 [00:14<-1:59:44, -14.77it/s, loss=0.0169, v_num=ypmf]Epoch 189:   9% 24/270 [00:14<-1:59:44, -14.77it/s, loss=0.0169, v_num=ypmf]Epoch 189:   9% 24/270 [00:14<-1:59:44, -14.60it/s, loss=0.017, v_num=ypmf] Epoch 189:   9% 25/270 [00:15<-1:59:43, -14.08it/s, loss=0.017, v_num=ypmf]Epoch 189:   9% 25/270 [00:15<-1:59:43, -14.08it/s, loss=0.017, v_num=ypmf]Epoch 189:   9% 25/270 [00:15<-1:59:43, -13.94it/s, loss=0.0168, v_num=ypmf]Epoch 189:  10% 26/270 [00:15<-1:59:42, -13.50it/s, loss=0.0168, v_num=ypmf]Epoch 189:  10% 26/270 [00:15<-1:59:42, -13.50it/s, loss=0.0168, v_num=ypmf]Epoch 189:  10% 26/270 [00:16<-1:59:42, -13.38it/s, loss=0.0168, v_num=ypmf]Epoch 189:  10% 27/270 [00:16<-1:59:42, -12.99it/s, loss=0.0168, v_num=ypmf]Epoch 189:  10% 27/270 [00:16<-1:59:42, -12.99it/s, loss=0.0168, v_num=ypmf]Epoch 189:  10% 27/270 [00:16<-1:59:42, -12.84it/s, loss=0.0169, v_num=ypmf]Epoch 189:  10% 28/270 [00:16<-1:59:41, -12.56it/s, loss=0.0169, v_num=ypmf]Epoch 189:  10% 28/270 [00:16<-1:59:41, -12.56it/s, loss=0.0169, v_num=ypmf]Epoch 189:  10% 28/270 [00:17<-1:59:41, -12.36it/s, loss=0.0168, v_num=ypmf]Epoch 189:  11% 29/270 [00:17<-1:59:40, -12.01it/s, loss=0.0168, v_num=ypmf]Epoch 189:  11% 29/270 [00:17<-1:59:40, -12.01it/s, loss=0.0168, v_num=ypmf]Epoch 189:  11% 29/270 [00:17<-1:59:40, -11.90it/s, loss=0.0168, v_num=ypmf]Epoch 189:  11% 30/270 [00:18<-1:59:40, -11.60it/s, loss=0.0168, v_num=ypmf]Epoch 189:  11% 30/270 [00:18<-1:59:40, -11.60it/s, loss=0.0168, v_num=ypmf]Epoch 189:  11% 30/270 [00:18<-1:59:39, -11.40it/s, loss=0.0168, v_num=ypmf]Epoch 189:  11% 31/270 [00:18<-1:59:39, -11.15it/s, loss=0.0168, v_num=ypmf]Epoch 189:  11% 31/270 [00:18<-1:59:39, -11.15it/s, loss=0.0168, v_num=ypmf]Epoch 189:  11% 31/270 [00:19<-1:59:39, -11.02it/s, loss=0.017, v_num=ypmf] Epoch 189:  12% 32/270 [00:19<-1:59:38, -10.80it/s, loss=0.017, v_num=ypmf]Epoch 189:  12% 32/270 [00:19<-1:59:38, -10.80it/s, loss=0.017, v_num=ypmf]Epoch 189:  12% 32/270 [00:19<-1:59:38, -10.65it/s, loss=0.0171, v_num=ypmf]Epoch 189:  12% 33/270 [00:19<-1:59:38, -10.41it/s, loss=0.0171, v_num=ypmf]Epoch 189:  12% 33/270 [00:19<-1:59:38, -10.41it/s, loss=0.0171, v_num=ypmf]Epoch 189:  12% 33/270 [00:20<-1:59:37, -10.28it/s, loss=0.017, v_num=ypmf] Epoch 189:  13% 34/270 [00:20<-1:59:37, -9.99it/s, loss=0.017, v_num=ypmf] Epoch 189:  13% 34/270 [00:20<-1:59:37, -9.99it/s, loss=0.017, v_num=ypmf]Epoch 189:  13% 34/270 [00:20<-1:59:37, -9.92it/s, loss=0.017, v_num=ypmf]Epoch 189:  13% 35/270 [00:21<-1:59:36, -9.73it/s, loss=0.017, v_num=ypmf]Epoch 189:  13% 35/270 [00:21<-1:59:36, -9.73it/s, loss=0.017, v_num=ypmf]Epoch 189:  13% 35/270 [00:21<-1:59:36, -9.44it/s, loss=0.017, v_num=ypmf]Epoch 189:  13% 36/270 [00:22<-1:59:35, -9.24it/s, loss=0.017, v_num=ypmf]Epoch 189:  13% 36/270 [00:22<-1:59:35, -9.24it/s, loss=0.017, v_num=ypmf]Epoch 189:  13% 36/270 [00:22<-1:59:35, -9.13it/s, loss=0.0172, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 351061. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 326790. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 275162. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 337901. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 299535. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 312868. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 305974. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 309558. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 305745. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 269814. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 289852. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 342897. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 363181. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 318385. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 341152. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 314426. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 310833. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 346435. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 328375. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 313435. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 279940. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 304863. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 351769. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 298286. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 331082. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 189:  14% 37/270 [00:22<-1:59:34, -8.91it/s, loss=0.0172, v_num=ypmf]Epoch 189:  14% 37/270 [00:22<-1:59:34, -8.91it/s, loss=0.0172, v_num=ypmf]Epoch 189:  14% 37/270 [00:23<-1:59:34, -8.86it/s, loss=0.0171, v_num=ypmf]Epoch 189:  14% 38/270 [00:23<-1:59:34, -8.66it/s, loss=0.0171, v_num=ypmf]Epoch 189:  14% 38/270 [00:23<-1:59:34, -8.66it/s, loss=0.0171, v_num=ypmf]Epoch 189:  14% 38/270 [00:23<-1:59:34, -8.60it/s, loss=0.0172, v_num=ypmf]Epoch 189:  14% 39/270 [00:23<-1:59:33, -8.46it/s, loss=0.0172, v_num=ypmf]Epoch 189:  14% 39/270 [00:23<-1:59:33, -8.46it/s, loss=0.0172, v_num=ypmf]Epoch 189:  14% 39/270 [00:24<-1:59:33, -8.38it/s, loss=0.0173, v_num=ypmf]Epoch 189:  15% 40/270 [00:24<-1:59:32, -8.20it/s, loss=0.0173, v_num=ypmf]Epoch 189:  15% 40/270 [00:24<-1:59:32, -8.20it/s, loss=0.0173, v_num=ypmf]Epoch 189:  15% 40/270 [00:24<-1:59:32, -8.15it/s, loss=0.0174, v_num=ypmf]Epoch 189:  15% 41/270 [00:25<-1:59:31, -7.89it/s, loss=0.0174, v_num=ypmf]Epoch 189:  15% 41/270 [00:25<-1:59:31, -7.89it/s, loss=0.0174, v_num=ypmf]Epoch 189:  15% 41/270 [00:25<-1:59:31, -7.89it/s, loss=0.0174, v_num=ypmf]Epoch 189:  16% 42/270 [00:25<-1:59:31, -7.73it/s, loss=0.0174, v_num=ypmf]Epoch 189:  16% 42/270 [00:25<-1:59:31, -7.73it/s, loss=0.0174, v_num=ypmf]Epoch 189:  16% 42/270 [00:25<-1:59:31, -7.68it/s, loss=0.0174, v_num=ypmf]Epoch 189:  16% 43/270 [00:26<-1:59:30, -7.52it/s, loss=0.0174, v_num=ypmf]Epoch 189:  16% 43/270 [00:26<-1:59:30, -7.52it/s, loss=0.0174, v_num=ypmf]Epoch 189:  16% 43/270 [00:26<-1:59:30, -7.47it/s, loss=0.0174, v_num=ypmf]Epoch 189:  16% 44/270 [00:27<-1:59:30, -7.29it/s, loss=0.0174, v_num=ypmf]Epoch 189:  16% 44/270 [00:27<-1:59:30, -7.29it/s, loss=0.0174, v_num=ypmf]Epoch 189:  16% 44/270 [00:27<-1:59:29, -7.25it/s, loss=0.0173, v_num=ypmf]Epoch 189:  17% 45/270 [00:27<-1:59:29, -7.14it/s, loss=0.0173, v_num=ypmf]Epoch 189:  17% 45/270 [00:27<-1:59:29, -7.14it/s, loss=0.0173, v_num=ypmf]Epoch 189:  17% 45/270 [00:27<-1:59:29, -7.07it/s, loss=0.0174, v_num=ypmf]Epoch 189:  17% 46/270 [00:28<-1:59:28, -6.94it/s, loss=0.0174, v_num=ypmf]Epoch 189:  17% 46/270 [00:28<-1:59:28, -6.94it/s, loss=0.0174, v_num=ypmf]Epoch 189:  17% 46/270 [00:28<-1:59:28, -6.90it/s, loss=0.0173, v_num=ypmf]Epoch 189:  17% 47/270 [00:28<-1:59:28, -6.79it/s, loss=0.0173, v_num=ypmf]Epoch 189:  17% 47/270 [00:28<-1:59:28, -6.79it/s, loss=0.0173, v_num=ypmf]Epoch 189:  17% 47/270 [00:28<-1:59:27, -6.74it/s, loss=0.0173, v_num=ypmf]Epoch 189:  18% 48/270 [00:29<-1:59:27, -6.63it/s, loss=0.0173, v_num=ypmf]Epoch 189:  18% 48/270 [00:29<-1:59:27, -6.63it/s, loss=0.0173, v_num=ypmf]Epoch 189:  18% 48/270 [00:29<-1:59:27, -6.60it/s, loss=0.0174, v_num=ypmf]Epoch 189:  18% 49/270 [00:29<-1:59:26, -6.50it/s, loss=0.0174, v_num=ypmf]Epoch 189:  18% 49/270 [00:29<-1:59:26, -6.50it/s, loss=0.0174, v_num=ypmf]Epoch 189:  18% 49/270 [00:29<-1:59:26, -6.43it/s, loss=0.0175, v_num=ypmf]Epoch 189:  19% 50/270 [00:30<-1:59:26, -6.30it/s, loss=0.0175, v_num=ypmf]Epoch 189:  19% 50/270 [00:30<-1:59:26, -6.30it/s, loss=0.0175, v_num=ypmf]Epoch 189:  19% 50/270 [00:30<-1:59:25, -6.27it/s, loss=0.0174, v_num=ypmf]Epoch 189:  19% 51/270 [00:30<-1:59:25, -6.15it/s, loss=0.0174, v_num=ypmf]Epoch 189:  19% 51/270 [00:30<-1:59:25, -6.15it/s, loss=0.0174, v_num=ypmf]Epoch 189:  19% 51/270 [00:31<-1:59:25, -6.12it/s, loss=0.0171, v_num=ypmf]Epoch 189:  19% 52/270 [00:31<-1:59:24, -5.96it/s, loss=0.0171, v_num=ypmf]Epoch 189:  19% 52/270 [00:31<-1:59:24, -5.96it/s, loss=0.0171, v_num=ypmf]Epoch 189:  19% 52/270 [00:31<-1:59:24, -5.93it/s, loss=0.017, v_num=ypmf] Epoch 189:  20% 53/270 [00:32<-1:59:23, -5.81it/s, loss=0.017, v_num=ypmf]Epoch 189:  20% 53/270 [00:32<-1:59:23, -5.81it/s, loss=0.017, v_num=ypmf]Epoch 189:  20% 53/270 [00:32<-1:59:23, -5.79it/s, loss=0.0169, v_num=ypmf]Epoch 189:  20% 54/270 [00:32<-1:59:23, -5.70it/s, loss=0.0169, v_num=ypmf]Epoch 189:  20% 54/270 [00:32<-1:59:23, -5.70it/s, loss=0.0169, v_num=ypmf]Epoch 189:  20% 54/270 [00:33<-1:59:22, -5.66it/s, loss=0.017, v_num=ypmf] Epoch 189:  20% 55/270 [00:33<-1:59:22, -5.56it/s, loss=0.017, v_num=ypmf]Epoch 189:  20% 55/270 [00:33<-1:59:22, -5.56it/s, loss=0.017, v_num=ypmf]Epoch 189:  20% 55/270 [00:33<-1:59:21, -5.51it/s, loss=0.0168, v_num=ypmf]Epoch 189:  21% 56/270 [00:34<-1:59:21, -5.36it/s, loss=0.0168, v_num=ypmf]Epoch 189:  21% 56/270 [00:34<-1:59:21, -5.36it/s, loss=0.0168, v_num=ypmf]Epoch 189:  21% 56/270 [00:34<-1:59:20, -5.34it/s, loss=0.0168, v_num=ypmf]Epoch 189:  21% 57/270 [00:35<-1:59:20, -5.25it/s, loss=0.0168, v_num=ypmf]Epoch 189:  21% 57/270 [00:35<-1:59:20, -5.25it/s, loss=0.0168, v_num=ypmf]Epoch 189:  21% 57/270 [00:35<-1:59:20, -5.23it/s, loss=0.0167, v_num=ypmf]Epoch 189:  21% 58/270 [00:36<-1:59:19, -5.08it/s, loss=0.0167, v_num=ypmf]Epoch 189:  21% 58/270 [00:36<-1:59:19, -5.08it/s, loss=0.0167, v_num=ypmf]Epoch 189:  21% 58/270 [00:36<-1:59:19, -5.06it/s, loss=0.0167, v_num=ypmf]Epoch 189:  22% 59/270 [00:36<-1:59:18, -4.98it/s, loss=0.0167, v_num=ypmf]Epoch 189:  22% 59/270 [00:36<-1:59:18, -4.98it/s, loss=0.0167, v_num=ypmf]Epoch 189:  22% 59/270 [00:36<-1:59:18, -4.94it/s, loss=0.0164, v_num=ypmf]Epoch 189:  22% 60/270 [00:37<-1:59:17, -4.86it/s, loss=0.0164, v_num=ypmf]Epoch 189:  22% 60/270 [00:37<-1:59:17, -4.86it/s, loss=0.0164, v_num=ypmf]Epoch 189:  22% 60/270 [00:37<-1:59:17, -4.84it/s, loss=0.0164, v_num=ypmf]Epoch 189:  23% 61/270 [00:37<-1:59:17, -4.75it/s, loss=0.0164, v_num=ypmf]Epoch 189:  23% 61/270 [00:37<-1:59:17, -4.75it/s, loss=0.0164, v_num=ypmf]Epoch 189:  23% 61/270 [00:38<-1:59:16, -4.73it/s, loss=0.0164, v_num=ypmf]Epoch 189:  23% 62/270 [00:38<-1:59:16, -4.65it/s, loss=0.0164, v_num=ypmf]Epoch 189:  23% 62/270 [00:38<-1:59:16, -4.65it/s, loss=0.0164, v_num=ypmf]Epoch 189:  23% 62/270 [00:38<-1:59:16, -4.63it/s, loss=0.0164, v_num=ypmf]Epoch 189:  23% 63/270 [00:38<-1:59:15, -4.56it/s, loss=0.0164, v_num=ypmf]Epoch 189:  23% 63/270 [00:38<-1:59:15, -4.56it/s, loss=0.0164, v_num=ypmf]Epoch 189:  23% 63/270 [00:39<-1:59:15, -4.55it/s, loss=0.0166, v_num=ypmf]Epoch 189:  24% 64/270 [00:39<-1:59:15, -4.48it/s, loss=0.0166, v_num=ypmf]Epoch 189:  24% 64/270 [00:39<-1:59:15, -4.48it/s, loss=0.0166, v_num=ypmf]Epoch 189:  24% 64/270 [00:39<-1:59:14, -4.45it/s, loss=0.0168, v_num=ypmf]Epoch 189:  24% 65/270 [00:40<-1:59:14, -4.38it/s, loss=0.0168, v_num=ypmf]Epoch 189:  24% 65/270 [00:40<-1:59:14, -4.38it/s, loss=0.0168, v_num=ypmf]Epoch 189:  24% 65/270 [00:40<-1:59:13, -4.36it/s, loss=0.0167, v_num=ypmf]Epoch 189:  24% 66/270 [00:40<-1:59:13, -4.28it/s, loss=0.0167, v_num=ypmf]Epoch 189:  24% 66/270 [00:40<-1:59:13, -4.28it/s, loss=0.0167, v_num=ypmf]Epoch 189:  24% 66/270 [00:41<-1:59:12, -4.22it/s, loss=0.0168, v_num=ypmf]Epoch 189:  25% 67/270 [00:41<-1:59:12, -4.16it/s, loss=0.0168, v_num=ypmf]Epoch 189:  25% 67/270 [00:41<-1:59:12, -4.16it/s, loss=0.0168, v_num=ypmf]Epoch 189:  25% 67/270 [00:42<-1:59:11, -4.13it/s, loss=0.0169, v_num=ypmf]Epoch 189:  25% 68/270 [00:42<-1:59:11, -4.05it/s, loss=0.0169, v_num=ypmf]Epoch 189:  25% 68/270 [00:42<-1:59:11, -4.05it/s, loss=0.0169, v_num=ypmf]Epoch 189:  25% 68/270 [00:42<-1:59:10, -4.04it/s, loss=0.0169, v_num=ypmf]Epoch 189:  26% 69/270 [00:43<-1:59:10, -3.99it/s, loss=0.0169, v_num=ypmf]Epoch 189:  26% 69/270 [00:43<-1:59:10, -3.99it/s, loss=0.0169, v_num=ypmf]Epoch 189:  26% 69/270 [00:43<-1:59:10, -3.96it/s, loss=0.0169, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 312112. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 245786. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 364414. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 326744. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 373515. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 311241. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 275332. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 302458. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 257480. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 349630. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 335590. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 351607. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 345591. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301522. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 336350. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 317462. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 346649. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 357964. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 280690. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 300600. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 347720. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 295610. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 300477. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 366086. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 282508. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 189:  26% 70/270 [00:43<-1:59:09, -3.91it/s, loss=0.0169, v_num=ypmf]Epoch 189:  26% 70/270 [00:43<-1:59:09, -3.91it/s, loss=0.0169, v_num=ypmf]Epoch 189:  26% 70/270 [00:44<-1:59:09, -3.89it/s, loss=0.017, v_num=ypmf] Epoch 189:  26% 71/270 [00:44<-1:59:09, -3.83it/s, loss=0.017, v_num=ypmf]Epoch 189:  26% 71/270 [00:44<-1:59:09, -3.83it/s, loss=0.017, v_num=ypmf]Epoch 189:  26% 71/270 [00:44<-1:59:08, -3.81it/s, loss=0.0171, v_num=ypmf]Epoch 189:  27% 72/270 [00:44<-1:59:08, -3.76it/s, loss=0.0171, v_num=ypmf]Epoch 189:  27% 72/270 [00:44<-1:59:08, -3.76it/s, loss=0.0171, v_num=ypmf]Epoch 189:  27% 72/270 [00:45<-1:59:08, -3.75it/s, loss=0.0171, v_num=ypmf]Epoch 189:  27% 73/270 [00:45<-1:59:07, -3.66it/s, loss=0.0171, v_num=ypmf]Epoch 189:  27% 73/270 [00:45<-1:59:07, -3.66it/s, loss=0.0171, v_num=ypmf]Epoch 189:  27% 73/270 [00:46<-1:59:07, -3.65it/s, loss=0.0172, v_num=ypmf]Epoch 189:  27% 74/270 [00:46<-1:59:06, -3.60it/s, loss=0.0172, v_num=ypmf]Epoch 189:  27% 74/270 [00:46<-1:59:06, -3.60it/s, loss=0.0172, v_num=ypmf]Epoch 189:  27% 74/270 [00:46<-1:59:06, -3.57it/s, loss=0.0172, v_num=ypmf]Epoch 189:  28% 75/270 [00:47<-1:59:05, -3.53it/s, loss=0.0172, v_num=ypmf]Epoch 189:  28% 75/270 [00:47<-1:59:05, -3.53it/s, loss=0.0172, v_num=ypmf]Epoch 189:  28% 75/270 [00:47<-1:59:05, -3.51it/s, loss=0.0173, v_num=ypmf]Epoch 189:  28% 76/270 [00:47<-1:59:04, -3.46it/s, loss=0.0173, v_num=ypmf]Epoch 189:  28% 76/270 [00:47<-1:59:04, -3.46it/s, loss=0.0173, v_num=ypmf]Epoch 189:  28% 76/270 [00:47<-1:59:04, -3.44it/s, loss=0.0172, v_num=ypmf]Epoch 189:  29% 77/270 [00:48<-1:59:04, -3.40it/s, loss=0.0172, v_num=ypmf]Epoch 189:  29% 77/270 [00:48<-1:59:04, -3.40it/s, loss=0.0172, v_num=ypmf]Epoch 189:  29% 77/270 [00:48<-1:59:03, -3.38it/s, loss=0.0173, v_num=ypmf]Epoch 189:  29% 78/270 [00:48<-1:59:03, -3.33it/s, loss=0.0173, v_num=ypmf]Epoch 189:  29% 78/270 [00:48<-1:59:03, -3.33it/s, loss=0.0173, v_num=ypmf]Epoch 189:  29% 78/270 [00:49<-1:59:03, -3.32it/s, loss=0.0173, v_num=ypmf]Epoch 189:  29% 79/270 [00:49<-1:59:02, -3.27it/s, loss=0.0173, v_num=ypmf]Epoch 189:  29% 79/270 [00:49<-1:59:02, -3.27it/s, loss=0.0173, v_num=ypmf]Epoch 189:  29% 79/270 [00:50<-1:59:01, -3.22it/s, loss=0.0174, v_num=ypmf]Epoch 189:  30% 80/270 [00:50<-1:59:01, -3.17it/s, loss=0.0174, v_num=ypmf]Epoch 189:  30% 80/270 [00:50<-1:59:01, -3.17it/s, loss=0.0174, v_num=ypmf]Epoch 189:  30% 80/270 [00:50<-1:59:00, -3.16it/s, loss=0.0174, v_num=ypmf]Epoch 189:  30% 81/270 [00:51<-1:59:00, -3.12it/s, loss=0.0174, v_num=ypmf]Epoch 189:  30% 81/270 [00:51<-1:59:00, -3.12it/s, loss=0.0174, v_num=ypmf]Epoch 189:  30% 81/270 [00:51<-1:59:00, -3.11it/s, loss=0.0174, v_num=ypmf]Epoch 189:  30% 82/270 [00:51<-1:58:59, -3.07it/s, loss=0.0174, v_num=ypmf]Epoch 189:  30% 82/270 [00:51<-1:58:59, -3.07it/s, loss=0.0174, v_num=ypmf]Epoch 189:  30% 82/270 [00:52<-1:58:59, -3.05it/s, loss=0.0174, v_num=ypmf]Epoch 189:  31% 83/270 [00:52<-1:58:58, -3.01it/s, loss=0.0174, v_num=ypmf]Epoch 189:  31% 83/270 [00:52<-1:58:58, -3.01it/s, loss=0.0174, v_num=ypmf]Epoch 189:  31% 83/270 [00:52<-1:58:58, -3.00it/s, loss=0.0173, v_num=ypmf]Epoch 189:  31% 84/270 [00:53<-1:58:58, -2.96it/s, loss=0.0173, v_num=ypmf]Epoch 189:  31% 84/270 [00:53<-1:58:58, -2.96it/s, loss=0.0173, v_num=ypmf]Epoch 189:  31% 84/270 [00:53<-1:58:57, -2.95it/s, loss=0.0173, v_num=ypmf]Epoch 189:  31% 85/270 [00:53<-1:58:57, -2.91it/s, loss=0.0173, v_num=ypmf]Epoch 189:  31% 85/270 [00:53<-1:58:57, -2.91it/s, loss=0.0173, v_num=ypmf]Epoch 189:  31% 85/270 [00:53<-1:58:57, -2.90it/s, loss=0.0173, v_num=ypmf]Epoch 189:  32% 86/270 [00:54<-1:58:56, -2.86it/s, loss=0.0173, v_num=ypmf]Epoch 189:  32% 86/270 [00:54<-1:58:56, -2.86it/s, loss=0.0173, v_num=ypmf]Epoch 189:  32% 86/270 [00:54<-1:58:56, -2.85it/s, loss=0.0173, v_num=ypmf]Epoch 189:  32% 87/270 [00:54<-1:58:55, -2.81it/s, loss=0.0173, v_num=ypmf]Epoch 189:  32% 87/270 [00:54<-1:58:55, -2.81it/s, loss=0.0173, v_num=ypmf]Epoch 189:  32% 87/270 [00:54<-1:58:55, -2.80it/s, loss=0.0172, v_num=ypmf]Epoch 189:  33% 88/270 [00:55<-1:58:55, -2.77it/s, loss=0.0172, v_num=ypmf]Epoch 189:  33% 88/270 [00:55<-1:58:55, -2.77it/s, loss=0.0172, v_num=ypmf]Epoch 189:  33% 88/270 [00:55<-1:58:54, -2.75it/s, loss=0.0172, v_num=ypmf]Epoch 189:  33% 89/270 [00:55<-1:58:54, -2.72it/s, loss=0.0172, v_num=ypmf]Epoch 189:  33% 89/270 [00:55<-1:58:54, -2.72it/s, loss=0.0172, v_num=ypmf]Epoch 189:  33% 89/270 [00:56<-1:58:53, -2.70it/s, loss=0.0171, v_num=ypmf]Epoch 189:  33% 90/270 [00:56<-1:58:53, -2.67it/s, loss=0.0171, v_num=ypmf]Epoch 189:  33% 90/270 [00:56<-1:58:53, -2.67it/s, loss=0.0171, v_num=ypmf]Epoch 189:  33% 90/270 [00:57<-1:58:52, -2.62it/s, loss=0.0171, v_num=ypmf]Epoch 189:  34% 91/270 [00:58<-1:58:51, -2.59it/s, loss=0.0171, v_num=ypmf]Epoch 189:  34% 91/270 [00:58<-1:58:51, -2.59it/s, loss=0.0171, v_num=ypmf]Epoch 189:  34% 91/270 [00:58<-1:58:51, -2.58it/s, loss=0.017, v_num=ypmf] Epoch 189:  34% 92/270 [00:58<-1:58:51, -2.55it/s, loss=0.017, v_num=ypmf]Epoch 189:  34% 92/270 [00:58<-1:58:51, -2.55it/s, loss=0.017, v_num=ypmf]Epoch 189:  34% 92/270 [00:59<-1:58:50, -2.51it/s, loss=0.0172, v_num=ypmf]Epoch 189:  34% 93/270 [00:59<-1:58:49, -2.48it/s, loss=0.0172, v_num=ypmf]Epoch 189:  34% 93/270 [00:59<-1:58:49, -2.48it/s, loss=0.0172, v_num=ypmf]Epoch 189:  34% 93/270 [00:59<-1:58:49, -2.48it/s, loss=0.0171, v_num=ypmf]Epoch 189:  35% 94/270 [01:00<-1:58:48, -2.44it/s, loss=0.0171, v_num=ypmf]Epoch 189:  35% 94/270 [01:00<-1:58:48, -2.44it/s, loss=0.0171, v_num=ypmf]Epoch 189:  35% 94/270 [01:00<-1:58:48, -2.44it/s, loss=0.0171, v_num=ypmf]Epoch 189:  35% 95/270 [01:00<-1:58:48, -2.41it/s, loss=0.0171, v_num=ypmf]Epoch 189:  35% 95/270 [01:00<-1:58:48, -2.41it/s, loss=0.0171, v_num=ypmf]Epoch 189:  35% 95/270 [01:00<-1:58:48, -2.40it/s, loss=0.017, v_num=ypmf] Epoch 189:  36% 96/270 [01:01<-1:58:47, -2.37it/s, loss=0.017, v_num=ypmf]Epoch 189:  36% 96/270 [01:01<-1:58:47, -2.37it/s, loss=0.017, v_num=ypmf]Epoch 189:  36% 96/270 [01:01<-1:58:47, -2.36it/s, loss=0.0171, v_num=ypmf]Epoch 189:  36% 97/270 [01:01<-1:58:46, -2.32it/s, loss=0.0171, v_num=ypmf]Epoch 189:  36% 97/270 [01:01<-1:58:46, -2.32it/s, loss=0.0171, v_num=ypmf]Epoch 189:  36% 97/270 [01:02<-1:58:46, -2.32it/s, loss=0.017, v_num=ypmf] Epoch 189:  36% 98/270 [01:02<-1:58:45, -2.29it/s, loss=0.017, v_num=ypmf]Epoch 189:  36% 98/270 [01:02<-1:58:45, -2.29it/s, loss=0.017, v_num=ypmf]Epoch 189:  36% 98/270 [01:02<-1:58:45, -2.28it/s, loss=0.0169, v_num=ypmf]Epoch 189:  37% 99/270 [01:03<-1:58:45, -2.25it/s, loss=0.0169, v_num=ypmf]Epoch 189:  37% 99/270 [01:03<-1:58:45, -2.25it/s, loss=0.0169, v_num=ypmf]Epoch 189:  37% 99/270 [01:03<-1:58:44, -2.25it/s, loss=0.017, v_num=ypmf] Epoch 189:  37% 100/270 [01:03<-1:58:44, -2.22it/s, loss=0.017, v_num=ypmf]Epoch 189:  37% 100/270 [01:03<-1:58:44, -2.22it/s, loss=0.017, v_num=ypmf]Epoch 189:  37% 100/270 [01:03<-1:58:44, -2.21it/s, loss=0.0171, v_num=ypmf]Epoch 189:  37% 101/270 [01:04<-1:58:43, -2.18it/s, loss=0.0171, v_num=ypmf]Epoch 189:  37% 101/270 [01:04<-1:58:43, -2.18it/s, loss=0.0171, v_num=ypmf]Epoch 189:  37% 101/270 [01:04<-1:58:43, -2.17it/s, loss=0.0172, v_num=ypmf]Epoch 189:  38% 102/270 [01:04<-1:58:42, -2.15it/s, loss=0.0172, v_num=ypmf]Epoch 189:  38% 102/270 [01:04<-1:58:42, -2.15it/s, loss=0.0172, v_num=ypmf]Epoch 189:  38% 102/270 [01:05<-1:58:42, -2.14it/s, loss=0.0171, v_num=ypmf]Epoch 189:  38% 103/270 [01:05<-1:58:41, -2.11it/s, loss=0.0171, v_num=ypmf]Epoch 189:  38% 103/270 [01:05<-1:58:41, -2.11it/s, loss=0.0171, v_num=ypmf]Epoch 189:  38% 103/270 [01:05<-1:58:41, -2.10it/s, loss=0.017, v_num=ypmf] Epoch 189:  39% 104/270 [01:06<-1:58:40, -2.07it/s, loss=0.017, v_num=ypmf]Epoch 189:  39% 104/270 [01:06<-1:58:40, -2.07it/s, loss=0.017, v_num=ypmf]Epoch 189:  39% 104/270 [01:06<-1:58:40, -2.07it/s, loss=0.0169, v_num=ypmf]Epoch 189:  39% 105/270 [01:06<-1:58:40, -2.04it/s, loss=0.0169, v_num=ypmf]Epoch 189:  39% 105/270 [01:06<-1:58:40, -2.04it/s, loss=0.0169, v_num=ypmf]Epoch 189:  39% 105/270 [01:06<-1:58:39, -2.03it/s, loss=0.0169, v_num=ypmf]Epoch 189:  39% 106/270 [01:07<-1:58:39, -2.01it/s, loss=0.0169, v_num=ypmf]Epoch 189:  39% 106/270 [01:07<-1:58:39, -2.01it/s, loss=0.0169, v_num=ypmf]Epoch 189:  39% 106/270 [01:07<-1:58:39, -2.00it/s, loss=0.0169, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 317219. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 260685. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 335060. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 333941. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 294565. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293741. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 299796. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301625. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293982. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 316259. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 272822. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 282189. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 238908. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 330364. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 253454. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 315272. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 361453. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 272685. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 277417. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 281587. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 327392. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 370367. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 307796. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301235. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 357039. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 189:  40% 107/270 [01:07<-1:58:38, -1.97it/s, loss=0.0169, v_num=ypmf]Epoch 189:  40% 107/270 [01:07<-1:58:38, -1.97it/s, loss=0.0169, v_num=ypmf]Epoch 189:  40% 107/270 [01:08<-1:58:38, -1.97it/s, loss=0.0169, v_num=ypmf]Epoch 189:  40% 108/270 [01:08<-1:58:37, -1.94it/s, loss=0.0169, v_num=ypmf]Epoch 189:  40% 108/270 [01:08<-1:58:37, -1.94it/s, loss=0.0169, v_num=ypmf]Epoch 189:  40% 108/270 [01:08<-1:58:37, -1.94it/s, loss=0.0169, v_num=ypmf]Epoch 189:  40% 109/270 [01:08<-1:58:36, -1.92it/s, loss=0.0169, v_num=ypmf]Epoch 189:  40% 109/270 [01:08<-1:58:36, -1.92it/s, loss=0.0169, v_num=ypmf]Epoch 189:  40% 109/270 [01:09<-1:58:36, -1.91it/s, loss=0.017, v_num=ypmf] Epoch 189:  41% 110/270 [01:09<-1:58:35, -1.88it/s, loss=0.017, v_num=ypmf]Epoch 189:  41% 110/270 [01:09<-1:58:35, -1.88it/s, loss=0.017, v_num=ypmf]Epoch 189:  41% 110/270 [01:09<-1:58:35, -1.87it/s, loss=0.0169, v_num=ypmf]Epoch 189:  41% 111/270 [01:10<-1:58:34, -1.85it/s, loss=0.0169, v_num=ypmf]Epoch 189:  41% 111/270 [01:10<-1:58:34, -1.85it/s, loss=0.0169, v_num=ypmf]Epoch 189:  41% 111/270 [01:10<-1:58:34, -1.84it/s, loss=0.0169, v_num=ypmf]Epoch 189:  41% 112/270 [01:10<-1:58:34, -1.82it/s, loss=0.0169, v_num=ypmf]Epoch 189:  41% 112/270 [01:10<-1:58:34, -1.82it/s, loss=0.0169, v_num=ypmf]Epoch 189:  41% 112/270 [01:11<-1:58:33, -1.81it/s, loss=0.0168, v_num=ypmf]Epoch 189:  42% 113/270 [01:11<-1:58:33, -1.79it/s, loss=0.0168, v_num=ypmf]Epoch 189:  42% 113/270 [01:11<-1:58:33, -1.79it/s, loss=0.0168, v_num=ypmf]Epoch 189:  42% 113/270 [01:11<-1:58:32, -1.78it/s, loss=0.0169, v_num=ypmf]Epoch 189:  42% 114/270 [01:12<-1:58:32, -1.76it/s, loss=0.0169, v_num=ypmf]Epoch 189:  42% 114/270 [01:12<-1:58:32, -1.76it/s, loss=0.0169, v_num=ypmf]Epoch 189:  42% 114/270 [01:12<-1:58:31, -1.75it/s, loss=0.0169, v_num=ypmf]Epoch 189:  43% 115/270 [01:12<-1:58:31, -1.73it/s, loss=0.0169, v_num=ypmf]Epoch 189:  43% 115/270 [01:12<-1:58:31, -1.73it/s, loss=0.0169, v_num=ypmf]Epoch 189:  43% 115/270 [01:13<-1:58:31, -1.72it/s, loss=0.0169, v_num=ypmf]Epoch 189:  43% 116/270 [01:13<-1:58:30, -1.70it/s, loss=0.0169, v_num=ypmf]Epoch 189:  43% 116/270 [01:13<-1:58:30, -1.70it/s, loss=0.0169, v_num=ypmf]Epoch 189:  43% 116/270 [01:13<-1:58:30, -1.70it/s, loss=0.0169, v_num=ypmf]Epoch 189:  43% 117/270 [01:13<-1:58:29, -1.68it/s, loss=0.0169, v_num=ypmf]Epoch 189:  43% 117/270 [01:13<-1:58:29, -1.68it/s, loss=0.0169, v_num=ypmf]Epoch 189:  43% 117/270 [01:14<-1:58:29, -1.67it/s, loss=0.0171, v_num=ypmf]Epoch 189:  44% 118/270 [01:14<-1:58:28, -1.65it/s, loss=0.0171, v_num=ypmf]Epoch 189:  44% 118/270 [01:14<-1:58:28, -1.65it/s, loss=0.0171, v_num=ypmf]Epoch 189:  44% 118/270 [01:14<-1:58:28, -1.65it/s, loss=0.0171, v_num=ypmf]Epoch 189:  44% 119/270 [01:15<-1:58:28, -1.62it/s, loss=0.0171, v_num=ypmf]Epoch 189:  44% 119/270 [01:15<-1:58:28, -1.62it/s, loss=0.0171, v_num=ypmf]Epoch 189:  44% 119/270 [01:15<-1:58:27, -1.62it/s, loss=0.017, v_num=ypmf] Epoch 189:  44% 120/270 [01:16<-1:58:26, -1.59it/s, loss=0.017, v_num=ypmf]Epoch 189:  44% 120/270 [01:16<-1:58:26, -1.59it/s, loss=0.017, v_num=ypmf]Epoch 189:  44% 120/270 [01:16<-1:58:26, -1.59it/s, loss=0.0169, v_num=ypmf]Epoch 189:  45% 121/270 [01:16<-1:58:25, -1.57it/s, loss=0.0169, v_num=ypmf]Epoch 189:  45% 121/270 [01:16<-1:58:25, -1.57it/s, loss=0.0169, v_num=ypmf]Epoch 189:  45% 121/270 [01:16<-1:58:25, -1.56it/s, loss=0.017, v_num=ypmf] Epoch 189:  45% 122/270 [01:17<-1:58:25, -1.54it/s, loss=0.017, v_num=ypmf]Epoch 189:  45% 122/270 [01:17<-1:58:25, -1.54it/s, loss=0.017, v_num=ypmf]Epoch 189:  45% 122/270 [01:17<-1:58:24, -1.54it/s, loss=0.0171, v_num=ypmf]Epoch 189:  46% 123/270 [01:17<-1:58:24, -1.52it/s, loss=0.0171, v_num=ypmf]Epoch 189:  46% 123/270 [01:17<-1:58:24, -1.52it/s, loss=0.0171, v_num=ypmf]Epoch 189:  46% 123/270 [01:17<-1:58:24, -1.52it/s, loss=0.0171, v_num=ypmf]Epoch 189:  46% 124/270 [01:18<-1:58:23, -1.49it/s, loss=0.0171, v_num=ypmf]Epoch 189:  46% 124/270 [01:18<-1:58:23, -1.49it/s, loss=0.0171, v_num=ypmf]Epoch 189:  46% 124/270 [01:18<-1:58:23, -1.49it/s, loss=0.0171, v_num=ypmf]Epoch 189:  46% 125/270 [01:18<-1:58:22, -1.47it/s, loss=0.0171, v_num=ypmf]Epoch 189:  46% 125/270 [01:18<-1:58:22, -1.47it/s, loss=0.0171, v_num=ypmf]Epoch 189:  46% 125/270 [01:19<-1:58:22, -1.47it/s, loss=0.0171, v_num=ypmf]Epoch 189:  47% 126/270 [01:19<-1:58:21, -1.44it/s, loss=0.0171, v_num=ypmf]Epoch 189:  47% 126/270 [01:19<-1:58:21, -1.44it/s, loss=0.0171, v_num=ypmf]Epoch 189:  47% 126/270 [01:19<-1:58:20, -1.44it/s, loss=0.017, v_num=ypmf] Epoch 189:  47% 127/270 [01:20<-1:58:20, -1.42it/s, loss=0.017, v_num=ypmf]Epoch 189:  47% 127/270 [01:20<-1:58:20, -1.42it/s, loss=0.017, v_num=ypmf]Epoch 189:  47% 127/270 [01:20<-1:58:20, -1.42it/s, loss=0.0171, v_num=ypmf]Epoch 189:  47% 128/270 [01:20<-1:58:19, -1.40it/s, loss=0.0171, v_num=ypmf]Epoch 189:  47% 128/270 [01:20<-1:58:19, -1.40it/s, loss=0.0171, v_num=ypmf]Epoch 189:  47% 128/270 [01:20<-1:58:19, -1.40it/s, loss=0.017, v_num=ypmf] Epoch 189:  48% 129/270 [01:21<-1:58:18, -1.38it/s, loss=0.017, v_num=ypmf]Epoch 189:  48% 129/270 [01:21<-1:58:18, -1.38it/s, loss=0.017, v_num=ypmf]Epoch 189:  48% 129/270 [01:21<-1:58:18, -1.37it/s, loss=0.017, v_num=ypmf]Epoch 189:  48% 130/270 [01:21<-1:58:17, -1.35it/s, loss=0.017, v_num=ypmf]Epoch 189:  48% 130/270 [01:21<-1:58:17, -1.35it/s, loss=0.017, v_num=ypmf]Epoch 189:  48% 130/270 [01:22<-1:58:17, -1.35it/s, loss=0.017, v_num=ypmf]Epoch 189:  49% 131/270 [01:22<-1:58:16, -1.33it/s, loss=0.017, v_num=ypmf]Epoch 189:  49% 131/270 [01:22<-1:58:16, -1.33it/s, loss=0.017, v_num=ypmf]Epoch 189:  49% 131/270 [01:22<-1:58:16, -1.33it/s, loss=0.017, v_num=ypmf]Epoch 189:  49% 132/270 [01:22<-1:58:15, -1.31it/s, loss=0.017, v_num=ypmf]Epoch 189:  49% 132/270 [01:22<-1:58:15, -1.31it/s, loss=0.017, v_num=ypmf]Epoch 189:  49% 132/270 [01:23<-1:58:15, -1.31it/s, loss=0.017, v_num=ypmf]Epoch 189:  49% 133/270 [01:23<-1:58:14, -1.29it/s, loss=0.017, v_num=ypmf]Epoch 189:  49% 133/270 [01:23<-1:58:14, -1.29it/s, loss=0.017, v_num=ypmf]Epoch 189:  49% 133/270 [01:23<-1:58:14, -1.29it/s, loss=0.0169, v_num=ypmf]Epoch 189:  50% 134/270 [01:24<-1:58:13, -1.27it/s, loss=0.0169, v_num=ypmf]Epoch 189:  50% 134/270 [01:24<-1:58:13, -1.27it/s, loss=0.0169, v_num=ypmf]Epoch 189:  50% 134/270 [01:24<-1:58:13, -1.27it/s, loss=0.0168, v_num=ypmf]Epoch 189:  50% 135/270 [01:24<-1:58:13, -1.25it/s, loss=0.0168, v_num=ypmf]Epoch 189:  50% 135/270 [01:24<-1:58:13, -1.25it/s, loss=0.0168, v_num=ypmf]Epoch 189:  50% 135/270 [01:24<-1:58:12, -1.25it/s, loss=0.0168, v_num=ypmf]Epoch 189:  50% 136/270 [01:25<-1:58:11, -1.22it/s, loss=0.0168, v_num=ypmf]Epoch 189:  50% 136/270 [01:25<-1:58:11, -1.22it/s, loss=0.0168, v_num=ypmf]Epoch 189:  50% 136/270 [01:26<-1:58:11, -1.22it/s, loss=0.0167, v_num=ypmf]Epoch 189:  51% 137/270 [01:26<-1:58:10, -1.20it/s, loss=0.0167, v_num=ypmf]Epoch 189:  51% 137/270 [01:26<-1:58:10, -1.20it/s, loss=0.0167, v_num=ypmf]Epoch 189:  51% 137/270 [01:26<-1:58:10, -1.20it/s, loss=0.0167, v_num=ypmf]Epoch 189:  51% 138/270 [01:26<-1:58:09, -1.19it/s, loss=0.0167, v_num=ypmf]Epoch 189:  51% 138/270 [01:26<-1:58:09, -1.19it/s, loss=0.0167, v_num=ypmf]Epoch 189:  51% 138/270 [01:27<-1:58:09, -1.18it/s, loss=0.0168, v_num=ypmf]Epoch 189:  51% 139/270 [01:27<-1:58:08, -1.17it/s, loss=0.0168, v_num=ypmf]Epoch 189:  51% 139/270 [01:27<-1:58:08, -1.17it/s, loss=0.0168, v_num=ypmf]Epoch 189:  51% 139/270 [01:27<-1:58:08, -1.16it/s, loss=0.0169, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301723. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 303737. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 378779. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 321702. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 332189. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 234325. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 330043. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 296710. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 344455. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 262607. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 311817. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 347221. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 326867. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 353251. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 230569. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 291156. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 296495. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 338301. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301791. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308976. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 347519. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 302644. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 261284. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 280889. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 324087. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 189:  52% 140/270 [01:28<-1:58:07, -1.15it/s, loss=0.0169, v_num=ypmf]Epoch 189:  52% 140/270 [01:28<-1:58:07, -1.15it/s, loss=0.0169, v_num=ypmf]Epoch 189:  52% 140/270 [01:28<-1:58:07, -1.14it/s, loss=0.017, v_num=ypmf] Epoch 189:  52% 141/270 [01:28<-1:58:06, -1.13it/s, loss=0.017, v_num=ypmf]Epoch 189:  52% 141/270 [01:28<-1:58:06, -1.13it/s, loss=0.017, v_num=ypmf]Epoch 189:  52% 141/270 [01:28<-1:58:06, -1.13it/s, loss=0.0169, v_num=ypmf]Epoch 189:  53% 142/270 [01:29<-1:58:05, -1.11it/s, loss=0.0169, v_num=ypmf]Epoch 189:  53% 142/270 [01:29<-1:58:05, -1.11it/s, loss=0.0169, v_num=ypmf]Epoch 189:  53% 142/270 [01:29<-1:58:05, -1.11it/s, loss=0.0167, v_num=ypmf]Epoch 189:  53% 143/270 [01:29<-1:58:04, -1.09it/s, loss=0.0167, v_num=ypmf]Epoch 189:  53% 143/270 [01:29<-1:58:04, -1.09it/s, loss=0.0167, v_num=ypmf]Epoch 189:  53% 143/270 [01:30<-1:58:04, -1.09it/s, loss=0.0167, v_num=ypmf]Epoch 189:  53% 144/270 [01:30<-1:58:03, -1.07it/s, loss=0.0167, v_num=ypmf]Epoch 189:  53% 144/270 [01:30<-1:58:03, -1.07it/s, loss=0.0167, v_num=ypmf]Epoch 189:  53% 144/270 [01:30<-1:58:03, -1.07it/s, loss=0.0167, v_num=ypmf]Epoch 189:  54% 145/270 [01:31<-1:58:02, -1.05it/s, loss=0.0167, v_num=ypmf]Epoch 189:  54% 145/270 [01:31<-1:58:02, -1.05it/s, loss=0.0167, v_num=ypmf]Epoch 189:  54% 145/270 [01:31<-1:58:01, -1.05it/s, loss=0.0167, v_num=ypmf]Epoch 189:  54% 146/270 [01:31<-1:58:01, -1.03it/s, loss=0.0167, v_num=ypmf]Epoch 189:  54% 146/270 [01:31<-1:58:01, -1.03it/s, loss=0.0167, v_num=ypmf]Epoch 189:  54% 146/270 [01:31<-1:58:00, -1.03it/s, loss=0.0168, v_num=ypmf]Epoch 189:  54% 147/270 [01:32<-1:58:00, -1.02it/s, loss=0.0168, v_num=ypmf]Epoch 189:  54% 147/270 [01:32<-1:58:00, -1.02it/s, loss=0.0168, v_num=ypmf]Epoch 189:  54% 147/270 [01:32<-1:57:59, -1.02it/s, loss=0.0166, v_num=ypmf]Epoch 189:  55% 148/270 [01:33<-1:57:58, -1.00it/s, loss=0.0166, v_num=ypmf]Epoch 189:  55% 148/270 [01:33<-1:57:58, -1.00it/s, loss=0.0166, v_num=ypmf]Epoch 189:  55% 148/270 [01:33<-1:57:58, -0.99it/s, loss=0.0166, v_num=ypmf]Epoch 189:  55% 149/270 [01:34<-1:57:57, -0.98it/s, loss=0.0166, v_num=ypmf]Epoch 189:  55% 149/270 [01:34<-1:57:57, -0.98it/s, loss=0.0166, v_num=ypmf]Epoch 189:  55% 149/270 [01:34<-1:57:57, -0.98it/s, loss=0.0166, v_num=ypmf]Epoch 189:  56% 150/270 [01:34<-1:57:56, -0.96it/s, loss=0.0166, v_num=ypmf]Epoch 189:  56% 150/270 [01:34<-1:57:56, -0.96it/s, loss=0.0166, v_num=ypmf]Epoch 189:  56% 150/270 [01:34<-1:57:56, -0.96it/s, loss=0.0167, v_num=ypmf]Epoch 189:  56% 151/270 [01:35<-1:57:55, -0.95it/s, loss=0.0167, v_num=ypmf]Epoch 189:  56% 151/270 [01:35<-1:57:55, -0.95it/s, loss=0.0167, v_num=ypmf]Epoch 189:  56% 151/270 [01:35<-1:57:54, -0.94it/s, loss=0.0167, v_num=ypmf]Epoch 189:  56% 152/270 [01:35<-1:57:54, -0.93it/s, loss=0.0167, v_num=ypmf]Epoch 189:  56% 152/270 [01:35<-1:57:54, -0.93it/s, loss=0.0167, v_num=ypmf]Epoch 189:  56% 152/270 [01:35<-1:57:53, -0.93it/s, loss=0.0166, v_num=ypmf]Epoch 189:  57% 153/270 [01:36<-1:57:52, -0.91it/s, loss=0.0166, v_num=ypmf]Epoch 189:  57% 153/270 [01:36<-1:57:52, -0.91it/s, loss=0.0166, v_num=ypmf]Epoch 189:  57% 153/270 [01:36<-1:57:52, -0.91it/s, loss=0.0168, v_num=ypmf]Epoch 189:  57% 154/270 [01:36<-1:57:51, -0.90it/s, loss=0.0168, v_num=ypmf]Epoch 189:  57% 154/270 [01:36<-1:57:51, -0.90it/s, loss=0.0168, v_num=ypmf]Epoch 189:  57% 154/270 [01:37<-1:57:51, -0.90it/s, loss=0.0169, v_num=ypmf]Epoch 189:  57% 155/270 [01:37<-1:57:50, -0.88it/s, loss=0.0169, v_num=ypmf]Epoch 189:  57% 155/270 [01:37<-1:57:50, -0.88it/s, loss=0.0169, v_num=ypmf]Epoch 189:  57% 155/270 [01:38<-1:57:49, -0.88it/s, loss=0.0168, v_num=ypmf]Epoch 189:  58% 156/270 [01:38<-1:57:48, -0.86it/s, loss=0.0168, v_num=ypmf]Epoch 189:  58% 156/270 [01:38<-1:57:48, -0.86it/s, loss=0.0168, v_num=ypmf]Epoch 189:  58% 156/270 [01:38<-1:57:48, -0.86it/s, loss=0.0168, v_num=ypmf]Epoch 189:  58% 157/270 [01:39<-1:57:47, -0.85it/s, loss=0.0168, v_num=ypmf]Epoch 189:  58% 157/270 [01:39<-1:57:47, -0.85it/s, loss=0.0168, v_num=ypmf]Epoch 189:  58% 157/270 [01:39<-1:57:47, -0.85it/s, loss=0.0168, v_num=ypmf]Epoch 189:  59% 158/270 [01:40<-1:57:45, -0.83it/s, loss=0.0168, v_num=ypmf]Epoch 189:  59% 158/270 [01:40<-1:57:45, -0.83it/s, loss=0.0168, v_num=ypmf]Epoch 189:  59% 158/270 [01:40<-1:57:45, -0.83it/s, loss=0.0168, v_num=ypmf]Epoch 189:  59% 159/270 [01:40<-1:57:44, -0.81it/s, loss=0.0168, v_num=ypmf]Epoch 189:  59% 159/270 [01:40<-1:57:44, -0.81it/s, loss=0.0168, v_num=ypmf]Epoch 189:  59% 159/270 [01:40<-1:57:44, -0.81it/s, loss=0.0166, v_num=ypmf]Epoch 189:  59% 160/270 [01:41<-1:57:43, -0.80it/s, loss=0.0166, v_num=ypmf]Epoch 189:  59% 160/270 [01:41<-1:57:43, -0.80it/s, loss=0.0166, v_num=ypmf]Epoch 189:  59% 160/270 [01:41<-1:57:43, -0.80it/s, loss=0.0166, v_num=ypmf]Epoch 189:  60% 161/270 [01:42<-1:57:41, -0.78it/s, loss=0.0166, v_num=ypmf]Epoch 189:  60% 161/270 [01:42<-1:57:41, -0.78it/s, loss=0.0166, v_num=ypmf]Epoch 189:  60% 161/270 [01:42<-1:57:41, -0.78it/s, loss=0.0166, v_num=ypmf]Epoch 189:  60% 162/270 [01:42<-1:57:40, -0.77it/s, loss=0.0166, v_num=ypmf]Epoch 189:  60% 162/270 [01:42<-1:57:40, -0.77it/s, loss=0.0166, v_num=ypmf]Epoch 189:  60% 162/270 [01:42<-1:57:40, -0.77it/s, loss=0.0167, v_num=ypmf]Epoch 189:  60% 163/270 [01:43<-1:57:38, -0.75it/s, loss=0.0167, v_num=ypmf]Epoch 189:  60% 163/270 [01:43<-1:57:38, -0.75it/s, loss=0.0167, v_num=ypmf]Epoch 189:  60% 163/270 [01:44<-1:57:38, -0.75it/s, loss=0.0167, v_num=ypmf]Epoch 189:  61% 164/270 [01:44<-1:57:37, -0.74it/s, loss=0.0167, v_num=ypmf]Epoch 189:  61% 164/270 [01:44<-1:57:37, -0.74it/s, loss=0.0167, v_num=ypmf]Epoch 189:  61% 164/270 [01:44<-1:57:36, -0.73it/s, loss=0.0167, v_num=ypmf]Epoch 189:  61% 165/270 [01:45<-1:57:35, -0.72it/s, loss=0.0167, v_num=ypmf]Epoch 189:  61% 165/270 [01:45<-1:57:35, -0.72it/s, loss=0.0167, v_num=ypmf]Epoch 189:  61% 165/270 [01:45<-1:57:35, -0.72it/s, loss=0.0168, v_num=ypmf]Epoch 189:  61% 166/270 [01:46<-1:57:33, -0.71it/s, loss=0.0168, v_num=ypmf]Epoch 189:  61% 166/270 [01:46<-1:57:33, -0.71it/s, loss=0.0168, v_num=ypmf]Epoch 189:  61% 166/270 [01:46<-1:57:33, -0.70it/s, loss=0.0169, v_num=ypmf]Epoch 189:  62% 167/270 [01:46<-1:57:32, -0.69it/s, loss=0.0169, v_num=ypmf]Epoch 189:  62% 167/270 [01:46<-1:57:32, -0.69it/s, loss=0.0169, v_num=ypmf]Epoch 189:  62% 167/270 [01:47<-1:57:32, -0.69it/s, loss=0.0169, v_num=ypmf]Epoch 189:  62% 168/270 [01:47<-1:57:30, -0.68it/s, loss=0.0169, v_num=ypmf]Epoch 189:  62% 168/270 [01:47<-1:57:30, -0.68it/s, loss=0.0169, v_num=ypmf]Epoch 189:  62% 168/270 [01:47<-1:57:30, -0.68it/s, loss=0.0168, v_num=ypmf]Epoch 189:  63% 169/270 [01:48<-1:57:28, -0.66it/s, loss=0.0168, v_num=ypmf]Epoch 189:  63% 169/270 [01:48<-1:57:28, -0.66it/s, loss=0.0168, v_num=ypmf]Epoch 189:  63% 169/270 [01:48<-1:57:28, -0.66it/s, loss=0.0169, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 280743. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 342799. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 379502. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 328413. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 323421. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 350932. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 353746. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 290458. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 364415. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 316969. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 320674. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 286337. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 384192. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 268914. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 364032. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 317725. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 313911. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 307684. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 310305. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 214212. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319620. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 342787. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 294458. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 304423. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 330289. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 189:  63% 170/270 [01:48<-1:57:27, -0.65it/s, loss=0.0169, v_num=ypmf]Epoch 189:  63% 170/270 [01:48<-1:57:27, -0.65it/s, loss=0.0169, v_num=ypmf]Epoch 189:  63% 170/270 [01:49<-1:57:27, -0.65it/s, loss=0.0168, v_num=ypmf]Epoch 189:  63% 171/270 [01:49<-1:57:26, -0.64it/s, loss=0.0168, v_num=ypmf]Epoch 189:  63% 171/270 [01:49<-1:57:26, -0.64it/s, loss=0.0168, v_num=ypmf]Epoch 189:  63% 171/270 [01:49<-1:57:26, -0.64it/s, loss=0.017, v_num=ypmf] Epoch 189:  64% 172/270 [01:49<-1:57:24, -0.63it/s, loss=0.017, v_num=ypmf]Epoch 189:  64% 172/270 [01:49<-1:57:24, -0.63it/s, loss=0.017, v_num=ypmf]Epoch 189:  64% 172/270 [01:50<-1:57:24, -0.63it/s, loss=0.017, v_num=ypmf]Epoch 189:  64% 173/270 [01:50<-1:57:23, -0.62it/s, loss=0.017, v_num=ypmf]Epoch 189:  64% 173/270 [01:50<-1:57:23, -0.62it/s, loss=0.017, v_num=ypmf]Epoch 189:  64% 173/270 [01:50<-1:57:23, -0.61it/s, loss=0.0168, v_num=ypmf]Epoch 189:  64% 174/270 [01:51<-1:57:21, -0.60it/s, loss=0.0168, v_num=ypmf]Epoch 189:  64% 174/270 [01:51<-1:57:21, -0.60it/s, loss=0.0168, v_num=ypmf]Epoch 189:  64% 174/270 [01:51<-1:57:21, -0.60it/s, loss=0.0169, v_num=ypmf]Epoch 189:  65% 175/270 [01:51<-1:57:20, -0.59it/s, loss=0.0169, v_num=ypmf]Epoch 189:  65% 175/270 [01:51<-1:57:20, -0.59it/s, loss=0.0169, v_num=ypmf]Epoch 189:  65% 175/270 [01:51<-1:57:20, -0.59it/s, loss=0.017, v_num=ypmf] Epoch 189:  65% 176/270 [01:52<-1:57:18, -0.58it/s, loss=0.017, v_num=ypmf]Epoch 189:  65% 176/270 [01:52<-1:57:18, -0.58it/s, loss=0.017, v_num=ypmf]Epoch 189:  65% 176/270 [01:52<-1:57:18, -0.58it/s, loss=0.017, v_num=ypmf]Epoch 189:  66% 177/270 [01:52<-1:57:17, -0.57it/s, loss=0.017, v_num=ypmf]Epoch 189:  66% 177/270 [01:52<-1:57:17, -0.57it/s, loss=0.017, v_num=ypmf]Epoch 189:  66% 177/270 [01:53<-1:57:16, -0.57it/s, loss=0.0171, v_num=ypmf]Epoch 189:  66% 178/270 [01:53<-1:57:15, -0.56it/s, loss=0.0171, v_num=ypmf]Epoch 189:  66% 178/270 [01:53<-1:57:15, -0.56it/s, loss=0.0171, v_num=ypmf]Epoch 189:  66% 178/270 [01:54<-1:57:14, -0.55it/s, loss=0.0171, v_num=ypmf]Epoch 189:  66% 179/270 [01:54<-1:57:12, -0.54it/s, loss=0.0171, v_num=ypmf]Epoch 189:  66% 179/270 [01:54<-1:57:12, -0.54it/s, loss=0.0171, v_num=ypmf]Epoch 189:  66% 179/270 [01:54<-1:57:12, -0.54it/s, loss=0.0171, v_num=ypmf]Epoch 189:  67% 180/270 [01:55<-1:57:11, -0.53it/s, loss=0.0171, v_num=ypmf]Epoch 189:  67% 180/270 [01:55<-1:57:11, -0.53it/s, loss=0.0171, v_num=ypmf]Epoch 189:  67% 180/270 [01:55<-1:57:10, -0.53it/s, loss=0.0171, v_num=ypmf]Epoch 189:  67% 181/270 [01:55<-1:57:09, -0.52it/s, loss=0.0171, v_num=ypmf]Epoch 189:  67% 181/270 [01:55<-1:57:09, -0.52it/s, loss=0.0171, v_num=ypmf]Epoch 189:  67% 181/270 [01:55<-1:57:09, -0.52it/s, loss=0.0171, v_num=ypmf]Epoch 189:  67% 182/270 [01:56<-1:57:07, -0.51it/s, loss=0.0171, v_num=ypmf]Epoch 189:  67% 182/270 [01:56<-1:57:07, -0.51it/s, loss=0.0171, v_num=ypmf]Epoch 189:  67% 182/270 [01:56<-1:57:07, -0.51it/s, loss=0.0171, v_num=ypmf]Epoch 189:  68% 183/270 [01:56<-1:57:05, -0.50it/s, loss=0.0171, v_num=ypmf]Epoch 189:  68% 183/270 [01:56<-1:57:05, -0.50it/s, loss=0.0171, v_num=ypmf]Epoch 189:  68% 183/270 [01:57<-1:57:05, -0.49it/s, loss=0.0173, v_num=ypmf]Epoch 189:  68% 184/270 [01:57<-1:57:03, -0.48it/s, loss=0.0173, v_num=ypmf]Epoch 189:  68% 184/270 [01:57<-1:57:03, -0.48it/s, loss=0.0173, v_num=ypmf]Epoch 189:  68% 184/270 [01:57<-1:57:03, -0.48it/s, loss=0.0173, v_num=ypmf]Epoch 189:  69% 185/270 [01:58<-1:57:01, -0.47it/s, loss=0.0173, v_num=ypmf]Epoch 189:  69% 185/270 [01:58<-1:57:01, -0.47it/s, loss=0.0173, v_num=ypmf]Epoch 189:  69% 185/270 [01:58<-1:57:01, -0.47it/s, loss=0.0172, v_num=ypmf]Epoch 189:  69% 186/270 [01:59<-1:56:59, -0.46it/s, loss=0.0172, v_num=ypmf]Epoch 189:  69% 186/270 [01:59<-1:56:59, -0.46it/s, loss=0.0172, v_num=ypmf]Epoch 189:  69% 186/270 [01:59<-1:56:58, -0.46it/s, loss=0.0171, v_num=ypmf]Epoch 189:  69% 187/270 [01:59<-1:56:57, -0.45it/s, loss=0.0171, v_num=ypmf]Epoch 189:  69% 187/270 [01:59<-1:56:57, -0.45it/s, loss=0.0171, v_num=ypmf]Epoch 189:  69% 187/270 [01:59<-1:56:56, -0.45it/s, loss=0.0171, v_num=ypmf]Epoch 189:  70% 188/270 [02:02<-1:56:51, -0.43it/s, loss=0.0171, v_num=ypmf]Epoch 189:  70% 188/270 [02:02<-1:56:51, -0.43it/s, loss=0.0171, v_num=ypmf]Epoch 189:  70% 188/270 [02:02<-1:56:51, -0.43it/s, loss=0.0172, v_num=ypmf]Epoch 189:  70% 189/270 [02:02<-1:56:49, -0.42it/s, loss=0.0172, v_num=ypmf]Epoch 189:  70% 189/270 [02:02<-1:56:49, -0.42it/s, loss=0.0172, v_num=ypmf]Epoch 189:  70% 189/270 [02:02<-1:56:49, -0.42it/s, loss=0.0171, v_num=ypmf]Epoch 189:  70% 190/270 [02:03<-1:56:47, -0.41it/s, loss=0.0171, v_num=ypmf]Epoch 189:  70% 190/270 [02:03<-1:56:47, -0.41it/s, loss=0.0171, v_num=ypmf]Epoch 189:  70% 190/270 [02:03<-1:56:47, -0.41it/s, loss=0.0174, v_num=ypmf]Epoch 189:  71% 191/270 [02:04<-1:56:45, -0.40it/s, loss=0.0174, v_num=ypmf]Epoch 189:  71% 191/270 [02:04<-1:56:45, -0.40it/s, loss=0.0174, v_num=ypmf]Epoch 189:  71% 191/270 [02:04<-1:56:44, -0.40it/s, loss=0.0172, v_num=ypmf]Epoch 189:  71% 192/270 [02:04<-1:56:42, -0.39it/s, loss=0.0172, v_num=ypmf]Epoch 189:  71% 192/270 [02:04<-1:56:42, -0.39it/s, loss=0.0172, v_num=ypmf]Epoch 189:  71% 192/270 [02:04<-1:56:42, -0.39it/s, loss=0.0171, v_num=ypmf]Epoch 189:  71% 193/270 [02:05<-1:56:40, -0.38it/s, loss=0.0171, v_num=ypmf]Epoch 189:  71% 193/270 [02:05<-1:56:40, -0.38it/s, loss=0.0171, v_num=ypmf]Epoch 189:  71% 193/270 [02:05<-1:56:39, -0.38it/s, loss=0.0171, v_num=ypmf]Epoch 189:  72% 194/270 [02:05<-1:56:37, -0.37it/s, loss=0.0171, v_num=ypmf]Epoch 189:  72% 194/270 [02:05<-1:56:37, -0.37it/s, loss=0.0171, v_num=ypmf]Epoch 189:  72% 194/270 [02:05<-1:56:37, -0.37it/s, loss=0.0172, v_num=ypmf]Epoch 189:  72% 195/270 [02:06<-1:56:35, -0.36it/s, loss=0.0172, v_num=ypmf]Epoch 189:  72% 195/270 [02:06<-1:56:35, -0.36it/s, loss=0.0172, v_num=ypmf]Epoch 189:  72% 195/270 [02:06<-1:56:34, -0.36it/s, loss=0.0171, v_num=ypmf]Epoch 189:  73% 196/270 [02:06<-1:56:32, -0.35it/s, loss=0.0171, v_num=ypmf]Epoch 189:  73% 196/270 [02:06<-1:56:32, -0.35it/s, loss=0.0171, v_num=ypmf]Epoch 189:  73% 196/270 [02:06<-1:56:32, -0.35it/s, loss=0.0171, v_num=ypmf]Epoch 189:  73% 197/270 [02:07<-1:56:30, -0.35it/s, loss=0.0171, v_num=ypmf]Epoch 189:  73% 197/270 [02:07<-1:56:29, -0.35it/s, loss=0.0171, v_num=ypmf]Epoch 189:  73% 197/270 [02:07<-1:56:29, -0.34it/s, loss=0.017, v_num=ypmf] Epoch 189:  73% 198/270 [02:08<-1:56:26, -0.34it/s, loss=0.017, v_num=ypmf]Epoch 189:  73% 198/270 [02:08<-1:56:26, -0.34it/s, loss=0.017, v_num=ypmf]Epoch 189:  73% 198/270 [02:08<-1:56:26, -0.34it/s, loss=0.017, v_num=ypmf]Epoch 189:  74% 199/270 [02:08<-1:56:23, -0.33it/s, loss=0.017, v_num=ypmf]Epoch 189:  74% 199/270 [02:08<-1:56:23, -0.33it/s, loss=0.017, v_num=ypmf]Epoch 189:  74% 199/270 [02:08<-1:56:23, -0.33it/s, loss=0.0169, v_num=ypmf]Epoch 189:  74% 200/270 [02:09<-1:56:20, -0.32it/s, loss=0.0169, v_num=ypmf]Epoch 189:  74% 200/270 [02:09<-1:56:20, -0.32it/s, loss=0.0169, v_num=ypmf]Epoch 189:  74% 200/270 [02:09<-1:56:20, -0.32it/s, loss=0.0169, v_num=ypmf]Epoch 189:  74% 201/270 [02:09<-1:56:17, -0.31it/s, loss=0.0169, v_num=ypmf]Epoch 189:  74% 201/270 [02:09<-1:56:17, -0.31it/s, loss=0.0169, v_num=ypmf]Epoch 189:  74% 201/270 [02:09<-1:56:16, -0.31it/s, loss=0.0169, v_num=ypmf]Epoch 189:  75% 202/270 [02:10<-1:56:13, -0.30it/s, loss=0.0169, v_num=ypmf]Epoch 189:  75% 202/270 [02:10<-1:56:13, -0.30it/s, loss=0.0169, v_num=ypmf]Epoch 189:  75% 202/270 [02:10<-1:56:13, -0.30it/s, loss=0.0169, v_num=ypmf]Epoch 189:  75% 203/270 [02:10<-1:56:10, -0.29it/s, loss=0.0169, v_num=ypmf]Epoch 189:  75% 203/270 [02:10<-1:56:10, -0.29it/s, loss=0.0169, v_num=ypmf]Epoch 189:  75% 203/270 [02:10<-1:56:10, -0.29it/s, loss=0.0169, v_num=ypmf]Epoch 189:  76% 204/270 [02:11<-1:56:06, -0.28it/s, loss=0.0169, v_num=ypmf]Epoch 189:  76% 204/270 [02:11<-1:56:06, -0.28it/s, loss=0.0169, v_num=ypmf]Epoch 189:  76% 204/270 [02:11<-1:56:06, -0.28it/s, loss=0.0169, v_num=ypmf]Epoch 189:  76% 205/270 [02:11<-1:56:02, -0.27it/s, loss=0.0169, v_num=ypmf]Epoch 189:  76% 205/270 [02:11<-1:56:02, -0.27it/s, loss=0.0169, v_num=ypmf]Epoch 189:  76% 205/270 [02:12<-1:56:02, -0.27it/s, loss=0.0169, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 250686. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 283981. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319427. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 270014. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 271740. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 233537. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 276801. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301455. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 338834. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 277239. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 313015. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 279656. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301695. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 259241. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 322814. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308951. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 285841. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 285199. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 314679. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 344677. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 298652. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 306594. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 272864. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293830. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 303777. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 189:  76% 206/270 [02:12<-1:55:58, -0.26it/s, loss=0.0169, v_num=ypmf]Epoch 189:  76% 206/270 [02:12<-1:55:58, -0.26it/s, loss=0.0169, v_num=ypmf]Epoch 189:  76% 206/270 [02:12<-1:55:58, -0.26it/s, loss=0.0169, v_num=ypmf]Epoch 189:  77% 207/270 [02:14<-1:55:51, -0.25it/s, loss=0.0169, v_num=ypmf]Epoch 189:  77% 207/270 [02:14<-1:55:51, -0.25it/s, loss=0.0169, v_num=ypmf]Epoch 189:  77% 207/270 [02:14<-1:55:51, -0.25it/s, loss=0.0168, v_num=ypmf]Epoch 189:  77% 208/270 [02:15<-1:55:47, -0.24it/s, loss=0.0168, v_num=ypmf]Epoch 189:  77% 208/270 [02:15<-1:55:47, -0.24it/s, loss=0.0168, v_num=ypmf]Epoch 189:  77% 208/270 [02:15<-1:55:46, -0.24it/s, loss=0.0168, v_num=ypmf]Epoch 189:  77% 209/270 [02:15<-1:55:41, -0.24it/s, loss=0.0168, v_num=ypmf]Epoch 189:  77% 209/270 [02:15<-1:55:41, -0.24it/s, loss=0.0168, v_num=ypmf]Epoch 189:  77% 209/270 [02:16<-1:55:41, -0.24it/s, loss=0.0168, v_num=ypmf]Epoch 189:  78% 210/270 [02:16<-1:55:37, -0.23it/s, loss=0.0168, v_num=ypmf]Epoch 189:  78% 210/270 [02:16<-1:55:37, -0.23it/s, loss=0.0168, v_num=ypmf]Epoch 189:  78% 210/270 [02:16<-1:55:36, -0.23it/s, loss=0.0167, v_num=ypmf]Epoch 189:  78% 211/270 [02:16<-1:55:31, -0.22it/s, loss=0.0167, v_num=ypmf]Epoch 189:  78% 211/270 [02:16<-1:55:31, -0.22it/s, loss=0.0167, v_num=ypmf]Epoch 189:  78% 211/270 [02:17<-1:55:31, -0.22it/s, loss=0.0169, v_num=ypmf]Epoch 189:  79% 212/270 [02:17<-1:55:26, -0.21it/s, loss=0.0169, v_num=ypmf]Epoch 189:  79% 212/270 [02:17<-1:55:26, -0.21it/s, loss=0.0169, v_num=ypmf]Epoch 189:  79% 212/270 [02:17<-1:55:25, -0.21it/s, loss=0.0169, v_num=ypmf]Epoch 189:  79% 213/270 [02:17<-1:55:20, -0.20it/s, loss=0.0169, v_num=ypmf]Epoch 189:  79% 213/270 [02:17<-1:55:20, -0.20it/s, loss=0.0169, v_num=ypmf]Epoch 189:  79% 213/270 [02:18<-1:55:19, -0.20it/s, loss=0.017, v_num=ypmf] Epoch 189:  79% 214/270 [02:18<-1:55:13, -0.20it/s, loss=0.017, v_num=ypmf]Epoch 189:  79% 214/270 [02:18<-1:55:13, -0.20it/s, loss=0.017, v_num=ypmf]Epoch 189:  79% 214/270 [02:18<-1:55:13, -0.19it/s, loss=0.017, v_num=ypmf]Epoch 189:  80% 215/270 [02:18<-1:55:07, -0.19it/s, loss=0.017, v_num=ypmf]Epoch 189:  80% 215/270 [02:18<-1:55:07, -0.19it/s, loss=0.017, v_num=ypmf]Epoch 189:  80% 215/270 [02:19<-1:55:06, -0.19it/s, loss=0.0171, v_num=ypmf]Epoch 189:  80% 216/270 [02:19<-1:54:59, -0.18it/s, loss=0.0171, v_num=ypmf]Epoch 189:  80% 216/270 [02:19<-1:54:59, -0.18it/s, loss=0.0171, v_num=ypmf]Epoch 189:  80% 216/270 [02:19<-1:54:59, -0.18it/s, loss=0.0171, v_num=ypmf]Epoch 189:  80% 217/270 [02:20<-1:54:51, -0.17it/s, loss=0.0171, v_num=ypmf]Epoch 189:  80% 217/270 [02:20<-1:54:51, -0.17it/s, loss=0.0171, v_num=ypmf]Epoch 189:  80% 217/270 [02:20<-1:54:51, -0.17it/s, loss=0.017, v_num=ypmf] Epoch 189:  81% 218/270 [02:20<-1:54:43, -0.16it/s, loss=0.017, v_num=ypmf]Epoch 189:  81% 218/270 [02:20<-1:54:43, -0.16it/s, loss=0.017, v_num=ypmf]Epoch 189:  81% 218/270 [02:20<-1:54:42, -0.16it/s, loss=0.0172, v_num=ypmf]Epoch 189:  81% 219/270 [02:21<-1:54:33, -0.16it/s, loss=0.0172, v_num=ypmf]Epoch 189:  81% 219/270 [02:21<-1:54:33, -0.16it/s, loss=0.0172, v_num=ypmf]Epoch 189:  81% 219/270 [02:21<-1:54:33, -0.16it/s, loss=0.0172, v_num=ypmf]Epoch 189:  81% 220/270 [02:21<-1:54:23, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 189:  81% 220/270 [02:21<-1:54:23, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 189:  81% 220/270 [02:21<-1:54:22, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 189:  82% 221/270 [02:22<-1:54:12, -0.14it/s, loss=0.0172, v_num=ypmf]Epoch 189:  82% 221/270 [02:22<-1:54:12, -0.14it/s, loss=0.0172, v_num=ypmf]Epoch 189:  82% 221/270 [02:22<-1:54:11, -0.14it/s, loss=0.0173, v_num=ypmf]Epoch 189:  82% 222/270 [02:23<-1:53:59, -0.13it/s, loss=0.0173, v_num=ypmf]Epoch 189:  82% 222/270 [02:23<-1:53:59, -0.13it/s, loss=0.0173, v_num=ypmf]Epoch 189:  82% 222/270 [02:23<-1:53:59, -0.13it/s, loss=0.0172, v_num=ypmf]Epoch 189:  83% 223/270 [02:23<-1:53:46, -0.13it/s, loss=0.0172, v_num=ypmf]Epoch 189:  83% 223/270 [02:23<-1:53:46, -0.13it/s, loss=0.0172, v_num=ypmf]Epoch 189:  83% 223/270 [02:23<-1:53:45, -0.13it/s, loss=0.0171, v_num=ypmf]Epoch 189:  83% 224/270 [02:24<-1:53:31, -0.12it/s, loss=0.0171, v_num=ypmf]Epoch 189:  83% 224/270 [02:24<-1:53:31, -0.12it/s, loss=0.0171, v_num=ypmf]Epoch 189:  83% 224/270 [02:24<-1:53:29, -0.12it/s, loss=0.0171, v_num=ypmf]Epoch 189:  83% 225/270 [02:25<-1:53:12, -0.11it/s, loss=0.0171, v_num=ypmf]Epoch 189:  83% 225/270 [02:25<-1:53:12, -0.11it/s, loss=0.0171, v_num=ypmf]Epoch 189:  83% 225/270 [02:25<-1:53:12, -0.11it/s, loss=0.0172, v_num=ypmf]Epoch 189:  84% 226/270 [02:25<-1:52:53, -0.10it/s, loss=0.0172, v_num=ypmf]Epoch 189:  84% 226/270 [02:25<-1:52:53, -0.10it/s, loss=0.0172, v_num=ypmf]Epoch 189:  84% 226/270 [02:25<-1:52:53, -0.10it/s, loss=0.0173, v_num=ypmf]Epoch 189:  84% 227/270 [02:26<-1:52:31, -0.10it/s, loss=0.0173, v_num=ypmf]Epoch 189:  84% 227/270 [02:26<-1:52:31, -0.10it/s, loss=0.0173, v_num=ypmf]Epoch 189:  84% 227/270 [02:26<-1:52:31, -0.10it/s, loss=0.0173, v_num=ypmf]Epoch 189:  84% 228/270 [02:26<-1:52:07, -0.09it/s, loss=0.0173, v_num=ypmf]Epoch 189:  84% 228/270 [02:26<-1:52:07, -0.09it/s, loss=0.0173, v_num=ypmf]Epoch 189:  84% 228/270 [02:26<-1:52:06, -0.09it/s, loss=0.0174, v_num=ypmf]Epoch 189:  85% 229/270 [02:27<-1:51:37, -0.08it/s, loss=0.0174, v_num=ypmf]Epoch 189:  85% 229/270 [02:27<-1:51:37, -0.08it/s, loss=0.0174, v_num=ypmf]Epoch 189:  85% 229/270 [02:29<-1:51:31, -0.08it/s, loss=0.0174, v_num=ypmf]Epoch 189:  85% 230/270 [02:29<-1:50:57, -0.07it/s, loss=0.0174, v_num=ypmf]Epoch 189:  85% 230/270 [02:29<-1:50:57, -0.07it/s, loss=0.0174, v_num=ypmf]Epoch 189:  85% 230/270 [02:29<-1:50:56, -0.07it/s, loss=0.0172, v_num=ypmf]Epoch 189:  86% 231/270 [02:30<-1:50:14, -0.07it/s, loss=0.0172, v_num=ypmf]Epoch 189:  86% 231/270 [02:30<-1:50:14, -0.07it/s, loss=0.0172, v_num=ypmf]Epoch 189:  86% 231/270 [02:30<-1:50:14, -0.07it/s, loss=0.017, v_num=ypmf] Epoch 189:  86% 232/270 [02:30<-1:49:24, -0.06it/s, loss=0.017, v_num=ypmf]Epoch 189:  86% 232/270 [02:30<-1:49:24, -0.06it/s, loss=0.017, v_num=ypmf]Epoch 189:  86% 232/270 [02:30<-1:49:23, -0.06it/s, loss=0.0169, v_num=ypmf]Epoch 189:  86% 233/270 [02:31<-1:48:21, -0.05it/s, loss=0.0169, v_num=ypmf]Epoch 189:  86% 233/270 [02:31<-1:48:21, -0.05it/s, loss=0.0169, v_num=ypmf]Epoch 189:  86% 233/270 [02:31<-1:48:19, -0.05it/s, loss=0.017, v_num=ypmf] Epoch 189:  87% 234/270 [02:32<-1:46:59, -0.05it/s, loss=0.017, v_num=ypmf]Epoch 189:  87% 234/270 [02:32<-1:46:59, -0.05it/s, loss=0.017, v_num=ypmf]Epoch 189:  87% 234/270 [02:32<-1:46:57, -0.05it/s, loss=0.017, v_num=ypmf]Epoch 189:  87% 235/270 [02:32<-1:45:10, -0.04it/s, loss=0.017, v_num=ypmf]Epoch 189:  87% 235/270 [02:32<-1:45:10, -0.04it/s, loss=0.017, v_num=ypmf]Epoch 189:  87% 235/270 [02:32<-1:45:09, -0.04it/s, loss=0.0169, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 353909. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 298483. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 323276. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 291853. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 264995. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 262024. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 257942. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 311850. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 286448. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 316549. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 297829. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 265644. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 372439. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 320645. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 338535. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 275686. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308980. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 289756. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 279582. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 329653. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 370927. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 255037. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308852. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 298478. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 264179. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 189:  87% 236/270 [02:33<-1:42:39, -0.03it/s, loss=0.0169, v_num=ypmf]Epoch 189:  87% 236/270 [02:33<-1:42:39, -0.03it/s, loss=0.0169, v_num=ypmf]Epoch 189:  87% 236/270 [02:33<-1:42:37, -0.03it/s, loss=0.017, v_num=ypmf] Epoch 189:  88% 237/270 [02:33<-1:38:51, -0.03it/s, loss=0.017, v_num=ypmf]Epoch 189:  88% 237/270 [02:33<-1:38:51, -0.03it/s, loss=0.017, v_num=ypmf]Epoch 189:  88% 237/270 [02:34<-1:38:48, -0.03it/s, loss=0.017, v_num=ypmf]Epoch 189:  88% 238/270 [02:34<-1:32:32, -0.02it/s, loss=0.017, v_num=ypmf]Epoch 189:  88% 238/270 [02:34<-1:32:32, -0.02it/s, loss=0.017, v_num=ypmf]Epoch 189:  88% 238/270 [02:34<-1:32:30, -0.02it/s, loss=0.0169, v_num=ypmf]Epoch 189:  89% 239/270 [02:35<-1:19:55, -0.01it/s, loss=0.0169, v_num=ypmf]Epoch 189:  89% 239/270 [02:35<-1:19:55, -0.01it/s, loss=0.0169, v_num=ypmf]Epoch 189:  89% 239/270 [02:36<-1:19:41, -0.01it/s, loss=0.0168, v_num=ypmf]Epoch 189:  89% 240/270 [02:36<-2:41:46, -0.01it/s, loss=0.0168, v_num=ypmf]Epoch 189:  89% 240/270 [02:36<-2:41:46, -0.01it/s, loss=0.0168, v_num=ypmf]Epoch 189:  89% 240/270 [02:36<-2:41:41, -0.01it/s, loss=0.0169, v_num=ypmf]Epoch 189:  89% 241/270 [02:37<?, ?it/s, loss=0.0169, v_num=ypmf]           Epoch 189:  89% 241/270 [02:37<?, ?it/s, loss=0.0169, v_num=ypmf]Epoch 189:  89% 241/270 [02:37<?, ?it/s, loss=0.0168, v_num=ypmf]Epoch 189:  90% 242/270 [02:37<1:13:30, 157.50s/it, loss=0.0168, v_num=ypmf]Epoch 189:  90% 242/270 [02:37<1:13:30, 157.50s/it, loss=0.0168, v_num=ypmf]Epoch 189:  90% 242/270 [02:37<1:13:33, 157.64s/it, loss=0.0168, v_num=ypmf]Epoch 189:  90% 243/270 [02:38<35:33, 79.02s/it, loss=0.0168, v_num=ypmf]   Epoch 189:  90% 243/270 [02:38<35:33, 79.02s/it, loss=0.0168, v_num=ypmf]Epoch 189:  90% 243/270 [02:38<35:37, 79.15s/it, loss=0.0168, v_num=ypmf]Epoch 189:  90% 244/270 [02:38<22:55, 52.91s/it, loss=0.0168, v_num=ypmf]Epoch 189:  90% 244/270 [02:38<22:55, 52.91s/it, loss=0.0168, v_num=ypmf]Epoch 189:  90% 244/270 [02:38<22:57, 52.98s/it, loss=0.0168, v_num=ypmf]Epoch 189:  91% 245/270 [02:39<16:36, 39.84s/it, loss=0.0168, v_num=ypmf]Epoch 189:  91% 245/270 [02:39<16:36, 39.84s/it, loss=0.0168, v_num=ypmf]Epoch 189:  91% 245/270 [02:39<16:36, 39.88s/it, loss=0.0167, v_num=ypmf]Epoch 189:  91% 246/270 [02:39<12:47, 31.98s/it, loss=0.0167, v_num=ypmf]Epoch 189:  91% 246/270 [02:39<12:47, 31.98s/it, loss=0.0167, v_num=ypmf]Epoch 189:  91% 246/270 [02:40<12:48, 32.03s/it, loss=0.0165, v_num=ypmf]Epoch 189:  91% 247/270 [02:40<10:15, 26.77s/it, loss=0.0165, v_num=ypmf]Epoch 189:  91% 247/270 [02:40<10:15, 26.77s/it, loss=0.0165, v_num=ypmf]Epoch 189:  91% 247/270 [02:40<10:16, 26.80s/it, loss=0.0164, v_num=ypmf]Epoch 189:  92% 248/270 [02:41<08:26, 23.02s/it, loss=0.0164, v_num=ypmf]Epoch 189:  92% 248/270 [02:41<08:26, 23.02s/it, loss=0.0164, v_num=ypmf]Epoch 189:  92% 248/270 [02:41<08:27, 23.07s/it, loss=0.0164, v_num=ypmf]Epoch 189:  92% 249/270 [02:41<07:04, 20.24s/it, loss=0.0164, v_num=ypmf]Epoch 189:  92% 249/270 [02:41<07:04, 20.24s/it, loss=0.0164, v_num=ypmf]Epoch 189:  92% 249/270 [02:42<07:05, 20.26s/it, loss=0.0166, v_num=ypmf]Epoch 189:  93% 250/270 [02:42<06:00, 18.05s/it, loss=0.0166, v_num=ypmf]Epoch 189:  93% 250/270 [02:42<06:00, 18.05s/it, loss=0.0166, v_num=ypmf]Epoch 189:  93% 250/270 [02:42<06:01, 18.09s/it, loss=0.0166, v_num=ypmf]
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 289266. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 341247. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 331277. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 302233. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 315446. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 328697. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 328527. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308086. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 365922. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308374. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 300608. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308876. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Validation: 0it [00:00, ?it/s][A
Validation:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.27it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.27it/s][AEpoch 189:  93% 251/270 [02:43<05:10, 16.37s/it, loss=0.0166, v_num=ypmf]Epoch 189:  93% 251/270 [02:43<05:10, 16.37s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  10% 2/20 [00:03<00:30,  1.72s/it][A
Validation DataLoader 0:  10% 2/20 [00:03<00:30,  1.72s/it][AEpoch 189:  93% 252/270 [02:46<04:32, 15.12s/it, loss=0.0166, v_num=ypmf]Epoch 189:  93% 252/270 [02:46<04:32, 15.12s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  15% 3/20 [00:04<00:27,  1.60s/it][A
Validation DataLoader 0:  15% 3/20 [00:04<00:27,  1.60s/it][AEpoch 189:  94% 253/270 [02:47<03:57, 13.98s/it, loss=0.0166, v_num=ypmf]Epoch 189:  94% 253/270 [02:47<03:57, 13.98s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  20% 4/20 [00:05<00:19,  1.24s/it][A
Validation DataLoader 0:  20% 4/20 [00:05<00:19,  1.24s/it][AEpoch 189:  94% 254/270 [02:48<03:27, 12.96s/it, loss=0.0166, v_num=ypmf]Epoch 189:  94% 254/270 [02:48<03:27, 12.96s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  25% 5/20 [00:06<00:20,  1.35s/it][A
Validation DataLoader 0:  25% 5/20 [00:06<00:20,  1.35s/it][AEpoch 189:  94% 255/270 [02:49<03:02, 12.14s/it, loss=0.0166, v_num=ypmf]Epoch 189:  94% 255/270 [02:49<03:02, 12.14s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  30% 6/20 [00:08<00:18,  1.34s/it][A
Validation DataLoader 0:  30% 6/20 [00:08<00:18,  1.34s/it][AEpoch 189:  95% 256/270 [02:51<02:39, 11.42s/it, loss=0.0166, v_num=ypmf]Epoch 189:  95% 256/270 [02:51<02:39, 11.42s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  35% 7/20 [00:10<00:21,  1.63s/it][A
Validation DataLoader 0:  35% 7/20 [00:10<00:21,  1.63s/it][AEpoch 189:  95% 257/270 [02:53<02:20, 10.84s/it, loss=0.0166, v_num=ypmf]Epoch 189:  95% 257/270 [02:53<02:20, 10.84s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  40% 8/20 [00:11<00:17,  1.44s/it][A
Validation DataLoader 0:  40% 8/20 [00:11<00:17,  1.44s/it][AEpoch 189:  96% 258/270 [02:54<02:03, 10.27s/it, loss=0.0166, v_num=ypmf]Epoch 189:  96% 258/270 [02:54<02:03, 10.27s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  45% 9/20 [00:12<00:13,  1.21s/it][A
Validation DataLoader 0:  45% 9/20 [00:12<00:13,  1.21s/it][AEpoch 189:  96% 259/270 [02:55<01:47,  9.74s/it, loss=0.0166, v_num=ypmf]Epoch 189:  96% 259/270 [02:55<01:47,  9.74s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  50% 10/20 [00:13<00:12,  1.26s/it][A
Validation DataLoader 0:  50% 10/20 [00:13<00:12,  1.26s/it][AEpoch 189:  96% 260/270 [02:56<01:32,  9.30s/it, loss=0.0166, v_num=ypmf]Epoch 189:  96% 260/270 [02:56<01:32,  9.30s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  55% 11/20 [00:14<00:09,  1.09s/it][A
Validation DataLoader 0:  55% 11/20 [00:14<00:09,  1.09s/it][AEpoch 189:  97% 261/270 [02:57<01:19,  8.87s/it, loss=0.0166, v_num=ypmf]Epoch 189:  97% 261/270 [02:57<01:19,  8.87s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  60% 12/20 [00:15<00:09,  1.24s/it][A
Validation DataLoader 0:  60% 12/20 [00:15<00:09,  1.24s/it][AEpoch 189:  97% 262/270 [02:58<01:08,  8.52s/it, loss=0.0166, v_num=ypmf]Epoch 189:  97% 262/270 [02:58<01:08,  8.52s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  65% 13/20 [00:16<00:07,  1.12s/it][A
Validation DataLoader 0:  65% 13/20 [00:16<00:07,  1.12s/it][AEpoch 189:  97% 263/270 [02:59<00:57,  8.17s/it, loss=0.0166, v_num=ypmf]Epoch 189:  97% 263/270 [02:59<00:57,  8.17s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  70% 14/20 [00:17<00:05,  1.01it/s][A
Validation DataLoader 0:  70% 14/20 [00:17<00:05,  1.01it/s][AEpoch 189:  98% 264/270 [03:00<00:47,  7.85s/it, loss=0.0166, v_num=ypmf]Epoch 189:  98% 264/270 [03:00<00:47,  7.85s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  75% 15/20 [00:18<00:04,  1.03it/s][A
Validation DataLoader 0:  75% 15/20 [00:18<00:04,  1.03it/s][AEpoch 189:  98% 265/270 [03:01<00:37,  7.56s/it, loss=0.0166, v_num=ypmf]Epoch 189:  98% 265/270 [03:01<00:37,  7.56s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  80% 16/20 [00:19<00:04,  1.19s/it][A
Validation DataLoader 0:  80% 16/20 [00:19<00:04,  1.19s/it][AEpoch 189:  99% 266/270 [03:03<00:29,  7.32s/it, loss=0.0166, v_num=ypmf]Epoch 189:  99% 266/270 [03:03<00:29,  7.32s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  85% 17/20 [00:20<00:03,  1.17s/it][A
Validation DataLoader 0:  85% 17/20 [00:20<00:03,  1.17s/it][AEpoch 189:  99% 267/270 [03:04<00:21,  7.08s/it, loss=0.0166, v_num=ypmf]Epoch 189:  99% 267/270 [03:04<00:21,  7.08s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  90% 18/20 [00:21<00:02,  1.06s/it][A
Validation DataLoader 0:  90% 18/20 [00:21<00:02,  1.06s/it][AEpoch 189:  99% 268/270 [03:05<00:13,  6.85s/it, loss=0.0166, v_num=ypmf]Epoch 189:  99% 268/270 [03:05<00:13,  6.85s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0:  95% 19/20 [00:23<00:01,  1.12s/it][A
Validation DataLoader 0:  95% 19/20 [00:23<00:01,  1.12s/it][AEpoch 189: 100% 269/270 [03:06<00:06,  6.65s/it, loss=0.0166, v_num=ypmf]Epoch 189: 100% 269/270 [03:06<00:06,  6.65s/it, loss=0.0166, v_num=ypmf]
Validation DataLoader 0: 100% 20/20 [00:23<00:00,  1.04it/s][A
Validation DataLoader 0: 100% 20/20 [00:23<00:00,  1.04it/s][AEpoch 189: 100% 270/270 [03:06<00:00,  6.44s/it, loss=0.0166, v_num=ypmf]Epoch 189: 100% 270/270 [03:06<00:00,  6.44s/it, loss=0.0166, v_num=ypmf]Epoch 189: 100% 270/270 [03:09<00:00,  6.52s/it, loss=0.0166, v_num=ypmf]
                                                            [AEpoch 189: 100% 270/270 [03:09<00:00,  6.52s/it, loss=0.0166, v_num=ypmf]Epoch 189:   0% 0/270 [00:00<00:00, -8789802.30it/s, loss=0.0166, v_num=ypmf]Epoch 190:   0% 0/270 [00:00<00:00, -2037958.19it/s, loss=0.0166, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 190:   0% 1/270 [00:01<-1:59:59, -184.45it/s, loss=0.0166, v_num=ypmf] Epoch 190:   0% 1/270 [00:01<-1:59:59, -184.40it/s, loss=0.0166, v_num=ypmf]Epoch 190:   0% 1/270 [00:03<-1:59:57, -72.88it/s, loss=0.0166, v_num=ypmf] Epoch 190:   1% 2/270 [00:03<-1:59:56, -65.02it/s, loss=0.0166, v_num=ypmf]Epoch 190:   1% 2/270 [00:03<-1:59:56, -65.02it/s, loss=0.0166, v_num=ypmf]Epoch 190:   1% 2/270 [00:03<-1:59:56, -62.02it/s, loss=0.0165, v_num=ypmf]Epoch 190:   1% 3/270 [00:04<-1:59:56, -56.45it/s, loss=0.0165, v_num=ypmf]Epoch 190:   1% 3/270 [00:04<-1:59:56, -56.45it/s, loss=0.0165, v_num=ypmf]Epoch 190:   1% 3/270 [00:04<-1:59:56, -53.90it/s, loss=0.0164, v_num=ypmf]Epoch 190:   1% 4/270 [00:04<-1:59:55, -49.27it/s, loss=0.0164, v_num=ypmf]Epoch 190:   1% 4/270 [00:04<-1:59:55, -49.27it/s, loss=0.0164, v_num=ypmf]Epoch 190:   1% 4/270 [00:04<-1:59:55, -47.50it/s, loss=0.0164, v_num=ypmf]Epoch 190:   2% 5/270 [00:05<-1:59:54, -44.04it/s, loss=0.0164, v_num=ypmf]Epoch 190:   2% 5/270 [00:05<-1:59:54, -44.04it/s, loss=0.0164, v_num=ypmf]Epoch 190:   2% 5/270 [00:07<-1:59:52, -31.03it/s, loss=0.0165, v_num=ypmf]Epoch 190:   2% 6/270 [00:07<-1:59:52, -29.59it/s, loss=0.0165, v_num=ypmf]Epoch 190:   2% 6/270 [00:07<-1:59:52, -29.59it/s, loss=0.0165, v_num=ypmf]Epoch 190:   2% 6/270 [00:08<-1:59:51, -28.52it/s, loss=0.0165, v_num=ypmf]Epoch 190:   3% 7/270 [00:08<-1:59:51, -27.02it/s, loss=0.0165, v_num=ypmf]Epoch 190:   3% 7/270 [00:08<-1:59:51, -27.02it/s, loss=0.0165, v_num=ypmf]Epoch 190:   3% 7/270 [00:08<-1:59:51, -26.34it/s, loss=0.0164, v_num=ypmf]Epoch 190:   3% 8/270 [00:09<-1:59:50, -24.90it/s, loss=0.0164, v_num=ypmf]Epoch 190:   3% 8/270 [00:09<-1:59:50, -24.90it/s, loss=0.0164, v_num=ypmf]Epoch 190:   3% 8/270 [00:09<-1:59:50, -24.50it/s, loss=0.0165, v_num=ypmf]Epoch 190:   3% 9/270 [00:09<-1:59:49, -23.36it/s, loss=0.0165, v_num=ypmf]Epoch 190:   3% 9/270 [00:09<-1:59:49, -23.36it/s, loss=0.0165, v_num=ypmf]Epoch 190:   3% 9/270 [00:10<-1:59:49, -22.89it/s, loss=0.0165, v_num=ypmf]Epoch 190:   4% 10/270 [00:10<-1:59:49, -21.97it/s, loss=0.0165, v_num=ypmf]Epoch 190:   4% 10/270 [00:10<-1:59:49, -21.97it/s, loss=0.0165, v_num=ypmf]Epoch 190:   4% 10/270 [00:10<-1:59:49, -21.71it/s, loss=0.0165, v_num=ypmf]Epoch 190:   4% 11/270 [00:10<-1:59:48, -20.92it/s, loss=0.0165, v_num=ypmf]Epoch 190:   4% 11/270 [00:10<-1:59:48, -20.92it/s, loss=0.0165, v_num=ypmf]Epoch 190:   4% 11/270 [00:11<-1:59:48, -20.29it/s, loss=0.0165, v_num=ypmf]Epoch 190:   4% 12/270 [00:11<-1:59:47, -19.58it/s, loss=0.0165, v_num=ypmf]Epoch 190:   4% 12/270 [00:11<-1:59:47, -19.58it/s, loss=0.0165, v_num=ypmf]Epoch 190:   4% 12/270 [00:11<-1:59:47, -19.23it/s, loss=0.0166, v_num=ypmf]Epoch 190:   5% 13/270 [00:12<-1:59:47, -18.71it/s, loss=0.0166, v_num=ypmf]Epoch 190:   5% 13/270 [00:12<-1:59:47, -18.71it/s, loss=0.0166, v_num=ypmf]Epoch 190:   5% 13/270 [00:12<-1:59:46, -18.25it/s, loss=0.0167, v_num=ypmf]Epoch 190:   5% 14/270 [00:12<-1:59:46, -17.62it/s, loss=0.0167, v_num=ypmf]Epoch 190:   5% 14/270 [00:12<-1:59:46, -17.62it/s, loss=0.0167, v_num=ypmf]Epoch 190:   5% 14/270 [00:13<-1:59:46, -17.44it/s, loss=0.0168, v_num=ypmf]Epoch 190:   6% 15/270 [00:13<-1:59:45, -16.87it/s, loss=0.0168, v_num=ypmf]Epoch 190:   6% 15/270 [00:13<-1:59:45, -16.87it/s, loss=0.0168, v_num=ypmf]Epoch 190:   6% 15/270 [00:13<-1:59:45, -16.55it/s, loss=0.0169, v_num=ypmf]Epoch 190:   6% 16/270 [00:14<-1:59:44, -15.62it/s, loss=0.0169, v_num=ypmf]Epoch 190:   6% 16/270 [00:14<-1:59:44, -15.62it/s, loss=0.0169, v_num=ypmf]Epoch 190:   6% 16/270 [00:14<-1:59:44, -15.60it/s, loss=0.0169, v_num=ypmf]Epoch 190:   6% 17/270 [00:14<-1:59:44, -15.20it/s, loss=0.0169, v_num=ypmf]Epoch 190:   6% 17/270 [00:14<-1:59:44, -15.20it/s, loss=0.0169, v_num=ypmf]Epoch 190:   6% 17/270 [00:15<-1:59:44, -14.91it/s, loss=0.017, v_num=ypmf] Epoch 190:   7% 18/270 [00:15<-1:59:43, -14.56it/s, loss=0.017, v_num=ypmf]Epoch 190:   7% 18/270 [00:15<-1:59:43, -14.56it/s, loss=0.017, v_num=ypmf]Epoch 190:   7% 18/270 [00:15<-1:59:43, -14.23it/s, loss=0.017, v_num=ypmf]Epoch 190:   7% 19/270 [00:15<-1:59:42, -13.89it/s, loss=0.017, v_num=ypmf]Epoch 190:   7% 19/270 [00:15<-1:59:42, -13.89it/s, loss=0.017, v_num=ypmf]Epoch 190:   7% 19/270 [00:16<-1:59:42, -13.71it/s, loss=0.017, v_num=ypmf]Epoch 190:   7% 20/270 [00:16<-1:59:42, -13.36it/s, loss=0.017, v_num=ypmf]Epoch 190:   7% 20/270 [00:16<-1:59:42, -13.36it/s, loss=0.017, v_num=ypmf]Epoch 190:   7% 20/270 [00:16<-1:59:42, -13.18it/s, loss=0.0172, v_num=ypmf]Epoch 190:   8% 21/270 [00:17<-1:59:41, -12.86it/s, loss=0.0172, v_num=ypmf]Epoch 190:   8% 21/270 [00:17<-1:59:41, -12.86it/s, loss=0.0172, v_num=ypmf]Epoch 190:   8% 21/270 [00:17<-1:59:41, -12.68it/s, loss=0.0172, v_num=ypmf]Epoch 190:   8% 22/270 [00:17<-1:59:40, -12.30it/s, loss=0.0172, v_num=ypmf]Epoch 190:   8% 22/270 [00:17<-1:59:40, -12.30it/s, loss=0.0172, v_num=ypmf]Epoch 190:   8% 22/270 [00:17<-1:59:40, -12.20it/s, loss=0.0172, v_num=ypmf]Epoch 190:   9% 23/270 [00:18<-1:59:40, -11.86it/s, loss=0.0172, v_num=ypmf]Epoch 190:   9% 23/270 [00:18<-1:59:40, -11.86it/s, loss=0.0172, v_num=ypmf]Epoch 190:   9% 23/270 [00:18<-1:59:40, -11.77it/s, loss=0.0172, v_num=ypmf]Epoch 190:   9% 24/270 [00:19<-1:59:39, -11.41it/s, loss=0.0172, v_num=ypmf]Epoch 190:   9% 24/270 [00:19<-1:59:39, -11.41it/s, loss=0.0172, v_num=ypmf]Epoch 190:   9% 24/270 [00:19<-1:59:39, -11.32it/s, loss=0.0171, v_num=ypmf]Epoch 190:   9% 25/270 [00:19<-1:59:38, -11.06it/s, loss=0.0171, v_num=ypmf]Epoch 190:   9% 25/270 [00:19<-1:59:38, -11.06it/s, loss=0.0171, v_num=ypmf]Epoch 190:   9% 25/270 [00:19<-1:59:38, -10.98it/s, loss=0.0171, v_num=ypmf]Epoch 190:  10% 26/270 [00:20<-1:59:38, -10.72it/s, loss=0.0171, v_num=ypmf]Epoch 190:  10% 26/270 [00:20<-1:59:38, -10.72it/s, loss=0.0171, v_num=ypmf]Epoch 190:  10% 26/270 [00:20<-1:59:38, -10.65it/s, loss=0.0171, v_num=ypmf]Epoch 190:  10% 27/270 [00:20<-1:59:37, -10.40it/s, loss=0.0171, v_num=ypmf]Epoch 190:  10% 27/270 [00:20<-1:59:37, -10.40it/s, loss=0.0171, v_num=ypmf]Epoch 190:  10% 27/270 [00:20<-1:59:37, -10.32it/s, loss=0.0171, v_num=ypmf]Epoch 190:  10% 28/270 [00:21<-1:59:36, -10.06it/s, loss=0.0171, v_num=ypmf]Epoch 190:  10% 28/270 [00:21<-1:59:36, -10.06it/s, loss=0.0171, v_num=ypmf]Epoch 190:  10% 28/270 [00:21<-1:59:36, -10.00it/s, loss=0.0171, v_num=ypmf]Epoch 190:  11% 29/270 [00:21<-1:59:36, -9.74it/s, loss=0.0171, v_num=ypmf] Epoch 190:  11% 29/270 [00:21<-1:59:36, -9.74it/s, loss=0.0171, v_num=ypmf]Epoch 190:  11% 29/270 [00:21<-1:59:36, -9.68it/s, loss=0.0172, v_num=ypmf]Epoch 190:  11% 30/270 [00:22<-1:59:35, -9.47it/s, loss=0.0172, v_num=ypmf]Epoch 190:  11% 30/270 [00:22<-1:59:35, -9.47it/s, loss=0.0172, v_num=ypmf]Epoch 190:  11% 30/270 [00:22<-1:59:35, -9.36it/s, loss=0.0171, v_num=ypmf]Epoch 190:  11% 31/270 [00:22<-1:59:34, -9.13it/s, loss=0.0171, v_num=ypmf]Epoch 190:  11% 31/270 [00:22<-1:59:34, -9.13it/s, loss=0.0171, v_num=ypmf]Epoch 190:  11% 31/270 [00:23<-1:59:34, -9.08it/s, loss=0.0169, v_num=ypmf]Epoch 190:  12% 32/270 [00:23<-1:59:34, -8.90it/s, loss=0.0169, v_num=ypmf]Epoch 190:  12% 32/270 [00:23<-1:59:34, -8.90it/s, loss=0.0169, v_num=ypmf]Epoch 190:  12% 32/270 [00:23<-1:59:33, -8.80it/s, loss=0.0169, v_num=ypmf]Epoch 190:  12% 33/270 [00:24<-1:59:33, -8.56it/s, loss=0.0169, v_num=ypmf]Epoch 190:  12% 33/270 [00:24<-1:59:33, -8.56it/s, loss=0.0169, v_num=ypmf]Epoch 190:  12% 33/270 [00:24<-1:59:33, -8.50it/s, loss=0.0167, v_num=ypmf]Epoch 190:  13% 34/270 [00:24<-1:59:32, -8.36it/s, loss=0.0167, v_num=ypmf]Epoch 190:  13% 34/270 [00:24<-1:59:32, -8.36it/s, loss=0.0167, v_num=ypmf]Epoch 190:  13% 34/270 [00:25<-1:59:32, -8.26it/s, loss=0.0168, v_num=ypmf]Epoch 190:  13% 35/270 [00:25<-1:59:31, -8.10it/s, loss=0.0168, v_num=ypmf]Epoch 190:  13% 35/270 [00:25<-1:59:31, -8.10it/s, loss=0.0168, v_num=ypmf]Epoch 190:  13% 35/270 [00:25<-1:59:31, -8.06it/s, loss=0.0167, v_num=ypmf]Epoch 190:  13% 36/270 [00:26<-1:59:31, -7.86it/s, loss=0.0167, v_num=ypmf]Epoch 190:  13% 36/270 [00:26<-1:59:31, -7.86it/s, loss=0.0167, v_num=ypmf]Epoch 190:  13% 36/270 [00:26<-1:59:31, -7.81it/s, loss=0.0167, v_num=ypmf]Epoch 190:  14% 37/270 [00:26<-1:59:30, -7.68it/s, loss=0.0167, v_num=ypmf]Epoch 190:  14% 37/270 [00:26<-1:59:30, -7.68it/s, loss=0.0167, v_num=ypmf]Epoch 190:  14% 37/270 [00:26<-1:59:30, -7.60it/s, loss=0.0167, v_num=ypmf]Epoch 190:  14% 38/270 [00:27<-1:59:29, -7.30it/s, loss=0.0167, v_num=ypmf]Epoch 190:  14% 38/270 [00:27<-1:59:29, -7.30it/s, loss=0.0167, v_num=ypmf]Epoch 190:  14% 38/270 [00:27<-1:59:29, -7.26it/s, loss=0.0166, v_num=ypmf]Epoch 190:  14% 39/270 [00:28<-1:59:28, -7.11it/s, loss=0.0166, v_num=ypmf]Epoch 190:  14% 39/270 [00:28<-1:59:28, -7.11it/s, loss=0.0166, v_num=ypmf]Epoch 190:  14% 39/270 [00:28<-1:59:28, -7.07it/s, loss=0.0165, v_num=ypmf]Epoch 190:  15% 40/270 [00:29<-1:59:27, -6.93it/s, loss=0.0165, v_num=ypmf]Epoch 190:  15% 40/270 [00:29<-1:59:27, -6.93it/s, loss=0.0165, v_num=ypmf]Epoch 190:  15% 40/270 [00:29<-1:59:27, -6.89it/s, loss=0.0163, v_num=ypmf]Epoch 190:  15% 41/270 [00:29<-1:59:27, -6.74it/s, loss=0.0163, v_num=ypmf]Epoch 190:  15% 41/270 [00:29<-1:59:27, -6.74it/s, loss=0.0163, v_num=ypmf]Epoch 190:  15% 41/270 [00:29<-1:59:27, -6.74it/s, loss=0.0164, v_num=ypmf]Epoch 190:  16% 42/270 [00:29<-1:59:26, -6.64it/s, loss=0.0164, v_num=ypmf]Epoch 190:  16% 42/270 [00:29<-1:59:26, -6.64it/s, loss=0.0164, v_num=ypmf]Epoch 190:  16% 42/270 [00:30<-1:59:26, -6.56it/s, loss=0.0165, v_num=ypmf]Epoch 190:  16% 43/270 [00:30<-1:59:25, -6.44it/s, loss=0.0165, v_num=ypmf]Epoch 190:  16% 43/270 [00:30<-1:59:25, -6.44it/s, loss=0.0165, v_num=ypmf]Epoch 190:  16% 43/270 [00:30<-1:59:25, -6.42it/s, loss=0.0165, v_num=ypmf]Epoch 190:  16% 44/270 [00:31<-1:59:25, -6.31it/s, loss=0.0165, v_num=ypmf]Epoch 190:  16% 44/270 [00:31<-1:59:25, -6.31it/s, loss=0.0165, v_num=ypmf]Epoch 190:  16% 44/270 [00:31<-1:59:24, -6.26it/s, loss=0.0166, v_num=ypmf]Epoch 190:  17% 45/270 [00:31<-1:59:24, -6.14it/s, loss=0.0166, v_num=ypmf]Epoch 190:  17% 45/270 [00:31<-1:59:24, -6.14it/s, loss=0.0166, v_num=ypmf]Epoch 190:  17% 45/270 [00:32<-1:59:24, -6.11it/s, loss=0.0165, v_num=ypmf]Epoch 190:  17% 46/270 [00:32<-1:59:23, -6.01it/s, loss=0.0165, v_num=ypmf]Epoch 190:  17% 46/270 [00:32<-1:59:23, -6.01it/s, loss=0.0165, v_num=ypmf]Epoch 190:  17% 46/270 [00:33<-1:59:22, -5.87it/s, loss=0.0164, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 282700. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 316501. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 306493. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301439. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 282886. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 287824. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 252399. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 317772. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 399709. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 276661. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 258543. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293611. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 298847. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 310317. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 325139. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 333642. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 304174. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 299088. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 344951. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 277101. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 305043. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 329749. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 305676. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 303988. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 309792. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 190:  17% 47/270 [00:33<-1:59:22, -5.77it/s, loss=0.0164, v_num=ypmf]Epoch 190:  17% 47/270 [00:33<-1:59:22, -5.77it/s, loss=0.0164, v_num=ypmf]Epoch 190:  17% 47/270 [00:33<-1:59:21, -5.71it/s, loss=0.0165, v_num=ypmf]Epoch 190:  18% 48/270 [00:34<-1:59:21, -5.61it/s, loss=0.0165, v_num=ypmf]Epoch 190:  18% 48/270 [00:34<-1:59:21, -5.61it/s, loss=0.0165, v_num=ypmf]Epoch 190:  18% 48/270 [00:34<-1:59:21, -5.59it/s, loss=0.0164, v_num=ypmf]Epoch 190:  18% 49/270 [00:34<-1:59:20, -5.50it/s, loss=0.0164, v_num=ypmf]Epoch 190:  18% 49/270 [00:34<-1:59:20, -5.50it/s, loss=0.0164, v_num=ypmf]Epoch 190:  18% 49/270 [00:35<-1:59:20, -5.47it/s, loss=0.0165, v_num=ypmf]Epoch 190:  19% 50/270 [00:35<-1:59:20, -5.39it/s, loss=0.0165, v_num=ypmf]Epoch 190:  19% 50/270 [00:35<-1:59:20, -5.39it/s, loss=0.0165, v_num=ypmf]Epoch 190:  19% 50/270 [00:35<-1:59:19, -5.35it/s, loss=0.0166, v_num=ypmf]Epoch 190:  19% 51/270 [00:36<-1:59:19, -5.26it/s, loss=0.0166, v_num=ypmf]Epoch 190:  19% 51/270 [00:36<-1:59:19, -5.26it/s, loss=0.0166, v_num=ypmf]Epoch 190:  19% 51/270 [00:36<-1:59:19, -5.24it/s, loss=0.0167, v_num=ypmf]Epoch 190:  19% 52/270 [00:36<-1:59:18, -5.15it/s, loss=0.0167, v_num=ypmf]Epoch 190:  19% 52/270 [00:36<-1:59:18, -5.15it/s, loss=0.0167, v_num=ypmf]Epoch 190:  19% 52/270 [00:36<-1:59:18, -5.12it/s, loss=0.0167, v_num=ypmf]Epoch 190:  20% 53/270 [00:37<-1:59:17, -5.03it/s, loss=0.0167, v_num=ypmf]Epoch 190:  20% 53/270 [00:37<-1:59:17, -5.03it/s, loss=0.0167, v_num=ypmf]Epoch 190:  20% 53/270 [00:37<-1:59:17, -4.99it/s, loss=0.0168, v_num=ypmf]Epoch 190:  20% 54/270 [00:37<-1:59:17, -4.93it/s, loss=0.0168, v_num=ypmf]Epoch 190:  20% 54/270 [00:37<-1:59:17, -4.93it/s, loss=0.0168, v_num=ypmf]Epoch 190:  20% 54/270 [00:38<-1:59:16, -4.91it/s, loss=0.0167, v_num=ypmf]Epoch 190:  20% 55/270 [00:38<-1:59:16, -4.83it/s, loss=0.0167, v_num=ypmf]Epoch 190:  20% 55/270 [00:38<-1:59:16, -4.83it/s, loss=0.0167, v_num=ypmf]Epoch 190:  20% 55/270 [00:38<-1:59:16, -4.81it/s, loss=0.0168, v_num=ypmf]Epoch 190:  21% 56/270 [00:39<-1:59:15, -4.74it/s, loss=0.0168, v_num=ypmf]Epoch 190:  21% 56/270 [00:39<-1:59:15, -4.74it/s, loss=0.0168, v_num=ypmf]Epoch 190:  21% 56/270 [00:39<-1:59:15, -4.72it/s, loss=0.017, v_num=ypmf] Epoch 190:  21% 57/270 [00:39<-1:59:15, -4.66it/s, loss=0.017, v_num=ypmf]Epoch 190:  21% 57/270 [00:39<-1:59:15, -4.66it/s, loss=0.017, v_num=ypmf]Epoch 190:  21% 57/270 [00:39<-1:59:14, -4.62it/s, loss=0.017, v_num=ypmf]Epoch 190:  21% 58/270 [00:40<-1:59:14, -4.56it/s, loss=0.017, v_num=ypmf]Epoch 190:  21% 58/270 [00:40<-1:59:14, -4.56it/s, loss=0.017, v_num=ypmf]Epoch 190:  21% 58/270 [00:40<-1:59:14, -4.52it/s, loss=0.017, v_num=ypmf]Epoch 190:  22% 59/270 [00:40<-1:59:13, -4.45it/s, loss=0.017, v_num=ypmf]Epoch 190:  22% 59/270 [00:40<-1:59:13, -4.45it/s, loss=0.017, v_num=ypmf]Epoch 190:  22% 59/270 [00:42<-1:59:12, -4.33it/s, loss=0.017, v_num=ypmf]Epoch 190:  22% 60/270 [00:42<-1:59:11, -4.27it/s, loss=0.017, v_num=ypmf]Epoch 190:  22% 60/270 [00:42<-1:59:11, -4.27it/s, loss=0.017, v_num=ypmf]Epoch 190:  22% 60/270 [00:42<-1:59:11, -4.25it/s, loss=0.0171, v_num=ypmf]Epoch 190:  23% 61/270 [00:42<-1:59:11, -4.19it/s, loss=0.0171, v_num=ypmf]Epoch 190:  23% 61/270 [00:42<-1:59:11, -4.19it/s, loss=0.0171, v_num=ypmf]Epoch 190:  23% 61/270 [00:43<-1:59:10, -4.17it/s, loss=0.0172, v_num=ypmf]Epoch 190:  23% 62/270 [00:43<-1:59:10, -4.12it/s, loss=0.0172, v_num=ypmf]Epoch 190:  23% 62/270 [00:43<-1:59:10, -4.12it/s, loss=0.0172, v_num=ypmf]Epoch 190:  23% 62/270 [00:43<-1:59:10, -4.11it/s, loss=0.0171, v_num=ypmf]Epoch 190:  23% 63/270 [00:43<-1:59:09, -4.05it/s, loss=0.0171, v_num=ypmf]Epoch 190:  23% 63/270 [00:43<-1:59:09, -4.05it/s, loss=0.0171, v_num=ypmf]Epoch 190:  23% 63/270 [00:44<-1:59:09, -4.02it/s, loss=0.0171, v_num=ypmf]Epoch 190:  24% 64/270 [00:44<-1:59:08, -3.96it/s, loss=0.0171, v_num=ypmf]Epoch 190:  24% 64/270 [00:44<-1:59:08, -3.96it/s, loss=0.0171, v_num=ypmf]Epoch 190:  24% 64/270 [00:44<-1:59:08, -3.94it/s, loss=0.0171, v_num=ypmf]Epoch 190:  24% 65/270 [00:45<-1:59:08, -3.89it/s, loss=0.0171, v_num=ypmf]Epoch 190:  24% 65/270 [00:45<-1:59:08, -3.89it/s, loss=0.0171, v_num=ypmf]Epoch 190:  24% 65/270 [00:45<-1:59:08, -3.88it/s, loss=0.0172, v_num=ypmf]Epoch 190:  24% 66/270 [00:45<-1:59:07, -3.81it/s, loss=0.0172, v_num=ypmf]Epoch 190:  24% 66/270 [00:45<-1:59:07, -3.81it/s, loss=0.0172, v_num=ypmf]Epoch 190:  24% 66/270 [00:46<-1:59:07, -3.80it/s, loss=0.0173, v_num=ypmf]Epoch 190:  25% 67/270 [00:46<-1:59:06, -3.75it/s, loss=0.0173, v_num=ypmf]Epoch 190:  25% 67/270 [00:46<-1:59:06, -3.75it/s, loss=0.0173, v_num=ypmf]Epoch 190:  25% 67/270 [00:46<-1:59:06, -3.74it/s, loss=0.0172, v_num=ypmf]Epoch 190:  25% 68/270 [00:46<-1:59:06, -3.69it/s, loss=0.0172, v_num=ypmf]Epoch 190:  25% 68/270 [00:46<-1:59:06, -3.69it/s, loss=0.0172, v_num=ypmf]Epoch 190:  25% 68/270 [00:47<-1:59:06, -3.68it/s, loss=0.0173, v_num=ypmf]Epoch 190:  26% 69/270 [00:47<-1:59:05, -3.63it/s, loss=0.0173, v_num=ypmf]Epoch 190:  26% 69/270 [00:47<-1:59:05, -3.63it/s, loss=0.0173, v_num=ypmf]Epoch 190:  26% 69/270 [00:47<-1:59:05, -3.61it/s, loss=0.0171, v_num=ypmf]Epoch 190:  26% 70/270 [00:48<-1:59:04, -3.56it/s, loss=0.0171, v_num=ypmf]Epoch 190:  26% 70/270 [00:48<-1:59:04, -3.56it/s, loss=0.0171, v_num=ypmf]Epoch 190:  26% 70/270 [00:48<-1:59:04, -3.55it/s, loss=0.017, v_num=ypmf] Epoch 190:  26% 71/270 [00:48<-1:59:04, -3.50it/s, loss=0.017, v_num=ypmf]Epoch 190:  26% 71/270 [00:48<-1:59:04, -3.50it/s, loss=0.017, v_num=ypmf]Epoch 190:  26% 71/270 [00:48<-1:59:03, -3.48it/s, loss=0.017, v_num=ypmf]Epoch 190:  27% 72/270 [00:49<-1:59:02, -3.39it/s, loss=0.017, v_num=ypmf]Epoch 190:  27% 72/270 [00:49<-1:59:02, -3.39it/s, loss=0.017, v_num=ypmf]Epoch 190:  27% 72/270 [00:50<-1:59:02, -3.38it/s, loss=0.0171, v_num=ypmf]Epoch 190:  27% 73/270 [00:50<-1:59:01, -3.34it/s, loss=0.0171, v_num=ypmf]Epoch 190:  27% 73/270 [00:50<-1:59:01, -3.34it/s, loss=0.0171, v_num=ypmf]Epoch 190:  27% 73/270 [00:50<-1:59:01, -3.32it/s, loss=0.017, v_num=ypmf] Epoch 190:  27% 74/270 [00:51<-1:59:00, -3.22it/s, loss=0.017, v_num=ypmf]Epoch 190:  27% 74/270 [00:51<-1:59:00, -3.22it/s, loss=0.017, v_num=ypmf]Epoch 190:  27% 74/270 [00:51<-1:59:00, -3.21it/s, loss=0.0169, v_num=ypmf]Epoch 190:  28% 75/270 [00:52<-1:58:59, -3.17it/s, loss=0.0169, v_num=ypmf]Epoch 190:  28% 75/270 [00:52<-1:58:59, -3.17it/s, loss=0.0169, v_num=ypmf]Epoch 190:  28% 75/270 [00:52<-1:58:59, -3.16it/s, loss=0.0169, v_num=ypmf]Epoch 190:  28% 76/270 [00:52<-1:58:58, -3.12it/s, loss=0.0169, v_num=ypmf]Epoch 190:  28% 76/270 [00:52<-1:58:58, -3.12it/s, loss=0.0169, v_num=ypmf]Epoch 190:  28% 76/270 [00:53<-1:58:58, -3.11it/s, loss=0.0169, v_num=ypmf]Epoch 190:  29% 77/270 [00:53<-1:58:58, -3.06it/s, loss=0.0169, v_num=ypmf]Epoch 190:  29% 77/270 [00:53<-1:58:58, -3.06it/s, loss=0.0169, v_num=ypmf]Epoch 190:  29% 77/270 [00:53<-1:58:57, -3.06it/s, loss=0.0168, v_num=ypmf]Epoch 190:  29% 78/270 [00:53<-1:58:57, -3.02it/s, loss=0.0168, v_num=ypmf]Epoch 190:  29% 78/270 [00:53<-1:58:57, -3.02it/s, loss=0.0168, v_num=ypmf]Epoch 190:  29% 78/270 [00:54<-1:58:57, -3.00it/s, loss=0.0169, v_num=ypmf]Epoch 190:  29% 79/270 [00:54<-1:58:56, -2.97it/s, loss=0.0169, v_num=ypmf]Epoch 190:  29% 79/270 [00:54<-1:58:56, -2.97it/s, loss=0.0169, v_num=ypmf]Epoch 190:  29% 79/270 [00:54<-1:58:56, -2.96it/s, loss=0.0169, v_num=ypmf]Epoch 190:  30% 80/270 [00:55<-1:58:55, -2.92it/s, loss=0.0169, v_num=ypmf]Epoch 190:  30% 80/270 [00:55<-1:58:55, -2.92it/s, loss=0.0169, v_num=ypmf]Epoch 190:  30% 80/270 [00:55<-1:58:55, -2.91it/s, loss=0.0167, v_num=ypmf]Epoch 190:  30% 81/270 [00:55<-1:58:55, -2.87it/s, loss=0.0167, v_num=ypmf]Epoch 190:  30% 81/270 [00:55<-1:58:55, -2.87it/s, loss=0.0167, v_num=ypmf]Epoch 190:  30% 81/270 [00:55<-1:58:54, -2.86it/s, loss=0.0167, v_num=ypmf]Epoch 190:  30% 82/270 [00:56<-1:58:54, -2.82it/s, loss=0.0167, v_num=ypmf]Epoch 190:  30% 82/270 [00:56<-1:58:54, -2.82it/s, loss=0.0167, v_num=ypmf]Epoch 190:  30% 82/270 [00:56<-1:58:54, -2.81it/s, loss=0.0168, v_num=ypmf]Epoch 190:  31% 83/270 [00:56<-1:58:53, -2.77it/s, loss=0.0168, v_num=ypmf]Epoch 190:  31% 83/270 [00:56<-1:58:53, -2.77it/s, loss=0.0168, v_num=ypmf]Epoch 190:  31% 83/270 [00:57<-1:58:53, -2.77it/s, loss=0.0168, v_num=ypmf]Epoch 190:  31% 84/270 [00:57<-1:58:52, -2.73it/s, loss=0.0168, v_num=ypmf]Epoch 190:  31% 84/270 [00:57<-1:58:52, -2.73it/s, loss=0.0168, v_num=ypmf]Epoch 190:  31% 84/270 [00:57<-1:58:52, -2.72it/s, loss=0.0167, v_num=ypmf]Epoch 190:  31% 85/270 [00:58<-1:58:52, -2.69it/s, loss=0.0167, v_num=ypmf]Epoch 190:  31% 85/270 [00:58<-1:58:52, -2.69it/s, loss=0.0167, v_num=ypmf]Epoch 190:  31% 85/270 [00:58<-1:58:51, -2.68it/s, loss=0.0166, v_num=ypmf]Epoch 190:  32% 86/270 [00:58<-1:58:51, -2.65it/s, loss=0.0166, v_num=ypmf]Epoch 190:  32% 86/270 [00:58<-1:58:51, -2.65it/s, loss=0.0166, v_num=ypmf]Epoch 190:  32% 86/270 [00:58<-1:58:51, -2.64it/s, loss=0.0166, v_num=ypmf]Epoch 190:  32% 87/270 [00:59<-1:58:50, -2.60it/s, loss=0.0166, v_num=ypmf]Epoch 190:  32% 87/270 [00:59<-1:58:50, -2.60it/s, loss=0.0166, v_num=ypmf]Epoch 190:  32% 87/270 [00:59<-1:58:50, -2.60it/s, loss=0.0166, v_num=ypmf]Epoch 190:  33% 88/270 [00:59<-1:58:50, -2.57it/s, loss=0.0166, v_num=ypmf]Epoch 190:  33% 88/270 [00:59<-1:58:50, -2.57it/s, loss=0.0166, v_num=ypmf]Epoch 190:  33% 88/270 [00:59<-1:58:49, -2.55it/s, loss=0.0166, v_num=ypmf]Epoch 190:  33% 89/270 [01:00<-1:58:49, -2.52it/s, loss=0.0166, v_num=ypmf]Epoch 190:  33% 89/270 [01:00<-1:58:49, -2.52it/s, loss=0.0166, v_num=ypmf]Epoch 190:  33% 89/270 [01:00<-1:58:48, -2.51it/s, loss=0.0169, v_num=ypmf]Epoch 190:  33% 90/270 [01:00<-1:58:48, -2.48it/s, loss=0.0169, v_num=ypmf]Epoch 190:  33% 90/270 [01:00<-1:58:48, -2.48it/s, loss=0.0169, v_num=ypmf]Epoch 190:  33% 90/270 [01:01<-1:58:48, -2.47it/s, loss=0.0169, v_num=ypmf]Epoch 190:  34% 91/270 [01:01<-1:58:47, -2.44it/s, loss=0.0169, v_num=ypmf]Epoch 190:  34% 91/270 [01:01<-1:58:47, -2.44it/s, loss=0.0169, v_num=ypmf]Epoch 190:  34% 91/270 [01:01<-1:58:47, -2.44it/s, loss=0.017, v_num=ypmf] Epoch 190:  34% 92/270 [01:01<-1:58:47, -2.41it/s, loss=0.017, v_num=ypmf]Epoch 190:  34% 92/270 [01:01<-1:58:47, -2.41it/s, loss=0.017, v_num=ypmf]Epoch 190:  34% 92/270 [01:02<-1:58:46, -2.39it/s, loss=0.0169, v_num=ypmf]Epoch 190:  34% 93/270 [01:02<-1:58:45, -2.36it/s, loss=0.0169, v_num=ypmf]Epoch 190:  34% 93/270 [01:02<-1:58:45, -2.36it/s, loss=0.0169, v_num=ypmf]Epoch 190:  34% 93/270 [01:02<-1:58:45, -2.35it/s, loss=0.017, v_num=ypmf] Epoch 190:  35% 94/270 [01:03<-1:58:45, -2.32it/s, loss=0.017, v_num=ypmf]Epoch 190:  35% 94/270 [01:03<-1:58:45, -2.32it/s, loss=0.017, v_num=ypmf]Epoch 190:  35% 94/270 [01:03<-1:58:44, -2.31it/s, loss=0.0171, v_num=ypmf]Epoch 190:  35% 95/270 [01:03<-1:58:44, -2.28it/s, loss=0.0171, v_num=ypmf]Epoch 190:  35% 95/270 [01:03<-1:58:44, -2.28it/s, loss=0.0171, v_num=ypmf]Epoch 190:  35% 95/270 [01:04<-1:58:44, -2.28it/s, loss=0.017, v_num=ypmf] Epoch 190:  36% 96/270 [01:04<-1:58:43, -2.24it/s, loss=0.017, v_num=ypmf]Epoch 190:  36% 96/270 [01:04<-1:58:43, -2.24it/s, loss=0.017, v_num=ypmf]Epoch 190:  36% 96/270 [01:04<-1:58:43, -2.24it/s, loss=0.017, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319978. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 278905. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 271985. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 330757. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 345951. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 318082. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301801. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319155. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 323168. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 278670. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 297329. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 259108. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 312648. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 382538. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 292124. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 298228. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 335067. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 314616. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 323791. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 292182. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 297697. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 286408. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308004. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 367558. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 372084. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 190:  36% 97/270 [01:05<-1:58:42, -2.21it/s, loss=0.017, v_num=ypmf]Epoch 190:  36% 97/270 [01:05<-1:58:42, -2.21it/s, loss=0.017, v_num=ypmf]Epoch 190:  36% 97/270 [01:05<-1:58:42, -2.20it/s, loss=0.017, v_num=ypmf]Epoch 190:  36% 98/270 [01:05<-1:58:41, -2.17it/s, loss=0.017, v_num=ypmf]Epoch 190:  36% 98/270 [01:05<-1:58:41, -2.17it/s, loss=0.017, v_num=ypmf]Epoch 190:  36% 98/270 [01:05<-1:58:41, -2.17it/s, loss=0.0169, v_num=ypmf]Epoch 190:  37% 99/270 [01:06<-1:58:41, -2.14it/s, loss=0.0169, v_num=ypmf]Epoch 190:  37% 99/270 [01:06<-1:58:41, -2.14it/s, loss=0.0169, v_num=ypmf]Epoch 190:  37% 99/270 [01:06<-1:58:40, -2.13it/s, loss=0.0169, v_num=ypmf]Epoch 190:  37% 100/270 [01:06<-1:58:40, -2.11it/s, loss=0.0169, v_num=ypmf]Epoch 190:  37% 100/270 [01:06<-1:58:40, -2.11it/s, loss=0.0169, v_num=ypmf]Epoch 190:  37% 100/270 [01:07<-1:58:40, -2.10it/s, loss=0.017, v_num=ypmf] Epoch 190:  37% 101/270 [01:07<-1:58:39, -2.07it/s, loss=0.017, v_num=ypmf]Epoch 190:  37% 101/270 [01:07<-1:58:39, -2.07it/s, loss=0.017, v_num=ypmf]Epoch 190:  37% 101/270 [01:07<-1:58:39, -2.07it/s, loss=0.017, v_num=ypmf]Epoch 190:  38% 102/270 [01:08<-1:58:38, -2.04it/s, loss=0.017, v_num=ypmf]Epoch 190:  38% 102/270 [01:08<-1:58:38, -2.04it/s, loss=0.017, v_num=ypmf]Epoch 190:  38% 102/270 [01:08<-1:58:38, -2.04it/s, loss=0.0169, v_num=ypmf]Epoch 190:  38% 103/270 [01:08<-1:58:37, -2.01it/s, loss=0.0169, v_num=ypmf]Epoch 190:  38% 103/270 [01:08<-1:58:37, -2.01it/s, loss=0.0169, v_num=ypmf]Epoch 190:  38% 103/270 [01:08<-1:58:37, -2.01it/s, loss=0.0169, v_num=ypmf]Epoch 190:  39% 104/270 [01:09<-1:58:37, -1.98it/s, loss=0.0169, v_num=ypmf]Epoch 190:  39% 104/270 [01:09<-1:58:37, -1.98it/s, loss=0.0169, v_num=ypmf]Epoch 190:  39% 104/270 [01:09<-1:58:36, -1.97it/s, loss=0.017, v_num=ypmf] Epoch 190:  39% 105/270 [01:09<-1:58:36, -1.95it/s, loss=0.017, v_num=ypmf]Epoch 190:  39% 105/270 [01:09<-1:58:36, -1.95it/s, loss=0.017, v_num=ypmf]Epoch 190:  39% 105/270 [01:10<-1:58:36, -1.94it/s, loss=0.017, v_num=ypmf]Epoch 190:  39% 106/270 [01:10<-1:58:35, -1.92it/s, loss=0.017, v_num=ypmf]Epoch 190:  39% 106/270 [01:10<-1:58:35, -1.92it/s, loss=0.017, v_num=ypmf]Epoch 190:  39% 106/270 [01:10<-1:58:35, -1.91it/s, loss=0.017, v_num=ypmf]Epoch 190:  40% 107/270 [01:10<-1:58:34, -1.89it/s, loss=0.017, v_num=ypmf]Epoch 190:  40% 107/270 [01:10<-1:58:34, -1.89it/s, loss=0.017, v_num=ypmf]Epoch 190:  40% 107/270 [01:11<-1:58:34, -1.88it/s, loss=0.017, v_num=ypmf]Epoch 190:  40% 108/270 [01:11<-1:58:33, -1.85it/s, loss=0.017, v_num=ypmf]Epoch 190:  40% 108/270 [01:11<-1:58:33, -1.85it/s, loss=0.017, v_num=ypmf]Epoch 190:  40% 108/270 [01:11<-1:58:33, -1.85it/s, loss=0.0171, v_num=ypmf]Epoch 190:  40% 109/270 [01:12<-1:58:32, -1.82it/s, loss=0.0171, v_num=ypmf]Epoch 190:  40% 109/270 [01:12<-1:58:32, -1.82it/s, loss=0.0171, v_num=ypmf]Epoch 190:  40% 109/270 [01:12<-1:58:32, -1.82it/s, loss=0.0169, v_num=ypmf]Epoch 190:  41% 110/270 [01:12<-1:58:31, -1.80it/s, loss=0.0169, v_num=ypmf]Epoch 190:  41% 110/270 [01:12<-1:58:31, -1.80it/s, loss=0.0169, v_num=ypmf]Epoch 190:  41% 110/270 [01:13<-1:58:31, -1.79it/s, loss=0.0169, v_num=ypmf]Epoch 190:  41% 111/270 [01:13<-1:58:30, -1.77it/s, loss=0.0169, v_num=ypmf]Epoch 190:  41% 111/270 [01:13<-1:58:30, -1.77it/s, loss=0.0169, v_num=ypmf]Epoch 190:  41% 111/270 [01:13<-1:58:30, -1.76it/s, loss=0.0168, v_num=ypmf]Epoch 190:  41% 112/270 [01:14<-1:58:30, -1.74it/s, loss=0.0168, v_num=ypmf]Epoch 190:  41% 112/270 [01:14<-1:58:30, -1.74it/s, loss=0.0168, v_num=ypmf]Epoch 190:  41% 112/270 [01:14<-1:58:29, -1.73it/s, loss=0.0169, v_num=ypmf]Epoch 190:  42% 113/270 [01:14<-1:58:29, -1.71it/s, loss=0.0169, v_num=ypmf]Epoch 190:  42% 113/270 [01:14<-1:58:29, -1.71it/s, loss=0.0169, v_num=ypmf]Epoch 190:  42% 113/270 [01:15<-1:58:28, -1.69it/s, loss=0.0168, v_num=ypmf]Epoch 190:  42% 114/270 [01:15<-1:58:27, -1.67it/s, loss=0.0168, v_num=ypmf]Epoch 190:  42% 114/270 [01:15<-1:58:27, -1.67it/s, loss=0.0168, v_num=ypmf]Epoch 190:  42% 114/270 [01:16<-1:58:27, -1.67it/s, loss=0.0169, v_num=ypmf]Epoch 190:  43% 115/270 [01:16<-1:58:26, -1.65it/s, loss=0.0169, v_num=ypmf]Epoch 190:  43% 115/270 [01:16<-1:58:26, -1.65it/s, loss=0.0169, v_num=ypmf]Epoch 190:  43% 115/270 [01:16<-1:58:26, -1.64it/s, loss=0.0168, v_num=ypmf]Epoch 190:  43% 116/270 [01:17<-1:58:25, -1.62it/s, loss=0.0168, v_num=ypmf]Epoch 190:  43% 116/270 [01:17<-1:58:25, -1.62it/s, loss=0.0168, v_num=ypmf]Epoch 190:  43% 116/270 [01:17<-1:58:25, -1.62it/s, loss=0.0168, v_num=ypmf]Epoch 190:  43% 117/270 [01:17<-1:58:24, -1.59it/s, loss=0.0168, v_num=ypmf]Epoch 190:  43% 117/270 [01:17<-1:58:24, -1.59it/s, loss=0.0168, v_num=ypmf]Epoch 190:  43% 117/270 [01:17<-1:58:24, -1.59it/s, loss=0.0168, v_num=ypmf]Epoch 190:  44% 118/270 [01:18<-1:58:24, -1.57it/s, loss=0.0168, v_num=ypmf]Epoch 190:  44% 118/270 [01:18<-1:58:24, -1.57it/s, loss=0.0168, v_num=ypmf]Epoch 190:  44% 118/270 [01:18<-1:58:23, -1.56it/s, loss=0.0168, v_num=ypmf]Epoch 190:  44% 119/270 [01:19<-1:58:23, -1.54it/s, loss=0.0168, v_num=ypmf]Epoch 190:  44% 119/270 [01:19<-1:58:23, -1.54it/s, loss=0.0168, v_num=ypmf]Epoch 190:  44% 119/270 [01:19<-1:58:22, -1.54it/s, loss=0.0167, v_num=ypmf]Epoch 190:  44% 120/270 [01:19<-1:58:22, -1.52it/s, loss=0.0167, v_num=ypmf]Epoch 190:  44% 120/270 [01:19<-1:58:22, -1.52it/s, loss=0.0167, v_num=ypmf]Epoch 190:  44% 120/270 [01:19<-1:58:22, -1.52it/s, loss=0.0167, v_num=ypmf]Epoch 190:  45% 121/270 [01:20<-1:58:21, -1.50it/s, loss=0.0167, v_num=ypmf]Epoch 190:  45% 121/270 [01:20<-1:58:21, -1.50it/s, loss=0.0167, v_num=ypmf]Epoch 190:  45% 121/270 [01:20<-1:58:21, -1.50it/s, loss=0.0168, v_num=ypmf]Epoch 190:  45% 122/270 [01:20<-1:58:20, -1.48it/s, loss=0.0168, v_num=ypmf]Epoch 190:  45% 122/270 [01:20<-1:58:20, -1.48it/s, loss=0.0168, v_num=ypmf]Epoch 190:  45% 122/270 [01:20<-1:58:20, -1.47it/s, loss=0.0168, v_num=ypmf]Epoch 190:  46% 123/270 [01:21<-1:58:19, -1.45it/s, loss=0.0168, v_num=ypmf]Epoch 190:  46% 123/270 [01:21<-1:58:19, -1.45it/s, loss=0.0168, v_num=ypmf]Epoch 190:  46% 123/270 [01:21<-1:58:19, -1.45it/s, loss=0.0168, v_num=ypmf]Epoch 190:  46% 124/270 [01:21<-1:58:19, -1.43it/s, loss=0.0168, v_num=ypmf]Epoch 190:  46% 124/270 [01:21<-1:58:19, -1.43it/s, loss=0.0168, v_num=ypmf]Epoch 190:  46% 124/270 [01:21<-1:58:18, -1.43it/s, loss=0.0168, v_num=ypmf]Epoch 190:  46% 125/270 [01:22<-1:58:18, -1.41it/s, loss=0.0168, v_num=ypmf]Epoch 190:  46% 125/270 [01:22<-1:58:18, -1.41it/s, loss=0.0168, v_num=ypmf]Epoch 190:  46% 125/270 [01:22<-1:58:18, -1.41it/s, loss=0.0167, v_num=ypmf]Epoch 190:  47% 126/270 [01:22<-1:58:17, -1.39it/s, loss=0.0167, v_num=ypmf]Epoch 190:  47% 126/270 [01:22<-1:58:17, -1.39it/s, loss=0.0167, v_num=ypmf]Epoch 190:  47% 126/270 [01:22<-1:58:17, -1.39it/s, loss=0.0169, v_num=ypmf]Epoch 190:  47% 127/270 [01:23<-1:58:16, -1.37it/s, loss=0.0169, v_num=ypmf]Epoch 190:  47% 127/270 [01:23<-1:58:16, -1.37it/s, loss=0.0169, v_num=ypmf]Epoch 190:  47% 127/270 [01:23<-1:58:16, -1.37it/s, loss=0.017, v_num=ypmf] Epoch 190:  47% 128/270 [01:23<-1:58:15, -1.35it/s, loss=0.017, v_num=ypmf]Epoch 190:  47% 128/270 [01:23<-1:58:15, -1.35it/s, loss=0.017, v_num=ypmf]Epoch 190:  47% 128/270 [01:23<-1:58:15, -1.35it/s, loss=0.0169, v_num=ypmf]Epoch 190:  48% 129/270 [01:24<-1:58:14, -1.33it/s, loss=0.0169, v_num=ypmf]Epoch 190:  48% 129/270 [01:24<-1:58:14, -1.33it/s, loss=0.0169, v_num=ypmf]Epoch 190:  48% 129/270 [01:24<-1:58:14, -1.32it/s, loss=0.0169, v_num=ypmf]Epoch 190:  48% 130/270 [01:24<-1:58:13, -1.31it/s, loss=0.0169, v_num=ypmf]Epoch 190:  48% 130/270 [01:24<-1:58:13, -1.31it/s, loss=0.0169, v_num=ypmf]Epoch 190:  48% 130/270 [01:25<-1:58:13, -1.30it/s, loss=0.0169, v_num=ypmf]Epoch 190:  49% 131/270 [01:25<-1:58:12, -1.28it/s, loss=0.0169, v_num=ypmf]Epoch 190:  49% 131/270 [01:25<-1:58:12, -1.28it/s, loss=0.0169, v_num=ypmf]Epoch 190:  49% 131/270 [01:25<-1:58:12, -1.28it/s, loss=0.0169, v_num=ypmf]Epoch 190:  49% 132/270 [01:26<-1:58:11, -1.27it/s, loss=0.0169, v_num=ypmf]Epoch 190:  49% 132/270 [01:26<-1:58:11, -1.27it/s, loss=0.0169, v_num=ypmf]Epoch 190:  49% 132/270 [01:26<-1:58:11, -1.26it/s, loss=0.0168, v_num=ypmf]Epoch 190:  49% 133/270 [01:26<-1:58:11, -1.25it/s, loss=0.0168, v_num=ypmf]Epoch 190:  49% 133/270 [01:26<-1:58:11, -1.25it/s, loss=0.0168, v_num=ypmf]Epoch 190:  49% 133/270 [01:27<-1:58:10, -1.24it/s, loss=0.0169, v_num=ypmf]Epoch 190:  50% 134/270 [01:27<-1:58:09, -1.22it/s, loss=0.0169, v_num=ypmf]Epoch 190:  50% 134/270 [01:27<-1:58:09, -1.22it/s, loss=0.0169, v_num=ypmf]Epoch 190:  50% 134/270 [01:27<-1:58:09, -1.22it/s, loss=0.0169, v_num=ypmf]Epoch 190:  50% 135/270 [01:27<-1:58:09, -1.21it/s, loss=0.0169, v_num=ypmf]Epoch 190:  50% 135/270 [01:27<-1:58:09, -1.21it/s, loss=0.0169, v_num=ypmf]Epoch 190:  50% 135/270 [01:28<-1:58:08, -1.20it/s, loss=0.017, v_num=ypmf] Epoch 190:  50% 136/270 [01:28<-1:58:08, -1.19it/s, loss=0.017, v_num=ypmf]Epoch 190:  50% 136/270 [01:28<-1:58:08, -1.19it/s, loss=0.017, v_num=ypmf]Epoch 190:  50% 136/270 [01:28<-1:58:07, -1.19it/s, loss=0.017, v_num=ypmf]Epoch 190:  51% 137/270 [01:28<-1:58:07, -1.17it/s, loss=0.017, v_num=ypmf]Epoch 190:  51% 137/270 [01:28<-1:58:07, -1.17it/s, loss=0.017, v_num=ypmf]Epoch 190:  51% 137/270 [01:29<-1:58:07, -1.17it/s, loss=0.0169, v_num=ypmf]Epoch 190:  51% 138/270 [01:29<-1:58:06, -1.15it/s, loss=0.0169, v_num=ypmf]Epoch 190:  51% 138/270 [01:29<-1:58:06, -1.15it/s, loss=0.0169, v_num=ypmf]Epoch 190:  51% 138/270 [01:29<-1:58:06, -1.15it/s, loss=0.017, v_num=ypmf] /global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 306492. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 321308. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 334297. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 337474. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 291778. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 318120. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 299750. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 322831. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 346719. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 304189. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 318422. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 281103. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 368049. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 344709. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 342345. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 286633. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 330246. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 264739. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301454. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 260552. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 317407. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 283251. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 307290. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 330393. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 273046. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 190:  51% 139/270 [01:29<-1:58:05, -1.13it/s, loss=0.017, v_num=ypmf]Epoch 190:  51% 139/270 [01:29<-1:58:05, -1.13it/s, loss=0.017, v_num=ypmf]Epoch 190:  51% 139/270 [01:30<-1:58:05, -1.13it/s, loss=0.017, v_num=ypmf]Epoch 190:  52% 140/270 [01:30<-1:58:04, -1.12it/s, loss=0.017, v_num=ypmf]Epoch 190:  52% 140/270 [01:30<-1:58:04, -1.12it/s, loss=0.017, v_num=ypmf]Epoch 190:  52% 140/270 [01:30<-1:58:04, -1.11it/s, loss=0.0169, v_num=ypmf]Epoch 190:  52% 141/270 [01:31<-1:58:03, -1.09it/s, loss=0.0169, v_num=ypmf]Epoch 190:  52% 141/270 [01:31<-1:58:03, -1.09it/s, loss=0.0169, v_num=ypmf]Epoch 190:  52% 141/270 [01:31<-1:58:03, -1.09it/s, loss=0.0169, v_num=ypmf]Epoch 190:  53% 142/270 [01:31<-1:58:02, -1.08it/s, loss=0.0169, v_num=ypmf]Epoch 190:  53% 142/270 [01:31<-1:58:02, -1.08it/s, loss=0.0169, v_num=ypmf]Epoch 190:  53% 142/270 [01:31<-1:58:02, -1.08it/s, loss=0.0169, v_num=ypmf]Epoch 190:  53% 143/270 [01:32<-1:58:01, -1.06it/s, loss=0.0169, v_num=ypmf]Epoch 190:  53% 143/270 [01:32<-1:58:01, -1.06it/s, loss=0.0169, v_num=ypmf]Epoch 190:  53% 143/270 [01:32<-1:58:01, -1.06it/s, loss=0.0169, v_num=ypmf]Epoch 190:  53% 144/270 [01:32<-1:58:00, -1.04it/s, loss=0.0169, v_num=ypmf]Epoch 190:  53% 144/270 [01:32<-1:58:00, -1.04it/s, loss=0.0169, v_num=ypmf]Epoch 190:  53% 144/270 [01:32<-1:58:00, -1.04it/s, loss=0.0169, v_num=ypmf]Epoch 190:  54% 145/270 [01:33<-1:57:59, -1.03it/s, loss=0.0169, v_num=ypmf]Epoch 190:  54% 145/270 [01:33<-1:57:59, -1.03it/s, loss=0.0169, v_num=ypmf]Epoch 190:  54% 145/270 [01:33<-1:57:59, -1.03it/s, loss=0.0168, v_num=ypmf]Epoch 190:  54% 146/270 [01:33<-1:57:58, -1.01it/s, loss=0.0168, v_num=ypmf]Epoch 190:  54% 146/270 [01:33<-1:57:58, -1.01it/s, loss=0.0168, v_num=ypmf]Epoch 190:  54% 146/270 [01:34<-1:57:58, -1.01it/s, loss=0.0167, v_num=ypmf]Epoch 190:  54% 147/270 [01:34<-1:57:57, -1.00it/s, loss=0.0167, v_num=ypmf]Epoch 190:  54% 147/270 [01:34<-1:57:57, -1.00it/s, loss=0.0167, v_num=ypmf]Epoch 190:  54% 147/270 [01:34<-1:57:57, -0.99it/s, loss=0.0168, v_num=ypmf]Epoch 190:  55% 148/270 [01:35<-1:57:56, -0.98it/s, loss=0.0168, v_num=ypmf]Epoch 190:  55% 148/270 [01:35<-1:57:56, -0.98it/s, loss=0.0168, v_num=ypmf]Epoch 190:  55% 148/270 [01:35<-1:57:55, -0.98it/s, loss=0.0167, v_num=ypmf]Epoch 190:  55% 149/270 [01:35<-1:57:55, -0.96it/s, loss=0.0167, v_num=ypmf]Epoch 190:  55% 149/270 [01:35<-1:57:55, -0.96it/s, loss=0.0167, v_num=ypmf]Epoch 190:  55% 149/270 [01:35<-1:57:54, -0.96it/s, loss=0.0167, v_num=ypmf]Epoch 190:  56% 150/270 [01:36<-1:57:53, -0.94it/s, loss=0.0167, v_num=ypmf]Epoch 190:  56% 150/270 [01:36<-1:57:53, -0.94it/s, loss=0.0167, v_num=ypmf]Epoch 190:  56% 150/270 [01:36<-1:57:53, -0.94it/s, loss=0.0167, v_num=ypmf]Epoch 190:  56% 151/270 [01:36<-1:57:52, -0.93it/s, loss=0.0167, v_num=ypmf]Epoch 190:  56% 151/270 [01:36<-1:57:52, -0.93it/s, loss=0.0167, v_num=ypmf]Epoch 190:  56% 151/270 [01:37<-1:57:52, -0.93it/s, loss=0.0167, v_num=ypmf]Epoch 190:  56% 152/270 [01:37<-1:57:51, -0.91it/s, loss=0.0167, v_num=ypmf]Epoch 190:  56% 152/270 [01:37<-1:57:51, -0.91it/s, loss=0.0167, v_num=ypmf]Epoch 190:  56% 152/270 [01:37<-1:57:51, -0.91it/s, loss=0.0169, v_num=ypmf]Epoch 190:  57% 153/270 [01:38<-1:57:50, -0.90it/s, loss=0.0169, v_num=ypmf]Epoch 190:  57% 153/270 [01:38<-1:57:50, -0.90it/s, loss=0.0169, v_num=ypmf]Epoch 190:  57% 153/270 [01:38<-1:57:50, -0.89it/s, loss=0.0167, v_num=ypmf]Epoch 190:  57% 154/270 [01:38<-1:57:49, -0.88it/s, loss=0.0167, v_num=ypmf]Epoch 190:  57% 154/270 [01:38<-1:57:49, -0.88it/s, loss=0.0167, v_num=ypmf]Epoch 190:  57% 154/270 [01:38<-1:57:49, -0.88it/s, loss=0.0167, v_num=ypmf]Epoch 190:  57% 155/270 [01:39<-1:57:48, -0.87it/s, loss=0.0167, v_num=ypmf]Epoch 190:  57% 155/270 [01:39<-1:57:48, -0.87it/s, loss=0.0167, v_num=ypmf]Epoch 190:  57% 155/270 [01:39<-1:57:47, -0.86it/s, loss=0.0166, v_num=ypmf]Epoch 190:  58% 156/270 [01:39<-1:57:46, -0.85it/s, loss=0.0166, v_num=ypmf]Epoch 190:  58% 156/270 [01:39<-1:57:46, -0.85it/s, loss=0.0166, v_num=ypmf]Epoch 190:  58% 156/270 [01:40<-1:57:46, -0.85it/s, loss=0.0168, v_num=ypmf]Epoch 190:  58% 157/270 [01:40<-1:57:45, -0.83it/s, loss=0.0168, v_num=ypmf]Epoch 190:  58% 157/270 [01:40<-1:57:45, -0.83it/s, loss=0.0168, v_num=ypmf]Epoch 190:  58% 157/270 [01:40<-1:57:45, -0.83it/s, loss=0.0168, v_num=ypmf]Epoch 190:  59% 158/270 [01:41<-1:57:44, -0.82it/s, loss=0.0168, v_num=ypmf]Epoch 190:  59% 158/270 [01:41<-1:57:44, -0.82it/s, loss=0.0168, v_num=ypmf]Epoch 190:  59% 158/270 [01:41<-1:57:44, -0.82it/s, loss=0.0168, v_num=ypmf]Epoch 190:  59% 159/270 [01:41<-1:57:43, -0.81it/s, loss=0.0168, v_num=ypmf]Epoch 190:  59% 159/270 [01:41<-1:57:43, -0.81it/s, loss=0.0168, v_num=ypmf]Epoch 190:  59% 159/270 [01:42<-1:57:42, -0.80it/s, loss=0.0167, v_num=ypmf]Epoch 190:  59% 160/270 [01:42<-1:57:42, -0.79it/s, loss=0.0167, v_num=ypmf]Epoch 190:  59% 160/270 [01:42<-1:57:42, -0.79it/s, loss=0.0167, v_num=ypmf]Epoch 190:  59% 160/270 [01:42<-1:57:41, -0.79it/s, loss=0.0168, v_num=ypmf]Epoch 190:  60% 161/270 [01:43<-1:57:40, -0.78it/s, loss=0.0168, v_num=ypmf]Epoch 190:  60% 161/270 [01:43<-1:57:40, -0.78it/s, loss=0.0168, v_num=ypmf]Epoch 190:  60% 161/270 [01:43<-1:57:40, -0.77it/s, loss=0.0168, v_num=ypmf]Epoch 190:  60% 162/270 [01:43<-1:57:39, -0.76it/s, loss=0.0168, v_num=ypmf]Epoch 190:  60% 162/270 [01:43<-1:57:39, -0.76it/s, loss=0.0168, v_num=ypmf]Epoch 190:  60% 162/270 [01:43<-1:57:38, -0.76it/s, loss=0.0168, v_num=ypmf]Epoch 190:  60% 163/270 [01:44<-1:57:37, -0.75it/s, loss=0.0168, v_num=ypmf]Epoch 190:  60% 163/270 [01:44<-1:57:37, -0.75it/s, loss=0.0168, v_num=ypmf]Epoch 190:  60% 163/270 [01:44<-1:57:37, -0.74it/s, loss=0.0168, v_num=ypmf]Epoch 190:  61% 164/270 [01:45<-1:57:36, -0.73it/s, loss=0.0168, v_num=ypmf]Epoch 190:  61% 164/270 [01:45<-1:57:36, -0.73it/s, loss=0.0168, v_num=ypmf]Epoch 190:  61% 164/270 [01:45<-1:57:36, -0.73it/s, loss=0.0167, v_num=ypmf]Epoch 190:  61% 165/270 [01:45<-1:57:35, -0.72it/s, loss=0.0167, v_num=ypmf]Epoch 190:  61% 165/270 [01:45<-1:57:35, -0.72it/s, loss=0.0167, v_num=ypmf]Epoch 190:  61% 165/270 [01:45<-1:57:34, -0.72it/s, loss=0.017, v_num=ypmf] Epoch 190:  61% 166/270 [01:46<-1:57:33, -0.71it/s, loss=0.017, v_num=ypmf]Epoch 190:  61% 166/270 [01:46<-1:57:33, -0.71it/s, loss=0.017, v_num=ypmf]Epoch 190:  61% 166/270 [01:46<-1:57:33, -0.70it/s, loss=0.0169, v_num=ypmf]Epoch 190:  62% 167/270 [01:46<-1:57:32, -0.69it/s, loss=0.0169, v_num=ypmf]Epoch 190:  62% 167/270 [01:46<-1:57:32, -0.69it/s, loss=0.0169, v_num=ypmf]Epoch 190:  62% 167/270 [01:47<-1:57:32, -0.69it/s, loss=0.0168, v_num=ypmf]Epoch 190:  62% 168/270 [01:47<-1:57:30, -0.68it/s, loss=0.0168, v_num=ypmf]Epoch 190:  62% 168/270 [01:47<-1:57:30, -0.68it/s, loss=0.0168, v_num=ypmf]Epoch 190:  62% 168/270 [01:47<-1:57:30, -0.68it/s, loss=0.0167, v_num=ypmf]Epoch 190:  63% 169/270 [01:47<-1:57:29, -0.67it/s, loss=0.0167, v_num=ypmf]Epoch 190:  63% 169/270 [01:47<-1:57:29, -0.67it/s, loss=0.0167, v_num=ypmf]Epoch 190:  63% 169/270 [01:48<-1:57:29, -0.67it/s, loss=0.0167, v_num=ypmf]Epoch 190:  63% 170/270 [01:48<-1:57:28, -0.65it/s, loss=0.0167, v_num=ypmf]Epoch 190:  63% 170/270 [01:48<-1:57:28, -0.65it/s, loss=0.0167, v_num=ypmf]Epoch 190:  63% 170/270 [01:48<-1:57:27, -0.65it/s, loss=0.0169, v_num=ypmf]Epoch 190:  63% 171/270 [01:49<-1:57:26, -0.64it/s, loss=0.0169, v_num=ypmf]Epoch 190:  63% 171/270 [01:49<-1:57:26, -0.64it/s, loss=0.0169, v_num=ypmf]Epoch 190:  63% 171/270 [01:49<-1:57:26, -0.64it/s, loss=0.017, v_num=ypmf] Epoch 190:  64% 172/270 [01:49<-1:57:25, -0.63it/s, loss=0.017, v_num=ypmf]Epoch 190:  64% 172/270 [01:49<-1:57:25, -0.63it/s, loss=0.017, v_num=ypmf]Epoch 190:  64% 172/270 [01:49<-1:57:24, -0.63it/s, loss=0.0168, v_num=ypmf]Epoch 190:  64% 173/270 [01:50<-1:57:23, -0.62it/s, loss=0.0168, v_num=ypmf]Epoch 190:  64% 173/270 [01:50<-1:57:23, -0.62it/s, loss=0.0168, v_num=ypmf]Epoch 190:  64% 173/270 [01:50<-1:57:23, -0.61it/s, loss=0.0169, v_num=ypmf]Epoch 190:  64% 174/270 [01:51<-1:57:21, -0.60it/s, loss=0.0169, v_num=ypmf]Epoch 190:  64% 174/270 [01:51<-1:57:21, -0.60it/s, loss=0.0169, v_num=ypmf]Epoch 190:  64% 174/270 [01:51<-1:57:21, -0.60it/s, loss=0.0169, v_num=ypmf]Epoch 190:  65% 175/270 [01:51<-1:57:20, -0.59it/s, loss=0.0169, v_num=ypmf]Epoch 190:  65% 175/270 [01:51<-1:57:20, -0.59it/s, loss=0.0169, v_num=ypmf]Epoch 190:  65% 175/270 [01:51<-1:57:19, -0.59it/s, loss=0.017, v_num=ypmf] Epoch 190:  65% 176/270 [01:52<-1:57:18, -0.58it/s, loss=0.017, v_num=ypmf]Epoch 190:  65% 176/270 [01:52<-1:57:18, -0.58it/s, loss=0.017, v_num=ypmf]Epoch 190:  65% 176/270 [01:52<-1:57:18, -0.58it/s, loss=0.0169, v_num=ypmf]Epoch 190:  66% 177/270 [01:52<-1:57:16, -0.57it/s, loss=0.0169, v_num=ypmf]Epoch 190:  66% 177/270 [01:52<-1:57:16, -0.57it/s, loss=0.0169, v_num=ypmf]Epoch 190:  66% 177/270 [01:53<-1:57:16, -0.57it/s, loss=0.0169, v_num=ypmf]Epoch 190:  66% 178/270 [01:54<-1:57:14, -0.55it/s, loss=0.0169, v_num=ypmf]Epoch 190:  66% 178/270 [01:54<-1:57:14, -0.55it/s, loss=0.0169, v_num=ypmf]Epoch 190:  66% 178/270 [01:54<-1:57:14, -0.55it/s, loss=0.017, v_num=ypmf] Epoch 190:  66% 179/270 [01:54<-1:57:12, -0.54it/s, loss=0.017, v_num=ypmf]Epoch 190:  66% 179/270 [01:54<-1:57:12, -0.54it/s, loss=0.017, v_num=ypmf]Epoch 190:  66% 179/270 [01:54<-1:57:12, -0.54it/s, loss=0.0171, v_num=ypmf]Epoch 190:  67% 180/270 [01:55<-1:57:11, -0.53it/s, loss=0.0171, v_num=ypmf]Epoch 190:  67% 180/270 [01:55<-1:57:11, -0.53it/s, loss=0.0171, v_num=ypmf]Epoch 190:  67% 180/270 [01:55<-1:57:10, -0.53it/s, loss=0.0171, v_num=ypmf]Epoch 190:  67% 181/270 [01:55<-1:57:09, -0.52it/s, loss=0.0171, v_num=ypmf]Epoch 190:  67% 181/270 [01:55<-1:57:09, -0.52it/s, loss=0.0171, v_num=ypmf]Epoch 190:  67% 181/270 [01:56<-1:57:08, -0.52it/s, loss=0.0171, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319476. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 325506. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 335327. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 278960. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 353490. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319533. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 299880. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 376791. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 304852. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 315084. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 340352. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 352045. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 306015. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 294471. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 343487. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 323960. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 294457. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 320118. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 295168. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 353222. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 270939. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 302786. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 310797. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 281838. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 292409. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 190:  67% 182/270 [01:56<-1:57:07, -0.51it/s, loss=0.0171, v_num=ypmf]Epoch 190:  67% 182/270 [01:56<-1:57:07, -0.51it/s, loss=0.0171, v_num=ypmf]Epoch 190:  67% 182/270 [01:56<-1:57:07, -0.51it/s, loss=0.0171, v_num=ypmf]Epoch 190:  68% 183/270 [01:57<-1:57:05, -0.50it/s, loss=0.0171, v_num=ypmf]Epoch 190:  68% 183/270 [01:57<-1:57:05, -0.50it/s, loss=0.0171, v_num=ypmf]Epoch 190:  68% 183/270 [01:57<-1:57:05, -0.49it/s, loss=0.0171, v_num=ypmf]Epoch 190:  68% 184/270 [01:57<-1:57:03, -0.48it/s, loss=0.0171, v_num=ypmf]Epoch 190:  68% 184/270 [01:57<-1:57:03, -0.48it/s, loss=0.0171, v_num=ypmf]Epoch 190:  68% 184/270 [01:57<-1:57:03, -0.48it/s, loss=0.0172, v_num=ypmf]Epoch 190:  69% 185/270 [01:58<-1:57:01, -0.47it/s, loss=0.0172, v_num=ypmf]Epoch 190:  69% 185/270 [01:58<-1:57:01, -0.47it/s, loss=0.0172, v_num=ypmf]Epoch 190:  69% 185/270 [01:58<-1:57:01, -0.47it/s, loss=0.017, v_num=ypmf] Epoch 190:  69% 186/270 [01:58<-1:56:59, -0.46it/s, loss=0.017, v_num=ypmf]Epoch 190:  69% 186/270 [01:58<-1:56:59, -0.46it/s, loss=0.017, v_num=ypmf]Epoch 190:  69% 186/270 [01:59<-1:56:58, -0.46it/s, loss=0.017, v_num=ypmf]Epoch 190:  69% 187/270 [01:59<-1:56:56, -0.45it/s, loss=0.017, v_num=ypmf]Epoch 190:  69% 187/270 [01:59<-1:56:56, -0.45it/s, loss=0.017, v_num=ypmf]Epoch 190:  69% 187/270 [01:59<-1:56:56, -0.45it/s, loss=0.0171, v_num=ypmf]Epoch 190:  70% 188/270 [02:00<-1:56:54, -0.44it/s, loss=0.0171, v_num=ypmf]Epoch 190:  70% 188/270 [02:00<-1:56:54, -0.44it/s, loss=0.0171, v_num=ypmf]Epoch 190:  70% 188/270 [02:00<-1:56:54, -0.44it/s, loss=0.0171, v_num=ypmf]Epoch 190:  70% 189/270 [02:01<-1:56:52, -0.43it/s, loss=0.0171, v_num=ypmf]Epoch 190:  70% 189/270 [02:01<-1:56:52, -0.43it/s, loss=0.0171, v_num=ypmf]Epoch 190:  70% 189/270 [02:01<-1:56:52, -0.43it/s, loss=0.0171, v_num=ypmf]Epoch 190:  70% 190/270 [02:01<-1:56:50, -0.42it/s, loss=0.0171, v_num=ypmf]Epoch 190:  70% 190/270 [02:01<-1:56:50, -0.42it/s, loss=0.0171, v_num=ypmf]Epoch 190:  70% 190/270 [02:01<-1:56:49, -0.42it/s, loss=0.0169, v_num=ypmf]Epoch 190:  71% 191/270 [02:02<-1:56:47, -0.41it/s, loss=0.0169, v_num=ypmf]Epoch 190:  71% 191/270 [02:02<-1:56:47, -0.41it/s, loss=0.0169, v_num=ypmf]Epoch 190:  71% 191/270 [02:02<-1:56:47, -0.41it/s, loss=0.0169, v_num=ypmf]Epoch 190:  71% 192/270 [02:02<-1:56:45, -0.40it/s, loss=0.0169, v_num=ypmf]Epoch 190:  71% 192/270 [02:02<-1:56:45, -0.40it/s, loss=0.0169, v_num=ypmf]Epoch 190:  71% 192/270 [02:02<-1:56:45, -0.40it/s, loss=0.0172, v_num=ypmf]Epoch 190:  71% 193/270 [02:03<-1:56:43, -0.39it/s, loss=0.0172, v_num=ypmf]Epoch 190:  71% 193/270 [02:03<-1:56:43, -0.39it/s, loss=0.0172, v_num=ypmf]Epoch 190:  71% 193/270 [02:03<-1:56:42, -0.39it/s, loss=0.0172, v_num=ypmf]Epoch 190:  72% 194/270 [02:03<-1:56:40, -0.38it/s, loss=0.0172, v_num=ypmf]Epoch 190:  72% 194/270 [02:03<-1:56:40, -0.38it/s, loss=0.0172, v_num=ypmf]Epoch 190:  72% 194/270 [02:04<-1:56:40, -0.38it/s, loss=0.0172, v_num=ypmf]Epoch 190:  72% 195/270 [02:04<-1:56:37, -0.37it/s, loss=0.0172, v_num=ypmf]Epoch 190:  72% 195/270 [02:04<-1:56:37, -0.37it/s, loss=0.0172, v_num=ypmf]Epoch 190:  72% 195/270 [02:05<-1:56:36, -0.37it/s, loss=0.0171, v_num=ypmf]Epoch 190:  73% 196/270 [02:05<-1:56:34, -0.36it/s, loss=0.0171, v_num=ypmf]Epoch 190:  73% 196/270 [02:05<-1:56:34, -0.36it/s, loss=0.0171, v_num=ypmf]Epoch 190:  73% 196/270 [02:05<-1:56:33, -0.36it/s, loss=0.0172, v_num=ypmf]Epoch 190:  73% 197/270 [02:06<-1:56:31, -0.35it/s, loss=0.0172, v_num=ypmf]Epoch 190:  73% 197/270 [02:06<-1:56:31, -0.35it/s, loss=0.0172, v_num=ypmf]Epoch 190:  73% 197/270 [02:07<-1:56:29, -0.35it/s, loss=0.0172, v_num=ypmf]Epoch 190:  73% 198/270 [02:08<-1:56:26, -0.34it/s, loss=0.0172, v_num=ypmf]Epoch 190:  73% 198/270 [02:08<-1:56:26, -0.34it/s, loss=0.0172, v_num=ypmf]Epoch 190:  73% 198/270 [02:08<-1:56:26, -0.34it/s, loss=0.0172, v_num=ypmf]Epoch 190:  74% 199/270 [02:08<-1:56:23, -0.33it/s, loss=0.0172, v_num=ypmf]Epoch 190:  74% 199/270 [02:08<-1:56:23, -0.33it/s, loss=0.0172, v_num=ypmf]Epoch 190:  74% 199/270 [02:08<-1:56:23, -0.33it/s, loss=0.0171, v_num=ypmf]Epoch 190:  74% 200/270 [02:09<-1:56:19, -0.32it/s, loss=0.0171, v_num=ypmf]Epoch 190:  74% 200/270 [02:09<-1:56:19, -0.32it/s, loss=0.0171, v_num=ypmf]Epoch 190:  74% 200/270 [02:09<-1:56:19, -0.32it/s, loss=0.0173, v_num=ypmf]Epoch 190:  74% 201/270 [02:10<-1:56:16, -0.31it/s, loss=0.0173, v_num=ypmf]Epoch 190:  74% 201/270 [02:10<-1:56:16, -0.31it/s, loss=0.0173, v_num=ypmf]Epoch 190:  74% 201/270 [02:11<-1:56:14, -0.31it/s, loss=0.0173, v_num=ypmf]Epoch 190:  75% 202/270 [02:11<-1:56:10, -0.30it/s, loss=0.0173, v_num=ypmf]Epoch 190:  75% 202/270 [02:11<-1:56:10, -0.30it/s, loss=0.0173, v_num=ypmf]Epoch 190:  75% 202/270 [02:12<-1:56:10, -0.30it/s, loss=0.0173, v_num=ypmf]Epoch 190:  75% 203/270 [02:12<-1:56:07, -0.29it/s, loss=0.0173, v_num=ypmf]Epoch 190:  75% 203/270 [02:12<-1:56:07, -0.29it/s, loss=0.0173, v_num=ypmf]Epoch 190:  75% 203/270 [02:12<-1:56:06, -0.29it/s, loss=0.0173, v_num=ypmf]Epoch 190:  76% 204/270 [02:13<-1:56:03, -0.28it/s, loss=0.0173, v_num=ypmf]Epoch 190:  76% 204/270 [02:13<-1:56:03, -0.28it/s, loss=0.0173, v_num=ypmf]Epoch 190:  76% 204/270 [02:13<-1:56:03, -0.28it/s, loss=0.0174, v_num=ypmf]Epoch 190:  76% 205/270 [02:13<-1:55:59, -0.27it/s, loss=0.0174, v_num=ypmf]Epoch 190:  76% 205/270 [02:13<-1:55:59, -0.27it/s, loss=0.0174, v_num=ypmf]Epoch 190:  76% 205/270 [02:13<-1:55:59, -0.27it/s, loss=0.0174, v_num=ypmf]Epoch 190:  76% 206/270 [02:14<-1:55:55, -0.26it/s, loss=0.0174, v_num=ypmf]Epoch 190:  76% 206/270 [02:14<-1:55:55, -0.26it/s, loss=0.0174, v_num=ypmf]Epoch 190:  76% 206/270 [02:14<-1:55:55, -0.26it/s, loss=0.0174, v_num=ypmf]Epoch 190:  77% 207/270 [02:14<-1:55:51, -0.25it/s, loss=0.0174, v_num=ypmf]Epoch 190:  77% 207/270 [02:14<-1:55:51, -0.25it/s, loss=0.0174, v_num=ypmf]Epoch 190:  77% 207/270 [02:14<-1:55:51, -0.25it/s, loss=0.0174, v_num=ypmf]Epoch 190:  77% 208/270 [02:15<-1:55:46, -0.24it/s, loss=0.0174, v_num=ypmf]Epoch 190:  77% 208/270 [02:15<-1:55:46, -0.24it/s, loss=0.0174, v_num=ypmf]Epoch 190:  77% 208/270 [02:15<-1:55:46, -0.24it/s, loss=0.0174, v_num=ypmf]Epoch 190:  77% 209/270 [02:15<-1:55:42, -0.24it/s, loss=0.0174, v_num=ypmf]Epoch 190:  77% 209/270 [02:15<-1:55:42, -0.24it/s, loss=0.0174, v_num=ypmf]Epoch 190:  77% 209/270 [02:15<-1:55:41, -0.24it/s, loss=0.0173, v_num=ypmf]Epoch 190:  78% 210/270 [02:16<-1:55:37, -0.23it/s, loss=0.0173, v_num=ypmf]Epoch 190:  78% 210/270 [02:16<-1:55:37, -0.23it/s, loss=0.0173, v_num=ypmf]Epoch 190:  78% 210/270 [02:16<-1:55:36, -0.23it/s, loss=0.0173, v_num=ypmf]Epoch 190:  78% 211/270 [02:16<-1:55:31, -0.22it/s, loss=0.0173, v_num=ypmf]Epoch 190:  78% 211/270 [02:16<-1:55:31, -0.22it/s, loss=0.0173, v_num=ypmf]Epoch 190:  78% 211/270 [02:17<-1:55:31, -0.22it/s, loss=0.0172, v_num=ypmf]Epoch 190:  79% 212/270 [02:17<-1:55:25, -0.21it/s, loss=0.0172, v_num=ypmf]Epoch 190:  79% 212/270 [02:17<-1:55:25, -0.21it/s, loss=0.0172, v_num=ypmf]Epoch 190:  79% 212/270 [02:17<-1:55:25, -0.21it/s, loss=0.017, v_num=ypmf] Epoch 190:  79% 213/270 [02:18<-1:55:19, -0.20it/s, loss=0.017, v_num=ypmf]Epoch 190:  79% 213/270 [02:18<-1:55:19, -0.20it/s, loss=0.017, v_num=ypmf]Epoch 190:  79% 213/270 [02:18<-1:55:19, -0.20it/s, loss=0.017, v_num=ypmf]Epoch 190:  79% 214/270 [02:18<-1:55:13, -0.19it/s, loss=0.017, v_num=ypmf]Epoch 190:  79% 214/270 [02:18<-1:55:13, -0.19it/s, loss=0.017, v_num=ypmf]Epoch 190:  79% 214/270 [02:18<-1:55:12, -0.19it/s, loss=0.017, v_num=ypmf]Epoch 190:  80% 215/270 [02:19<-1:55:06, -0.19it/s, loss=0.017, v_num=ypmf]Epoch 190:  80% 215/270 [02:19<-1:55:06, -0.19it/s, loss=0.017, v_num=ypmf]Epoch 190:  80% 215/270 [02:19<-1:55:05, -0.19it/s, loss=0.017, v_num=ypmf]Epoch 190:  80% 216/270 [02:19<-1:54:58, -0.18it/s, loss=0.017, v_num=ypmf]Epoch 190:  80% 216/270 [02:19<-1:54:58, -0.18it/s, loss=0.017, v_num=ypmf]Epoch 190:  80% 216/270 [02:20<-1:54:58, -0.18it/s, loss=0.017, v_num=ypmf]Epoch 190:  80% 217/270 [02:20<-1:54:50, -0.17it/s, loss=0.017, v_num=ypmf]Epoch 190:  80% 217/270 [02:20<-1:54:50, -0.17it/s, loss=0.017, v_num=ypmf]Epoch 190:  80% 217/270 [02:20<-1:54:50, -0.17it/s, loss=0.017, v_num=ypmf]Epoch 190:  81% 218/270 [02:21<-1:54:41, -0.16it/s, loss=0.017, v_num=ypmf]Epoch 190:  81% 218/270 [02:21<-1:54:41, -0.16it/s, loss=0.017, v_num=ypmf]Epoch 190:  81% 218/270 [02:21<-1:54:41, -0.16it/s, loss=0.017, v_num=ypmf]Epoch 190:  81% 219/270 [02:21<-1:54:32, -0.16it/s, loss=0.017, v_num=ypmf]Epoch 190:  81% 219/270 [02:21<-1:54:32, -0.16it/s, loss=0.017, v_num=ypmf]Epoch 190:  81% 219/270 [02:21<-1:54:32, -0.16it/s, loss=0.0171, v_num=ypmf]Epoch 190:  81% 220/270 [02:22<-1:54:22, -0.15it/s, loss=0.0171, v_num=ypmf]Epoch 190:  81% 220/270 [02:22<-1:54:22, -0.15it/s, loss=0.0171, v_num=ypmf]Epoch 190:  81% 220/270 [02:22<-1:54:21, -0.15it/s, loss=0.0168, v_num=ypmf]Epoch 190:  82% 221/270 [02:22<-1:54:10, -0.14it/s, loss=0.0168, v_num=ypmf]Epoch 190:  82% 221/270 [02:22<-1:54:10, -0.14it/s, loss=0.0168, v_num=ypmf]Epoch 190:  82% 221/270 [02:23<-1:54:10, -0.14it/s, loss=0.0167, v_num=ypmf]Epoch 190:  82% 222/270 [02:23<-1:53:58, -0.13it/s, loss=0.0167, v_num=ypmf]Epoch 190:  82% 222/270 [02:23<-1:53:58, -0.13it/s, loss=0.0167, v_num=ypmf]Epoch 190:  82% 222/270 [02:23<-1:53:57, -0.13it/s, loss=0.0166, v_num=ypmf]Epoch 190:  83% 223/270 [02:24<-1:53:44, -0.12it/s, loss=0.0166, v_num=ypmf]Epoch 190:  83% 223/270 [02:24<-1:53:44, -0.12it/s, loss=0.0166, v_num=ypmf]Epoch 190:  83% 223/270 [02:24<-1:53:44, -0.12it/s, loss=0.0166, v_num=ypmf]Epoch 190:  83% 224/270 [02:24<-1:53:29, -0.12it/s, loss=0.0166, v_num=ypmf]Epoch 190:  83% 224/270 [02:24<-1:53:29, -0.12it/s, loss=0.0166, v_num=ypmf]Epoch 190:  83% 224/270 [02:25<-1:53:28, -0.12it/s, loss=0.0166, v_num=ypmf]Epoch 190:  83% 225/270 [02:25<-1:53:12, -0.11it/s, loss=0.0166, v_num=ypmf]Epoch 190:  83% 225/270 [02:25<-1:53:12, -0.11it/s, loss=0.0166, v_num=ypmf]Epoch 190:  83% 225/270 [02:25<-1:53:11, -0.11it/s, loss=0.0166, v_num=ypmf]Epoch 190:  84% 226/270 [02:25<-1:52:52, -0.10it/s, loss=0.0166, v_num=ypmf]Epoch 190:  84% 226/270 [02:25<-1:52:52, -0.10it/s, loss=0.0166, v_num=ypmf]Epoch 190:  84% 226/270 [02:26<-1:52:52, -0.10it/s, loss=0.0167, v_num=ypmf]Epoch 190:  84% 227/270 [02:26<-1:52:30, -0.10it/s, loss=0.0167, v_num=ypmf]Epoch 190:  84% 227/270 [02:26<-1:52:30, -0.10it/s, loss=0.0167, v_num=ypmf]Epoch 190:  84% 227/270 [02:26<-1:52:29, -0.10it/s, loss=0.0167, v_num=ypmf]Epoch 190:  84% 228/270 [02:27<-1:52:05, -0.09it/s, loss=0.0167, v_num=ypmf]Epoch 190:  84% 228/270 [02:27<-1:52:05, -0.09it/s, loss=0.0167, v_num=ypmf]Epoch 190:  84% 228/270 [02:27<-1:52:04, -0.09it/s, loss=0.0167, v_num=ypmf]Epoch 190:  85% 229/270 [02:27<-1:51:36, -0.08it/s, loss=0.0167, v_num=ypmf]Epoch 190:  85% 229/270 [02:27<-1:51:36, -0.08it/s, loss=0.0167, v_num=ypmf]Epoch 190:  85% 229/270 [02:27<-1:51:35, -0.08it/s, loss=0.0168, v_num=ypmf]Epoch 190:  85% 230/270 [02:28<-1:51:01, -0.07it/s, loss=0.0168, v_num=ypmf]Epoch 190:  85% 230/270 [02:28<-1:51:01, -0.07it/s, loss=0.0168, v_num=ypmf]Epoch 190:  85% 230/270 [02:28<-1:51:00, -0.07it/s, loss=0.0167, v_num=ypmf]Epoch 190:  86% 231/270 [02:29<-1:50:19, -0.07it/s, loss=0.0167, v_num=ypmf]Epoch 190:  86% 231/270 [02:29<-1:50:19, -0.07it/s, loss=0.0167, v_num=ypmf]Epoch 190:  86% 231/270 [02:29<-1:50:19, -0.07it/s, loss=0.0168, v_num=ypmf]Epoch 190:  86% 232/270 [02:29<-1:49:29, -0.06it/s, loss=0.0168, v_num=ypmf]Epoch 190:  86% 232/270 [02:29<-1:49:29, -0.06it/s, loss=0.0168, v_num=ypmf]Epoch 190:  86% 232/270 [02:29<-1:49:28, -0.06it/s, loss=0.0168, v_num=ypmf]Epoch 190:  86% 233/270 [02:30<-1:48:26, -0.05it/s, loss=0.0168, v_num=ypmf]Epoch 190:  86% 233/270 [02:30<-1:48:26, -0.05it/s, loss=0.0168, v_num=ypmf]Epoch 190:  86% 233/270 [02:30<-1:48:25, -0.05it/s, loss=0.0168, v_num=ypmf]Epoch 190:  87% 234/270 [02:30<-1:47:05, -0.05it/s, loss=0.0168, v_num=ypmf]Epoch 190:  87% 234/270 [02:30<-1:47:05, -0.05it/s, loss=0.0168, v_num=ypmf]Epoch 190:  87% 234/270 [02:30<-1:47:05, -0.05it/s, loss=0.0168, v_num=ypmf]Epoch 190:  87% 235/270 [02:31<-1:45:18, -0.04it/s, loss=0.0168, v_num=ypmf]Epoch 190:  87% 235/270 [02:31<-1:45:18, -0.04it/s, loss=0.0168, v_num=ypmf]Epoch 190:  87% 235/270 [02:31<-1:45:17, -0.04it/s, loss=0.0169, v_num=ypmf]Epoch 190:  87% 236/270 [02:31<-1:42:48, -0.03it/s, loss=0.0169, v_num=ypmf]Epoch 190:  87% 236/270 [02:31<-1:42:48, -0.03it/s, loss=0.0169, v_num=ypmf]Epoch 190:  87% 236/270 [02:32<-1:42:46, -0.03it/s, loss=0.0168, v_num=ypmf]Epoch 190:  88% 237/270 [02:32<-1:39:02, -0.03it/s, loss=0.0168, v_num=ypmf]Epoch 190:  88% 237/270 [02:32<-1:39:02, -0.03it/s, loss=0.0168, v_num=ypmf]Epoch 190:  88% 237/270 [02:32<-1:39:01, -0.03it/s, loss=0.0168, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 283685. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 295606. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 310578. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 300106. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308573. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 359676. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 354572. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 300541. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 267832. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 272601. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 296619. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 290234. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 288775. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 269556. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 312199. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 290405. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 359130. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 296107. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 267206. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 316153. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 275032. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 314603. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 300045. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 277023. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 316496. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 190:  88% 238/270 [02:33<-1:32:48, -0.02it/s, loss=0.0168, v_num=ypmf]Epoch 190:  88% 238/270 [02:33<-1:32:48, -0.02it/s, loss=0.0168, v_num=ypmf]Epoch 190:  88% 238/270 [02:33<-1:32:44, -0.02it/s, loss=0.0167, v_num=ypmf]Epoch 190:  89% 239/270 [02:33<-1:20:16, -0.01it/s, loss=0.0167, v_num=ypmf]Epoch 190:  89% 239/270 [02:33<-1:20:16, -0.01it/s, loss=0.0167, v_num=ypmf]Epoch 190:  89% 239/270 [02:33<-1:20:14, -0.01it/s, loss=0.0167, v_num=ypmf]Epoch 190:  89% 240/270 [02:34<-2:42:52, -0.01it/s, loss=0.0167, v_num=ypmf]Epoch 190:  89% 240/270 [02:34<-2:42:52, -0.01it/s, loss=0.0167, v_num=ypmf]Epoch 190:  89% 240/270 [02:34<-2:42:49, -0.01it/s, loss=0.0167, v_num=ypmf]Epoch 190:  89% 241/270 [02:34<?, ?it/s, loss=0.0167, v_num=ypmf]           Epoch 190:  89% 241/270 [02:34<?, ?it/s, loss=0.0167, v_num=ypmf]Epoch 190:  89% 241/270 [02:34<?, ?it/s, loss=0.0168, v_num=ypmf]Epoch 190:  90% 242/270 [02:35<1:12:31, 155.43s/it, loss=0.0168, v_num=ypmf]Epoch 190:  90% 242/270 [02:35<1:12:31, 155.43s/it, loss=0.0168, v_num=ypmf]Epoch 190:  90% 242/270 [02:35<1:12:36, 155.57s/it, loss=0.0168, v_num=ypmf]Epoch 190:  90% 243/270 [02:35<35:05, 77.99s/it, loss=0.0168, v_num=ypmf]   Epoch 190:  90% 243/270 [02:35<35:05, 77.99s/it, loss=0.0168, v_num=ypmf]Epoch 190:  90% 243/270 [02:36<35:07, 78.06s/it, loss=0.0168, v_num=ypmf]Epoch 190:  90% 244/270 [02:36<22:36, 52.18s/it, loss=0.0168, v_num=ypmf]Epoch 190:  90% 244/270 [02:36<22:36, 52.18s/it, loss=0.0168, v_num=ypmf]Epoch 190:  90% 244/270 [02:36<22:39, 52.28s/it, loss=0.0168, v_num=ypmf]Epoch 190:  91% 245/270 [02:37<16:22, 39.31s/it, loss=0.0168, v_num=ypmf]Epoch 190:  91% 245/270 [02:37<16:22, 39.31s/it, loss=0.0168, v_num=ypmf]Epoch 190:  91% 245/270 [02:37<16:24, 39.39s/it, loss=0.0167, v_num=ypmf]Epoch 190:  91% 246/270 [02:37<12:38, 31.59s/it, loss=0.0167, v_num=ypmf]Epoch 190:  91% 246/270 [02:37<12:38, 31.59s/it, loss=0.0167, v_num=ypmf]Epoch 190:  91% 246/270 [02:38<12:38, 31.62s/it, loss=0.0168, v_num=ypmf]Epoch 190:  91% 247/270 [02:38<10:07, 26.42s/it, loss=0.0168, v_num=ypmf]Epoch 190:  91% 247/270 [02:38<10:07, 26.42s/it, loss=0.0168, v_num=ypmf]Epoch 190:  91% 247/270 [02:38<10:08, 26.45s/it, loss=0.0168, v_num=ypmf]Epoch 190:  92% 248/270 [02:39<08:19, 22.72s/it, loss=0.0168, v_num=ypmf]Epoch 190:  92% 248/270 [02:39<08:19, 22.72s/it, loss=0.0168, v_num=ypmf]Epoch 190:  92% 248/270 [02:39<08:20, 22.75s/it, loss=0.0168, v_num=ypmf]Epoch 190:  92% 249/270 [02:39<06:59, 19.96s/it, loss=0.0168, v_num=ypmf]Epoch 190:  92% 249/270 [02:39<06:59, 19.96s/it, loss=0.0168, v_num=ypmf]Epoch 190:  92% 249/270 [02:39<06:59, 19.97s/it, loss=0.0168, v_num=ypmf]Epoch 190:  93% 250/270 [02:40<05:56, 17.81s/it, loss=0.0168, v_num=ypmf]Epoch 190:  93% 250/270 [02:40<05:56, 17.81s/it, loss=0.0168, v_num=ypmf]Epoch 190:  93% 250/270 [02:40<05:56, 17.82s/it, loss=0.0168, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 277866. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 345530. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 317458. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319962. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 331915. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 312402. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 339710. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 295198. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 311156. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(

Validation: 0it [00:00, ?it/s][A
Validation:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.23it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.23it/s][AEpoch 190:  93% 251/270 [02:41<05:06, 16.11s/it, loss=0.0168, v_num=ypmf]Epoch 190:  93% 251/270 [02:41<05:06, 16.11s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  10% 2/20 [00:01<00:18,  1.01s/it][A
Validation DataLoader 0:  10% 2/20 [00:01<00:18,  1.01s/it][AEpoch 190:  93% 252/270 [02:42<04:25, 14.78s/it, loss=0.0168, v_num=ypmf]Epoch 190:  93% 252/270 [02:42<04:25, 14.78s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  15% 3/20 [00:03<00:19,  1.14s/it][A
Validation DataLoader 0:  15% 3/20 [00:03<00:19,  1.14s/it][AEpoch 190:  94% 253/270 [02:43<03:52, 13.65s/it, loss=0.0168, v_num=ypmf]Epoch 190:  94% 253/270 [02:43<03:52, 13.65s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  20% 4/20 [00:03<00:15,  1.04it/s][A
Validation DataLoader 0:  20% 4/20 [00:03<00:15,  1.04it/s][AEpoch 190:  94% 254/270 [02:44<03:22, 12.66s/it, loss=0.0168, v_num=ypmf]Epoch 190:  94% 254/270 [02:44<03:22, 12.66s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  25% 5/20 [00:04<00:13,  1.10it/s][A
Validation DataLoader 0:  25% 5/20 [00:04<00:13,  1.10it/s][AEpoch 190:  94% 255/270 [02:45<02:57, 11.81s/it, loss=0.0168, v_num=ypmf]Epoch 190:  94% 255/270 [02:45<02:57, 11.81s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  30% 6/20 [00:05<00:11,  1.17it/s][A
Validation DataLoader 0:  30% 6/20 [00:05<00:11,  1.17it/s][AEpoch 190:  95% 256/270 [02:46<02:35, 11.07s/it, loss=0.0168, v_num=ypmf]Epoch 190:  95% 256/270 [02:46<02:35, 11.07s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  35% 7/20 [00:06<00:11,  1.14it/s][A
Validation DataLoader 0:  35% 7/20 [00:06<00:11,  1.14it/s][AEpoch 190:  95% 257/270 [02:47<02:15, 10.44s/it, loss=0.0168, v_num=ypmf]Epoch 190:  95% 257/270 [02:47<02:15, 10.44s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  40% 8/20 [00:07<00:11,  1.07it/s][A
Validation DataLoader 0:  40% 8/20 [00:07<00:11,  1.07it/s][AEpoch 190:  96% 258/270 [02:48<01:58,  9.89s/it, loss=0.0168, v_num=ypmf]Epoch 190:  96% 258/270 [02:48<01:58,  9.89s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  45% 9/20 [00:08<00:09,  1.15it/s][A
Validation DataLoader 0:  45% 9/20 [00:08<00:09,  1.15it/s][AEpoch 190:  96% 259/270 [02:48<01:43,  9.38s/it, loss=0.0168, v_num=ypmf]Epoch 190:  96% 259/270 [02:48<01:43,  9.38s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  50% 10/20 [00:08<00:07,  1.30it/s][A
Validation DataLoader 0:  50% 10/20 [00:08<00:07,  1.30it/s][AEpoch 190:  96% 260/270 [02:49<01:29,  8.91s/it, loss=0.0168, v_num=ypmf]Epoch 190:  96% 260/270 [02:49<01:29,  8.91s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  55% 11/20 [00:09<00:07,  1.27it/s][A
Validation DataLoader 0:  55% 11/20 [00:09<00:07,  1.27it/s][AEpoch 190:  97% 261/270 [02:50<01:16,  8.51s/it, loss=0.0168, v_num=ypmf]Epoch 190:  97% 261/270 [02:50<01:16,  8.51s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  60% 12/20 [00:10<00:07,  1.01it/s][A
Validation DataLoader 0:  60% 12/20 [00:10<00:07,  1.01it/s][AEpoch 190:  97% 262/270 [02:51<01:05,  8.17s/it, loss=0.0168, v_num=ypmf]Epoch 190:  97% 262/270 [02:51<01:05,  8.17s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  65% 13/20 [00:11<00:06,  1.06it/s][A
Validation DataLoader 0:  65% 13/20 [00:11<00:06,  1.06it/s][AEpoch 190:  97% 263/270 [02:52<00:54,  7.84s/it, loss=0.0168, v_num=ypmf]Epoch 190:  97% 263/270 [02:52<00:54,  7.84s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  70% 14/20 [00:12<00:05,  1.15it/s][A
Validation DataLoader 0:  70% 14/20 [00:12<00:05,  1.15it/s][AEpoch 190:  98% 264/270 [02:53<00:45,  7.53s/it, loss=0.0168, v_num=ypmf]Epoch 190:  98% 264/270 [02:53<00:45,  7.53s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  75% 15/20 [00:14<00:06,  1.22s/it][A
Validation DataLoader 0:  75% 15/20 [00:14<00:06,  1.22s/it][AEpoch 190:  98% 265/270 [02:55<00:36,  7.30s/it, loss=0.0168, v_num=ypmf]Epoch 190:  98% 265/270 [02:55<00:36,  7.30s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  80% 16/20 [00:15<00:04,  1.07s/it][A
Validation DataLoader 0:  80% 16/20 [00:15<00:04,  1.07s/it][AEpoch 190:  99% 266/270 [02:55<00:28,  7.04s/it, loss=0.0168, v_num=ypmf]Epoch 190:  99% 266/270 [02:55<00:28,  7.04s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  85% 17/20 [00:16<00:03,  1.04s/it][A
Validation DataLoader 0:  85% 17/20 [00:16<00:03,  1.04s/it][AEpoch 190:  99% 267/270 [02:56<00:20,  6.80s/it, loss=0.0168, v_num=ypmf]Epoch 190:  99% 267/270 [02:56<00:20,  6.80s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  90% 18/20 [00:16<00:01,  1.08it/s][A
Validation DataLoader 0:  90% 18/20 [00:16<00:01,  1.08it/s][AEpoch 190:  99% 268/270 [02:57<00:13,  6.58s/it, loss=0.0168, v_num=ypmf]Epoch 190:  99% 268/270 [02:57<00:13,  6.58s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  95% 19/20 [00:18<00:01,  1.11s/it][A
Validation DataLoader 0:  95% 19/20 [00:18<00:01,  1.11s/it][AEpoch 190: 100% 269/270 [02:59<00:06,  6.40s/it, loss=0.0168, v_num=ypmf]Epoch 190: 100% 269/270 [02:59<00:06,  6.40s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0: 100% 20/20 [00:19<00:00,  1.05s/it][A
Validation DataLoader 0: 100% 20/20 [00:19<00:00,  1.05s/it][AEpoch 190: 100% 270/270 [03:00<00:00,  6.21s/it, loss=0.0168, v_num=ypmf]Epoch 190: 100% 270/270 [03:00<00:00,  6.21s/it, loss=0.0168, v_num=ypmf]Epoch 190: 100% 270/270 [03:01<00:00,  6.27s/it, loss=0.0168, v_num=ypmf]
                                                            [AEpoch 190: 100% 270/270 [03:01<00:00,  6.27s/it, loss=0.0168, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 190:   0% 0/270 [00:00<00:00, -5647079.69it/s, loss=0.0168, v_num=ypmf]Epoch 191:   0% 0/270 [00:00<00:00, -1540895.22it/s, loss=0.0168, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 191:   0% 1/270 [00:01<-1:59:59, -200.35it/s, loss=0.0168, v_num=ypmf] Epoch 191:   0% 1/270 [00:01<-1:59:59, -200.32it/s, loss=0.0168, v_num=ypmf]Epoch 191:   0% 1/270 [00:01<-1:59:59, -163.33it/s, loss=0.0168, v_num=ypmf]Epoch 191:   1% 2/270 [00:01<-1:59:59, -134.55it/s, loss=0.0168, v_num=ypmf]Epoch 191:   1% 2/270 [00:01<-1:59:59, -134.54it/s, loss=0.0168, v_num=ypmf]Epoch 191:   1% 2/270 [00:02<-1:59:58, -112.18it/s, loss=0.0169, v_num=ypmf]Epoch 191:   1% 3/270 [00:02<-1:59:58, -92.92it/s, loss=0.0169, v_num=ypmf] Epoch 191:   1% 3/270 [00:02<-1:59:58, -92.91it/s, loss=0.0169, v_num=ypmf]Epoch 191:   1% 3/270 [00:02<-1:59:57, -85.45it/s, loss=0.0169, v_num=ypmf]Epoch 191:   1% 4/270 [00:03<-1:59:57, -76.01it/s, loss=0.0169, v_num=ypmf]Epoch 191:   1% 4/270 [00:03<-1:59:57, -76.01it/s, loss=0.0169, v_num=ypmf]Epoch 191:   1% 4/270 [00:03<-1:59:57, -69.45it/s, loss=0.0168, v_num=ypmf]Epoch 191:   2% 5/270 [00:03<-1:59:56, -62.67it/s, loss=0.0168, v_num=ypmf]Epoch 191:   2% 5/270 [00:03<-1:59:56, -62.67it/s, loss=0.0168, v_num=ypmf]Epoch 191:   2% 5/270 [00:04<-1:59:56, -58.62it/s, loss=0.0168, v_num=ypmf]Epoch 191:   2% 6/270 [00:04<-1:59:56, -54.31it/s, loss=0.0168, v_num=ypmf]Epoch 191:   2% 6/270 [00:04<-1:59:56, -54.31it/s, loss=0.0168, v_num=ypmf]Epoch 191:   2% 6/270 [00:04<-1:59:55, -51.96it/s, loss=0.0168, v_num=ypmf]Epoch 191:   3% 7/270 [00:04<-1:59:55, -48.37it/s, loss=0.0168, v_num=ypmf]Epoch 191:   3% 7/270 [00:04<-1:59:55, -48.37it/s, loss=0.0168, v_num=ypmf]Epoch 191:   3% 7/270 [00:05<-1:59:55, -45.13it/s, loss=0.0169, v_num=ypmf]Epoch 191:   3% 8/270 [00:05<-1:59:54, -41.48it/s, loss=0.0169, v_num=ypmf]Epoch 191:   3% 8/270 [00:05<-1:59:54, -41.48it/s, loss=0.0169, v_num=ypmf]Epoch 191:   3% 8/270 [00:05<-1:59:54, -40.49it/s, loss=0.0168, v_num=ypmf]Epoch 191:   3% 9/270 [00:06<-1:59:54, -37.90it/s, loss=0.0168, v_num=ypmf]Epoch 191:   3% 9/270 [00:06<-1:59:54, -37.90it/s, loss=0.0168, v_num=ypmf]Epoch 191:   3% 9/270 [00:07<-1:59:52, -31.63it/s, loss=0.0169, v_num=ypmf]Epoch 191:   4% 10/270 [00:07<-1:59:52, -29.50it/s, loss=0.0169, v_num=ypmf]Epoch 191:   4% 10/270 [00:07<-1:59:52, -29.50it/s, loss=0.0169, v_num=ypmf]Epoch 191:   4% 10/270 [00:07<-1:59:52, -28.95it/s, loss=0.0169, v_num=ypmf]Epoch 191:   4% 11/270 [00:08<-1:59:51, -27.62it/s, loss=0.0169, v_num=ypmf]Epoch 191:   4% 11/270 [00:08<-1:59:51, -27.62it/s, loss=0.0169, v_num=ypmf]Epoch 191:   4% 11/270 [00:09<-1:59:50, -25.16it/s, loss=0.0169, v_num=ypmf]Epoch 191:   4% 12/270 [00:09<-1:59:50, -23.98it/s, loss=0.0169, v_num=ypmf]Epoch 191:   4% 12/270 [00:09<-1:59:50, -23.98it/s, loss=0.0169, v_num=ypmf]Epoch 191:   4% 12/270 [00:09<-1:59:50, -23.57it/s, loss=0.017, v_num=ypmf] Epoch 191:   5% 13/270 [00:10<-1:59:49, -22.59it/s, loss=0.017, v_num=ypmf]Epoch 191:   5% 13/270 [00:10<-1:59:49, -22.59it/s, loss=0.017, v_num=ypmf]Epoch 191:   5% 13/270 [00:10<-1:59:49, -21.52it/s, loss=0.017, v_num=ypmf]Epoch 191:   5% 14/270 [00:10<-1:59:48, -20.68it/s, loss=0.017, v_num=ypmf]Epoch 191:   5% 14/270 [00:10<-1:59:48, -20.68it/s, loss=0.017, v_num=ypmf]Epoch 191:   5% 14/270 [00:11<-1:59:48, -20.36it/s, loss=0.0171, v_num=ypmf]Epoch 191:   6% 15/270 [00:11<-1:59:48, -19.65it/s, loss=0.0171, v_num=ypmf]Epoch 191:   6% 15/270 [00:11<-1:59:48, -19.65it/s, loss=0.0171, v_num=ypmf]Epoch 191:   6% 15/270 [00:11<-1:59:47, -18.96it/s, loss=0.0171, v_num=ypmf]Epoch 191:   6% 16/270 [00:12<-1:59:46, -18.12it/s, loss=0.0171, v_num=ypmf]Epoch 191:   6% 16/270 [00:12<-1:59:46, -18.12it/s, loss=0.0171, v_num=ypmf]Epoch 191:   6% 16/270 [00:12<-1:59:46, -18.08it/s, loss=0.017, v_num=ypmf] Epoch 191:   6% 17/270 [00:12<-1:59:46, -17.45it/s, loss=0.017, v_num=ypmf]Epoch 191:   6% 17/270 [00:12<-1:59:46, -17.45it/s, loss=0.017, v_num=ypmf]Epoch 191:   6% 17/270 [00:13<-1:59:45, -16.59it/s, loss=0.0171, v_num=ypmf]Epoch 191:   7% 18/270 [00:13<-1:59:45, -16.07it/s, loss=0.0171, v_num=ypmf]Epoch 191:   7% 18/270 [00:13<-1:59:45, -16.07it/s, loss=0.0171, v_num=ypmf]Epoch 191:   7% 18/270 [00:14<-1:59:45, -15.89it/s, loss=0.017, v_num=ypmf] Epoch 191:   7% 19/270 [00:14<-1:59:44, -15.43it/s, loss=0.017, v_num=ypmf]Epoch 191:   7% 19/270 [00:14<-1:59:44, -15.43it/s, loss=0.017, v_num=ypmf]Epoch 191:   7% 19/270 [00:14<-1:59:44, -15.15it/s, loss=0.0169, v_num=ypmf]Epoch 191:   7% 20/270 [00:15<-1:59:43, -14.66it/s, loss=0.0169, v_num=ypmf]Epoch 191:   7% 20/270 [00:15<-1:59:43, -14.66it/s, loss=0.0169, v_num=ypmf]Epoch 191:   7% 20/270 [00:15<-1:59:43, -14.53it/s, loss=0.017, v_num=ypmf] Epoch 191:   8% 21/270 [00:15<-1:59:43, -14.12it/s, loss=0.017, v_num=ypmf]Epoch 191:   8% 21/270 [00:15<-1:59:43, -14.12it/s, loss=0.017, v_num=ypmf]Epoch 191:   8% 21/270 [00:15<-1:59:43, -13.98it/s, loss=0.0169, v_num=ypmf]Epoch 191:   8% 22/270 [00:16<-1:59:42, -13.58it/s, loss=0.0169, v_num=ypmf]Epoch 191:   8% 22/270 [00:16<-1:59:42, -13.58it/s, loss=0.0169, v_num=ypmf]Epoch 191:   8% 22/270 [00:16<-1:59:42, -13.47it/s, loss=0.0168, v_num=ypmf]Epoch 191:   9% 23/270 [00:16<-1:59:42, -13.07it/s, loss=0.0168, v_num=ypmf]Epoch 191:   9% 23/270 [00:16<-1:59:42, -13.07it/s, loss=0.0168, v_num=ypmf]Epoch 191:   9% 23/270 [00:16<-1:59:41, -12.97it/s, loss=0.0168, v_num=ypmf]Epoch 191:   9% 24/270 [00:17<-1:59:41, -12.57it/s, loss=0.0168, v_num=ypmf]Epoch 191:   9% 24/270 [00:17<-1:59:41, -12.57it/s, loss=0.0168, v_num=ypmf]Epoch 191:   9% 24/270 [00:17<-1:59:41, -12.46it/s, loss=0.0168, v_num=ypmf]Epoch 191:   9% 25/270 [00:17<-1:59:40, -12.08it/s, loss=0.0168, v_num=ypmf]Epoch 191:   9% 25/270 [00:17<-1:59:40, -12.08it/s, loss=0.0168, v_num=ypmf]Epoch 191:   9% 25/270 [00:18<-1:59:40, -11.98it/s, loss=0.0167, v_num=ypmf]Epoch 191:  10% 26/270 [00:18<-1:59:40, -11.65it/s, loss=0.0167, v_num=ypmf]Epoch 191:  10% 26/270 [00:18<-1:59:40, -11.65it/s, loss=0.0167, v_num=ypmf]Epoch 191:  10% 26/270 [00:18<-1:59:39, -11.53it/s, loss=0.0167, v_num=ypmf]Epoch 191:  10% 27/270 [00:19<-1:59:39, -11.23it/s, loss=0.0167, v_num=ypmf]Epoch 191:  10% 27/270 [00:19<-1:59:39, -11.23it/s, loss=0.0167, v_num=ypmf]Epoch 191:  10% 27/270 [00:19<-1:59:39, -11.15it/s, loss=0.0165, v_num=ypmf]Epoch 191:  10% 28/270 [00:19<-1:59:38, -10.89it/s, loss=0.0165, v_num=ypmf]Epoch 191:  10% 28/270 [00:19<-1:59:38, -10.89it/s, loss=0.0165, v_num=ypmf]Epoch 191:  10% 28/270 [00:20<-1:59:37, -10.23it/s, loss=0.0165, v_num=ypmf]Epoch 191:  11% 29/270 [00:21<-1:59:36, -10.00it/s, loss=0.0165, v_num=ypmf]Epoch 191:  11% 29/270 [00:21<-1:59:36, -9.99it/s, loss=0.0165, v_num=ypmf] Epoch 191:  11% 29/270 [00:21<-1:59:36, -9.91it/s, loss=0.0165, v_num=ypmf]Epoch 191:  11% 30/270 [00:21<-1:59:36, -9.67it/s, loss=0.0165, v_num=ypmf]Epoch 191:  11% 30/270 [00:21<-1:59:36, -9.67it/s, loss=0.0165, v_num=ypmf]Epoch 191:  11% 30/270 [00:22<-1:59:35, -9.43it/s, loss=0.0166, v_num=ypmf]Epoch 191:  11% 31/270 [00:22<-1:59:35, -9.23it/s, loss=0.0166, v_num=ypmf]Epoch 191:  11% 31/270 [00:22<-1:59:35, -9.23it/s, loss=0.0166, v_num=ypmf]Epoch 191:  11% 31/270 [00:22<-1:59:34, -9.14it/s, loss=0.0166, v_num=ypmf]Epoch 191:  12% 32/270 [00:23<-1:59:34, -8.93it/s, loss=0.0166, v_num=ypmf]Epoch 191:  12% 32/270 [00:23<-1:59:34, -8.93it/s, loss=0.0166, v_num=ypmf]Epoch 191:  12% 32/270 [00:23<-1:59:34, -8.88it/s, loss=0.0167, v_num=ypmf]Epoch 191:  12% 33/270 [00:23<-1:59:33, -8.67it/s, loss=0.0167, v_num=ypmf]Epoch 191:  12% 33/270 [00:23<-1:59:33, -8.67it/s, loss=0.0167, v_num=ypmf]Epoch 191:  12% 33/270 [00:24<-1:59:33, -8.61it/s, loss=0.0166, v_num=ypmf]Epoch 191:  13% 34/270 [00:24<-1:59:32, -8.42it/s, loss=0.0166, v_num=ypmf]Epoch 191:  13% 34/270 [00:24<-1:59:32, -8.42it/s, loss=0.0166, v_num=ypmf]Epoch 191:  13% 34/270 [00:26<-1:59:31, -7.92it/s, loss=0.0165, v_num=ypmf]Epoch 191:  13% 35/270 [00:26<-1:59:30, -7.78it/s, loss=0.0165, v_num=ypmf]Epoch 191:  13% 35/270 [00:26<-1:59:30, -7.78it/s, loss=0.0165, v_num=ypmf]Epoch 191:  13% 35/270 [00:26<-1:59:30, -7.73it/s, loss=0.0165, v_num=ypmf]Epoch 191:  13% 36/270 [00:27<-1:59:29, -7.51it/s, loss=0.0165, v_num=ypmf]Epoch 191:  13% 36/270 [00:27<-1:59:29, -7.51it/s, loss=0.0165, v_num=ypmf]Epoch 191:  13% 36/270 [00:27<-1:59:29, -7.47it/s, loss=0.0165, v_num=ypmf]Epoch 191:  14% 37/270 [00:27<-1:59:29, -7.34it/s, loss=0.0165, v_num=ypmf]Epoch 191:  14% 37/270 [00:27<-1:59:29, -7.34it/s, loss=0.0165, v_num=ypmf]Epoch 191:  14% 37/270 [00:27<-1:59:29, -7.31it/s, loss=0.0164, v_num=ypmf]Epoch 191:  14% 38/270 [00:28<-1:59:28, -7.18it/s, loss=0.0164, v_num=ypmf]Epoch 191:  14% 38/270 [00:28<-1:59:28, -7.18it/s, loss=0.0164, v_num=ypmf]Epoch 191:  14% 38/270 [00:28<-1:59:28, -7.13it/s, loss=0.0165, v_num=ypmf]Epoch 191:  14% 39/270 [00:28<-1:59:28, -7.02it/s, loss=0.0165, v_num=ypmf]Epoch 191:  14% 39/270 [00:28<-1:59:28, -7.02it/s, loss=0.0165, v_num=ypmf]Epoch 191:  14% 39/270 [00:29<-1:59:27, -6.95it/s, loss=0.0165, v_num=ypmf]Epoch 191:  15% 40/270 [00:29<-1:59:27, -6.82it/s, loss=0.0165, v_num=ypmf]Epoch 191:  15% 40/270 [00:29<-1:59:27, -6.82it/s, loss=0.0165, v_num=ypmf]Epoch 191:  15% 40/270 [00:29<-1:59:26, -6.73it/s, loss=0.0165, v_num=ypmf]Epoch 191:  15% 41/270 [00:30<-1:59:26, -6.59it/s, loss=0.0165, v_num=ypmf]Epoch 191:  15% 41/270 [00:30<-1:59:26, -6.59it/s, loss=0.0165, v_num=ypmf]Epoch 191:  15% 41/270 [00:30<-1:59:26, -6.55it/s, loss=0.0165, v_num=ypmf]Epoch 191:  16% 42/270 [00:30<-1:59:25, -6.42it/s, loss=0.0165, v_num=ypmf]Epoch 191:  16% 42/270 [00:30<-1:59:25, -6.42it/s, loss=0.0165, v_num=ypmf]Epoch 191:  16% 42/270 [00:31<-1:59:25, -6.39it/s, loss=0.0165, v_num=ypmf]Epoch 191:  16% 43/270 [00:31<-1:59:24, -6.29it/s, loss=0.0165, v_num=ypmf]Epoch 191:  16% 43/270 [00:31<-1:59:24, -6.29it/s, loss=0.0165, v_num=ypmf]Epoch 191:  16% 43/270 [00:31<-1:59:24, -6.26it/s, loss=0.0166, v_num=ypmf]Epoch 191:  16% 44/270 [00:31<-1:59:24, -6.17it/s, loss=0.0166, v_num=ypmf]Epoch 191:  16% 44/270 [00:31<-1:59:24, -6.17it/s, loss=0.0166, v_num=ypmf]Epoch 191:  16% 44/270 [00:32<-1:59:23, -6.07it/s, loss=0.0167, v_num=ypmf]Epoch 191:  17% 45/270 [00:33<-1:59:23, -5.94it/s, loss=0.0167, v_num=ypmf]Epoch 191:  17% 45/270 [00:33<-1:59:23, -5.94it/s, loss=0.0167, v_num=ypmf]Epoch 191:  17% 45/270 [00:33<-1:59:22, -5.90it/s, loss=0.0167, v_num=ypmf]Epoch 191:  17% 46/270 [00:33<-1:59:22, -5.81it/s, loss=0.0167, v_num=ypmf]Epoch 191:  17% 46/270 [00:33<-1:59:22, -5.81it/s, loss=0.0167, v_num=ypmf]Epoch 191:  17% 46/270 [00:34<-1:59:21, -5.68it/s, loss=0.0168, v_num=ypmf]Epoch 191:  17% 47/270 [00:34<-1:59:21, -5.59it/s, loss=0.0168, v_num=ypmf]Epoch 191:  17% 47/270 [00:34<-1:59:21, -5.59it/s, loss=0.0168, v_num=ypmf]Epoch 191:  17% 47/270 [00:34<-1:59:20, -5.56it/s, loss=0.0167, v_num=ypmf]Epoch 191:  18% 48/270 [00:35<-1:59:20, -5.46it/s, loss=0.0167, v_num=ypmf]Epoch 191:  18% 48/270 [00:35<-1:59:20, -5.46it/s, loss=0.0167, v_num=ypmf]Epoch 191:  18% 48/270 [00:35<-1:59:20, -5.44it/s, loss=0.0168, v_num=ypmf]Epoch 191:  18% 49/270 [00:35<-1:59:19, -5.35it/s, loss=0.0168, v_num=ypmf]Epoch 191:  18% 49/270 [00:35<-1:59:19, -5.35it/s, loss=0.0168, v_num=ypmf]Epoch 191:  18% 49/270 [00:36<-1:59:19, -5.32it/s, loss=0.0167, v_num=ypmf]Epoch 191:  19% 50/270 [00:36<-1:59:18, -5.23it/s, loss=0.0167, v_num=ypmf]Epoch 191:  19% 50/270 [00:36<-1:59:18, -5.23it/s, loss=0.0167, v_num=ypmf]Epoch 191:  19% 50/270 [00:36<-1:59:18, -5.21it/s, loss=0.0166, v_num=ypmf]Epoch 191:  19% 51/270 [00:37<-1:59:18, -5.11it/s, loss=0.0166, v_num=ypmf]Epoch 191:  19% 51/270 [00:37<-1:59:18, -5.11it/s, loss=0.0166, v_num=ypmf]Epoch 191:  19% 51/270 [00:37<-1:59:17, -5.09it/s, loss=0.0165, v_num=ypmf]Epoch 191:  19% 52/270 [00:37<-1:59:17, -5.00it/s, loss=0.0165, v_num=ypmf]Epoch 191:  19% 52/270 [00:37<-1:59:17, -5.00it/s, loss=0.0165, v_num=ypmf]Epoch 191:  19% 52/270 [00:38<-1:59:17, -4.96it/s, loss=0.0165, v_num=ypmf]Epoch 191:  20% 53/270 [00:38<-1:59:16, -4.89it/s, loss=0.0165, v_num=ypmf]Epoch 191:  20% 53/270 [00:38<-1:59:16, -4.89it/s, loss=0.0165, v_num=ypmf]Epoch 191:  20% 53/270 [00:38<-1:59:16, -4.86it/s, loss=0.0165, v_num=ypmf]Epoch 191:  20% 54/270 [00:39<-1:59:15, -4.79it/s, loss=0.0165, v_num=ypmf]Epoch 191:  20% 54/270 [00:39<-1:59:15, -4.79it/s, loss=0.0165, v_num=ypmf]Epoch 191:  20% 54/270 [00:39<-1:59:15, -4.76it/s, loss=0.0165, v_num=ypmf]Epoch 191:  20% 55/270 [00:39<-1:59:15, -4.69it/s, loss=0.0165, v_num=ypmf]Epoch 191:  20% 55/270 [00:39<-1:59:15, -4.69it/s, loss=0.0165, v_num=ypmf]Epoch 191:  20% 55/270 [00:39<-1:59:15, -4.67it/s, loss=0.0165, v_num=ypmf]Epoch 191:  21% 56/270 [00:40<-1:59:14, -4.61it/s, loss=0.0165, v_num=ypmf]Epoch 191:  21% 56/270 [00:40<-1:59:14, -4.61it/s, loss=0.0165, v_num=ypmf]Epoch 191:  21% 56/270 [00:40<-1:59:13, -4.55it/s, loss=0.0165, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 263019. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 254601. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 284786. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 291296. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 304178. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 307274. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308249. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301271. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 320559. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 327284. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 306398. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 339006. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 306681. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 298070. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293168. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 281094. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 283545. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 277287. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 306788. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 342924. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 360421. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 335051. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 286481. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 299501. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 296587. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 191:  21% 57/270 [00:41<-1:59:13, -4.48it/s, loss=0.0165, v_num=ypmf]Epoch 191:  21% 57/270 [00:41<-1:59:13, -4.48it/s, loss=0.0165, v_num=ypmf]Epoch 191:  21% 57/270 [00:41<-1:59:13, -4.47it/s, loss=0.0165, v_num=ypmf]Epoch 191:  21% 58/270 [00:41<-1:59:12, -4.41it/s, loss=0.0165, v_num=ypmf]Epoch 191:  21% 58/270 [00:41<-1:59:12, -4.41it/s, loss=0.0165, v_num=ypmf]Epoch 191:  21% 58/270 [00:42<-1:59:12, -4.35it/s, loss=0.0165, v_num=ypmf]Epoch 191:  22% 59/270 [00:42<-1:59:11, -4.30it/s, loss=0.0165, v_num=ypmf]Epoch 191:  22% 59/270 [00:42<-1:59:11, -4.30it/s, loss=0.0165, v_num=ypmf]Epoch 191:  22% 59/270 [00:42<-1:59:11, -4.27it/s, loss=0.0166, v_num=ypmf]Epoch 191:  22% 60/270 [00:43<-1:59:11, -4.21it/s, loss=0.0166, v_num=ypmf]Epoch 191:  22% 60/270 [00:43<-1:59:11, -4.21it/s, loss=0.0166, v_num=ypmf]Epoch 191:  22% 60/270 [00:44<-1:59:09, -4.11it/s, loss=0.0166, v_num=ypmf]Epoch 191:  23% 61/270 [00:44<-1:59:09, -4.04it/s, loss=0.0166, v_num=ypmf]Epoch 191:  23% 61/270 [00:44<-1:59:09, -4.04it/s, loss=0.0166, v_num=ypmf]Epoch 191:  23% 61/270 [00:44<-1:59:08, -4.02it/s, loss=0.0165, v_num=ypmf]Epoch 191:  23% 62/270 [00:45<-1:59:08, -3.96it/s, loss=0.0165, v_num=ypmf]Epoch 191:  23% 62/270 [00:45<-1:59:08, -3.96it/s, loss=0.0165, v_num=ypmf]Epoch 191:  23% 62/270 [00:45<-1:59:08, -3.95it/s, loss=0.0165, v_num=ypmf]Epoch 191:  23% 63/270 [00:45<-1:59:07, -3.90it/s, loss=0.0165, v_num=ypmf]Epoch 191:  23% 63/270 [00:45<-1:59:07, -3.90it/s, loss=0.0165, v_num=ypmf]Epoch 191:  23% 63/270 [00:45<-1:59:07, -3.89it/s, loss=0.0165, v_num=ypmf]Epoch 191:  24% 64/270 [00:46<-1:59:07, -3.83it/s, loss=0.0165, v_num=ypmf]Epoch 191:  24% 64/270 [00:46<-1:59:07, -3.83it/s, loss=0.0165, v_num=ypmf]Epoch 191:  24% 64/270 [00:46<-1:59:07, -3.82it/s, loss=0.0164, v_num=ypmf]Epoch 191:  24% 65/270 [00:46<-1:59:06, -3.76it/s, loss=0.0164, v_num=ypmf]Epoch 191:  24% 65/270 [00:46<-1:59:06, -3.76it/s, loss=0.0164, v_num=ypmf]Epoch 191:  24% 65/270 [00:46<-1:59:06, -3.75it/s, loss=0.0165, v_num=ypmf]Epoch 191:  24% 66/270 [00:47<-1:59:05, -3.68it/s, loss=0.0165, v_num=ypmf]Epoch 191:  24% 66/270 [00:47<-1:59:05, -3.68it/s, loss=0.0165, v_num=ypmf]Epoch 191:  24% 66/270 [00:47<-1:59:05, -3.68it/s, loss=0.0164, v_num=ypmf]Epoch 191:  25% 67/270 [00:47<-1:59:05, -3.63it/s, loss=0.0164, v_num=ypmf]Epoch 191:  25% 67/270 [00:47<-1:59:05, -3.63it/s, loss=0.0164, v_num=ypmf]Epoch 191:  25% 67/270 [00:48<-1:59:04, -3.62it/s, loss=0.0166, v_num=ypmf]Epoch 191:  25% 68/270 [00:48<-1:59:04, -3.57it/s, loss=0.0166, v_num=ypmf]Epoch 191:  25% 68/270 [00:48<-1:59:04, -3.57it/s, loss=0.0166, v_num=ypmf]Epoch 191:  25% 68/270 [00:48<-1:59:04, -3.55it/s, loss=0.0166, v_num=ypmf]Epoch 191:  26% 69/270 [00:49<-1:59:03, -3.51it/s, loss=0.0166, v_num=ypmf]Epoch 191:  26% 69/270 [00:49<-1:59:03, -3.51it/s, loss=0.0166, v_num=ypmf]Epoch 191:  26% 69/270 [00:49<-1:59:03, -3.49it/s, loss=0.0166, v_num=ypmf]Epoch 191:  26% 70/270 [00:49<-1:59:02, -3.44it/s, loss=0.0166, v_num=ypmf]Epoch 191:  26% 70/270 [00:49<-1:59:02, -3.44it/s, loss=0.0166, v_num=ypmf]Epoch 191:  26% 70/270 [00:49<-1:59:02, -3.43it/s, loss=0.0167, v_num=ypmf]Epoch 191:  26% 71/270 [00:50<-1:59:02, -3.38it/s, loss=0.0167, v_num=ypmf]Epoch 191:  26% 71/270 [00:50<-1:59:02, -3.38it/s, loss=0.0167, v_num=ypmf]Epoch 191:  26% 71/270 [00:50<-1:59:01, -3.37it/s, loss=0.0168, v_num=ypmf]Epoch 191:  27% 72/270 [00:50<-1:59:01, -3.32it/s, loss=0.0168, v_num=ypmf]Epoch 191:  27% 72/270 [00:50<-1:59:01, -3.32it/s, loss=0.0168, v_num=ypmf]Epoch 191:  27% 72/270 [00:51<-1:59:01, -3.31it/s, loss=0.0168, v_num=ypmf]Epoch 191:  27% 73/270 [00:51<-1:59:00, -3.26it/s, loss=0.0168, v_num=ypmf]Epoch 191:  27% 73/270 [00:51<-1:59:00, -3.26it/s, loss=0.0168, v_num=ypmf]Epoch 191:  27% 73/270 [00:51<-1:59:00, -3.25it/s, loss=0.0167, v_num=ypmf]Epoch 191:  27% 74/270 [00:52<-1:58:59, -3.21it/s, loss=0.0167, v_num=ypmf]Epoch 191:  27% 74/270 [00:52<-1:58:59, -3.21it/s, loss=0.0167, v_num=ypmf]Epoch 191:  27% 74/270 [00:52<-1:58:59, -3.18it/s, loss=0.0167, v_num=ypmf]Epoch 191:  28% 75/270 [00:52<-1:58:58, -3.14it/s, loss=0.0167, v_num=ypmf]Epoch 191:  28% 75/270 [00:52<-1:58:58, -3.14it/s, loss=0.0167, v_num=ypmf]Epoch 191:  28% 75/270 [00:53<-1:58:58, -3.13it/s, loss=0.0167, v_num=ypmf]Epoch 191:  28% 76/270 [00:53<-1:58:58, -3.09it/s, loss=0.0167, v_num=ypmf]Epoch 191:  28% 76/270 [00:53<-1:58:58, -3.09it/s, loss=0.0167, v_num=ypmf]Epoch 191:  28% 76/270 [00:54<-1:58:56, -3.03it/s, loss=0.0167, v_num=ypmf]Epoch 191:  29% 77/270 [00:54<-1:58:56, -2.99it/s, loss=0.0167, v_num=ypmf]Epoch 191:  29% 77/270 [00:54<-1:58:56, -2.99it/s, loss=0.0167, v_num=ypmf]Epoch 191:  29% 77/270 [00:55<-1:58:56, -2.98it/s, loss=0.0167, v_num=ypmf]Epoch 191:  29% 78/270 [00:55<-1:58:55, -2.94it/s, loss=0.0167, v_num=ypmf]Epoch 191:  29% 78/270 [00:55<-1:58:55, -2.94it/s, loss=0.0167, v_num=ypmf]Epoch 191:  29% 78/270 [00:55<-1:58:55, -2.93it/s, loss=0.0168, v_num=ypmf]Epoch 191:  29% 79/270 [00:55<-1:58:55, -2.89it/s, loss=0.0168, v_num=ypmf]Epoch 191:  29% 79/270 [00:55<-1:58:55, -2.89it/s, loss=0.0168, v_num=ypmf]Epoch 191:  29% 79/270 [00:56<-1:58:54, -2.88it/s, loss=0.0168, v_num=ypmf]Epoch 191:  30% 80/270 [00:56<-1:58:54, -2.84it/s, loss=0.0168, v_num=ypmf]Epoch 191:  30% 80/270 [00:56<-1:58:54, -2.84it/s, loss=0.0168, v_num=ypmf]Epoch 191:  30% 80/270 [00:56<-1:58:53, -2.83it/s, loss=0.0168, v_num=ypmf]Epoch 191:  30% 81/270 [00:57<-1:58:53, -2.80it/s, loss=0.0168, v_num=ypmf]Epoch 191:  30% 81/270 [00:57<-1:58:53, -2.80it/s, loss=0.0168, v_num=ypmf]Epoch 191:  30% 81/270 [00:57<-1:58:53, -2.79it/s, loss=0.0169, v_num=ypmf]Epoch 191:  30% 82/270 [00:57<-1:58:52, -2.76it/s, loss=0.0169, v_num=ypmf]Epoch 191:  30% 82/270 [00:57<-1:58:52, -2.76it/s, loss=0.0169, v_num=ypmf]Epoch 191:  30% 82/270 [00:57<-1:58:52, -2.75it/s, loss=0.017, v_num=ypmf] Epoch 191:  31% 83/270 [00:59<-1:58:50, -2.64it/s, loss=0.017, v_num=ypmf]Epoch 191:  31% 83/270 [00:59<-1:58:50, -2.64it/s, loss=0.017, v_num=ypmf]Epoch 191:  31% 83/270 [00:59<-1:58:50, -2.64it/s, loss=0.0169, v_num=ypmf]Epoch 191:  31% 84/270 [01:00<-1:58:49, -2.61it/s, loss=0.0169, v_num=ypmf]Epoch 191:  31% 84/270 [01:00<-1:58:49, -2.61it/s, loss=0.0169, v_num=ypmf]Epoch 191:  31% 84/270 [01:00<-1:58:49, -2.59it/s, loss=0.0169, v_num=ypmf]Epoch 191:  31% 85/270 [01:02<-1:58:47, -2.50it/s, loss=0.0169, v_num=ypmf]Epoch 191:  31% 85/270 [01:02<-1:58:47, -2.50it/s, loss=0.0169, v_num=ypmf]Epoch 191:  31% 85/270 [01:02<-1:58:46, -2.50it/s, loss=0.0169, v_num=ypmf]Epoch 191:  32% 86/270 [01:02<-1:58:46, -2.47it/s, loss=0.0169, v_num=ypmf]Epoch 191:  32% 86/270 [01:02<-1:58:46, -2.47it/s, loss=0.0169, v_num=ypmf]Epoch 191:  32% 86/270 [01:03<-1:58:46, -2.46it/s, loss=0.0169, v_num=ypmf]Epoch 191:  32% 87/270 [01:03<-1:58:45, -2.42it/s, loss=0.0169, v_num=ypmf]Epoch 191:  32% 87/270 [01:03<-1:58:45, -2.42it/s, loss=0.0169, v_num=ypmf]Epoch 191:  32% 87/270 [01:03<-1:58:45, -2.42it/s, loss=0.0169, v_num=ypmf]Epoch 191:  33% 88/270 [01:04<-1:58:44, -2.39it/s, loss=0.0169, v_num=ypmf]Epoch 191:  33% 88/270 [01:04<-1:58:44, -2.39it/s, loss=0.0169, v_num=ypmf]Epoch 191:  33% 88/270 [01:04<-1:58:44, -2.38it/s, loss=0.0167, v_num=ypmf]Epoch 191:  33% 89/270 [01:04<-1:58:44, -2.35it/s, loss=0.0167, v_num=ypmf]Epoch 191:  33% 89/270 [01:04<-1:58:44, -2.35it/s, loss=0.0167, v_num=ypmf]Epoch 191:  33% 89/270 [01:04<-1:58:43, -2.34it/s, loss=0.0167, v_num=ypmf]Epoch 191:  33% 90/270 [01:05<-1:58:43, -2.32it/s, loss=0.0167, v_num=ypmf]Epoch 191:  33% 90/270 [01:05<-1:58:43, -2.32it/s, loss=0.0167, v_num=ypmf]Epoch 191:  33% 90/270 [01:05<-1:58:43, -2.31it/s, loss=0.0168, v_num=ypmf]Epoch 191:  34% 91/270 [01:05<-1:58:42, -2.27it/s, loss=0.0168, v_num=ypmf]Epoch 191:  34% 91/270 [01:05<-1:58:42, -2.27it/s, loss=0.0168, v_num=ypmf]Epoch 191:  34% 91/270 [01:05<-1:58:42, -2.27it/s, loss=0.0168, v_num=ypmf]Epoch 191:  34% 92/270 [01:06<-1:58:41, -2.25it/s, loss=0.0168, v_num=ypmf]Epoch 191:  34% 92/270 [01:06<-1:58:41, -2.25it/s, loss=0.0168, v_num=ypmf]Epoch 191:  34% 92/270 [01:06<-1:58:41, -2.24it/s, loss=0.0168, v_num=ypmf]Epoch 191:  34% 93/270 [01:06<-1:58:40, -2.21it/s, loss=0.0168, v_num=ypmf]Epoch 191:  34% 93/270 [01:06<-1:58:40, -2.21it/s, loss=0.0168, v_num=ypmf]Epoch 191:  34% 93/270 [01:07<-1:58:40, -2.20it/s, loss=0.0168, v_num=ypmf]Epoch 191:  35% 94/270 [01:07<-1:58:40, -2.18it/s, loss=0.0168, v_num=ypmf]Epoch 191:  35% 94/270 [01:07<-1:58:40, -2.18it/s, loss=0.0168, v_num=ypmf]Epoch 191:  35% 94/270 [01:07<-1:58:39, -2.17it/s, loss=0.0168, v_num=ypmf]Epoch 191:  35% 95/270 [01:08<-1:58:39, -2.15it/s, loss=0.0168, v_num=ypmf]Epoch 191:  35% 95/270 [01:08<-1:58:39, -2.15it/s, loss=0.0168, v_num=ypmf]Epoch 191:  35% 95/270 [01:08<-1:58:38, -2.13it/s, loss=0.0168, v_num=ypmf]Epoch 191:  36% 96/270 [01:08<-1:58:38, -2.10it/s, loss=0.0168, v_num=ypmf]Epoch 191:  36% 96/270 [01:08<-1:58:38, -2.10it/s, loss=0.0168, v_num=ypmf]Epoch 191:  36% 96/270 [01:09<-1:58:37, -2.09it/s, loss=0.0168, v_num=ypmf]Epoch 191:  36% 97/270 [01:09<-1:58:37, -2.07it/s, loss=0.0168, v_num=ypmf]Epoch 191:  36% 97/270 [01:09<-1:58:37, -2.07it/s, loss=0.0168, v_num=ypmf]Epoch 191:  36% 97/270 [01:09<-1:58:37, -2.06it/s, loss=0.0169, v_num=ypmf]Epoch 191:  36% 98/270 [01:10<-1:58:36, -2.04it/s, loss=0.0169, v_num=ypmf]Epoch 191:  36% 98/270 [01:10<-1:58:36, -2.04it/s, loss=0.0169, v_num=ypmf]Epoch 191:  36% 98/270 [01:10<-1:58:36, -2.03it/s, loss=0.0168, v_num=ypmf]Epoch 191:  37% 99/270 [01:10<-1:58:35, -2.01it/s, loss=0.0168, v_num=ypmf]Epoch 191:  37% 99/270 [01:10<-1:58:35, -2.01it/s, loss=0.0168, v_num=ypmf]Epoch 191:  37% 99/270 [01:10<-1:58:35, -2.00it/s, loss=0.0167, v_num=ypmf]Epoch 191:  37% 100/270 [01:11<-1:58:35, -1.98it/s, loss=0.0167, v_num=ypmf]Epoch 191:  37% 100/270 [01:11<-1:58:35, -1.98it/s, loss=0.0167, v_num=ypmf]Epoch 191:  37% 100/270 [01:11<-1:58:34, -1.97it/s, loss=0.0169, v_num=ypmf]Epoch 191:  37% 101/270 [01:11<-1:58:34, -1.95it/s, loss=0.0169, v_num=ypmf]Epoch 191:  37% 101/270 [01:11<-1:58:34, -1.95it/s, loss=0.0169, v_num=ypmf]Epoch 191:  37% 101/270 [01:12<-1:58:34, -1.94it/s, loss=0.0168, v_num=ypmf]Epoch 191:  38% 102/270 [01:12<-1:58:33, -1.92it/s, loss=0.0168, v_num=ypmf]Epoch 191:  38% 102/270 [01:12<-1:58:33, -1.92it/s, loss=0.0168, v_num=ypmf]Epoch 191:  38% 102/270 [01:12<-1:58:33, -1.91it/s, loss=0.0169, v_num=ypmf]Epoch 191:  38% 103/270 [01:12<-1:58:32, -1.89it/s, loss=0.0169, v_num=ypmf]Epoch 191:  38% 103/270 [01:12<-1:58:32, -1.89it/s, loss=0.0169, v_num=ypmf]Epoch 191:  38% 103/270 [01:13<-1:58:32, -1.89it/s, loss=0.0171, v_num=ypmf]Epoch 191:  39% 104/270 [01:13<-1:58:31, -1.86it/s, loss=0.0171, v_num=ypmf]Epoch 191:  39% 104/270 [01:13<-1:58:31, -1.86it/s, loss=0.0171, v_num=ypmf]Epoch 191:  39% 104/270 [01:13<-1:58:31, -1.86it/s, loss=0.017, v_num=ypmf] Epoch 191:  39% 105/270 [01:14<-1:58:31, -1.83it/s, loss=0.017, v_num=ypmf]Epoch 191:  39% 105/270 [01:14<-1:58:31, -1.83it/s, loss=0.017, v_num=ypmf]Epoch 191:  39% 105/270 [01:14<-1:58:30, -1.83it/s, loss=0.0172, v_num=ypmf]Epoch 191:  39% 106/270 [01:14<-1:58:30, -1.81it/s, loss=0.0172, v_num=ypmf]Epoch 191:  39% 106/270 [01:14<-1:58:30, -1.81it/s, loss=0.0172, v_num=ypmf]Epoch 191:  39% 106/270 [01:14<-1:58:29, -1.80it/s, loss=0.0172, v_num=ypmf]Epoch 191:  40% 107/270 [01:15<-1:58:29, -1.78it/s, loss=0.0172, v_num=ypmf]Epoch 191:  40% 107/270 [01:15<-1:58:29, -1.78it/s, loss=0.0172, v_num=ypmf]Epoch 191:  40% 107/270 [01:15<-1:58:29, -1.77it/s, loss=0.0172, v_num=ypmf]Epoch 191:  40% 108/270 [01:16<-1:58:28, -1.75it/s, loss=0.0172, v_num=ypmf]Epoch 191:  40% 108/270 [01:16<-1:58:28, -1.75it/s, loss=0.0172, v_num=ypmf]Epoch 191:  40% 108/270 [01:16<-1:58:28, -1.75it/s, loss=0.0172, v_num=ypmf]Epoch 191:  40% 109/270 [01:16<-1:58:27, -1.72it/s, loss=0.0172, v_num=ypmf]Epoch 191:  40% 109/270 [01:16<-1:58:27, -1.72it/s, loss=0.0172, v_num=ypmf]Epoch 191:  40% 109/270 [01:16<-1:58:27, -1.72it/s, loss=0.0172, v_num=ypmf]Epoch 191:  41% 110/270 [01:17<-1:58:26, -1.70it/s, loss=0.0172, v_num=ypmf]Epoch 191:  41% 110/270 [01:17<-1:58:26, -1.70it/s, loss=0.0172, v_num=ypmf]Epoch 191:  41% 110/270 [01:17<-1:58:26, -1.69it/s, loss=0.017, v_num=ypmf] Epoch 191:  41% 111/270 [01:17<-1:58:25, -1.67it/s, loss=0.017, v_num=ypmf]Epoch 191:  41% 111/270 [01:17<-1:58:25, -1.67it/s, loss=0.017, v_num=ypmf]Epoch 191:  41% 111/270 [01:17<-1:58:25, -1.67it/s, loss=0.0171, v_num=ypmf]Epoch 191:  41% 112/270 [01:18<-1:58:25, -1.65it/s, loss=0.0171, v_num=ypmf]Epoch 191:  41% 112/270 [01:18<-1:58:25, -1.65it/s, loss=0.0171, v_num=ypmf]Epoch 191:  41% 112/270 [01:18<-1:58:24, -1.64it/s, loss=0.0171, v_num=ypmf]Epoch 191:  42% 113/270 [01:19<-1:58:23, -1.61it/s, loss=0.0171, v_num=ypmf]Epoch 191:  42% 113/270 [01:19<-1:58:23, -1.61it/s, loss=0.0171, v_num=ypmf]Epoch 191:  42% 113/270 [01:19<-1:58:23, -1.61it/s, loss=0.0171, v_num=ypmf]Epoch 191:  42% 114/270 [01:19<-1:58:23, -1.59it/s, loss=0.0171, v_num=ypmf]Epoch 191:  42% 114/270 [01:19<-1:58:23, -1.59it/s, loss=0.0171, v_num=ypmf]Epoch 191:  42% 114/270 [01:19<-1:58:22, -1.59it/s, loss=0.0172, v_num=ypmf]Epoch 191:  43% 115/270 [01:20<-1:58:22, -1.57it/s, loss=0.0172, v_num=ypmf]Epoch 191:  43% 115/270 [01:20<-1:58:22, -1.57it/s, loss=0.0172, v_num=ypmf]Epoch 191:  43% 115/270 [01:20<-1:58:21, -1.56it/s, loss=0.0173, v_num=ypmf]Epoch 191:  43% 116/270 [01:21<-1:58:21, -1.54it/s, loss=0.0173, v_num=ypmf]Epoch 191:  43% 116/270 [01:21<-1:58:21, -1.54it/s, loss=0.0173, v_num=ypmf]Epoch 191:  43% 116/270 [01:21<-1:58:21, -1.54it/s, loss=0.0173, v_num=ypmf]Epoch 191:  43% 117/270 [01:21<-1:58:20, -1.52it/s, loss=0.0173, v_num=ypmf]Epoch 191:  43% 117/270 [01:21<-1:58:20, -1.52it/s, loss=0.0173, v_num=ypmf]Epoch 191:  43% 117/270 [01:21<-1:58:20, -1.52it/s, loss=0.0173, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 346264. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 282891. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 309641. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 366104. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 328916. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 302084. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 338706. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 347769. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 338583. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 294891. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 342961. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319610. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 302209. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 266485. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 323411. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 297766. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 266863. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 271521. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 302047. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 279059. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 295145. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 356593. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 350517. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 331858. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 272508. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 191:  44% 118/270 [01:21<-1:58:19, -1.50it/s, loss=0.0173, v_num=ypmf]Epoch 191:  44% 118/270 [01:21<-1:58:19, -1.50it/s, loss=0.0173, v_num=ypmf]Epoch 191:  44% 118/270 [01:22<-1:58:19, -1.50it/s, loss=0.0173, v_num=ypmf]Epoch 191:  44% 119/270 [01:22<-1:58:18, -1.48it/s, loss=0.0173, v_num=ypmf]Epoch 191:  44% 119/270 [01:22<-1:58:18, -1.48it/s, loss=0.0173, v_num=ypmf]Epoch 191:  44% 119/270 [01:22<-1:58:18, -1.48it/s, loss=0.0173, v_num=ypmf]Epoch 191:  44% 120/270 [01:23<-1:58:18, -1.46it/s, loss=0.0173, v_num=ypmf]Epoch 191:  44% 120/270 [01:23<-1:58:18, -1.46it/s, loss=0.0173, v_num=ypmf]Epoch 191:  44% 120/270 [01:24<-1:58:16, -1.44it/s, loss=0.0172, v_num=ypmf]Epoch 191:  45% 121/270 [01:24<-1:58:16, -1.42it/s, loss=0.0172, v_num=ypmf]Epoch 191:  45% 121/270 [01:24<-1:58:16, -1.42it/s, loss=0.0172, v_num=ypmf]Epoch 191:  45% 121/270 [01:24<-1:58:15, -1.42it/s, loss=0.0172, v_num=ypmf]Epoch 191:  45% 122/270 [01:24<-1:58:15, -1.40it/s, loss=0.0172, v_num=ypmf]Epoch 191:  45% 122/270 [01:24<-1:58:15, -1.40it/s, loss=0.0172, v_num=ypmf]Epoch 191:  45% 122/270 [01:25<-1:58:14, -1.40it/s, loss=0.0171, v_num=ypmf]Epoch 191:  46% 123/270 [01:25<-1:58:14, -1.38it/s, loss=0.0171, v_num=ypmf]Epoch 191:  46% 123/270 [01:25<-1:58:14, -1.38it/s, loss=0.0171, v_num=ypmf]Epoch 191:  46% 123/270 [01:25<-1:58:14, -1.38it/s, loss=0.0171, v_num=ypmf]Epoch 191:  46% 124/270 [01:26<-1:58:13, -1.36it/s, loss=0.0171, v_num=ypmf]Epoch 191:  46% 124/270 [01:26<-1:58:13, -1.36it/s, loss=0.0171, v_num=ypmf]Epoch 191:  46% 124/270 [01:27<-1:58:12, -1.34it/s, loss=0.0171, v_num=ypmf]Epoch 191:  46% 125/270 [01:27<-1:58:11, -1.33it/s, loss=0.0171, v_num=ypmf]Epoch 191:  46% 125/270 [01:27<-1:58:11, -1.33it/s, loss=0.0171, v_num=ypmf]Epoch 191:  46% 125/270 [01:27<-1:58:11, -1.32it/s, loss=0.0171, v_num=ypmf]Epoch 191:  47% 126/270 [01:28<-1:58:10, -1.31it/s, loss=0.0171, v_num=ypmf]Epoch 191:  47% 126/270 [01:28<-1:58:10, -1.31it/s, loss=0.0171, v_num=ypmf]Epoch 191:  47% 126/270 [01:28<-1:58:09, -1.29it/s, loss=0.0169, v_num=ypmf]Epoch 191:  47% 127/270 [01:29<-1:58:09, -1.28it/s, loss=0.0169, v_num=ypmf]Epoch 191:  47% 127/270 [01:29<-1:58:09, -1.28it/s, loss=0.0169, v_num=ypmf]Epoch 191:  47% 127/270 [01:29<-1:58:08, -1.27it/s, loss=0.017, v_num=ypmf] Epoch 191:  47% 128/270 [01:29<-1:58:08, -1.26it/s, loss=0.017, v_num=ypmf]Epoch 191:  47% 128/270 [01:29<-1:58:08, -1.26it/s, loss=0.017, v_num=ypmf]Epoch 191:  47% 128/270 [01:30<-1:58:07, -1.25it/s, loss=0.0172, v_num=ypmf]Epoch 191:  48% 129/270 [01:30<-1:58:06, -1.24it/s, loss=0.0172, v_num=ypmf]Epoch 191:  48% 129/270 [01:30<-1:58:06, -1.24it/s, loss=0.0172, v_num=ypmf]Epoch 191:  48% 129/270 [01:30<-1:58:06, -1.23it/s, loss=0.0172, v_num=ypmf]Epoch 191:  48% 130/270 [01:31<-1:58:06, -1.22it/s, loss=0.0172, v_num=ypmf]Epoch 191:  48% 130/270 [01:31<-1:58:06, -1.22it/s, loss=0.0172, v_num=ypmf]Epoch 191:  48% 130/270 [01:31<-1:58:05, -1.21it/s, loss=0.0173, v_num=ypmf]Epoch 191:  49% 131/270 [01:31<-1:58:04, -1.20it/s, loss=0.0173, v_num=ypmf]Epoch 191:  49% 131/270 [01:31<-1:58:04, -1.20it/s, loss=0.0173, v_num=ypmf]Epoch 191:  49% 131/270 [01:32<-1:58:04, -1.19it/s, loss=0.0173, v_num=ypmf]Epoch 191:  49% 132/270 [01:32<-1:58:03, -1.18it/s, loss=0.0173, v_num=ypmf]Epoch 191:  49% 132/270 [01:32<-1:58:03, -1.18it/s, loss=0.0173, v_num=ypmf]Epoch 191:  49% 132/270 [01:32<-1:58:03, -1.18it/s, loss=0.0173, v_num=ypmf]Epoch 191:  49% 133/270 [01:33<-1:58:02, -1.16it/s, loss=0.0173, v_num=ypmf]Epoch 191:  49% 133/270 [01:33<-1:58:02, -1.16it/s, loss=0.0173, v_num=ypmf]Epoch 191:  49% 133/270 [01:33<-1:58:02, -1.16it/s, loss=0.0173, v_num=ypmf]Epoch 191:  50% 134/270 [01:33<-1:58:01, -1.14it/s, loss=0.0173, v_num=ypmf]Epoch 191:  50% 134/270 [01:33<-1:58:01, -1.14it/s, loss=0.0173, v_num=ypmf]Epoch 191:  50% 134/270 [01:33<-1:58:01, -1.14it/s, loss=0.0173, v_num=ypmf]Epoch 191:  50% 135/270 [01:35<-1:57:59, -1.11it/s, loss=0.0173, v_num=ypmf]Epoch 191:  50% 135/270 [01:35<-1:57:59, -1.11it/s, loss=0.0173, v_num=ypmf]Epoch 191:  50% 135/270 [01:35<-1:57:59, -1.11it/s, loss=0.0172, v_num=ypmf]Epoch 191:  50% 136/270 [01:36<-1:57:58, -1.09it/s, loss=0.0172, v_num=ypmf]Epoch 191:  50% 136/270 [01:36<-1:57:58, -1.09it/s, loss=0.0172, v_num=ypmf]Epoch 191:  50% 136/270 [01:36<-1:57:57, -1.09it/s, loss=0.0171, v_num=ypmf]Epoch 191:  51% 137/270 [01:36<-1:57:57, -1.07it/s, loss=0.0171, v_num=ypmf]Epoch 191:  51% 137/270 [01:36<-1:57:57, -1.07it/s, loss=0.0171, v_num=ypmf]Epoch 191:  51% 137/270 [01:37<-1:57:56, -1.07it/s, loss=0.017, v_num=ypmf] Epoch 191:  51% 138/270 [01:37<-1:57:56, -1.06it/s, loss=0.017, v_num=ypmf]Epoch 191:  51% 138/270 [01:37<-1:57:56, -1.06it/s, loss=0.017, v_num=ypmf]Epoch 191:  51% 138/270 [01:37<-1:57:55, -1.06it/s, loss=0.0171, v_num=ypmf]Epoch 191:  51% 139/270 [01:37<-1:57:55, -1.04it/s, loss=0.0171, v_num=ypmf]Epoch 191:  51% 139/270 [01:37<-1:57:55, -1.04it/s, loss=0.0171, v_num=ypmf]Epoch 191:  51% 139/270 [01:38<-1:57:55, -1.04it/s, loss=0.0171, v_num=ypmf]Epoch 191:  52% 140/270 [01:38<-1:57:54, -1.03it/s, loss=0.0171, v_num=ypmf]Epoch 191:  52% 140/270 [01:38<-1:57:54, -1.03it/s, loss=0.0171, v_num=ypmf]Epoch 191:  52% 140/270 [01:38<-1:57:53, -1.02it/s, loss=0.0171, v_num=ypmf]Epoch 191:  52% 141/270 [01:39<-1:57:52, -1.01it/s, loss=0.0171, v_num=ypmf]Epoch 191:  52% 141/270 [01:39<-1:57:52, -1.01it/s, loss=0.0171, v_num=ypmf]Epoch 191:  52% 141/270 [01:39<-1:57:52, -1.01it/s, loss=0.017, v_num=ypmf] Epoch 191:  53% 142/270 [01:39<-1:57:52, -0.99it/s, loss=0.017, v_num=ypmf]Epoch 191:  53% 142/270 [01:39<-1:57:52, -0.99it/s, loss=0.017, v_num=ypmf]Epoch 191:  53% 142/270 [01:39<-1:57:51, -0.99it/s, loss=0.017, v_num=ypmf]Epoch 191:  53% 143/270 [01:40<-1:57:50, -0.97it/s, loss=0.017, v_num=ypmf]Epoch 191:  53% 143/270 [01:40<-1:57:50, -0.97it/s, loss=0.017, v_num=ypmf]Epoch 191:  53% 143/270 [01:41<-1:57:49, -0.97it/s, loss=0.0168, v_num=ypmf]Epoch 191:  53% 144/270 [01:41<-1:57:49, -0.96it/s, loss=0.0168, v_num=ypmf]Epoch 191:  53% 144/270 [01:41<-1:57:49, -0.96it/s, loss=0.0168, v_num=ypmf]Epoch 191:  53% 144/270 [01:41<-1:57:48, -0.95it/s, loss=0.0168, v_num=ypmf]Epoch 191:  54% 145/270 [01:42<-1:57:48, -0.94it/s, loss=0.0168, v_num=ypmf]Epoch 191:  54% 145/270 [01:42<-1:57:48, -0.94it/s, loss=0.0168, v_num=ypmf]Epoch 191:  54% 145/270 [01:42<-1:57:47, -0.94it/s, loss=0.0167, v_num=ypmf]Epoch 191:  54% 146/270 [01:42<-1:57:47, -0.93it/s, loss=0.0167, v_num=ypmf]Epoch 191:  54% 146/270 [01:42<-1:57:47, -0.93it/s, loss=0.0167, v_num=ypmf]Epoch 191:  54% 146/270 [01:42<-1:57:46, -0.92it/s, loss=0.0169, v_num=ypmf]Epoch 191:  54% 147/270 [01:43<-1:57:45, -0.91it/s, loss=0.0169, v_num=ypmf]Epoch 191:  54% 147/270 [01:43<-1:57:45, -0.91it/s, loss=0.0169, v_num=ypmf]Epoch 191:  54% 147/270 [01:43<-1:57:45, -0.91it/s, loss=0.0169, v_num=ypmf]Epoch 191:  55% 148/270 [01:43<-1:57:45, -0.90it/s, loss=0.0169, v_num=ypmf]Epoch 191:  55% 148/270 [01:43<-1:57:45, -0.90it/s, loss=0.0169, v_num=ypmf]Epoch 191:  55% 148/270 [01:43<-1:57:44, -0.90it/s, loss=0.0168, v_num=ypmf]Epoch 191:  55% 149/270 [01:44<-1:57:43, -0.88it/s, loss=0.0168, v_num=ypmf]Epoch 191:  55% 149/270 [01:44<-1:57:43, -0.88it/s, loss=0.0168, v_num=ypmf]Epoch 191:  55% 149/270 [01:44<-1:57:43, -0.88it/s, loss=0.0169, v_num=ypmf]Epoch 191:  56% 150/270 [01:44<-1:57:42, -0.87it/s, loss=0.0169, v_num=ypmf]Epoch 191:  56% 150/270 [01:44<-1:57:42, -0.87it/s, loss=0.0169, v_num=ypmf]Epoch 191:  56% 150/270 [01:44<-1:57:42, -0.87it/s, loss=0.0168, v_num=ypmf]Epoch 191:  56% 151/270 [01:45<-1:57:41, -0.85it/s, loss=0.0168, v_num=ypmf]Epoch 191:  56% 151/270 [01:45<-1:57:41, -0.85it/s, loss=0.0168, v_num=ypmf]Epoch 191:  56% 151/270 [01:45<-1:57:41, -0.85it/s, loss=0.0168, v_num=ypmf]Epoch 191:  56% 152/270 [01:45<-1:57:40, -0.84it/s, loss=0.0168, v_num=ypmf]Epoch 191:  56% 152/270 [01:45<-1:57:40, -0.84it/s, loss=0.0168, v_num=ypmf]Epoch 191:  56% 152/270 [01:46<-1:57:40, -0.84it/s, loss=0.0169, v_num=ypmf]Epoch 191:  57% 153/270 [01:46<-1:57:39, -0.83it/s, loss=0.0169, v_num=ypmf]Epoch 191:  57% 153/270 [01:46<-1:57:39, -0.83it/s, loss=0.0169, v_num=ypmf]Epoch 191:  57% 153/270 [01:46<-1:57:39, -0.82it/s, loss=0.0168, v_num=ypmf]Epoch 191:  57% 154/270 [01:47<-1:57:38, -0.81it/s, loss=0.0168, v_num=ypmf]Epoch 191:  57% 154/270 [01:47<-1:57:38, -0.81it/s, loss=0.0168, v_num=ypmf]Epoch 191:  57% 154/270 [01:47<-1:57:37, -0.81it/s, loss=0.0167, v_num=ypmf]Epoch 191:  57% 155/270 [01:47<-1:57:36, -0.80it/s, loss=0.0167, v_num=ypmf]Epoch 191:  57% 155/270 [01:47<-1:57:36, -0.80it/s, loss=0.0167, v_num=ypmf]Epoch 191:  57% 155/270 [01:48<-1:57:36, -0.80it/s, loss=0.0169, v_num=ypmf]Epoch 191:  58% 156/270 [01:48<-1:57:35, -0.78it/s, loss=0.0169, v_num=ypmf]Epoch 191:  58% 156/270 [01:48<-1:57:35, -0.78it/s, loss=0.0169, v_num=ypmf]Epoch 191:  58% 156/270 [01:48<-1:57:35, -0.78it/s, loss=0.0169, v_num=ypmf]Epoch 191:  58% 157/270 [01:49<-1:57:34, -0.77it/s, loss=0.0169, v_num=ypmf]Epoch 191:  58% 157/270 [01:49<-1:57:34, -0.77it/s, loss=0.0169, v_num=ypmf]Epoch 191:  58% 157/270 [01:49<-1:57:33, -0.77it/s, loss=0.0169, v_num=ypmf]Epoch 191:  59% 158/270 [01:49<-1:57:33, -0.76it/s, loss=0.0169, v_num=ypmf]Epoch 191:  59% 158/270 [01:49<-1:57:33, -0.76it/s, loss=0.0169, v_num=ypmf]Epoch 191:  59% 158/270 [01:49<-1:57:32, -0.76it/s, loss=0.017, v_num=ypmf] Epoch 191:  59% 159/270 [01:50<-1:57:31, -0.74it/s, loss=0.017, v_num=ypmf]Epoch 191:  59% 159/270 [01:50<-1:57:31, -0.74it/s, loss=0.017, v_num=ypmf]Epoch 191:  59% 159/270 [01:50<-1:57:31, -0.74it/s, loss=0.0171, v_num=ypmf]Epoch 191:  59% 160/270 [01:50<-1:57:30, -0.73it/s, loss=0.0171, v_num=ypmf]Epoch 191:  59% 160/270 [01:50<-1:57:30, -0.73it/s, loss=0.0171, v_num=ypmf]Epoch 191:  59% 160/270 [01:51<-1:57:29, -0.73it/s, loss=0.0171, v_num=ypmf]Epoch 191:  60% 161/270 [01:51<-1:57:29, -0.72it/s, loss=0.0171, v_num=ypmf]Epoch 191:  60% 161/270 [01:51<-1:57:29, -0.72it/s, loss=0.0171, v_num=ypmf]Epoch 191:  60% 161/270 [01:51<-1:57:28, -0.72it/s, loss=0.0172, v_num=ypmf]Epoch 191:  60% 162/270 [01:52<-1:57:27, -0.71it/s, loss=0.0172, v_num=ypmf]Epoch 191:  60% 162/270 [01:52<-1:57:27, -0.71it/s, loss=0.0172, v_num=ypmf]Epoch 191:  60% 162/270 [01:52<-1:57:27, -0.70it/s, loss=0.0172, v_num=ypmf]Epoch 191:  60% 163/270 [01:52<-1:57:26, -0.69it/s, loss=0.0172, v_num=ypmf]Epoch 191:  60% 163/270 [01:52<-1:57:26, -0.69it/s, loss=0.0172, v_num=ypmf]Epoch 191:  60% 163/270 [01:52<-1:57:26, -0.69it/s, loss=0.0173, v_num=ypmf]Epoch 191:  61% 164/270 [01:53<-1:57:25, -0.68it/s, loss=0.0173, v_num=ypmf]Epoch 191:  61% 164/270 [01:53<-1:57:25, -0.68it/s, loss=0.0173, v_num=ypmf]Epoch 191:  61% 164/270 [01:53<-1:57:25, -0.68it/s, loss=0.0172, v_num=ypmf]Epoch 191:  61% 165/270 [01:53<-1:57:23, -0.67it/s, loss=0.0172, v_num=ypmf]Epoch 191:  61% 165/270 [01:53<-1:57:23, -0.67it/s, loss=0.0172, v_num=ypmf]Epoch 191:  61% 165/270 [01:53<-1:57:23, -0.67it/s, loss=0.0173, v_num=ypmf]Epoch 191:  61% 166/270 [01:54<-1:57:22, -0.65it/s, loss=0.0173, v_num=ypmf]Epoch 191:  61% 166/270 [01:54<-1:57:22, -0.65it/s, loss=0.0173, v_num=ypmf]Epoch 191:  61% 166/270 [01:54<-1:57:22, -0.65it/s, loss=0.0172, v_num=ypmf]Epoch 191:  62% 167/270 [01:54<-1:57:21, -0.64it/s, loss=0.0172, v_num=ypmf]Epoch 191:  62% 167/270 [01:54<-1:57:21, -0.64it/s, loss=0.0172, v_num=ypmf]Epoch 191:  62% 167/270 [01:55<-1:57:20, -0.64it/s, loss=0.0171, v_num=ypmf]Epoch 191:  62% 168/270 [01:56<-1:57:18, -0.63it/s, loss=0.0171, v_num=ypmf]Epoch 191:  62% 168/270 [01:56<-1:57:18, -0.63it/s, loss=0.0171, v_num=ypmf]Epoch 191:  62% 168/270 [01:56<-1:57:18, -0.63it/s, loss=0.017, v_num=ypmf] Epoch 191:  63% 169/270 [01:56<-1:57:17, -0.62it/s, loss=0.017, v_num=ypmf]Epoch 191:  63% 169/270 [01:56<-1:57:17, -0.62it/s, loss=0.017, v_num=ypmf]Epoch 191:  63% 169/270 [01:56<-1:57:16, -0.62it/s, loss=0.0169, v_num=ypmf]Epoch 191:  63% 170/270 [01:57<-1:57:15, -0.61it/s, loss=0.0169, v_num=ypmf]Epoch 191:  63% 170/270 [01:57<-1:57:15, -0.61it/s, loss=0.0169, v_num=ypmf]Epoch 191:  63% 170/270 [01:57<-1:57:15, -0.60it/s, loss=0.0169, v_num=ypmf]Epoch 191:  63% 171/270 [01:57<-1:57:14, -0.59it/s, loss=0.0169, v_num=ypmf]Epoch 191:  63% 171/270 [01:57<-1:57:14, -0.59it/s, loss=0.0169, v_num=ypmf]Epoch 191:  63% 171/270 [01:58<-1:57:14, -0.59it/s, loss=0.0169, v_num=ypmf]Epoch 191:  64% 172/270 [01:58<-1:57:12, -0.58it/s, loss=0.0169, v_num=ypmf]Epoch 191:  64% 172/270 [01:58<-1:57:12, -0.58it/s, loss=0.0169, v_num=ypmf]Epoch 191:  64% 172/270 [01:58<-1:57:12, -0.58it/s, loss=0.0169, v_num=ypmf]Epoch 191:  64% 173/270 [01:58<-1:57:11, -0.57it/s, loss=0.0169, v_num=ypmf]Epoch 191:  64% 173/270 [01:58<-1:57:11, -0.57it/s, loss=0.0169, v_num=ypmf]Epoch 191:  64% 173/270 [01:59<-1:57:11, -0.57it/s, loss=0.0169, v_num=ypmf]Epoch 191:  64% 174/270 [02:00<-1:57:08, -0.56it/s, loss=0.0169, v_num=ypmf]Epoch 191:  64% 174/270 [02:00<-1:57:08, -0.56it/s, loss=0.0169, v_num=ypmf]Epoch 191:  64% 174/270 [02:00<-1:57:08, -0.56it/s, loss=0.0168, v_num=ypmf]Epoch 191:  65% 175/270 [02:00<-1:57:07, -0.55it/s, loss=0.0168, v_num=ypmf]Epoch 191:  65% 175/270 [02:00<-1:57:07, -0.55it/s, loss=0.0168, v_num=ypmf]Epoch 191:  65% 175/270 [02:00<-1:57:06, -0.55it/s, loss=0.0167, v_num=ypmf]Epoch 191:  65% 176/270 [02:01<-1:57:05, -0.54it/s, loss=0.0167, v_num=ypmf]Epoch 191:  65% 176/270 [02:01<-1:57:05, -0.54it/s, loss=0.0167, v_num=ypmf]Epoch 191:  65% 176/270 [02:01<-1:57:05, -0.54it/s, loss=0.0168, v_num=ypmf]Epoch 191:  66% 177/270 [02:01<-1:57:04, -0.53it/s, loss=0.0168, v_num=ypmf]Epoch 191:  66% 177/270 [02:01<-1:57:04, -0.53it/s, loss=0.0168, v_num=ypmf]Epoch 191:  66% 177/270 [02:01<-1:57:03, -0.52it/s, loss=0.0168, v_num=ypmf]Epoch 191:  66% 178/270 [02:02<-1:57:01, -0.51it/s, loss=0.0168, v_num=ypmf]Epoch 191:  66% 178/270 [02:02<-1:57:01, -0.51it/s, loss=0.0168, v_num=ypmf]Epoch 191:  66% 178/270 [02:02<-1:57:01, -0.51it/s, loss=0.0168, v_num=ypmf]Epoch 191:  66% 179/270 [02:03<-1:57:00, -0.50it/s, loss=0.0168, v_num=ypmf]Epoch 191:  66% 179/270 [02:03<-1:57:00, -0.50it/s, loss=0.0168, v_num=ypmf]Epoch 191:  66% 179/270 [02:03<-1:56:59, -0.50it/s, loss=0.0167, v_num=ypmf]Epoch 191:  67% 180/270 [02:03<-1:56:58, -0.49it/s, loss=0.0167, v_num=ypmf]Epoch 191:  67% 180/270 [02:03<-1:56:58, -0.49it/s, loss=0.0167, v_num=ypmf]Epoch 191:  67% 180/270 [02:04<-1:56:58, -0.49it/s, loss=0.0168, v_num=ypmf]Epoch 191:  67% 181/270 [02:04<-1:56:55, -0.48it/s, loss=0.0168, v_num=ypmf]Epoch 191:  67% 181/270 [02:04<-1:56:55, -0.48it/s, loss=0.0168, v_num=ypmf]Epoch 191:  67% 181/270 [02:04<-1:56:55, -0.48it/s, loss=0.0167, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 296311. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 306324. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 370594. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 337408. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 411973. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 278783. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308355. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 285048. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 290394. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 334756. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 300220. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 328437. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 289393. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 281544. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 270820. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 306954. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 304657. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 283090. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 287698. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 309028. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 295959. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 291887. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 318067. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 361518. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 340214. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 191:  67% 182/270 [02:05<-1:56:54, -0.47it/s, loss=0.0167, v_num=ypmf]Epoch 191:  67% 182/270 [02:05<-1:56:54, -0.47it/s, loss=0.0167, v_num=ypmf]Epoch 191:  67% 182/270 [02:05<-1:56:53, -0.47it/s, loss=0.0167, v_num=ypmf]Epoch 191:  68% 183/270 [02:06<-1:56:51, -0.46it/s, loss=0.0167, v_num=ypmf]Epoch 191:  68% 183/270 [02:06<-1:56:51, -0.46it/s, loss=0.0167, v_num=ypmf]Epoch 191:  68% 183/270 [02:06<-1:56:51, -0.46it/s, loss=0.0165, v_num=ypmf]Epoch 191:  68% 184/270 [02:06<-1:56:49, -0.45it/s, loss=0.0165, v_num=ypmf]Epoch 191:  68% 184/270 [02:06<-1:56:49, -0.45it/s, loss=0.0165, v_num=ypmf]Epoch 191:  68% 184/270 [02:06<-1:56:49, -0.45it/s, loss=0.0165, v_num=ypmf]Epoch 191:  69% 185/270 [02:07<-1:56:47, -0.44it/s, loss=0.0165, v_num=ypmf]Epoch 191:  69% 185/270 [02:07<-1:56:47, -0.44it/s, loss=0.0165, v_num=ypmf]Epoch 191:  69% 185/270 [02:07<-1:56:47, -0.44it/s, loss=0.0164, v_num=ypmf]Epoch 191:  69% 186/270 [02:07<-1:56:46, -0.43it/s, loss=0.0164, v_num=ypmf]Epoch 191:  69% 186/270 [02:07<-1:56:46, -0.43it/s, loss=0.0164, v_num=ypmf]Epoch 191:  69% 186/270 [02:07<-1:56:45, -0.43it/s, loss=0.0165, v_num=ypmf]Epoch 191:  69% 187/270 [02:08<-1:56:43, -0.42it/s, loss=0.0165, v_num=ypmf]Epoch 191:  69% 187/270 [02:08<-1:56:43, -0.42it/s, loss=0.0165, v_num=ypmf]Epoch 191:  69% 187/270 [02:08<-1:56:43, -0.42it/s, loss=0.0166, v_num=ypmf]Epoch 191:  70% 188/270 [02:09<-1:56:41, -0.41it/s, loss=0.0166, v_num=ypmf]Epoch 191:  70% 188/270 [02:09<-1:56:41, -0.41it/s, loss=0.0166, v_num=ypmf]Epoch 191:  70% 188/270 [02:09<-1:56:40, -0.41it/s, loss=0.0166, v_num=ypmf]Epoch 191:  70% 189/270 [02:10<-1:56:38, -0.40it/s, loss=0.0166, v_num=ypmf]Epoch 191:  70% 189/270 [02:10<-1:56:38, -0.40it/s, loss=0.0166, v_num=ypmf]Epoch 191:  70% 189/270 [02:10<-1:56:38, -0.40it/s, loss=0.0167, v_num=ypmf]Epoch 191:  70% 190/270 [02:11<-1:56:34, -0.39it/s, loss=0.0167, v_num=ypmf]Epoch 191:  70% 190/270 [02:11<-1:56:34, -0.39it/s, loss=0.0167, v_num=ypmf]Epoch 191:  70% 190/270 [02:11<-1:56:34, -0.39it/s, loss=0.0167, v_num=ypmf]Epoch 191:  71% 191/270 [02:11<-1:56:32, -0.38it/s, loss=0.0167, v_num=ypmf]Epoch 191:  71% 191/270 [02:11<-1:56:32, -0.38it/s, loss=0.0167, v_num=ypmf]Epoch 191:  71% 191/270 [02:12<-1:56:32, -0.38it/s, loss=0.0168, v_num=ypmf]Epoch 191:  71% 192/270 [02:12<-1:56:29, -0.37it/s, loss=0.0168, v_num=ypmf]Epoch 191:  71% 192/270 [02:12<-1:56:29, -0.37it/s, loss=0.0168, v_num=ypmf]Epoch 191:  71% 192/270 [02:12<-1:56:29, -0.37it/s, loss=0.0168, v_num=ypmf]Epoch 191:  71% 193/270 [02:14<-1:56:25, -0.36it/s, loss=0.0168, v_num=ypmf]Epoch 191:  71% 193/270 [02:14<-1:56:25, -0.36it/s, loss=0.0168, v_num=ypmf]Epoch 191:  71% 193/270 [02:14<-1:56:25, -0.36it/s, loss=0.0168, v_num=ypmf]Epoch 191:  72% 194/270 [02:14<-1:56:22, -0.35it/s, loss=0.0168, v_num=ypmf]Epoch 191:  72% 194/270 [02:14<-1:56:22, -0.35it/s, loss=0.0168, v_num=ypmf]Epoch 191:  72% 194/270 [02:15<-1:56:22, -0.35it/s, loss=0.017, v_num=ypmf] Epoch 191:  72% 195/270 [02:15<-1:56:20, -0.34it/s, loss=0.017, v_num=ypmf]Epoch 191:  72% 195/270 [02:15<-1:56:20, -0.34it/s, loss=0.017, v_num=ypmf]Epoch 191:  72% 195/270 [02:15<-1:56:19, -0.34it/s, loss=0.017, v_num=ypmf]Epoch 191:  73% 196/270 [02:16<-1:56:17, -0.33it/s, loss=0.017, v_num=ypmf]Epoch 191:  73% 196/270 [02:16<-1:56:17, -0.33it/s, loss=0.017, v_num=ypmf]Epoch 191:  73% 196/270 [02:16<-1:56:16, -0.33it/s, loss=0.0171, v_num=ypmf]Epoch 191:  73% 197/270 [02:16<-1:56:14, -0.32it/s, loss=0.0171, v_num=ypmf]Epoch 191:  73% 197/270 [02:16<-1:56:14, -0.32it/s, loss=0.0171, v_num=ypmf]Epoch 191:  73% 197/270 [02:16<-1:56:13, -0.32it/s, loss=0.0171, v_num=ypmf]Epoch 191:  73% 198/270 [02:17<-1:56:11, -0.31it/s, loss=0.0171, v_num=ypmf]Epoch 191:  73% 198/270 [02:17<-1:56:11, -0.31it/s, loss=0.0171, v_num=ypmf]Epoch 191:  73% 198/270 [02:17<-1:56:10, -0.31it/s, loss=0.0171, v_num=ypmf]Epoch 191:  74% 199/270 [02:17<-1:56:08, -0.30it/s, loss=0.0171, v_num=ypmf]Epoch 191:  74% 199/270 [02:17<-1:56:08, -0.30it/s, loss=0.0171, v_num=ypmf]Epoch 191:  74% 199/270 [02:17<-1:56:07, -0.30it/s, loss=0.0172, v_num=ypmf]Epoch 191:  74% 200/270 [02:18<-1:56:04, -0.30it/s, loss=0.0172, v_num=ypmf]Epoch 191:  74% 200/270 [02:18<-1:56:04, -0.30it/s, loss=0.0172, v_num=ypmf]Epoch 191:  74% 200/270 [02:18<-1:56:04, -0.30it/s, loss=0.0171, v_num=ypmf]Epoch 191:  74% 201/270 [02:18<-1:56:01, -0.29it/s, loss=0.0171, v_num=ypmf]Epoch 191:  74% 201/270 [02:18<-1:56:01, -0.29it/s, loss=0.0171, v_num=ypmf]Epoch 191:  74% 201/270 [02:19<-1:56:00, -0.29it/s, loss=0.0172, v_num=ypmf]Epoch 191:  75% 202/270 [02:20<-1:55:56, -0.28it/s, loss=0.0172, v_num=ypmf]Epoch 191:  75% 202/270 [02:20<-1:55:56, -0.28it/s, loss=0.0172, v_num=ypmf]Epoch 191:  75% 202/270 [02:20<-1:55:56, -0.28it/s, loss=0.0172, v_num=ypmf]Epoch 191:  75% 203/270 [02:20<-1:55:52, -0.27it/s, loss=0.0172, v_num=ypmf]Epoch 191:  75% 203/270 [02:20<-1:55:52, -0.27it/s, loss=0.0172, v_num=ypmf]Epoch 191:  75% 203/270 [02:20<-1:55:52, -0.27it/s, loss=0.0173, v_num=ypmf]Epoch 191:  76% 204/270 [02:21<-1:55:49, -0.26it/s, loss=0.0173, v_num=ypmf]Epoch 191:  76% 204/270 [02:21<-1:55:49, -0.26it/s, loss=0.0173, v_num=ypmf]Epoch 191:  76% 204/270 [02:21<-1:55:48, -0.26it/s, loss=0.0173, v_num=ypmf]Epoch 191:  76% 205/270 [02:21<-1:55:45, -0.25it/s, loss=0.0173, v_num=ypmf]Epoch 191:  76% 205/270 [02:21<-1:55:45, -0.25it/s, loss=0.0173, v_num=ypmf]Epoch 191:  76% 205/270 [02:21<-1:55:44, -0.25it/s, loss=0.0174, v_num=ypmf]Epoch 191:  76% 206/270 [02:22<-1:55:40, -0.25it/s, loss=0.0174, v_num=ypmf]Epoch 191:  76% 206/270 [02:22<-1:55:40, -0.25it/s, loss=0.0174, v_num=ypmf]Epoch 191:  76% 206/270 [02:22<-1:55:40, -0.25it/s, loss=0.0173, v_num=ypmf]Epoch 191:  77% 207/270 [02:22<-1:55:36, -0.24it/s, loss=0.0173, v_num=ypmf]Epoch 191:  77% 207/270 [02:22<-1:55:36, -0.24it/s, loss=0.0173, v_num=ypmf]Epoch 191:  77% 207/270 [02:23<-1:55:35, -0.24it/s, loss=0.0173, v_num=ypmf]Epoch 191:  77% 208/270 [02:23<-1:55:31, -0.23it/s, loss=0.0173, v_num=ypmf]Epoch 191:  77% 208/270 [02:23<-1:55:31, -0.23it/s, loss=0.0173, v_num=ypmf]Epoch 191:  77% 208/270 [02:23<-1:55:31, -0.23it/s, loss=0.0175, v_num=ypmf]Epoch 191:  77% 209/270 [02:24<-1:55:26, -0.22it/s, loss=0.0175, v_num=ypmf]Epoch 191:  77% 209/270 [02:24<-1:55:26, -0.22it/s, loss=0.0175, v_num=ypmf]Epoch 191:  77% 209/270 [02:24<-1:55:26, -0.22it/s, loss=0.0174, v_num=ypmf]Epoch 191:  78% 210/270 [02:24<-1:55:21, -0.21it/s, loss=0.0174, v_num=ypmf]Epoch 191:  78% 210/270 [02:24<-1:55:21, -0.21it/s, loss=0.0174, v_num=ypmf]Epoch 191:  78% 210/270 [02:24<-1:55:20, -0.21it/s, loss=0.0174, v_num=ypmf]Epoch 191:  78% 211/270 [02:25<-1:55:15, -0.21it/s, loss=0.0174, v_num=ypmf]Epoch 191:  78% 211/270 [02:25<-1:55:15, -0.21it/s, loss=0.0174, v_num=ypmf]Epoch 191:  78% 211/270 [02:25<-1:55:15, -0.21it/s, loss=0.0173, v_num=ypmf]Epoch 191:  79% 212/270 [02:25<-1:55:09, -0.20it/s, loss=0.0173, v_num=ypmf]Epoch 191:  79% 212/270 [02:25<-1:55:09, -0.20it/s, loss=0.0173, v_num=ypmf]Epoch 191:  79% 212/270 [02:25<-1:55:09, -0.20it/s, loss=0.0173, v_num=ypmf]Epoch 191:  79% 213/270 [02:26<-1:55:03, -0.19it/s, loss=0.0173, v_num=ypmf]Epoch 191:  79% 213/270 [02:26<-1:55:03, -0.19it/s, loss=0.0173, v_num=ypmf]Epoch 191:  79% 213/270 [02:26<-1:55:02, -0.19it/s, loss=0.0173, v_num=ypmf]Epoch 191:  79% 214/270 [02:26<-1:54:56, -0.18it/s, loss=0.0173, v_num=ypmf]Epoch 191:  79% 214/270 [02:26<-1:54:56, -0.18it/s, loss=0.0173, v_num=ypmf]Epoch 191:  79% 214/270 [02:26<-1:54:56, -0.18it/s, loss=0.0173, v_num=ypmf]Epoch 191:  80% 215/270 [02:27<-1:54:49, -0.18it/s, loss=0.0173, v_num=ypmf]Epoch 191:  80% 215/270 [02:27<-1:54:49, -0.18it/s, loss=0.0173, v_num=ypmf]Epoch 191:  80% 215/270 [02:27<-1:54:48, -0.18it/s, loss=0.0173, v_num=ypmf]Epoch 191:  80% 216/270 [02:28<-1:54:40, -0.17it/s, loss=0.0173, v_num=ypmf]Epoch 191:  80% 216/270 [02:28<-1:54:40, -0.17it/s, loss=0.0173, v_num=ypmf]Epoch 191:  80% 216/270 [02:28<-1:54:40, -0.17it/s, loss=0.0171, v_num=ypmf]Epoch 191:  80% 217/270 [02:28<-1:54:33, -0.16it/s, loss=0.0171, v_num=ypmf]Epoch 191:  80% 217/270 [02:28<-1:54:33, -0.16it/s, loss=0.0171, v_num=ypmf]Epoch 191:  80% 217/270 [02:28<-1:54:32, -0.16it/s, loss=0.0172, v_num=ypmf]Epoch 191:  81% 218/270 [02:29<-1:54:23, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 191:  81% 218/270 [02:29<-1:54:23, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 191:  81% 218/270 [02:29<-1:54:23, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 191:  81% 219/270 [02:29<-1:54:13, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 191:  81% 219/270 [02:29<-1:54:13, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 191:  81% 219/270 [02:30<-1:54:13, -0.15it/s, loss=0.0171, v_num=ypmf]Epoch 191:  81% 220/270 [02:30<-1:54:02, -0.14it/s, loss=0.0171, v_num=ypmf]Epoch 191:  81% 220/270 [02:30<-1:54:02, -0.14it/s, loss=0.0171, v_num=ypmf]Epoch 191:  81% 220/270 [02:30<-1:54:01, -0.14it/s, loss=0.0171, v_num=ypmf]Epoch 191:  82% 221/270 [02:31<-1:53:50, -0.13it/s, loss=0.0171, v_num=ypmf]Epoch 191:  82% 221/270 [02:31<-1:53:50, -0.13it/s, loss=0.0171, v_num=ypmf]Epoch 191:  82% 221/270 [02:31<-1:53:50, -0.13it/s, loss=0.0171, v_num=ypmf]Epoch 191:  82% 222/270 [02:31<-1:53:37, -0.13it/s, loss=0.0171, v_num=ypmf]Epoch 191:  82% 222/270 [02:31<-1:53:37, -0.13it/s, loss=0.0171, v_num=ypmf]Epoch 191:  82% 222/270 [02:31<-1:53:37, -0.13it/s, loss=0.0171, v_num=ypmf]Epoch 191:  83% 223/270 [02:32<-1:53:23, -0.12it/s, loss=0.0171, v_num=ypmf]Epoch 191:  83% 223/270 [02:32<-1:53:23, -0.12it/s, loss=0.0171, v_num=ypmf]Epoch 191:  83% 223/270 [02:32<-1:53:23, -0.12it/s, loss=0.0172, v_num=ypmf]Epoch 191:  83% 224/270 [02:32<-1:53:07, -0.11it/s, loss=0.0172, v_num=ypmf]Epoch 191:  83% 224/270 [02:32<-1:53:07, -0.11it/s, loss=0.0172, v_num=ypmf]Epoch 191:  83% 224/270 [02:32<-1:53:07, -0.11it/s, loss=0.0171, v_num=ypmf]Epoch 191:  83% 225/270 [02:33<-1:52:49, -0.10it/s, loss=0.0171, v_num=ypmf]Epoch 191:  83% 225/270 [02:33<-1:52:49, -0.10it/s, loss=0.0171, v_num=ypmf]Epoch 191:  83% 225/270 [02:33<-1:52:49, -0.10it/s, loss=0.0171, v_num=ypmf]Epoch 191:  84% 226/270 [02:34<-1:52:28, -0.10it/s, loss=0.0171, v_num=ypmf]Epoch 191:  84% 226/270 [02:34<-1:52:28, -0.10it/s, loss=0.0171, v_num=ypmf]Epoch 191:  84% 226/270 [02:34<-1:52:28, -0.10it/s, loss=0.017, v_num=ypmf] Epoch 191:  84% 227/270 [02:34<-1:52:06, -0.09it/s, loss=0.017, v_num=ypmf]Epoch 191:  84% 227/270 [02:34<-1:52:06, -0.09it/s, loss=0.017, v_num=ypmf]Epoch 191:  84% 227/270 [02:35<-1:52:03, -0.09it/s, loss=0.017, v_num=ypmf]Epoch 191:  84% 228/270 [02:35<-1:51:37, -0.08it/s, loss=0.017, v_num=ypmf]Epoch 191:  84% 228/270 [02:35<-1:51:37, -0.08it/s, loss=0.017, v_num=ypmf]Epoch 191:  84% 228/270 [02:35<-1:51:37, -0.08it/s, loss=0.0168, v_num=ypmf]Epoch 191:  85% 229/270 [02:36<-1:51:06, -0.08it/s, loss=0.0168, v_num=ypmf]Epoch 191:  85% 229/270 [02:36<-1:51:06, -0.08it/s, loss=0.0168, v_num=ypmf]Epoch 191:  85% 229/270 [02:36<-1:51:06, -0.08it/s, loss=0.0168, v_num=ypmf]Epoch 191:  85% 230/270 [02:36<-1:50:30, -0.07it/s, loss=0.0168, v_num=ypmf]Epoch 191:  85% 230/270 [02:36<-1:50:30, -0.07it/s, loss=0.0168, v_num=ypmf]Epoch 191:  85% 230/270 [02:37<-1:50:29, -0.07it/s, loss=0.0167, v_num=ypmf]Epoch 191:  86% 231/270 [02:37<-1:49:46, -0.06it/s, loss=0.0167, v_num=ypmf]Epoch 191:  86% 231/270 [02:37<-1:49:46, -0.06it/s, loss=0.0167, v_num=ypmf]Epoch 191:  86% 231/270 [02:37<-1:49:46, -0.06it/s, loss=0.0167, v_num=ypmf]Epoch 191:  86% 232/270 [02:38<-1:48:53, -0.06it/s, loss=0.0167, v_num=ypmf]Epoch 191:  86% 232/270 [02:38<-1:48:53, -0.06it/s, loss=0.0167, v_num=ypmf]Epoch 191:  86% 232/270 [02:38<-1:48:52, -0.06it/s, loss=0.0168, v_num=ypmf]Epoch 191:  86% 233/270 [02:38<-1:47:47, -0.05it/s, loss=0.0168, v_num=ypmf]Epoch 191:  86% 233/270 [02:38<-1:47:47, -0.05it/s, loss=0.0168, v_num=ypmf]Epoch 191:  86% 233/270 [02:38<-1:47:45, -0.05it/s, loss=0.0167, v_num=ypmf]Epoch 191:  87% 234/270 [02:39<-1:46:21, -0.04it/s, loss=0.0167, v_num=ypmf]Epoch 191:  87% 234/270 [02:39<-1:46:21, -0.04it/s, loss=0.0167, v_num=ypmf]Epoch 191:  87% 234/270 [02:39<-1:46:20, -0.04it/s, loss=0.0167, v_num=ypmf]Epoch 191:  87% 235/270 [02:40<-1:44:27, -0.04it/s, loss=0.0167, v_num=ypmf]Epoch 191:  87% 235/270 [02:40<-1:44:27, -0.04it/s, loss=0.0167, v_num=ypmf]Epoch 191:  87% 235/270 [02:40<-1:44:26, -0.04it/s, loss=0.0167, v_num=ypmf]Epoch 191:  87% 236/270 [02:40<-1:41:48, -0.03it/s, loss=0.0167, v_num=ypmf]Epoch 191:  87% 236/270 [02:40<-1:41:48, -0.03it/s, loss=0.0167, v_num=ypmf]Epoch 191:  87% 236/270 [02:40<-1:41:47, -0.03it/s, loss=0.0167, v_num=ypmf]Epoch 191:  88% 237/270 [02:41<-1:37:51, -0.02it/s, loss=0.0167, v_num=ypmf]Epoch 191:  88% 237/270 [02:41<-1:37:51, -0.02it/s, loss=0.0167, v_num=ypmf]Epoch 191:  88% 237/270 [02:41<-1:37:50, -0.02it/s, loss=0.0167, v_num=ypmf]Epoch 191:  88% 238/270 [02:41<-1:31:17, -0.02it/s, loss=0.0167, v_num=ypmf]Epoch 191:  88% 238/270 [02:41<-1:31:17, -0.02it/s, loss=0.0167, v_num=ypmf]Epoch 191:  88% 238/270 [02:41<-1:31:14, -0.02it/s, loss=0.0167, v_num=ypmf]Epoch 191:  89% 239/270 [02:42<-1:17:59, -0.01it/s, loss=0.0167, v_num=ypmf]Epoch 191:  89% 239/270 [02:42<-1:17:59, -0.01it/s, loss=0.0167, v_num=ypmf]Epoch 191:  89% 239/270 [02:42<-1:17:56, -0.01it/s, loss=0.0167, v_num=ypmf]Epoch 191:  89% 240/270 [02:43<-2:38:24, -0.01it/s, loss=0.0167, v_num=ypmf]Epoch 191:  89% 240/270 [02:43<-2:38:24, -0.01it/s, loss=0.0167, v_num=ypmf]Epoch 191:  89% 240/270 [02:43<-2:38:18, -0.01it/s, loss=0.0167, v_num=ypmf]Epoch 191:  89% 241/270 [02:43<?, ?it/s, loss=0.0167, v_num=ypmf]           Epoch 191:  89% 241/270 [02:43<?, ?it/s, loss=0.0167, v_num=ypmf]Epoch 191:  89% 241/270 [02:43<?, ?it/s, loss=0.0167, v_num=ypmf]Epoch 191:  90% 242/270 [02:44<1:16:42, 164.38s/it, loss=0.0167, v_num=ypmf]Epoch 191:  90% 242/270 [02:44<1:16:42, 164.38s/it, loss=0.0167, v_num=ypmf]Epoch 191:  90% 242/270 [02:44<1:16:48, 164.58s/it, loss=0.0167, v_num=ypmf]Epoch 191:  90% 243/270 [02:44<37:06, 82.45s/it, loss=0.0167, v_num=ypmf]   Epoch 191:  90% 243/270 [02:44<37:06, 82.45s/it, loss=0.0167, v_num=ypmf]Epoch 191:  90% 243/270 [02:45<37:09, 82.58s/it, loss=0.0167, v_num=ypmf]Epoch 191:  90% 244/270 [02:45<23:54, 55.19s/it, loss=0.0167, v_num=ypmf]Epoch 191:  90% 244/270 [02:45<23:54, 55.19s/it, loss=0.0167, v_num=ypmf]Epoch 191:  90% 244/270 [02:45<23:56, 55.24s/it, loss=0.0168, v_num=ypmf]Epoch 191:  91% 245/270 [02:46<17:17, 41.52s/it, loss=0.0168, v_num=ypmf]Epoch 191:  91% 245/270 [02:46<17:17, 41.52s/it, loss=0.0168, v_num=ypmf]Epoch 191:  91% 245/270 [02:46<17:19, 41.57s/it, loss=0.0168, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 286025. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 329923. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 289753. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 254495. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 382843. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 302448. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319139. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 280420. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 320836. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 287990. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 338197. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 343835. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 273501. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 287757. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 288261. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 332022. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 342330. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 349988. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 272668. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 298957. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293505. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 294353. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 307360. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 273471. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 335412. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 191:  91% 246/270 [02:46<13:20, 33.35s/it, loss=0.0168, v_num=ypmf]Epoch 191:  91% 246/270 [02:46<13:20, 33.35s/it, loss=0.0168, v_num=ypmf]Epoch 191:  91% 246/270 [02:46<13:21, 33.39s/it, loss=0.0169, v_num=ypmf]Epoch 191:  91% 247/270 [02:47<10:41, 27.89s/it, loss=0.0169, v_num=ypmf]Epoch 191:  91% 247/270 [02:47<10:41, 27.89s/it, loss=0.0169, v_num=ypmf]Epoch 191:  91% 247/270 [02:47<10:42, 27.91s/it, loss=0.0169, v_num=ypmf]Epoch 191:  92% 248/270 [02:47<08:47, 23.98s/it, loss=0.0169, v_num=ypmf]Epoch 191:  92% 248/270 [02:47<08:47, 23.98s/it, loss=0.0169, v_num=ypmf]Epoch 191:  92% 248/270 [02:47<08:47, 24.00s/it, loss=0.0169, v_num=ypmf]Epoch 191:  92% 249/270 [02:48<07:21, 21.04s/it, loss=0.0169, v_num=ypmf]Epoch 191:  92% 249/270 [02:48<07:21, 21.04s/it, loss=0.0169, v_num=ypmf]Epoch 191:  92% 249/270 [02:48<07:22, 21.06s/it, loss=0.017, v_num=ypmf] Epoch 191:  93% 250/270 [02:48<06:15, 18.76s/it, loss=0.017, v_num=ypmf]Epoch 191:  93% 250/270 [02:48<06:15, 18.76s/it, loss=0.017, v_num=ypmf]Epoch 191:  93% 250/270 [02:49<06:15, 18.79s/it, loss=0.017, v_num=ypmf]
Validation: 0it [00:00, ?it/s][A
Validation:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.27it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.27it/s][AEpoch 191:  93% 251/270 [02:49<05:22, 16.98s/it, loss=0.017, v_num=ypmf]Epoch 191:  93% 251/270 [02:49<05:22, 16.98s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  10% 2/20 [00:02<00:24,  1.35s/it][A
Validation DataLoader 0:  10% 2/20 [00:02<00:24,  1.35s/it][AEpoch 191:  93% 252/270 [02:51<04:41, 15.62s/it, loss=0.017, v_num=ypmf]Epoch 191:  93% 252/270 [02:51<04:41, 15.62s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  15% 3/20 [00:03<00:23,  1.41s/it][A
Validation DataLoader 0:  15% 3/20 [00:03<00:23,  1.41s/it][AEpoch 191:  94% 253/270 [02:53<04:05, 14.44s/it, loss=0.017, v_num=ypmf]Epoch 191:  94% 253/270 [02:53<04:05, 14.44s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  20% 4/20 [00:04<00:18,  1.14s/it][A
Validation DataLoader 0:  20% 4/20 [00:04<00:18,  1.14s/it][AEpoch 191:  94% 254/270 [02:53<03:34, 13.38s/it, loss=0.017, v_num=ypmf]Epoch 191:  94% 254/270 [02:53<03:34, 13.38s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  25% 5/20 [00:06<00:18,  1.26s/it][A
Validation DataLoader 0:  25% 5/20 [00:06<00:18,  1.26s/it][AEpoch 191:  94% 255/270 [02:55<03:07, 12.53s/it, loss=0.017, v_num=ypmf]Epoch 191:  94% 255/270 [02:55<03:07, 12.53s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  30% 6/20 [00:07<00:16,  1.17s/it][A
Validation DataLoader 0:  30% 6/20 [00:07<00:16,  1.17s/it][AEpoch 191:  95% 256/270 [02:56<02:44, 11.76s/it, loss=0.017, v_num=ypmf]Epoch 191:  95% 256/270 [02:56<02:44, 11.76s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  35% 7/20 [00:08<00:15,  1.16s/it][A
Validation DataLoader 0:  35% 7/20 [00:08<00:15,  1.16s/it][AEpoch 191:  95% 257/270 [02:57<02:24, 11.10s/it, loss=0.017, v_num=ypmf]Epoch 191:  95% 257/270 [02:57<02:24, 11.10s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  40% 8/20 [00:10<00:18,  1.54s/it][A
Validation DataLoader 0:  40% 8/20 [00:10<00:18,  1.54s/it][AEpoch 191:  96% 258/270 [02:59<02:07, 10.58s/it, loss=0.017, v_num=ypmf]Epoch 191:  96% 258/270 [02:59<02:07, 10.58s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  45% 9/20 [00:11<00:14,  1.29s/it][A
Validation DataLoader 0:  45% 9/20 [00:11<00:14,  1.29s/it][AEpoch 191:  96% 259/270 [03:00<01:50, 10.04s/it, loss=0.017, v_num=ypmf]Epoch 191:  96% 259/270 [03:00<01:50, 10.04s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  50% 10/20 [00:11<00:10,  1.06s/it][A
Validation DataLoader 0:  50% 10/20 [00:11<00:10,  1.06s/it][AEpoch 191:  96% 260/270 [03:01<01:35,  9.54s/it, loss=0.017, v_num=ypmf]Epoch 191:  96% 260/270 [03:01<01:35,  9.54s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  55% 11/20 [00:12<00:08,  1.03it/s][A
Validation DataLoader 0:  55% 11/20 [00:12<00:08,  1.03it/s][AEpoch 191:  97% 261/270 [03:01<01:21,  9.10s/it, loss=0.017, v_num=ypmf]Epoch 191:  97% 261/270 [03:01<01:21,  9.10s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  60% 12/20 [00:13<00:08,  1.05s/it][A
Validation DataLoader 0:  60% 12/20 [00:13<00:08,  1.05s/it][AEpoch 191:  97% 262/270 [03:03<01:09,  8.72s/it, loss=0.017, v_num=ypmf]Epoch 191:  97% 262/270 [03:03<01:09,  8.72s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  65% 13/20 [00:14<00:06,  1.01it/s][A
Validation DataLoader 0:  65% 13/20 [00:14<00:06,  1.01it/s][AEpoch 191:  97% 263/270 [03:04<00:58,  8.37s/it, loss=0.017, v_num=ypmf]Epoch 191:  97% 263/270 [03:04<00:58,  8.37s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  70% 14/20 [00:15<00:05,  1.11it/s][A
Validation DataLoader 0:  70% 14/20 [00:15<00:05,  1.11it/s][AEpoch 191:  98% 264/270 [03:04<00:48,  8.03s/it, loss=0.017, v_num=ypmf]Epoch 191:  98% 264/270 [03:04<00:48,  8.03s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  75% 15/20 [00:16<00:05,  1.09s/it][A
Validation DataLoader 0:  75% 15/20 [00:16<00:05,  1.09s/it][AEpoch 191:  98% 265/270 [03:06<00:38,  7.76s/it, loss=0.017, v_num=ypmf]Epoch 191:  98% 265/270 [03:06<00:38,  7.76s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  80% 16/20 [00:18<00:05,  1.26s/it][A
Validation DataLoader 0:  80% 16/20 [00:18<00:05,  1.26s/it][AEpoch 191:  99% 266/270 [03:07<00:30,  7.52s/it, loss=0.017, v_num=ypmf]Epoch 191:  99% 266/270 [03:07<00:30,  7.52s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  85% 17/20 [00:19<00:03,  1.27s/it][A
Validation DataLoader 0:  85% 17/20 [00:19<00:03,  1.27s/it][AEpoch 191:  99% 267/270 [03:09<00:21,  7.28s/it, loss=0.017, v_num=ypmf]Epoch 191:  99% 267/270 [03:09<00:21,  7.28s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  90% 18/20 [00:20<00:02,  1.10s/it][A
Validation DataLoader 0:  90% 18/20 [00:20<00:02,  1.10s/it][AEpoch 191:  99% 268/270 [03:09<00:14,  7.03s/it, loss=0.017, v_num=ypmf]Epoch 191:  99% 268/270 [03:09<00:14,  7.03s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  95% 19/20 [00:21<00:01,  1.06s/it][A
Validation DataLoader 0:  95% 19/20 [00:21<00:01,  1.06s/it][AEpoch 191: 100% 269/270 [03:10<00:06,  6.82s/it, loss=0.017, v_num=ypmf]Epoch 191: 100% 269/270 [03:10<00:06,  6.82s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0: 100% 20/20 [00:22<00:00,  1.09it/s][A
Validation DataLoader 0: 100% 20/20 [00:22<00:00,  1.09it/s][AEpoch 191: 100% 270/270 [03:11<00:00,  6.60s/it, loss=0.017, v_num=ypmf]Epoch 191: 100% 270/270 [03:11<00:00,  6.60s/it, loss=0.017, v_num=ypmf]Epoch 191: 100% 270/270 [03:13<00:00,  6.69s/it, loss=0.017, v_num=ypmf]
                                                            [AEpoch 191: 100% 270/270 [03:13<00:00,  6.69s/it, loss=0.017, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 191:   0% 0/270 [00:00<00:00, -5809352.09it/s, loss=0.017, v_num=ypmf]Epoch 192:   0% 0/270 [00:00<00:00, -1567174.05it/s, loss=0.017, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 192:   0% 1/270 [00:02<-1:59:58, -98.02it/s, loss=0.017, v_num=ypmf]  Epoch 192:   0% 1/270 [00:02<-1:59:58, -98.01it/s, loss=0.017, v_num=ypmf]Epoch 192:   0% 1/270 [00:02<-1:59:58, -92.50it/s, loss=0.017, v_num=ypmf]Epoch 192:   1% 2/270 [00:03<-1:59:57, -79.65it/s, loss=0.017, v_num=ypmf]Epoch 192:   1% 2/270 [00:03<-1:59:57, -79.65it/s, loss=0.017, v_num=ypmf]Epoch 192:   1% 2/270 [00:03<-1:59:57, -75.07it/s, loss=0.0169, v_num=ypmf]Epoch 192:   1% 3/270 [00:03<-1:59:57, -67.55it/s, loss=0.0169, v_num=ypmf]Epoch 192:   1% 3/270 [00:03<-1:59:57, -67.55it/s, loss=0.0169, v_num=ypmf]Epoch 192:   1% 3/270 [00:03<-1:59:56, -60.71it/s, loss=0.0169, v_num=ypmf]Epoch 192:   1% 4/270 [00:04<-1:59:56, -53.77it/s, loss=0.0169, v_num=ypmf]Epoch 192:   1% 4/270 [00:04<-1:59:56, -53.76it/s, loss=0.0169, v_num=ypmf]Epoch 192:   1% 4/270 [00:04<-1:59:55, -51.93it/s, loss=0.017, v_num=ypmf] Epoch 192:   2% 5/270 [00:04<-1:59:55, -48.05it/s, loss=0.017, v_num=ypmf]Epoch 192:   2% 5/270 [00:04<-1:59:55, -48.05it/s, loss=0.017, v_num=ypmf]Epoch 192:   2% 5/270 [00:05<-1:59:55, -46.94it/s, loss=0.0171, v_num=ypmf]Epoch 192:   2% 6/270 [00:05<-1:59:54, -43.14it/s, loss=0.0171, v_num=ypmf]Epoch 192:   2% 6/270 [00:05<-1:59:54, -43.13it/s, loss=0.0171, v_num=ypmf]Epoch 192:   2% 6/270 [00:05<-1:59:54, -42.05it/s, loss=0.0171, v_num=ypmf]Epoch 192:   3% 7/270 [00:05<-1:59:54, -39.91it/s, loss=0.0171, v_num=ypmf]Epoch 192:   3% 7/270 [00:05<-1:59:54, -39.91it/s, loss=0.0171, v_num=ypmf]Epoch 192:   3% 7/270 [00:06<-1:59:54, -37.67it/s, loss=0.017, v_num=ypmf] Epoch 192:   3% 8/270 [00:06<-1:59:53, -35.64it/s, loss=0.017, v_num=ypmf]Epoch 192:   3% 8/270 [00:06<-1:59:53, -35.64it/s, loss=0.017, v_num=ypmf]Epoch 192:   3% 8/270 [00:06<-1:59:53, -34.94it/s, loss=0.0169, v_num=ypmf]Epoch 192:   3% 9/270 [00:07<-1:59:53, -32.84it/s, loss=0.0169, v_num=ypmf]Epoch 192:   3% 9/270 [00:07<-1:59:53, -32.84it/s, loss=0.0169, v_num=ypmf]Epoch 192:   3% 9/270 [00:07<-1:59:52, -32.24it/s, loss=0.0169, v_num=ypmf]Epoch 192:   4% 10/270 [00:07<-1:59:52, -30.66it/s, loss=0.0169, v_num=ypmf]Epoch 192:   4% 10/270 [00:07<-1:59:52, -30.66it/s, loss=0.0169, v_num=ypmf]Epoch 192:   4% 10/270 [00:07<-1:59:52, -29.67it/s, loss=0.0169, v_num=ypmf]Epoch 192:   4% 11/270 [00:08<-1:59:51, -28.09it/s, loss=0.0169, v_num=ypmf]Epoch 192:   4% 11/270 [00:08<-1:59:51, -28.09it/s, loss=0.0169, v_num=ypmf]Epoch 192:   4% 11/270 [00:08<-1:59:51, -27.49it/s, loss=0.0168, v_num=ypmf]Epoch 192:   4% 12/270 [00:08<-1:59:51, -26.09it/s, loss=0.0168, v_num=ypmf]Epoch 192:   4% 12/270 [00:08<-1:59:51, -26.09it/s, loss=0.0168, v_num=ypmf]Epoch 192:   4% 12/270 [00:09<-1:59:50, -24.69it/s, loss=0.0167, v_num=ypmf]Epoch 192:   5% 13/270 [00:09<-1:59:50, -23.53it/s, loss=0.0167, v_num=ypmf]Epoch 192:   5% 13/270 [00:09<-1:59:50, -23.53it/s, loss=0.0167, v_num=ypmf]Epoch 192:   5% 13/270 [00:09<-1:59:49, -23.11it/s, loss=0.0166, v_num=ypmf]Epoch 192:   5% 14/270 [00:10<-1:59:49, -22.26it/s, loss=0.0166, v_num=ypmf]Epoch 192:   5% 14/270 [00:10<-1:59:49, -22.26it/s, loss=0.0166, v_num=ypmf]Epoch 192:   5% 14/270 [00:10<-1:59:48, -20.97it/s, loss=0.0167, v_num=ypmf]Epoch 192:   6% 15/270 [00:11<-1:59:48, -20.19it/s, loss=0.0167, v_num=ypmf]Epoch 192:   6% 15/270 [00:11<-1:59:48, -20.19it/s, loss=0.0167, v_num=ypmf]Epoch 192:   6% 15/270 [00:11<-1:59:48, -19.73it/s, loss=0.0167, v_num=ypmf]Epoch 192:   6% 16/270 [00:11<-1:59:47, -18.77it/s, loss=0.0167, v_num=ypmf]Epoch 192:   6% 16/270 [00:11<-1:59:47, -18.77it/s, loss=0.0167, v_num=ypmf]Epoch 192:   6% 16/270 [00:11<-1:59:47, -18.75it/s, loss=0.0166, v_num=ypmf]Epoch 192:   6% 17/270 [00:12<-1:59:47, -18.11it/s, loss=0.0166, v_num=ypmf]Epoch 192:   6% 17/270 [00:12<-1:59:47, -18.11it/s, loss=0.0166, v_num=ypmf]Epoch 192:   6% 17/270 [00:12<-1:59:46, -17.91it/s, loss=0.0167, v_num=ypmf]Epoch 192:   7% 18/270 [00:12<-1:59:46, -17.26it/s, loss=0.0167, v_num=ypmf]Epoch 192:   7% 18/270 [00:12<-1:59:46, -17.26it/s, loss=0.0167, v_num=ypmf]Epoch 192:   7% 18/270 [00:13<-1:59:46, -16.84it/s, loss=0.0167, v_num=ypmf]Epoch 192:   7% 19/270 [00:13<-1:59:45, -16.33it/s, loss=0.0167, v_num=ypmf]Epoch 192:   7% 19/270 [00:13<-1:59:45, -16.33it/s, loss=0.0167, v_num=ypmf]Epoch 192:   7% 19/270 [00:13<-1:59:45, -16.07it/s, loss=0.0167, v_num=ypmf]Epoch 192:   7% 20/270 [00:14<-1:59:44, -15.61it/s, loss=0.0167, v_num=ypmf]Epoch 192:   7% 20/270 [00:14<-1:59:44, -15.61it/s, loss=0.0167, v_num=ypmf]Epoch 192:   7% 20/270 [00:14<-1:59:44, -15.45it/s, loss=0.0168, v_num=ypmf]Epoch 192:   8% 21/270 [00:14<-1:59:44, -14.96it/s, loss=0.0168, v_num=ypmf]Epoch 192:   8% 21/270 [00:14<-1:59:44, -14.96it/s, loss=0.0168, v_num=ypmf]Epoch 192:   8% 21/270 [00:14<-1:59:44, -14.83it/s, loss=0.0169, v_num=ypmf]Epoch 192:   8% 22/270 [00:15<-1:59:43, -14.36it/s, loss=0.0169, v_num=ypmf]Epoch 192:   8% 22/270 [00:15<-1:59:43, -14.36it/s, loss=0.0169, v_num=ypmf]Epoch 192:   8% 22/270 [00:15<-1:59:43, -14.24it/s, loss=0.0169, v_num=ypmf]Epoch 192:   9% 23/270 [00:15<-1:59:43, -13.84it/s, loss=0.0169, v_num=ypmf]Epoch 192:   9% 23/270 [00:15<-1:59:43, -13.84it/s, loss=0.0169, v_num=ypmf]Epoch 192:   9% 23/270 [00:15<-1:59:43, -13.73it/s, loss=0.0169, v_num=ypmf]Epoch 192:   9% 24/270 [00:16<-1:59:42, -13.44it/s, loss=0.0169, v_num=ypmf]Epoch 192:   9% 24/270 [00:16<-1:59:42, -13.44it/s, loss=0.0169, v_num=ypmf]Epoch 192:   9% 24/270 [00:16<-1:59:42, -13.24it/s, loss=0.0169, v_num=ypmf]Epoch 192:   9% 25/270 [00:16<-1:59:41, -12.89it/s, loss=0.0169, v_num=ypmf]Epoch 192:   9% 25/270 [00:16<-1:59:41, -12.89it/s, loss=0.0169, v_num=ypmf]Epoch 192:   9% 25/270 [00:16<-1:59:41, -12.72it/s, loss=0.0168, v_num=ypmf]Epoch 192:  10% 26/270 [00:17<-1:59:41, -12.43it/s, loss=0.0168, v_num=ypmf]Epoch 192:  10% 26/270 [00:17<-1:59:41, -12.43it/s, loss=0.0168, v_num=ypmf]Epoch 192:  10% 26/270 [00:17<-1:59:41, -12.30it/s, loss=0.0169, v_num=ypmf]Epoch 192:  10% 27/270 [00:17<-1:59:40, -11.99it/s, loss=0.0169, v_num=ypmf]Epoch 192:  10% 27/270 [00:17<-1:59:40, -11.99it/s, loss=0.0169, v_num=ypmf]Epoch 192:  10% 27/270 [00:18<-1:59:40, -11.81it/s, loss=0.017, v_num=ypmf] Epoch 192:  10% 28/270 [00:18<-1:59:39, -11.46it/s, loss=0.017, v_num=ypmf]Epoch 192:  10% 28/270 [00:18<-1:59:39, -11.46it/s, loss=0.017, v_num=ypmf]Epoch 192:  10% 28/270 [00:18<-1:59:39, -11.37it/s, loss=0.017, v_num=ypmf]Epoch 192:  11% 29/270 [00:19<-1:59:39, -11.11it/s, loss=0.017, v_num=ypmf]Epoch 192:  11% 29/270 [00:19<-1:59:39, -11.11it/s, loss=0.017, v_num=ypmf]Epoch 192:  11% 29/270 [00:19<-1:59:39, -10.98it/s, loss=0.017, v_num=ypmf]Epoch 192:  11% 30/270 [00:19<-1:59:38, -10.71it/s, loss=0.017, v_num=ypmf]Epoch 192:  11% 30/270 [00:19<-1:59:38, -10.71it/s, loss=0.017, v_num=ypmf]Epoch 192:  11% 30/270 [00:19<-1:59:38, -10.63it/s, loss=0.017, v_num=ypmf]Epoch 192:  11% 31/270 [00:20<-1:59:38, -10.42it/s, loss=0.017, v_num=ypmf]Epoch 192:  11% 31/270 [00:20<-1:59:38, -10.42it/s, loss=0.017, v_num=ypmf]Epoch 192:  11% 31/270 [00:20<-1:59:37, -10.28it/s, loss=0.0172, v_num=ypmf]Epoch 192:  12% 32/270 [00:20<-1:59:37, -10.04it/s, loss=0.0172, v_num=ypmf]Epoch 192:  12% 32/270 [00:20<-1:59:37, -10.04it/s, loss=0.0172, v_num=ypmf]Epoch 192:  12% 32/270 [00:20<-1:59:37, -9.98it/s, loss=0.0172, v_num=ypmf] Epoch 192:  12% 33/270 [00:21<-1:59:36, -9.73it/s, loss=0.0172, v_num=ypmf]Epoch 192:  12% 33/270 [00:21<-1:59:36, -9.73it/s, loss=0.0172, v_num=ypmf]Epoch 192:  12% 33/270 [00:21<-1:59:36, -9.60it/s, loss=0.0171, v_num=ypmf]Epoch 192:  13% 34/270 [00:22<-1:59:35, -9.35it/s, loss=0.0171, v_num=ypmf]Epoch 192:  13% 34/270 [00:22<-1:59:35, -9.35it/s, loss=0.0171, v_num=ypmf]Epoch 192:  13% 34/270 [00:22<-1:59:35, -9.29it/s, loss=0.017, v_num=ypmf] Epoch 192:  13% 35/270 [00:22<-1:59:35, -9.09it/s, loss=0.017, v_num=ypmf]Epoch 192:  13% 35/270 [00:22<-1:59:35, -9.09it/s, loss=0.017, v_num=ypmf]Epoch 192:  13% 35/270 [00:22<-1:59:34, -9.03it/s, loss=0.017, v_num=ypmf]Epoch 192:  13% 36/270 [00:23<-1:59:34, -8.84it/s, loss=0.017, v_num=ypmf]Epoch 192:  13% 36/270 [00:23<-1:59:34, -8.84it/s, loss=0.017, v_num=ypmf]Epoch 192:  13% 36/270 [00:23<-1:59:34, -8.77it/s, loss=0.0171, v_num=ypmf]Epoch 192:  14% 37/270 [00:23<-1:59:33, -8.55it/s, loss=0.0171, v_num=ypmf]Epoch 192:  14% 37/270 [00:23<-1:59:33, -8.55it/s, loss=0.0171, v_num=ypmf]Epoch 192:  14% 37/270 [00:23<-1:59:33, -8.50it/s, loss=0.017, v_num=ypmf] Epoch 192:  14% 38/270 [00:24<-1:59:33, -8.36it/s, loss=0.017, v_num=ypmf]Epoch 192:  14% 38/270 [00:24<-1:59:33, -8.36it/s, loss=0.017, v_num=ypmf]Epoch 192:  14% 38/270 [00:24<-1:59:33, -8.30it/s, loss=0.017, v_num=ypmf]Epoch 192:  14% 39/270 [00:24<-1:59:32, -8.11it/s, loss=0.017, v_num=ypmf]Epoch 192:  14% 39/270 [00:24<-1:59:32, -8.11it/s, loss=0.017, v_num=ypmf]Epoch 192:  14% 39/270 [00:25<-1:59:32, -8.07it/s, loss=0.0169, v_num=ypmf]Epoch 192:  15% 40/270 [00:25<-1:59:31, -7.92it/s, loss=0.0169, v_num=ypmf]Epoch 192:  15% 40/270 [00:25<-1:59:31, -7.92it/s, loss=0.0169, v_num=ypmf]Epoch 192:  15% 40/270 [00:25<-1:59:31, -7.83it/s, loss=0.0167, v_num=ypmf]Epoch 192:  15% 41/270 [00:26<-1:59:31, -7.64it/s, loss=0.0167, v_num=ypmf]Epoch 192:  15% 41/270 [00:26<-1:59:31, -7.64it/s, loss=0.0167, v_num=ypmf]Epoch 192:  15% 41/270 [00:26<-1:59:30, -7.60it/s, loss=0.0168, v_num=ypmf]Epoch 192:  16% 42/270 [00:26<-1:59:30, -7.47it/s, loss=0.0168, v_num=ypmf]Epoch 192:  16% 42/270 [00:26<-1:59:30, -7.47it/s, loss=0.0168, v_num=ypmf]Epoch 192:  16% 42/270 [00:26<-1:59:30, -7.38it/s, loss=0.0169, v_num=ypmf]Epoch 192:  16% 43/270 [00:27<-1:59:29, -7.26it/s, loss=0.0169, v_num=ypmf]Epoch 192:  16% 43/270 [00:27<-1:59:29, -7.26it/s, loss=0.0169, v_num=ypmf]Epoch 192:  16% 43/270 [00:27<-1:59:29, -7.20it/s, loss=0.0169, v_num=ypmf]Epoch 192:  16% 44/270 [00:27<-1:59:29, -7.07it/s, loss=0.0169, v_num=ypmf]Epoch 192:  16% 44/270 [00:27<-1:59:29, -7.07it/s, loss=0.0169, v_num=ypmf]Epoch 192:  16% 44/270 [00:27<-1:59:28, -7.04it/s, loss=0.0169, v_num=ypmf]Epoch 192:  17% 45/270 [00:28<-1:59:28, -6.91it/s, loss=0.0169, v_num=ypmf]Epoch 192:  17% 45/270 [00:28<-1:59:28, -6.91it/s, loss=0.0169, v_num=ypmf]Epoch 192:  17% 45/270 [00:28<-1:59:28, -6.87it/s, loss=0.0169, v_num=ypmf]Epoch 192:  17% 46/270 [00:28<-1:59:27, -6.75it/s, loss=0.0169, v_num=ypmf]Epoch 192:  17% 46/270 [00:28<-1:59:27, -6.75it/s, loss=0.0169, v_num=ypmf]Epoch 192:  17% 46/270 [00:29<-1:59:27, -6.69it/s, loss=0.0169, v_num=ypmf]Epoch 192:  17% 47/270 [00:29<-1:59:27, -6.56it/s, loss=0.0169, v_num=ypmf]Epoch 192:  17% 47/270 [00:29<-1:59:27, -6.56it/s, loss=0.0169, v_num=ypmf]Epoch 192:  17% 47/270 [00:29<-1:59:26, -6.51it/s, loss=0.0168, v_num=ypmf]Epoch 192:  18% 48/270 [00:30<-1:59:26, -6.39it/s, loss=0.0168, v_num=ypmf]Epoch 192:  18% 48/270 [00:30<-1:59:26, -6.39it/s, loss=0.0168, v_num=ypmf]Epoch 192:  18% 48/270 [00:30<-1:59:26, -6.35it/s, loss=0.0168, v_num=ypmf]Epoch 192:  18% 49/270 [00:30<-1:59:25, -6.25it/s, loss=0.0168, v_num=ypmf]Epoch 192:  18% 49/270 [00:30<-1:59:25, -6.25it/s, loss=0.0168, v_num=ypmf]Epoch 192:  18% 49/270 [00:31<-1:59:25, -6.19it/s, loss=0.0167, v_num=ypmf]Epoch 192:  19% 50/270 [00:31<-1:59:24, -6.08it/s, loss=0.0167, v_num=ypmf]Epoch 192:  19% 50/270 [00:31<-1:59:24, -6.08it/s, loss=0.0167, v_num=ypmf]Epoch 192:  19% 50/270 [00:31<-1:59:24, -6.05it/s, loss=0.0167, v_num=ypmf]Epoch 192:  19% 51/270 [00:33<-1:59:22, -5.75it/s, loss=0.0167, v_num=ypmf]Epoch 192:  19% 51/270 [00:33<-1:59:22, -5.75it/s, loss=0.0167, v_num=ypmf]Epoch 192:  19% 51/270 [00:33<-1:59:22, -5.72it/s, loss=0.0167, v_num=ypmf]Epoch 192:  19% 52/270 [00:33<-1:59:22, -5.63it/s, loss=0.0167, v_num=ypmf]Epoch 192:  19% 52/270 [00:33<-1:59:22, -5.63it/s, loss=0.0167, v_num=ypmf]Epoch 192:  19% 52/270 [00:33<-1:59:22, -5.61it/s, loss=0.0168, v_num=ypmf]Epoch 192:  20% 53/270 [00:34<-1:59:21, -5.49it/s, loss=0.0168, v_num=ypmf]Epoch 192:  20% 53/270 [00:34<-1:59:21, -5.49it/s, loss=0.0168, v_num=ypmf]Epoch 192:  20% 53/270 [00:35<-1:59:19, -5.29it/s, loss=0.0169, v_num=ypmf]Epoch 192:  20% 54/270 [00:35<-1:59:19, -5.21it/s, loss=0.0169, v_num=ypmf]Epoch 192:  20% 54/270 [00:35<-1:59:19, -5.21it/s, loss=0.0169, v_num=ypmf]Epoch 192:  20% 54/270 [00:36<-1:59:19, -5.18it/s, loss=0.017, v_num=ypmf] Epoch 192:  20% 55/270 [00:36<-1:59:18, -5.08it/s, loss=0.017, v_num=ypmf]Epoch 192:  20% 55/270 [00:36<-1:59:18, -5.08it/s, loss=0.017, v_num=ypmf]Epoch 192:  20% 55/270 [00:36<-1:59:18, -5.06it/s, loss=0.017, v_num=ypmf]Epoch 192:  21% 56/270 [00:37<-1:59:17, -4.98it/s, loss=0.017, v_num=ypmf]Epoch 192:  21% 56/270 [00:37<-1:59:17, -4.98it/s, loss=0.017, v_num=ypmf]Epoch 192:  21% 56/270 [00:37<-1:59:17, -4.93it/s, loss=0.0169, v_num=ypmf]Epoch 192:  21% 57/270 [00:37<-1:59:17, -4.84it/s, loss=0.0169, v_num=ypmf]Epoch 192:  21% 57/270 [00:37<-1:59:17, -4.84it/s, loss=0.0169, v_num=ypmf]Epoch 192:  21% 57/270 [00:38<-1:59:16, -4.83it/s, loss=0.017, v_num=ypmf] Epoch 192:  21% 58/270 [00:38<-1:59:16, -4.76it/s, loss=0.017, v_num=ypmf]Epoch 192:  21% 58/270 [00:38<-1:59:16, -4.76it/s, loss=0.017, v_num=ypmf]Epoch 192:  21% 58/270 [00:38<-1:59:16, -4.73it/s, loss=0.0172, v_num=ypmf]Epoch 192:  22% 59/270 [00:39<-1:59:15, -4.65it/s, loss=0.0172, v_num=ypmf]Epoch 192:  22% 59/270 [00:39<-1:59:15, -4.65it/s, loss=0.0172, v_num=ypmf]Epoch 192:  22% 59/270 [00:39<-1:59:15, -4.63it/s, loss=0.0173, v_num=ypmf]Epoch 192:  22% 60/270 [00:39<-1:59:15, -4.57it/s, loss=0.0173, v_num=ypmf]Epoch 192:  22% 60/270 [00:39<-1:59:15, -4.57it/s, loss=0.0173, v_num=ypmf]Epoch 192:  22% 60/270 [00:39<-1:59:14, -4.55it/s, loss=0.0173, v_num=ypmf]Epoch 192:  23% 61/270 [00:40<-1:59:14, -4.49it/s, loss=0.0173, v_num=ypmf]Epoch 192:  23% 61/270 [00:40<-1:59:14, -4.48it/s, loss=0.0173, v_num=ypmf]Epoch 192:  23% 61/270 [00:40<-1:59:14, -4.47it/s, loss=0.0172, v_num=ypmf]Epoch 192:  23% 62/270 [00:40<-1:59:13, -4.41it/s, loss=0.0172, v_num=ypmf]Epoch 192:  23% 62/270 [00:40<-1:59:13, -4.41it/s, loss=0.0172, v_num=ypmf]Epoch 192:  23% 62/270 [00:41<-1:59:12, -4.31it/s, loss=0.0171, v_num=ypmf]Epoch 192:  23% 63/270 [00:41<-1:59:12, -4.25it/s, loss=0.0171, v_num=ypmf]Epoch 192:  23% 63/270 [00:41<-1:59:12, -4.25it/s, loss=0.0171, v_num=ypmf]Epoch 192:  23% 63/270 [00:42<-1:59:11, -4.22it/s, loss=0.0171, v_num=ypmf]Epoch 192:  24% 64/270 [00:42<-1:59:11, -4.17it/s, loss=0.0171, v_num=ypmf]Epoch 192:  24% 64/270 [00:42<-1:59:11, -4.17it/s, loss=0.0171, v_num=ypmf]Epoch 192:  24% 64/270 [00:42<-1:59:11, -4.15it/s, loss=0.0171, v_num=ypmf]Epoch 192:  24% 65/270 [00:42<-1:59:10, -4.09it/s, loss=0.0171, v_num=ypmf]Epoch 192:  24% 65/270 [00:42<-1:59:10, -4.09it/s, loss=0.0171, v_num=ypmf]Epoch 192:  24% 65/270 [00:43<-1:59:10, -4.06it/s, loss=0.0172, v_num=ypmf]Epoch 192:  24% 66/270 [00:43<-1:59:09, -3.99it/s, loss=0.0172, v_num=ypmf]Epoch 192:  24% 66/270 [00:43<-1:59:09, -3.99it/s, loss=0.0172, v_num=ypmf]Epoch 192:  24% 66/270 [00:43<-1:59:09, -3.99it/s, loss=0.0171, v_num=ypmf]Epoch 192:  25% 67/270 [00:44<-1:59:09, -3.93it/s, loss=0.0171, v_num=ypmf]Epoch 192:  25% 67/270 [00:44<-1:59:09, -3.93it/s, loss=0.0171, v_num=ypmf]Epoch 192:  25% 67/270 [00:44<-1:59:09, -3.91it/s, loss=0.0172, v_num=ypmf]Epoch 192:  25% 68/270 [00:44<-1:59:08, -3.86it/s, loss=0.0172, v_num=ypmf]Epoch 192:  25% 68/270 [00:44<-1:59:08, -3.86it/s, loss=0.0172, v_num=ypmf]Epoch 192:  25% 68/270 [00:45<-1:59:08, -3.84it/s, loss=0.0173, v_num=ypmf]Epoch 192:  26% 69/270 [00:45<-1:59:07, -3.79it/s, loss=0.0173, v_num=ypmf]Epoch 192:  26% 69/270 [00:45<-1:59:07, -3.79it/s, loss=0.0173, v_num=ypmf]Epoch 192:  26% 69/270 [00:45<-1:59:07, -3.78it/s, loss=0.0173, v_num=ypmf]Epoch 192:  26% 70/270 [00:45<-1:59:07, -3.72it/s, loss=0.0173, v_num=ypmf]Epoch 192:  26% 70/270 [00:45<-1:59:07, -3.72it/s, loss=0.0173, v_num=ypmf]Epoch 192:  26% 70/270 [00:46<-1:59:07, -3.71it/s, loss=0.0173, v_num=ypmf]Epoch 192:  26% 71/270 [00:46<-1:59:06, -3.65it/s, loss=0.0173, v_num=ypmf]Epoch 192:  26% 71/270 [00:46<-1:59:06, -3.65it/s, loss=0.0173, v_num=ypmf]Epoch 192:  26% 71/270 [00:46<-1:59:06, -3.64it/s, loss=0.0172, v_num=ypmf]Epoch 192:  27% 72/270 [00:47<-1:59:05, -3.59it/s, loss=0.0172, v_num=ypmf]Epoch 192:  27% 72/270 [00:47<-1:59:05, -3.59it/s, loss=0.0172, v_num=ypmf]Epoch 192:  27% 72/270 [00:47<-1:59:05, -3.57it/s, loss=0.0172, v_num=ypmf]Epoch 192:  27% 73/270 [00:47<-1:59:05, -3.53it/s, loss=0.0172, v_num=ypmf]Epoch 192:  27% 73/270 [00:47<-1:59:05, -3.53it/s, loss=0.0172, v_num=ypmf]Epoch 192:  27% 73/270 [00:47<-1:59:04, -3.51it/s, loss=0.0173, v_num=ypmf]Epoch 192:  27% 74/270 [00:48<-1:59:04, -3.47it/s, loss=0.0173, v_num=ypmf]Epoch 192:  27% 74/270 [00:48<-1:59:04, -3.47it/s, loss=0.0173, v_num=ypmf]Epoch 192:  27% 74/270 [00:48<-1:59:04, -3.45it/s, loss=0.0172, v_num=ypmf]Epoch 192:  28% 75/270 [00:48<-1:59:03, -3.40it/s, loss=0.0172, v_num=ypmf]Epoch 192:  28% 75/270 [00:48<-1:59:03, -3.40it/s, loss=0.0172, v_num=ypmf]Epoch 192:  28% 75/270 [00:48<-1:59:03, -3.39it/s, loss=0.0172, v_num=ypmf]Epoch 192:  28% 76/270 [00:49<-1:59:03, -3.35it/s, loss=0.0172, v_num=ypmf]Epoch 192:  28% 76/270 [00:49<-1:59:03, -3.35it/s, loss=0.0172, v_num=ypmf]Epoch 192:  28% 76/270 [00:49<-1:59:02, -3.33it/s, loss=0.0172, v_num=ypmf]Epoch 192:  29% 77/270 [00:49<-1:59:02, -3.28it/s, loss=0.0172, v_num=ypmf]Epoch 192:  29% 77/270 [00:49<-1:59:02, -3.28it/s, loss=0.0172, v_num=ypmf]Epoch 192:  29% 77/270 [00:50<-1:59:02, -3.28it/s, loss=0.0172, v_num=ypmf]Epoch 192:  29% 78/270 [00:50<-1:59:01, -3.23it/s, loss=0.0172, v_num=ypmf]Epoch 192:  29% 78/270 [00:50<-1:59:01, -3.23it/s, loss=0.0172, v_num=ypmf]Epoch 192:  29% 78/270 [00:50<-1:59:01, -3.23it/s, loss=0.0171, v_num=ypmf]Epoch 192:  29% 79/270 [00:50<-1:59:01, -3.18it/s, loss=0.0171, v_num=ypmf]Epoch 192:  29% 79/270 [00:50<-1:59:01, -3.18it/s, loss=0.0171, v_num=ypmf]Epoch 192:  29% 79/270 [00:51<-1:59:00, -3.18it/s, loss=0.0172, v_num=ypmf]Epoch 192:  30% 80/270 [00:51<-1:59:00, -3.14it/s, loss=0.0172, v_num=ypmf]Epoch 192:  30% 80/270 [00:51<-1:59:00, -3.14it/s, loss=0.0172, v_num=ypmf]Epoch 192:  30% 80/270 [00:51<-1:59:00, -3.12it/s, loss=0.0172, v_num=ypmf]Epoch 192:  30% 81/270 [00:51<-1:58:59, -3.08it/s, loss=0.0172, v_num=ypmf]Epoch 192:  30% 81/270 [00:51<-1:58:59, -3.08it/s, loss=0.0172, v_num=ypmf]Epoch 192:  30% 81/270 [00:52<-1:58:59, -3.07it/s, loss=0.0174, v_num=ypmf]Epoch 192:  30% 82/270 [00:52<-1:58:58, -3.03it/s, loss=0.0174, v_num=ypmf]Epoch 192:  30% 82/270 [00:52<-1:58:58, -3.03it/s, loss=0.0174, v_num=ypmf]Epoch 192:  30% 82/270 [00:52<-1:58:58, -3.02it/s, loss=0.0174, v_num=ypmf]Epoch 192:  31% 83/270 [00:53<-1:58:58, -2.97it/s, loss=0.0174, v_num=ypmf]Epoch 192:  31% 83/270 [00:53<-1:58:58, -2.97it/s, loss=0.0174, v_num=ypmf]Epoch 192:  31% 83/270 [00:53<-1:58:57, -2.96it/s, loss=0.0175, v_num=ypmf]Epoch 192:  31% 84/270 [00:53<-1:58:57, -2.92it/s, loss=0.0175, v_num=ypmf]Epoch 192:  31% 84/270 [00:53<-1:58:57, -2.92it/s, loss=0.0175, v_num=ypmf]Epoch 192:  31% 84/270 [00:53<-1:58:57, -2.91it/s, loss=0.0174, v_num=ypmf]Epoch 192:  31% 85/270 [00:54<-1:58:56, -2.88it/s, loss=0.0174, v_num=ypmf]Epoch 192:  31% 85/270 [00:54<-1:58:56, -2.88it/s, loss=0.0174, v_num=ypmf]Epoch 192:  31% 85/270 [00:54<-1:58:56, -2.85it/s, loss=0.0173, v_num=ypmf]Epoch 192:  32% 86/270 [00:55<-1:58:55, -2.81it/s, loss=0.0173, v_num=ypmf]Epoch 192:  32% 86/270 [00:55<-1:58:55, -2.81it/s, loss=0.0173, v_num=ypmf]Epoch 192:  32% 86/270 [00:55<-1:58:55, -2.81it/s, loss=0.0174, v_num=ypmf]Epoch 192:  32% 87/270 [00:55<-1:58:54, -2.77it/s, loss=0.0174, v_num=ypmf]Epoch 192:  32% 87/270 [00:55<-1:58:54, -2.77it/s, loss=0.0174, v_num=ypmf]Epoch 192:  32% 87/270 [00:55<-1:58:54, -2.76it/s, loss=0.0175, v_num=ypmf]Epoch 192:  33% 88/270 [00:56<-1:58:54, -2.72it/s, loss=0.0175, v_num=ypmf]Epoch 192:  33% 88/270 [00:56<-1:58:54, -2.72it/s, loss=0.0175, v_num=ypmf]Epoch 192:  33% 88/270 [00:56<-1:58:53, -2.71it/s, loss=0.0174, v_num=ypmf]Epoch 192:  33% 89/270 [00:56<-1:58:53, -2.68it/s, loss=0.0174, v_num=ypmf]Epoch 192:  33% 89/270 [00:56<-1:58:53, -2.68it/s, loss=0.0174, v_num=ypmf]Epoch 192:  33% 89/270 [00:56<-1:58:53, -2.67it/s, loss=0.0174, v_num=ypmf]Epoch 192:  33% 90/270 [00:57<-1:58:52, -2.64it/s, loss=0.0174, v_num=ypmf]Epoch 192:  33% 90/270 [00:57<-1:58:52, -2.64it/s, loss=0.0174, v_num=ypmf]Epoch 192:  33% 90/270 [00:57<-1:58:52, -2.63it/s, loss=0.0174, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 292699. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 242405. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 323057. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 325981. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 324903. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293310. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 321651. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 325059. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 249872. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 329800. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 292093. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319979. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 367805. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 330978. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 287650. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 322847. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319099. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 343871. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 294557. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 311545. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 337517. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 286397. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 243278. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 295921. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 354958. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 192:  34% 91/270 [00:58<-1:58:51, -2.59it/s, loss=0.0174, v_num=ypmf]Epoch 192:  34% 91/270 [00:58<-1:58:51, -2.59it/s, loss=0.0174, v_num=ypmf]Epoch 192:  34% 91/270 [00:58<-1:58:51, -2.59it/s, loss=0.0174, v_num=ypmf]Epoch 192:  34% 92/270 [00:58<-1:58:51, -2.55it/s, loss=0.0174, v_num=ypmf]Epoch 192:  34% 92/270 [00:58<-1:58:51, -2.55it/s, loss=0.0174, v_num=ypmf]Epoch 192:  34% 92/270 [00:58<-1:58:50, -2.54it/s, loss=0.0173, v_num=ypmf]Epoch 192:  34% 93/270 [00:59<-1:58:50, -2.50it/s, loss=0.0173, v_num=ypmf]Epoch 192:  34% 93/270 [00:59<-1:58:50, -2.50it/s, loss=0.0173, v_num=ypmf]Epoch 192:  34% 93/270 [00:59<-1:58:50, -2.49it/s, loss=0.0173, v_num=ypmf]Epoch 192:  35% 94/270 [00:59<-1:58:49, -2.46it/s, loss=0.0173, v_num=ypmf]Epoch 192:  35% 94/270 [00:59<-1:58:49, -2.46it/s, loss=0.0173, v_num=ypmf]Epoch 192:  35% 94/270 [00:59<-1:58:49, -2.45it/s, loss=0.0173, v_num=ypmf]Epoch 192:  35% 95/270 [01:00<-1:58:48, -2.42it/s, loss=0.0173, v_num=ypmf]Epoch 192:  35% 95/270 [01:00<-1:58:48, -2.42it/s, loss=0.0173, v_num=ypmf]Epoch 192:  35% 95/270 [01:01<-1:58:47, -2.37it/s, loss=0.0173, v_num=ypmf]Epoch 192:  36% 96/270 [01:01<-1:58:46, -2.34it/s, loss=0.0173, v_num=ypmf]Epoch 192:  36% 96/270 [01:01<-1:58:46, -2.34it/s, loss=0.0173, v_num=ypmf]Epoch 192:  36% 96/270 [01:02<-1:58:46, -2.33it/s, loss=0.0172, v_num=ypmf]Epoch 192:  36% 97/270 [01:02<-1:58:45, -2.30it/s, loss=0.0172, v_num=ypmf]Epoch 192:  36% 97/270 [01:02<-1:58:45, -2.30it/s, loss=0.0172, v_num=ypmf]Epoch 192:  36% 97/270 [01:02<-1:58:45, -2.29it/s, loss=0.0173, v_num=ypmf]Epoch 192:  36% 98/270 [01:03<-1:58:44, -2.26it/s, loss=0.0173, v_num=ypmf]Epoch 192:  36% 98/270 [01:03<-1:58:44, -2.26it/s, loss=0.0173, v_num=ypmf]Epoch 192:  36% 98/270 [01:03<-1:58:44, -2.25it/s, loss=0.0172, v_num=ypmf]Epoch 192:  37% 99/270 [01:03<-1:58:44, -2.22it/s, loss=0.0172, v_num=ypmf]Epoch 192:  37% 99/270 [01:03<-1:58:44, -2.22it/s, loss=0.0172, v_num=ypmf]Epoch 192:  37% 99/270 [01:04<-1:58:43, -2.22it/s, loss=0.017, v_num=ypmf] Epoch 192:  37% 100/270 [01:04<-1:58:43, -2.19it/s, loss=0.017, v_num=ypmf]Epoch 192:  37% 100/270 [01:04<-1:58:43, -2.19it/s, loss=0.017, v_num=ypmf]Epoch 192:  37% 100/270 [01:04<-1:58:42, -2.18it/s, loss=0.017, v_num=ypmf]Epoch 192:  37% 101/270 [01:05<-1:58:42, -2.15it/s, loss=0.017, v_num=ypmf]Epoch 192:  37% 101/270 [01:05<-1:58:42, -2.15it/s, loss=0.017, v_num=ypmf]Epoch 192:  37% 101/270 [01:05<-1:58:42, -2.15it/s, loss=0.0169, v_num=ypmf]Epoch 192:  38% 102/270 [01:05<-1:58:41, -2.12it/s, loss=0.0169, v_num=ypmf]Epoch 192:  38% 102/270 [01:05<-1:58:41, -2.12it/s, loss=0.0169, v_num=ypmf]Epoch 192:  38% 102/270 [01:05<-1:58:41, -2.11it/s, loss=0.017, v_num=ypmf] Epoch 192:  38% 103/270 [01:06<-1:58:40, -2.09it/s, loss=0.017, v_num=ypmf]Epoch 192:  38% 103/270 [01:06<-1:58:40, -2.09it/s, loss=0.017, v_num=ypmf]Epoch 192:  38% 103/270 [01:06<-1:58:40, -2.08it/s, loss=0.0168, v_num=ypmf]Epoch 192:  39% 104/270 [01:06<-1:58:40, -2.06it/s, loss=0.0168, v_num=ypmf]Epoch 192:  39% 104/270 [01:06<-1:58:40, -2.06it/s, loss=0.0168, v_num=ypmf]Epoch 192:  39% 104/270 [01:06<-1:58:39, -2.05it/s, loss=0.017, v_num=ypmf] Epoch 192:  39% 105/270 [01:07<-1:58:39, -2.01it/s, loss=0.017, v_num=ypmf]Epoch 192:  39% 105/270 [01:07<-1:58:39, -2.01it/s, loss=0.017, v_num=ypmf]Epoch 192:  39% 105/270 [01:08<-1:58:37, -1.98it/s, loss=0.0168, v_num=ypmf]Epoch 192:  39% 106/270 [01:08<-1:58:37, -1.96it/s, loss=0.0168, v_num=ypmf]Epoch 192:  39% 106/270 [01:08<-1:58:37, -1.96it/s, loss=0.0168, v_num=ypmf]Epoch 192:  39% 106/270 [01:09<-1:58:36, -1.95it/s, loss=0.0168, v_num=ypmf]Epoch 192:  40% 107/270 [01:09<-1:58:36, -1.93it/s, loss=0.0168, v_num=ypmf]Epoch 192:  40% 107/270 [01:09<-1:58:36, -1.93it/s, loss=0.0168, v_num=ypmf]Epoch 192:  40% 107/270 [01:09<-1:58:36, -1.92it/s, loss=0.0167, v_num=ypmf]Epoch 192:  40% 108/270 [01:10<-1:58:35, -1.89it/s, loss=0.0167, v_num=ypmf]Epoch 192:  40% 108/270 [01:10<-1:58:35, -1.89it/s, loss=0.0167, v_num=ypmf]Epoch 192:  40% 108/270 [01:10<-1:58:35, -1.89it/s, loss=0.0168, v_num=ypmf]Epoch 192:  40% 109/270 [01:10<-1:58:34, -1.87it/s, loss=0.0168, v_num=ypmf]Epoch 192:  40% 109/270 [01:10<-1:58:34, -1.87it/s, loss=0.0168, v_num=ypmf]Epoch 192:  40% 109/270 [01:10<-1:58:34, -1.86it/s, loss=0.0168, v_num=ypmf]Epoch 192:  41% 110/270 [01:11<-1:58:33, -1.84it/s, loss=0.0168, v_num=ypmf]Epoch 192:  41% 110/270 [01:11<-1:58:33, -1.84it/s, loss=0.0168, v_num=ypmf]Epoch 192:  41% 110/270 [01:11<-1:58:33, -1.83it/s, loss=0.0167, v_num=ypmf]Epoch 192:  41% 111/270 [01:11<-1:58:33, -1.81it/s, loss=0.0167, v_num=ypmf]Epoch 192:  41% 111/270 [01:11<-1:58:33, -1.81it/s, loss=0.0167, v_num=ypmf]Epoch 192:  41% 111/270 [01:12<-1:58:32, -1.81it/s, loss=0.0167, v_num=ypmf]Epoch 192:  41% 112/270 [01:12<-1:58:32, -1.78it/s, loss=0.0167, v_num=ypmf]Epoch 192:  41% 112/270 [01:12<-1:58:32, -1.78it/s, loss=0.0167, v_num=ypmf]Epoch 192:  41% 112/270 [01:12<-1:58:32, -1.78it/s, loss=0.0166, v_num=ypmf]Epoch 192:  42% 113/270 [01:12<-1:58:31, -1.76it/s, loss=0.0166, v_num=ypmf]Epoch 192:  42% 113/270 [01:12<-1:58:31, -1.76it/s, loss=0.0166, v_num=ypmf]Epoch 192:  42% 113/270 [01:13<-1:58:31, -1.75it/s, loss=0.0167, v_num=ypmf]Epoch 192:  42% 114/270 [01:13<-1:58:30, -1.73it/s, loss=0.0167, v_num=ypmf]Epoch 192:  42% 114/270 [01:13<-1:58:30, -1.73it/s, loss=0.0167, v_num=ypmf]Epoch 192:  42% 114/270 [01:13<-1:58:30, -1.73it/s, loss=0.0167, v_num=ypmf]Epoch 192:  43% 115/270 [01:13<-1:58:30, -1.70it/s, loss=0.0167, v_num=ypmf]Epoch 192:  43% 115/270 [01:13<-1:58:30, -1.70it/s, loss=0.0167, v_num=ypmf]Epoch 192:  43% 115/270 [01:14<-1:58:29, -1.70it/s, loss=0.0167, v_num=ypmf]Epoch 192:  43% 116/270 [01:14<-1:58:29, -1.68it/s, loss=0.0167, v_num=ypmf]Epoch 192:  43% 116/270 [01:14<-1:58:29, -1.68it/s, loss=0.0167, v_num=ypmf]Epoch 192:  43% 116/270 [01:14<-1:58:28, -1.67it/s, loss=0.0169, v_num=ypmf]Epoch 192:  43% 117/270 [01:15<-1:58:28, -1.65it/s, loss=0.0169, v_num=ypmf]Epoch 192:  43% 117/270 [01:15<-1:58:28, -1.65it/s, loss=0.0169, v_num=ypmf]Epoch 192:  43% 117/270 [01:15<-1:58:27, -1.64it/s, loss=0.0168, v_num=ypmf]Epoch 192:  44% 118/270 [01:15<-1:58:27, -1.62it/s, loss=0.0168, v_num=ypmf]Epoch 192:  44% 118/270 [01:15<-1:58:27, -1.62it/s, loss=0.0168, v_num=ypmf]Epoch 192:  44% 118/270 [01:16<-1:58:27, -1.62it/s, loss=0.0169, v_num=ypmf]Epoch 192:  44% 119/270 [01:16<-1:58:26, -1.60it/s, loss=0.0169, v_num=ypmf]Epoch 192:  44% 119/270 [01:16<-1:58:26, -1.60it/s, loss=0.0169, v_num=ypmf]Epoch 192:  44% 119/270 [01:16<-1:58:26, -1.59it/s, loss=0.017, v_num=ypmf] Epoch 192:  44% 120/270 [01:16<-1:58:25, -1.57it/s, loss=0.017, v_num=ypmf]Epoch 192:  44% 120/270 [01:16<-1:58:25, -1.57it/s, loss=0.017, v_num=ypmf]Epoch 192:  44% 120/270 [01:17<-1:58:25, -1.57it/s, loss=0.017, v_num=ypmf]Epoch 192:  45% 121/270 [01:17<-1:58:24, -1.55it/s, loss=0.017, v_num=ypmf]Epoch 192:  45% 121/270 [01:17<-1:58:24, -1.55it/s, loss=0.017, v_num=ypmf]Epoch 192:  45% 121/270 [01:17<-1:58:24, -1.54it/s, loss=0.017, v_num=ypmf]Epoch 192:  45% 122/270 [01:18<-1:58:23, -1.52it/s, loss=0.017, v_num=ypmf]Epoch 192:  45% 122/270 [01:18<-1:58:23, -1.52it/s, loss=0.017, v_num=ypmf]Epoch 192:  45% 122/270 [01:18<-1:58:23, -1.52it/s, loss=0.0169, v_num=ypmf]Epoch 192:  46% 123/270 [01:18<-1:58:22, -1.50it/s, loss=0.0169, v_num=ypmf]Epoch 192:  46% 123/270 [01:18<-1:58:22, -1.50it/s, loss=0.0169, v_num=ypmf]Epoch 192:  46% 123/270 [01:18<-1:58:22, -1.50it/s, loss=0.0169, v_num=ypmf]Epoch 192:  46% 124/270 [01:19<-1:58:21, -1.47it/s, loss=0.0169, v_num=ypmf]Epoch 192:  46% 124/270 [01:19<-1:58:21, -1.47it/s, loss=0.0169, v_num=ypmf]Epoch 192:  46% 124/270 [01:19<-1:58:21, -1.47it/s, loss=0.0168, v_num=ypmf]Epoch 192:  46% 125/270 [01:19<-1:58:21, -1.45it/s, loss=0.0168, v_num=ypmf]Epoch 192:  46% 125/270 [01:19<-1:58:21, -1.45it/s, loss=0.0168, v_num=ypmf]Epoch 192:  46% 125/270 [01:19<-1:58:21, -1.45it/s, loss=0.0168, v_num=ypmf]Epoch 192:  47% 126/270 [01:20<-1:58:20, -1.43it/s, loss=0.0168, v_num=ypmf]Epoch 192:  47% 126/270 [01:20<-1:58:20, -1.43it/s, loss=0.0168, v_num=ypmf]Epoch 192:  47% 126/270 [01:20<-1:58:20, -1.43it/s, loss=0.0168, v_num=ypmf]Epoch 192:  47% 127/270 [01:20<-1:58:19, -1.41it/s, loss=0.0168, v_num=ypmf]Epoch 192:  47% 127/270 [01:20<-1:58:19, -1.41it/s, loss=0.0168, v_num=ypmf]Epoch 192:  47% 127/270 [01:21<-1:58:19, -1.41it/s, loss=0.0168, v_num=ypmf]Epoch 192:  47% 128/270 [01:21<-1:58:18, -1.39it/s, loss=0.0168, v_num=ypmf]Epoch 192:  47% 128/270 [01:21<-1:58:18, -1.39it/s, loss=0.0168, v_num=ypmf]Epoch 192:  47% 128/270 [01:21<-1:58:18, -1.38it/s, loss=0.0167, v_num=ypmf]Epoch 192:  48% 129/270 [01:22<-1:58:17, -1.36it/s, loss=0.0167, v_num=ypmf]Epoch 192:  48% 129/270 [01:22<-1:58:17, -1.36it/s, loss=0.0167, v_num=ypmf]Epoch 192:  48% 129/270 [01:22<-1:58:17, -1.36it/s, loss=0.0167, v_num=ypmf]Epoch 192:  48% 130/270 [01:22<-1:58:16, -1.34it/s, loss=0.0167, v_num=ypmf]Epoch 192:  48% 130/270 [01:22<-1:58:16, -1.34it/s, loss=0.0167, v_num=ypmf]Epoch 192:  48% 130/270 [01:22<-1:58:16, -1.34it/s, loss=0.0169, v_num=ypmf]Epoch 192:  49% 131/270 [01:23<-1:58:15, -1.32it/s, loss=0.0169, v_num=ypmf]Epoch 192:  49% 131/270 [01:23<-1:58:15, -1.32it/s, loss=0.0169, v_num=ypmf]Epoch 192:  49% 131/270 [01:24<-1:58:14, -1.31it/s, loss=0.0169, v_num=ypmf]Epoch 192:  49% 132/270 [01:24<-1:58:14, -1.29it/s, loss=0.0169, v_num=ypmf]Epoch 192:  49% 132/270 [01:24<-1:58:14, -1.29it/s, loss=0.0169, v_num=ypmf]Epoch 192:  49% 132/270 [01:24<-1:58:13, -1.29it/s, loss=0.0169, v_num=ypmf]Epoch 192:  49% 133/270 [01:25<-1:58:13, -1.27it/s, loss=0.0169, v_num=ypmf]Epoch 192:  49% 133/270 [01:25<-1:58:13, -1.27it/s, loss=0.0169, v_num=ypmf]Epoch 192:  49% 133/270 [01:25<-1:58:12, -1.27it/s, loss=0.0169, v_num=ypmf]Epoch 192:  50% 134/270 [01:25<-1:58:12, -1.25it/s, loss=0.0169, v_num=ypmf]Epoch 192:  50% 134/270 [01:25<-1:58:12, -1.25it/s, loss=0.0169, v_num=ypmf]Epoch 192:  50% 134/270 [01:25<-1:58:12, -1.25it/s, loss=0.0169, v_num=ypmf]Epoch 192:  50% 135/270 [01:26<-1:58:11, -1.23it/s, loss=0.0169, v_num=ypmf]Epoch 192:  50% 135/270 [01:26<-1:58:11, -1.23it/s, loss=0.0169, v_num=ypmf]Epoch 192:  50% 135/270 [01:26<-1:58:11, -1.23it/s, loss=0.0169, v_num=ypmf]Epoch 192:  50% 136/270 [01:26<-1:58:10, -1.21it/s, loss=0.0169, v_num=ypmf]Epoch 192:  50% 136/270 [01:26<-1:58:10, -1.21it/s, loss=0.0169, v_num=ypmf]Epoch 192:  50% 136/270 [01:26<-1:58:10, -1.21it/s, loss=0.0169, v_num=ypmf]Epoch 192:  51% 137/270 [01:27<-1:58:09, -1.19it/s, loss=0.0169, v_num=ypmf]Epoch 192:  51% 137/270 [01:27<-1:58:09, -1.19it/s, loss=0.0169, v_num=ypmf]Epoch 192:  51% 137/270 [01:27<-1:58:09, -1.19it/s, loss=0.017, v_num=ypmf] Epoch 192:  51% 138/270 [01:27<-1:58:08, -1.17it/s, loss=0.017, v_num=ypmf]Epoch 192:  51% 138/270 [01:27<-1:58:08, -1.17it/s, loss=0.017, v_num=ypmf]Epoch 192:  51% 138/270 [01:28<-1:58:08, -1.17it/s, loss=0.017, v_num=ypmf]Epoch 192:  51% 139/270 [01:28<-1:58:07, -1.15it/s, loss=0.017, v_num=ypmf]Epoch 192:  51% 139/270 [01:28<-1:58:07, -1.15it/s, loss=0.017, v_num=ypmf]Epoch 192:  51% 139/270 [01:28<-1:58:07, -1.15it/s, loss=0.0169, v_num=ypmf]Epoch 192:  52% 140/270 [01:28<-1:58:06, -1.13it/s, loss=0.0169, v_num=ypmf]Epoch 192:  52% 140/270 [01:28<-1:58:06, -1.13it/s, loss=0.0169, v_num=ypmf]Epoch 192:  52% 140/270 [01:29<-1:58:06, -1.13it/s, loss=0.0168, v_num=ypmf]Epoch 192:  52% 141/270 [01:29<-1:58:05, -1.12it/s, loss=0.0168, v_num=ypmf]Epoch 192:  52% 141/270 [01:29<-1:58:05, -1.12it/s, loss=0.0168, v_num=ypmf]Epoch 192:  52% 141/270 [01:29<-1:58:05, -1.12it/s, loss=0.0169, v_num=ypmf]Epoch 192:  53% 142/270 [01:30<-1:58:04, -1.10it/s, loss=0.0169, v_num=ypmf]Epoch 192:  53% 142/270 [01:30<-1:58:04, -1.10it/s, loss=0.0169, v_num=ypmf]Epoch 192:  53% 142/270 [01:30<-1:58:04, -1.10it/s, loss=0.0169, v_num=ypmf]Epoch 192:  53% 143/270 [01:30<-1:58:03, -1.08it/s, loss=0.0169, v_num=ypmf]Epoch 192:  53% 143/270 [01:30<-1:58:03, -1.08it/s, loss=0.0169, v_num=ypmf]Epoch 192:  53% 143/270 [01:30<-1:58:03, -1.08it/s, loss=0.0169, v_num=ypmf]Epoch 192:  53% 144/270 [01:31<-1:58:02, -1.06it/s, loss=0.0169, v_num=ypmf]Epoch 192:  53% 144/270 [01:31<-1:58:02, -1.06it/s, loss=0.0169, v_num=ypmf]Epoch 192:  53% 144/270 [01:31<-1:58:02, -1.06it/s, loss=0.017, v_num=ypmf] Epoch 192:  54% 145/270 [01:31<-1:58:01, -1.05it/s, loss=0.017, v_num=ypmf]Epoch 192:  54% 145/270 [01:31<-1:58:01, -1.05it/s, loss=0.017, v_num=ypmf]Epoch 192:  54% 145/270 [01:32<-1:58:01, -1.04it/s, loss=0.017, v_num=ypmf]Epoch 192:  54% 146/270 [01:32<-1:58:00, -1.03it/s, loss=0.017, v_num=ypmf]Epoch 192:  54% 146/270 [01:32<-1:58:00, -1.03it/s, loss=0.017, v_num=ypmf]Epoch 192:  54% 146/270 [01:32<-1:58:00, -1.03it/s, loss=0.017, v_num=ypmf]Epoch 192:  54% 147/270 [01:32<-1:57:59, -1.01it/s, loss=0.017, v_num=ypmf]Epoch 192:  54% 147/270 [01:32<-1:57:59, -1.01it/s, loss=0.017, v_num=ypmf]Epoch 192:  54% 147/270 [01:33<-1:57:59, -1.01it/s, loss=0.0171, v_num=ypmf]Epoch 192:  55% 148/270 [01:33<-1:57:58, -1.00it/s, loss=0.0171, v_num=ypmf]Epoch 192:  55% 148/270 [01:33<-1:57:58, -1.00it/s, loss=0.0171, v_num=ypmf]Epoch 192:  55% 148/270 [01:33<-1:57:58, -0.99it/s, loss=0.0173, v_num=ypmf]Epoch 192:  55% 149/270 [01:34<-1:57:57, -0.98it/s, loss=0.0173, v_num=ypmf]Epoch 192:  55% 149/270 [01:34<-1:57:57, -0.98it/s, loss=0.0173, v_num=ypmf]Epoch 192:  55% 149/270 [01:34<-1:57:57, -0.98it/s, loss=0.0173, v_num=ypmf]Epoch 192:  56% 150/270 [01:34<-1:57:56, -0.96it/s, loss=0.0173, v_num=ypmf]Epoch 192:  56% 150/270 [01:34<-1:57:56, -0.96it/s, loss=0.0173, v_num=ypmf]Epoch 192:  56% 150/270 [01:34<-1:57:55, -0.96it/s, loss=0.0173, v_num=ypmf]Epoch 192:  56% 151/270 [01:35<-1:57:54, -0.94it/s, loss=0.0173, v_num=ypmf]Epoch 192:  56% 151/270 [01:35<-1:57:54, -0.94it/s, loss=0.0173, v_num=ypmf]Epoch 192:  56% 151/270 [01:35<-1:57:54, -0.94it/s, loss=0.0172, v_num=ypmf]Epoch 192:  56% 152/270 [01:35<-1:57:53, -0.93it/s, loss=0.0172, v_num=ypmf]Epoch 192:  56% 152/270 [01:35<-1:57:53, -0.93it/s, loss=0.0172, v_num=ypmf]Epoch 192:  56% 152/270 [01:36<-1:57:53, -0.93it/s, loss=0.0172, v_num=ypmf]Epoch 192:  57% 153/270 [01:36<-1:57:52, -0.91it/s, loss=0.0172, v_num=ypmf]Epoch 192:  57% 153/270 [01:36<-1:57:52, -0.91it/s, loss=0.0172, v_num=ypmf]Epoch 192:  57% 153/270 [01:36<-1:57:52, -0.91it/s, loss=0.0171, v_num=ypmf]Epoch 192:  57% 154/270 [01:37<-1:57:51, -0.90it/s, loss=0.0171, v_num=ypmf]Epoch 192:  57% 154/270 [01:37<-1:57:51, -0.90it/s, loss=0.0171, v_num=ypmf]Epoch 192:  57% 154/270 [01:37<-1:57:51, -0.89it/s, loss=0.0172, v_num=ypmf]Epoch 192:  57% 155/270 [01:37<-1:57:50, -0.88it/s, loss=0.0172, v_num=ypmf]Epoch 192:  57% 155/270 [01:37<-1:57:50, -0.88it/s, loss=0.0172, v_num=ypmf]Epoch 192:  57% 155/270 [01:37<-1:57:50, -0.88it/s, loss=0.0173, v_num=ypmf]Epoch 192:  58% 156/270 [01:38<-1:57:49, -0.87it/s, loss=0.0173, v_num=ypmf]Epoch 192:  58% 156/270 [01:38<-1:57:49, -0.87it/s, loss=0.0173, v_num=ypmf]Epoch 192:  58% 156/270 [01:38<-1:57:49, -0.86it/s, loss=0.0171, v_num=ypmf]Epoch 192:  58% 157/270 [01:38<-1:57:48, -0.85it/s, loss=0.0171, v_num=ypmf]Epoch 192:  58% 157/270 [01:38<-1:57:48, -0.85it/s, loss=0.0171, v_num=ypmf]Epoch 192:  58% 157/270 [01:38<-1:57:47, -0.85it/s, loss=0.0171, v_num=ypmf]Epoch 192:  59% 158/270 [01:39<-1:57:46, -0.84it/s, loss=0.0171, v_num=ypmf]Epoch 192:  59% 158/270 [01:39<-1:57:46, -0.84it/s, loss=0.0171, v_num=ypmf]Epoch 192:  59% 158/270 [01:39<-1:57:46, -0.83it/s, loss=0.0171, v_num=ypmf]Epoch 192:  59% 159/270 [01:39<-1:57:45, -0.82it/s, loss=0.0171, v_num=ypmf]Epoch 192:  59% 159/270 [01:39<-1:57:45, -0.82it/s, loss=0.0171, v_num=ypmf]Epoch 192:  59% 159/270 [01:40<-1:57:45, -0.82it/s, loss=0.0171, v_num=ypmf]Epoch 192:  59% 160/270 [01:40<-1:57:44, -0.81it/s, loss=0.0171, v_num=ypmf]Epoch 192:  59% 160/270 [01:40<-1:57:44, -0.81it/s, loss=0.0171, v_num=ypmf]Epoch 192:  59% 160/270 [01:40<-1:57:44, -0.80it/s, loss=0.0172, v_num=ypmf]Epoch 192:  60% 161/270 [01:41<-1:57:43, -0.79it/s, loss=0.0172, v_num=ypmf]Epoch 192:  60% 161/270 [01:41<-1:57:43, -0.79it/s, loss=0.0172, v_num=ypmf]Epoch 192:  60% 161/270 [01:41<-1:57:43, -0.79it/s, loss=0.0173, v_num=ypmf]Epoch 192:  60% 162/270 [01:41<-1:57:42, -0.78it/s, loss=0.0173, v_num=ypmf]Epoch 192:  60% 162/270 [01:41<-1:57:42, -0.78it/s, loss=0.0173, v_num=ypmf]Epoch 192:  60% 162/270 [01:41<-1:57:41, -0.78it/s, loss=0.0174, v_num=ypmf]Epoch 192:  60% 163/270 [01:42<-1:57:40, -0.76it/s, loss=0.0174, v_num=ypmf]Epoch 192:  60% 163/270 [01:42<-1:57:40, -0.76it/s, loss=0.0174, v_num=ypmf]Epoch 192:  60% 163/270 [01:42<-1:57:40, -0.76it/s, loss=0.0173, v_num=ypmf]Epoch 192:  61% 164/270 [01:42<-1:57:39, -0.75it/s, loss=0.0173, v_num=ypmf]Epoch 192:  61% 164/270 [01:42<-1:57:39, -0.75it/s, loss=0.0173, v_num=ypmf]Epoch 192:  61% 164/270 [01:42<-1:57:39, -0.75it/s, loss=0.0173, v_num=ypmf]Epoch 192:  61% 165/270 [01:43<-1:57:38, -0.74it/s, loss=0.0173, v_num=ypmf]Epoch 192:  61% 165/270 [01:43<-1:57:38, -0.74it/s, loss=0.0173, v_num=ypmf]Epoch 192:  61% 165/270 [01:43<-1:57:37, -0.73it/s, loss=0.0172, v_num=ypmf]Epoch 192:  61% 166/270 [01:44<-1:57:36, -0.72it/s, loss=0.0172, v_num=ypmf]Epoch 192:  61% 166/270 [01:44<-1:57:36, -0.72it/s, loss=0.0172, v_num=ypmf]Epoch 192:  61% 166/270 [01:44<-1:57:36, -0.72it/s, loss=0.0172, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 291929. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 266455. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 310282. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 304346. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301426. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 330303. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 323827. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319178. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 316121. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 250914. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 278488. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 292660. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 298310. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 324598. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 325777. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 326470. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 322247. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 259710. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 349455. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 279041. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 292530. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 287772. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 321643. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 287032. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 307945. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 192:  62% 167/270 [01:44<-1:57:35, -0.71it/s, loss=0.0172, v_num=ypmf]Epoch 192:  62% 167/270 [01:44<-1:57:35, -0.71it/s, loss=0.0172, v_num=ypmf]Epoch 192:  62% 167/270 [01:44<-1:57:35, -0.71it/s, loss=0.0171, v_num=ypmf]Epoch 192:  62% 168/270 [01:44<-1:57:34, -0.70it/s, loss=0.0171, v_num=ypmf]Epoch 192:  62% 168/270 [01:44<-1:57:34, -0.70it/s, loss=0.0171, v_num=ypmf]Epoch 192:  62% 168/270 [01:45<-1:57:33, -0.69it/s, loss=0.017, v_num=ypmf] Epoch 192:  63% 169/270 [01:45<-1:57:32, -0.68it/s, loss=0.017, v_num=ypmf]Epoch 192:  63% 169/270 [01:45<-1:57:32, -0.68it/s, loss=0.017, v_num=ypmf]Epoch 192:  63% 169/270 [01:45<-1:57:32, -0.68it/s, loss=0.017, v_num=ypmf]Epoch 192:  63% 170/270 [01:46<-1:57:31, -0.67it/s, loss=0.017, v_num=ypmf]Epoch 192:  63% 170/270 [01:46<-1:57:31, -0.67it/s, loss=0.017, v_num=ypmf]Epoch 192:  63% 170/270 [01:46<-1:57:31, -0.67it/s, loss=0.017, v_num=ypmf]Epoch 192:  63% 171/270 [01:46<-1:57:29, -0.65it/s, loss=0.017, v_num=ypmf]Epoch 192:  63% 171/270 [01:46<-1:57:29, -0.65it/s, loss=0.017, v_num=ypmf]Epoch 192:  63% 171/270 [01:47<-1:57:29, -0.65it/s, loss=0.0171, v_num=ypmf]Epoch 192:  64% 172/270 [01:47<-1:57:28, -0.64it/s, loss=0.0171, v_num=ypmf]Epoch 192:  64% 172/270 [01:47<-1:57:28, -0.64it/s, loss=0.0171, v_num=ypmf]Epoch 192:  64% 172/270 [01:47<-1:57:28, -0.64it/s, loss=0.0171, v_num=ypmf]Epoch 192:  64% 173/270 [01:47<-1:57:26, -0.63it/s, loss=0.0171, v_num=ypmf]Epoch 192:  64% 173/270 [01:47<-1:57:26, -0.63it/s, loss=0.0171, v_num=ypmf]Epoch 192:  64% 173/270 [01:48<-1:57:26, -0.63it/s, loss=0.0171, v_num=ypmf]Epoch 192:  64% 174/270 [01:48<-1:57:25, -0.62it/s, loss=0.0171, v_num=ypmf]Epoch 192:  64% 174/270 [01:48<-1:57:25, -0.62it/s, loss=0.0171, v_num=ypmf]Epoch 192:  64% 174/270 [01:48<-1:57:25, -0.62it/s, loss=0.0171, v_num=ypmf]Epoch 192:  65% 175/270 [01:49<-1:57:23, -0.60it/s, loss=0.0171, v_num=ypmf]Epoch 192:  65% 175/270 [01:49<-1:57:23, -0.60it/s, loss=0.0171, v_num=ypmf]Epoch 192:  65% 175/270 [01:49<-1:57:23, -0.60it/s, loss=0.017, v_num=ypmf] Epoch 192:  65% 176/270 [01:49<-1:57:22, -0.59it/s, loss=0.017, v_num=ypmf]Epoch 192:  65% 176/270 [01:49<-1:57:22, -0.59it/s, loss=0.017, v_num=ypmf]Epoch 192:  65% 176/270 [01:49<-1:57:22, -0.59it/s, loss=0.017, v_num=ypmf]Epoch 192:  66% 177/270 [01:50<-1:57:20, -0.58it/s, loss=0.017, v_num=ypmf]Epoch 192:  66% 177/270 [01:50<-1:57:20, -0.58it/s, loss=0.017, v_num=ypmf]Epoch 192:  66% 177/270 [01:50<-1:57:20, -0.58it/s, loss=0.017, v_num=ypmf]Epoch 192:  66% 178/270 [01:50<-1:57:19, -0.57it/s, loss=0.017, v_num=ypmf]Epoch 192:  66% 178/270 [01:50<-1:57:19, -0.57it/s, loss=0.017, v_num=ypmf]Epoch 192:  66% 178/270 [01:51<-1:57:18, -0.57it/s, loss=0.0171, v_num=ypmf]Epoch 192:  66% 179/270 [01:51<-1:57:17, -0.56it/s, loss=0.0171, v_num=ypmf]Epoch 192:  66% 179/270 [01:51<-1:57:17, -0.56it/s, loss=0.0171, v_num=ypmf]Epoch 192:  66% 179/270 [01:51<-1:57:17, -0.56it/s, loss=0.0171, v_num=ypmf]Epoch 192:  67% 180/270 [01:51<-1:57:15, -0.55it/s, loss=0.0171, v_num=ypmf]Epoch 192:  67% 180/270 [01:51<-1:57:15, -0.55it/s, loss=0.0171, v_num=ypmf]Epoch 192:  67% 180/270 [01:52<-1:57:15, -0.54it/s, loss=0.017, v_num=ypmf] Epoch 192:  67% 181/270 [01:52<-1:57:13, -0.53it/s, loss=0.017, v_num=ypmf]Epoch 192:  67% 181/270 [01:52<-1:57:13, -0.53it/s, loss=0.017, v_num=ypmf]Epoch 192:  67% 181/270 [01:52<-1:57:13, -0.53it/s, loss=0.0168, v_num=ypmf]Epoch 192:  67% 182/270 [01:53<-1:57:12, -0.52it/s, loss=0.0168, v_num=ypmf]Epoch 192:  67% 182/270 [01:53<-1:57:12, -0.52it/s, loss=0.0168, v_num=ypmf]Epoch 192:  67% 182/270 [01:53<-1:57:11, -0.52it/s, loss=0.0167, v_num=ypmf]Epoch 192:  68% 183/270 [01:53<-1:57:10, -0.51it/s, loss=0.0167, v_num=ypmf]Epoch 192:  68% 183/270 [01:53<-1:57:10, -0.51it/s, loss=0.0167, v_num=ypmf]Epoch 192:  68% 183/270 [01:54<-1:57:09, -0.51it/s, loss=0.0167, v_num=ypmf]Epoch 192:  68% 184/270 [01:54<-1:57:08, -0.50it/s, loss=0.0167, v_num=ypmf]Epoch 192:  68% 184/270 [01:54<-1:57:08, -0.50it/s, loss=0.0167, v_num=ypmf]Epoch 192:  68% 184/270 [01:54<-1:57:08, -0.50it/s, loss=0.0167, v_num=ypmf]Epoch 192:  69% 185/270 [01:55<-1:57:06, -0.49it/s, loss=0.0167, v_num=ypmf]Epoch 192:  69% 185/270 [01:55<-1:57:06, -0.49it/s, loss=0.0167, v_num=ypmf]Epoch 192:  69% 185/270 [01:55<-1:57:06, -0.49it/s, loss=0.0168, v_num=ypmf]Epoch 192:  69% 186/270 [01:55<-1:57:04, -0.48it/s, loss=0.0168, v_num=ypmf]Epoch 192:  69% 186/270 [01:55<-1:57:04, -0.48it/s, loss=0.0168, v_num=ypmf]Epoch 192:  69% 186/270 [01:56<-1:57:03, -0.47it/s, loss=0.0168, v_num=ypmf]Epoch 192:  69% 187/270 [01:56<-1:57:01, -0.46it/s, loss=0.0168, v_num=ypmf]Epoch 192:  69% 187/270 [01:56<-1:57:01, -0.46it/s, loss=0.0168, v_num=ypmf]Epoch 192:  69% 187/270 [01:56<-1:57:01, -0.46it/s, loss=0.0168, v_num=ypmf]Epoch 192:  70% 188/270 [01:57<-1:56:59, -0.45it/s, loss=0.0168, v_num=ypmf]Epoch 192:  70% 188/270 [01:57<-1:56:59, -0.45it/s, loss=0.0168, v_num=ypmf]Epoch 192:  70% 188/270 [01:57<-1:56:59, -0.45it/s, loss=0.0167, v_num=ypmf]Epoch 192:  70% 189/270 [01:57<-1:56:57, -0.44it/s, loss=0.0167, v_num=ypmf]Epoch 192:  70% 189/270 [01:57<-1:56:57, -0.44it/s, loss=0.0167, v_num=ypmf]Epoch 192:  70% 189/270 [01:57<-1:56:57, -0.44it/s, loss=0.0167, v_num=ypmf]Epoch 192:  70% 190/270 [01:58<-1:56:55, -0.43it/s, loss=0.0167, v_num=ypmf]Epoch 192:  70% 190/270 [01:58<-1:56:55, -0.43it/s, loss=0.0167, v_num=ypmf]Epoch 192:  70% 190/270 [01:58<-1:56:55, -0.43it/s, loss=0.0166, v_num=ypmf]Epoch 192:  71% 191/270 [01:59<-1:56:52, -0.42it/s, loss=0.0166, v_num=ypmf]Epoch 192:  71% 191/270 [01:59<-1:56:52, -0.42it/s, loss=0.0166, v_num=ypmf]Epoch 192:  71% 191/270 [01:59<-1:56:52, -0.42it/s, loss=0.0166, v_num=ypmf]Epoch 192:  71% 192/270 [01:59<-1:56:50, -0.41it/s, loss=0.0166, v_num=ypmf]Epoch 192:  71% 192/270 [01:59<-1:56:50, -0.41it/s, loss=0.0166, v_num=ypmf]Epoch 192:  71% 192/270 [01:59<-1:56:50, -0.41it/s, loss=0.0166, v_num=ypmf]Epoch 192:  71% 193/270 [02:00<-1:56:48, -0.40it/s, loss=0.0166, v_num=ypmf]Epoch 192:  71% 193/270 [02:00<-1:56:48, -0.40it/s, loss=0.0166, v_num=ypmf]Epoch 192:  71% 193/270 [02:00<-1:56:48, -0.40it/s, loss=0.0167, v_num=ypmf]Epoch 192:  72% 194/270 [02:00<-1:56:45, -0.39it/s, loss=0.0167, v_num=ypmf]Epoch 192:  72% 194/270 [02:00<-1:56:45, -0.39it/s, loss=0.0167, v_num=ypmf]Epoch 192:  72% 194/270 [02:00<-1:56:45, -0.39it/s, loss=0.0166, v_num=ypmf]Epoch 192:  72% 195/270 [02:01<-1:56:43, -0.38it/s, loss=0.0166, v_num=ypmf]Epoch 192:  72% 195/270 [02:01<-1:56:43, -0.38it/s, loss=0.0166, v_num=ypmf]Epoch 192:  72% 195/270 [02:01<-1:56:42, -0.38it/s, loss=0.0167, v_num=ypmf]Epoch 192:  73% 196/270 [02:01<-1:56:40, -0.37it/s, loss=0.0167, v_num=ypmf]Epoch 192:  73% 196/270 [02:01<-1:56:40, -0.37it/s, loss=0.0167, v_num=ypmf]Epoch 192:  73% 196/270 [02:02<-1:56:40, -0.37it/s, loss=0.0167, v_num=ypmf]Epoch 192:  73% 197/270 [02:02<-1:56:37, -0.36it/s, loss=0.0167, v_num=ypmf]Epoch 192:  73% 197/270 [02:02<-1:56:37, -0.36it/s, loss=0.0167, v_num=ypmf]Epoch 192:  73% 197/270 [02:02<-1:56:37, -0.36it/s, loss=0.0168, v_num=ypmf]Epoch 192:  73% 198/270 [02:02<-1:56:35, -0.35it/s, loss=0.0168, v_num=ypmf]Epoch 192:  73% 198/270 [02:02<-1:56:35, -0.35it/s, loss=0.0168, v_num=ypmf]Epoch 192:  73% 198/270 [02:03<-1:56:34, -0.35it/s, loss=0.0166, v_num=ypmf]Epoch 192:  74% 199/270 [02:03<-1:56:32, -0.34it/s, loss=0.0166, v_num=ypmf]Epoch 192:  74% 199/270 [02:03<-1:56:32, -0.34it/s, loss=0.0166, v_num=ypmf]Epoch 192:  74% 199/270 [02:03<-1:56:31, -0.34it/s, loss=0.0166, v_num=ypmf]Epoch 192:  74% 200/270 [02:04<-1:56:29, -0.33it/s, loss=0.0166, v_num=ypmf]Epoch 192:  74% 200/270 [02:04<-1:56:29, -0.33it/s, loss=0.0166, v_num=ypmf]Epoch 192:  74% 200/270 [02:04<-1:56:28, -0.33it/s, loss=0.0166, v_num=ypmf]Epoch 192:  74% 201/270 [02:04<-1:56:25, -0.32it/s, loss=0.0166, v_num=ypmf]Epoch 192:  74% 201/270 [02:04<-1:56:25, -0.32it/s, loss=0.0166, v_num=ypmf]Epoch 192:  74% 201/270 [02:05<-1:56:23, -0.32it/s, loss=0.0166, v_num=ypmf]Epoch 192:  75% 202/270 [02:06<-1:56:20, -0.31it/s, loss=0.0166, v_num=ypmf]Epoch 192:  75% 202/270 [02:06<-1:56:20, -0.31it/s, loss=0.0166, v_num=ypmf]Epoch 192:  75% 202/270 [02:06<-1:56:20, -0.31it/s, loss=0.0165, v_num=ypmf]Epoch 192:  75% 203/270 [02:06<-1:56:17, -0.30it/s, loss=0.0165, v_num=ypmf]Epoch 192:  75% 203/270 [02:06<-1:56:17, -0.30it/s, loss=0.0165, v_num=ypmf]Epoch 192:  75% 203/270 [02:07<-1:56:17, -0.30it/s, loss=0.0165, v_num=ypmf]Epoch 192:  76% 204/270 [02:07<-1:56:13, -0.29it/s, loss=0.0165, v_num=ypmf]Epoch 192:  76% 204/270 [02:07<-1:56:13, -0.29it/s, loss=0.0165, v_num=ypmf]Epoch 192:  76% 204/270 [02:07<-1:56:13, -0.29it/s, loss=0.0166, v_num=ypmf]Epoch 192:  76% 205/270 [02:07<-1:56:09, -0.28it/s, loss=0.0166, v_num=ypmf]Epoch 192:  76% 205/270 [02:07<-1:56:09, -0.28it/s, loss=0.0166, v_num=ypmf]Epoch 192:  76% 205/270 [02:08<-1:56:09, -0.28it/s, loss=0.0166, v_num=ypmf]Epoch 192:  76% 206/270 [02:08<-1:56:05, -0.27it/s, loss=0.0166, v_num=ypmf]Epoch 192:  76% 206/270 [02:08<-1:56:05, -0.27it/s, loss=0.0166, v_num=ypmf]Epoch 192:  76% 206/270 [02:08<-1:56:05, -0.27it/s, loss=0.0165, v_num=ypmf]Epoch 192:  77% 207/270 [02:09<-1:56:01, -0.26it/s, loss=0.0165, v_num=ypmf]Epoch 192:  77% 207/270 [02:09<-1:56:01, -0.26it/s, loss=0.0165, v_num=ypmf]Epoch 192:  77% 207/270 [02:09<-1:56:01, -0.26it/s, loss=0.0166, v_num=ypmf]Epoch 192:  77% 208/270 [02:09<-1:55:57, -0.25it/s, loss=0.0166, v_num=ypmf]Epoch 192:  77% 208/270 [02:09<-1:55:57, -0.25it/s, loss=0.0166, v_num=ypmf]Epoch 192:  77% 208/270 [02:09<-1:55:56, -0.25it/s, loss=0.0167, v_num=ypmf]Epoch 192:  77% 209/270 [02:10<-1:55:52, -0.25it/s, loss=0.0167, v_num=ypmf]Epoch 192:  77% 209/270 [02:10<-1:55:52, -0.25it/s, loss=0.0167, v_num=ypmf]Epoch 192:  77% 209/270 [02:10<-1:55:52, -0.25it/s, loss=0.0167, v_num=ypmf]Epoch 192:  78% 210/270 [02:10<-1:55:47, -0.24it/s, loss=0.0167, v_num=ypmf]Epoch 192:  78% 210/270 [02:10<-1:55:47, -0.24it/s, loss=0.0167, v_num=ypmf]Epoch 192:  78% 210/270 [02:11<-1:55:47, -0.24it/s, loss=0.0169, v_num=ypmf]Epoch 192:  78% 211/270 [02:11<-1:55:41, -0.23it/s, loss=0.0169, v_num=ypmf]Epoch 192:  78% 211/270 [02:11<-1:55:41, -0.23it/s, loss=0.0169, v_num=ypmf]Epoch 192:  78% 211/270 [02:11<-1:55:41, -0.23it/s, loss=0.0168, v_num=ypmf]Epoch 192:  79% 212/270 [02:12<-1:55:36, -0.22it/s, loss=0.0168, v_num=ypmf]Epoch 192:  79% 212/270 [02:12<-1:55:36, -0.22it/s, loss=0.0168, v_num=ypmf]Epoch 192:  79% 212/270 [02:12<-1:55:36, -0.22it/s, loss=0.0169, v_num=ypmf]Epoch 192:  79% 213/270 [02:12<-1:55:30, -0.21it/s, loss=0.0169, v_num=ypmf]Epoch 192:  79% 213/270 [02:12<-1:55:30, -0.21it/s, loss=0.0169, v_num=ypmf]Epoch 192:  79% 213/270 [02:12<-1:55:30, -0.21it/s, loss=0.0169, v_num=ypmf]Epoch 192:  79% 214/270 [02:13<-1:55:24, -0.20it/s, loss=0.0169, v_num=ypmf]Epoch 192:  79% 214/270 [02:13<-1:55:24, -0.20it/s, loss=0.0169, v_num=ypmf]Epoch 192:  79% 214/270 [02:13<-1:55:24, -0.20it/s, loss=0.0169, v_num=ypmf]Epoch 192:  80% 215/270 [02:13<-1:55:18, -0.19it/s, loss=0.0169, v_num=ypmf]Epoch 192:  80% 215/270 [02:13<-1:55:18, -0.19it/s, loss=0.0169, v_num=ypmf]Epoch 192:  80% 215/270 [02:13<-1:55:17, -0.19it/s, loss=0.0169, v_num=ypmf]Epoch 192:  80% 216/270 [02:14<-1:55:10, -0.19it/s, loss=0.0169, v_num=ypmf]Epoch 192:  80% 216/270 [02:14<-1:55:10, -0.19it/s, loss=0.0169, v_num=ypmf]Epoch 192:  80% 216/270 [02:14<-1:55:10, -0.19it/s, loss=0.0168, v_num=ypmf]Epoch 192:  80% 217/270 [02:15<-1:55:02, -0.18it/s, loss=0.0168, v_num=ypmf]Epoch 192:  80% 217/270 [02:15<-1:55:02, -0.18it/s, loss=0.0168, v_num=ypmf]Epoch 192:  80% 217/270 [02:15<-1:55:02, -0.18it/s, loss=0.0167, v_num=ypmf]Epoch 192:  81% 218/270 [02:15<-1:54:53, -0.17it/s, loss=0.0167, v_num=ypmf]Epoch 192:  81% 218/270 [02:15<-1:54:53, -0.17it/s, loss=0.0167, v_num=ypmf]Epoch 192:  81% 218/270 [02:15<-1:54:53, -0.17it/s, loss=0.0166, v_num=ypmf]Epoch 192:  81% 219/270 [02:16<-1:54:44, -0.16it/s, loss=0.0166, v_num=ypmf]Epoch 192:  81% 219/270 [02:16<-1:54:44, -0.16it/s, loss=0.0166, v_num=ypmf]Epoch 192:  81% 219/270 [02:16<-1:54:44, -0.16it/s, loss=0.0167, v_num=ypmf]Epoch 192:  81% 220/270 [02:16<-1:54:35, -0.15it/s, loss=0.0167, v_num=ypmf]Epoch 192:  81% 220/270 [02:16<-1:54:35, -0.15it/s, loss=0.0167, v_num=ypmf]Epoch 192:  81% 220/270 [02:17<-1:54:34, -0.15it/s, loss=0.0167, v_num=ypmf]Epoch 192:  82% 221/270 [02:17<-1:54:24, -0.15it/s, loss=0.0167, v_num=ypmf]Epoch 192:  82% 221/270 [02:17<-1:54:24, -0.15it/s, loss=0.0167, v_num=ypmf]Epoch 192:  82% 221/270 [02:17<-1:54:23, -0.15it/s, loss=0.0169, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 355132. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 273000. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 326646. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 302536. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 338697. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 342420. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 332369. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 324045. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 355390. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 285421. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 335089. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 317136. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293784. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 286001. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 321486. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 331001. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 283978. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 305647. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308620. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 352107. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 259667. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 313181. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 401441. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 297712. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 305629. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 192:  82% 222/270 [02:17<-1:54:12, -0.14it/s, loss=0.0169, v_num=ypmf]Epoch 192:  82% 222/270 [02:17<-1:54:12, -0.14it/s, loss=0.0169, v_num=ypmf]Epoch 192:  82% 222/270 [02:18<-1:54:11, -0.14it/s, loss=0.017, v_num=ypmf] Epoch 192:  83% 223/270 [02:18<-1:53:59, -0.13it/s, loss=0.017, v_num=ypmf]Epoch 192:  83% 223/270 [02:18<-1:53:59, -0.13it/s, loss=0.017, v_num=ypmf]Epoch 192:  83% 223/270 [02:18<-1:53:58, -0.13it/s, loss=0.017, v_num=ypmf]Epoch 192:  83% 224/270 [02:19<-1:53:44, -0.12it/s, loss=0.017, v_num=ypmf]Epoch 192:  83% 224/270 [02:19<-1:53:44, -0.12it/s, loss=0.017, v_num=ypmf]Epoch 192:  83% 224/270 [02:19<-1:53:44, -0.12it/s, loss=0.0171, v_num=ypmf]Epoch 192:  83% 225/270 [02:19<-1:53:28, -0.11it/s, loss=0.0171, v_num=ypmf]Epoch 192:  83% 225/270 [02:19<-1:53:28, -0.11it/s, loss=0.0171, v_num=ypmf]Epoch 192:  83% 225/270 [02:19<-1:53:27, -0.11it/s, loss=0.0171, v_num=ypmf]Epoch 192:  84% 226/270 [02:20<-1:53:09, -0.11it/s, loss=0.0171, v_num=ypmf]Epoch 192:  84% 226/270 [02:20<-1:53:09, -0.11it/s, loss=0.0171, v_num=ypmf]Epoch 192:  84% 226/270 [02:20<-1:53:08, -0.11it/s, loss=0.0171, v_num=ypmf]Epoch 192:  84% 227/270 [02:20<-1:52:48, -0.10it/s, loss=0.0171, v_num=ypmf]Epoch 192:  84% 227/270 [02:20<-1:52:48, -0.10it/s, loss=0.0171, v_num=ypmf]Epoch 192:  84% 227/270 [02:21<-1:52:47, -0.10it/s, loss=0.0171, v_num=ypmf]Epoch 192:  84% 228/270 [02:21<-1:52:24, -0.09it/s, loss=0.0171, v_num=ypmf]Epoch 192:  84% 228/270 [02:21<-1:52:24, -0.09it/s, loss=0.0171, v_num=ypmf]Epoch 192:  84% 228/270 [02:21<-1:52:23, -0.09it/s, loss=0.0171, v_num=ypmf]Epoch 192:  85% 229/270 [02:21<-1:51:56, -0.08it/s, loss=0.0171, v_num=ypmf]Epoch 192:  85% 229/270 [02:21<-1:51:56, -0.08it/s, loss=0.0171, v_num=ypmf]Epoch 192:  85% 229/270 [02:22<-1:51:55, -0.08it/s, loss=0.0171, v_num=ypmf]Epoch 192:  85% 230/270 [02:22<-1:51:22, -0.08it/s, loss=0.0171, v_num=ypmf]Epoch 192:  85% 230/270 [02:22<-1:51:22, -0.08it/s, loss=0.0171, v_num=ypmf]Epoch 192:  85% 230/270 [02:22<-1:51:22, -0.08it/s, loss=0.0171, v_num=ypmf]Epoch 192:  86% 231/270 [02:23<-1:50:42, -0.07it/s, loss=0.0171, v_num=ypmf]Epoch 192:  86% 231/270 [02:23<-1:50:42, -0.07it/s, loss=0.0171, v_num=ypmf]Epoch 192:  86% 231/270 [02:23<-1:50:41, -0.07it/s, loss=0.0171, v_num=ypmf]Epoch 192:  86% 232/270 [02:23<-1:49:53, -0.06it/s, loss=0.0171, v_num=ypmf]Epoch 192:  86% 232/270 [02:23<-1:49:53, -0.06it/s, loss=0.0171, v_num=ypmf]Epoch 192:  86% 232/270 [02:23<-1:49:53, -0.06it/s, loss=0.017, v_num=ypmf] Epoch 192:  86% 233/270 [02:24<-1:48:53, -0.06it/s, loss=0.017, v_num=ypmf]Epoch 192:  86% 233/270 [02:24<-1:48:53, -0.06it/s, loss=0.017, v_num=ypmf]Epoch 192:  86% 233/270 [02:24<-1:48:52, -0.06it/s, loss=0.0169, v_num=ypmf]Epoch 192:  87% 234/270 [02:24<-1:47:35, -0.05it/s, loss=0.0169, v_num=ypmf]Epoch 192:  87% 234/270 [02:24<-1:47:35, -0.05it/s, loss=0.0169, v_num=ypmf]Epoch 192:  87% 234/270 [02:25<-1:47:34, -0.05it/s, loss=0.0168, v_num=ypmf]Epoch 192:  87% 235/270 [02:25<-1:45:51, -0.04it/s, loss=0.0168, v_num=ypmf]Epoch 192:  87% 235/270 [02:25<-1:45:51, -0.04it/s, loss=0.0168, v_num=ypmf]Epoch 192:  87% 235/270 [02:25<-1:45:51, -0.04it/s, loss=0.0168, v_num=ypmf]Epoch 192:  87% 236/270 [02:26<-1:43:27, -0.03it/s, loss=0.0168, v_num=ypmf]Epoch 192:  87% 236/270 [02:26<-1:43:27, -0.03it/s, loss=0.0168, v_num=ypmf]Epoch 192:  87% 236/270 [02:26<-1:43:26, -0.03it/s, loss=0.017, v_num=ypmf] Epoch 192:  88% 237/270 [02:26<-1:39:51, -0.03it/s, loss=0.017, v_num=ypmf]Epoch 192:  88% 237/270 [02:26<-1:39:51, -0.03it/s, loss=0.017, v_num=ypmf]Epoch 192:  88% 237/270 [02:26<-1:39:49, -0.03it/s, loss=0.017, v_num=ypmf]Epoch 192:  88% 238/270 [02:27<-1:33:50, -0.02it/s, loss=0.017, v_num=ypmf]Epoch 192:  88% 238/270 [02:27<-1:33:50, -0.02it/s, loss=0.017, v_num=ypmf]Epoch 192:  88% 238/270 [02:27<-1:33:48, -0.02it/s, loss=0.017, v_num=ypmf]Epoch 192:  89% 239/270 [02:27<-1:21:49, -0.01it/s, loss=0.017, v_num=ypmf]Epoch 192:  89% 239/270 [02:27<-1:21:49, -0.01it/s, loss=0.017, v_num=ypmf]Epoch 192:  89% 239/270 [02:28<-1:21:40, -0.01it/s, loss=0.017, v_num=ypmf]Epoch 192:  89% 240/270 [02:28<-2:45:40, -0.01it/s, loss=0.017, v_num=ypmf]Epoch 192:  89% 240/270 [02:28<-2:45:40, -0.01it/s, loss=0.017, v_num=ypmf]Epoch 192:  89% 240/270 [02:29<-2:45:30, -0.01it/s, loss=0.0171, v_num=ypmf]Epoch 192:  89% 241/270 [02:29<?, ?it/s, loss=0.0171, v_num=ypmf]           Epoch 192:  89% 241/270 [02:29<?, ?it/s, loss=0.0171, v_num=ypmf]Epoch 192:  89% 241/270 [02:29<?, ?it/s, loss=0.0169, v_num=ypmf]Epoch 192:  90% 242/270 [02:30<1:10:03, 150.11s/it, loss=0.0169, v_num=ypmf]Epoch 192:  90% 242/270 [02:30<1:10:03, 150.11s/it, loss=0.0169, v_num=ypmf]Epoch 192:  90% 242/270 [02:30<1:10:25, 150.90s/it, loss=0.0168, v_num=ypmf]Epoch 192:  90% 243/270 [02:31<34:02, 75.63s/it, loss=0.0168, v_num=ypmf]   Epoch 192:  90% 243/270 [02:31<34:02, 75.63s/it, loss=0.0168, v_num=ypmf]Epoch 192:  90% 243/270 [02:31<34:04, 75.74s/it, loss=0.0169, v_num=ypmf]Epoch 192:  90% 244/270 [02:31<21:56, 50.62s/it, loss=0.0169, v_num=ypmf]Epoch 192:  90% 244/270 [02:31<21:56, 50.62s/it, loss=0.0169, v_num=ypmf]Epoch 192:  90% 244/270 [02:32<21:57, 50.67s/it, loss=0.0167, v_num=ypmf]Epoch 192:  91% 245/270 [02:32<15:52, 38.09s/it, loss=0.0167, v_num=ypmf]Epoch 192:  91% 245/270 [02:32<15:52, 38.09s/it, loss=0.0167, v_num=ypmf]Epoch 192:  91% 245/270 [02:32<15:53, 38.15s/it, loss=0.0168, v_num=ypmf]Epoch 192:  91% 246/270 [02:32<12:13, 30.58s/it, loss=0.0168, v_num=ypmf]Epoch 192:  91% 246/270 [02:32<12:13, 30.58s/it, loss=0.0168, v_num=ypmf]Epoch 192:  91% 246/270 [02:33<12:15, 30.64s/it, loss=0.0169, v_num=ypmf]Epoch 192:  91% 247/270 [02:33<09:48, 25.58s/it, loss=0.0169, v_num=ypmf]Epoch 192:  91% 247/270 [02:33<09:48, 25.58s/it, loss=0.0169, v_num=ypmf]Epoch 192:  91% 247/270 [02:33<09:49, 25.62s/it, loss=0.0171, v_num=ypmf]Epoch 192:  92% 248/270 [02:34<08:04, 22.01s/it, loss=0.0171, v_num=ypmf]Epoch 192:  92% 248/270 [02:34<08:04, 22.01s/it, loss=0.0171, v_num=ypmf]Epoch 192:  92% 248/270 [02:34<08:04, 22.04s/it, loss=0.0169, v_num=ypmf]Epoch 192:  92% 249/270 [02:34<06:45, 19.32s/it, loss=0.0169, v_num=ypmf]Epoch 192:  92% 249/270 [02:34<06:45, 19.32s/it, loss=0.0169, v_num=ypmf]Epoch 192:  92% 249/270 [02:34<06:46, 19.37s/it, loss=0.0171, v_num=ypmf]Epoch 192:  93% 250/270 [02:35<05:45, 17.26s/it, loss=0.0171, v_num=ypmf]Epoch 192:  93% 250/270 [02:35<05:45, 17.26s/it, loss=0.0171, v_num=ypmf]Epoch 192:  93% 250/270 [02:35<05:45, 17.28s/it, loss=0.017, v_num=ypmf] 
Validation: 0it [00:00, ?it/s]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 285657. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 329599. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 347084. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301878. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 296821. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 291248. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 228443. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 292434. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 303031. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 277354. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 237638. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 294913. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
[A
Validation:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.27it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.27it/s][AEpoch 192:  93% 251/270 [02:36<04:56, 15.61s/it, loss=0.017, v_num=ypmf]Epoch 192:  93% 251/270 [02:36<04:56, 15.61s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  10% 2/20 [00:01<00:15,  1.15it/s][A
Validation DataLoader 0:  10% 2/20 [00:01<00:15,  1.15it/s][AEpoch 192:  93% 252/270 [02:37<04:17, 14.30s/it, loss=0.017, v_num=ypmf]Epoch 192:  93% 252/270 [02:37<04:17, 14.30s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  15% 3/20 [00:03<00:21,  1.29s/it][A
Validation DataLoader 0:  15% 3/20 [00:03<00:21,  1.29s/it][AEpoch 192:  94% 253/270 [02:39<03:45, 13.26s/it, loss=0.017, v_num=ypmf]Epoch 192:  94% 253/270 [02:39<03:45, 13.26s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  20% 4/20 [00:04<00:16,  1.06s/it][A
Validation DataLoader 0:  20% 4/20 [00:04<00:16,  1.06s/it][AEpoch 192:  94% 254/270 [02:39<03:16, 12.29s/it, loss=0.017, v_num=ypmf]Epoch 192:  94% 254/270 [02:39<03:16, 12.29s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  25% 5/20 [00:05<00:15,  1.05s/it][A
Validation DataLoader 0:  25% 5/20 [00:05<00:15,  1.05s/it][AEpoch 192:  94% 255/270 [02:40<02:52, 11.49s/it, loss=0.017, v_num=ypmf]Epoch 192:  94% 255/270 [02:40<02:52, 11.49s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  30% 6/20 [00:06<00:17,  1.22s/it][A
Validation DataLoader 0:  30% 6/20 [00:06<00:17,  1.22s/it][AEpoch 192:  95% 256/270 [02:42<02:31, 10.83s/it, loss=0.017, v_num=ypmf]Epoch 192:  95% 256/270 [02:42<02:31, 10.83s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  35% 7/20 [00:08<00:17,  1.36s/it][A
Validation DataLoader 0:  35% 7/20 [00:08<00:17,  1.36s/it][AEpoch 192:  95% 257/270 [02:44<02:13, 10.25s/it, loss=0.017, v_num=ypmf]Epoch 192:  95% 257/270 [02:44<02:13, 10.25s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  40% 8/20 [00:09<00:17,  1.42s/it][A
Validation DataLoader 0:  40% 8/20 [00:09<00:17,  1.42s/it][AEpoch 192:  96% 258/270 [02:45<01:56,  9.74s/it, loss=0.017, v_num=ypmf]Epoch 192:  96% 258/270 [02:45<01:56,  9.74s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  45% 9/20 [00:10<00:13,  1.20s/it][A
Validation DataLoader 0:  45% 9/20 [00:10<00:13,  1.20s/it][AEpoch 192:  96% 259/270 [02:46<01:41,  9.24s/it, loss=0.017, v_num=ypmf]Epoch 192:  96% 259/270 [02:46<01:41,  9.24s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  50% 10/20 [00:11<00:10,  1.03s/it][A
Validation DataLoader 0:  50% 10/20 [00:11<00:10,  1.03s/it][AEpoch 192:  96% 260/270 [02:46<01:27,  8.79s/it, loss=0.017, v_num=ypmf]Epoch 192:  96% 260/270 [02:46<01:27,  8.79s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  55% 11/20 [00:12<00:08,  1.05it/s][A
Validation DataLoader 0:  55% 11/20 [00:12<00:08,  1.05it/s][AEpoch 192:  97% 261/270 [02:47<01:15,  8.39s/it, loss=0.017, v_num=ypmf]Epoch 192:  97% 261/270 [02:47<01:15,  8.39s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  60% 12/20 [00:13<00:08,  1.05s/it][A
Validation DataLoader 0:  60% 12/20 [00:13<00:08,  1.05s/it][AEpoch 192:  97% 262/270 [02:49<01:04,  8.05s/it, loss=0.017, v_num=ypmf]Epoch 192:  97% 262/270 [02:49<01:04,  8.05s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  65% 13/20 [00:14<00:06,  1.01it/s][A
Validation DataLoader 0:  65% 13/20 [00:14<00:06,  1.01it/s][AEpoch 192:  97% 263/270 [02:49<00:54,  7.72s/it, loss=0.017, v_num=ypmf]Epoch 192:  97% 263/270 [02:49<00:54,  7.72s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  70% 14/20 [00:15<00:06,  1.03s/it][A
Validation DataLoader 0:  70% 14/20 [00:15<00:06,  1.03s/it][AEpoch 192:  98% 264/270 [02:50<00:44,  7.43s/it, loss=0.017, v_num=ypmf]Epoch 192:  98% 264/270 [02:50<00:44,  7.43s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  75% 15/20 [00:16<00:05,  1.20s/it][A
Validation DataLoader 0:  75% 15/20 [00:16<00:05,  1.20s/it][AEpoch 192:  98% 265/270 [02:52<00:35,  7.19s/it, loss=0.017, v_num=ypmf]Epoch 192:  98% 265/270 [02:52<00:35,  7.19s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  80% 16/20 [00:18<00:04,  1.23s/it][A
Validation DataLoader 0:  80% 16/20 [00:18<00:04,  1.23s/it][AEpoch 192:  99% 266/270 [02:53<00:27,  6.96s/it, loss=0.017, v_num=ypmf]Epoch 192:  99% 266/270 [02:53<00:27,  6.96s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  85% 17/20 [00:18<00:03,  1.08s/it][A
Validation DataLoader 0:  85% 17/20 [00:18<00:03,  1.08s/it][AEpoch 192:  99% 267/270 [02:54<00:20,  6.72s/it, loss=0.017, v_num=ypmf]Epoch 192:  99% 267/270 [02:54<00:20,  6.72s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  90% 18/20 [00:19<00:02,  1.01s/it][A
Validation DataLoader 0:  90% 18/20 [00:19<00:02,  1.01s/it][AEpoch 192:  99% 268/270 [02:55<00:12,  6.50s/it, loss=0.017, v_num=ypmf]Epoch 192:  99% 268/270 [02:55<00:12,  6.50s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  95% 19/20 [00:21<00:01,  1.33s/it][A
Validation DataLoader 0:  95% 19/20 [00:21<00:01,  1.33s/it][AEpoch 192: 100% 269/270 [02:57<00:06,  6.34s/it, loss=0.017, v_num=ypmf]Epoch 192: 100% 269/270 [02:57<00:06,  6.34s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0: 100% 20/20 [00:22<00:00,  1.11s/it][A
Validation DataLoader 0: 100% 20/20 [00:22<00:00,  1.11s/it][AEpoch 192: 100% 270/270 [02:58<00:00,  6.14s/it, loss=0.017, v_num=ypmf]Epoch 192: 100% 270/270 [02:58<00:00,  6.14s/it, loss=0.017, v_num=ypmf]Epoch 192: 100% 270/270 [03:01<00:00,  6.27s/it, loss=0.017, v_num=ypmf]
                                                            [AEpoch 192: 100% 270/270 [03:01<00:00,  6.27s/it, loss=0.017, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 192:   0% 0/270 [00:00<00:00, -5523646.25it/s, loss=0.017, v_num=ypmf]Epoch 193:   0% 0/270 [00:00<00:00, -1415724.46it/s, loss=0.017, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 193:   0% 1/270 [00:01<-1:59:59, -135.37it/s, loss=0.017, v_num=ypmf] Epoch 193:   0% 1/270 [00:01<-1:59:59, -135.35it/s, loss=0.017, v_num=ypmf]Epoch 193:   0% 1/270 [00:01<-1:59:58, -127.09it/s, loss=0.0171, v_num=ypmf]Epoch 193:   1% 2/270 [00:02<-1:59:57, -80.18it/s, loss=0.0171, v_num=ypmf] Epoch 193:   1% 2/270 [00:02<-1:59:57, -80.18it/s, loss=0.0171, v_num=ypmf]Epoch 193:   1% 2/270 [00:03<-1:59:57, -77.47it/s, loss=0.0172, v_num=ypmf]Epoch 193:   1% 3/270 [00:03<-1:59:57, -69.01it/s, loss=0.0172, v_num=ypmf]Epoch 193:   1% 3/270 [00:03<-1:59:57, -69.00it/s, loss=0.0172, v_num=ypmf]Epoch 193:   1% 3/270 [00:03<-1:59:56, -66.60it/s, loss=0.0172, v_num=ypmf]Epoch 193:   1% 4/270 [00:04<-1:59:55, -49.01it/s, loss=0.0172, v_num=ypmf]Epoch 193:   1% 4/270 [00:04<-1:59:55, -49.01it/s, loss=0.0172, v_num=ypmf]Epoch 193:   1% 4/270 [00:04<-1:59:55, -47.67it/s, loss=0.0172, v_num=ypmf]Epoch 193:   2% 5/270 [00:05<-1:59:54, -43.91it/s, loss=0.0172, v_num=ypmf]Epoch 193:   2% 5/270 [00:05<-1:59:54, -43.91it/s, loss=0.0172, v_num=ypmf]Epoch 193:   2% 5/270 [00:05<-1:59:54, -42.79it/s, loss=0.0172, v_num=ypmf]Epoch 193:   2% 6/270 [00:05<-1:59:54, -39.59it/s, loss=0.0172, v_num=ypmf]Epoch 193:   2% 6/270 [00:05<-1:59:54, -39.59it/s, loss=0.0172, v_num=ypmf]Epoch 193:   2% 6/270 [00:06<-1:59:54, -38.67it/s, loss=0.017, v_num=ypmf] Epoch 193:   3% 7/270 [00:06<-1:59:53, -36.44it/s, loss=0.017, v_num=ypmf]Epoch 193:   3% 7/270 [00:06<-1:59:53, -36.44it/s, loss=0.017, v_num=ypmf]Epoch 193:   3% 7/270 [00:06<-1:59:53, -34.95it/s, loss=0.017, v_num=ypmf]Epoch 193:   3% 8/270 [00:07<-1:59:53, -32.89it/s, loss=0.017, v_num=ypmf]Epoch 193:   3% 8/270 [00:07<-1:59:53, -32.89it/s, loss=0.017, v_num=ypmf]Epoch 193:   3% 8/270 [00:07<-1:59:52, -32.33it/s, loss=0.0171, v_num=ypmf]Epoch 193:   3% 9/270 [00:07<-1:59:52, -30.34it/s, loss=0.0171, v_num=ypmf]Epoch 193:   3% 9/270 [00:07<-1:59:52, -30.34it/s, loss=0.0171, v_num=ypmf]Epoch 193:   3% 9/270 [00:07<-1:59:52, -29.77it/s, loss=0.0171, v_num=ypmf]Epoch 193:   4% 10/270 [00:08<-1:59:51, -28.18it/s, loss=0.0171, v_num=ypmf]Epoch 193:   4% 10/270 [00:08<-1:59:51, -28.18it/s, loss=0.0171, v_num=ypmf]Epoch 193:   4% 10/270 [00:08<-1:59:51, -27.75it/s, loss=0.017, v_num=ypmf] Epoch 193:   4% 11/270 [00:08<-1:59:51, -26.52it/s, loss=0.017, v_num=ypmf]Epoch 193:   4% 11/270 [00:08<-1:59:51, -26.52it/s, loss=0.017, v_num=ypmf]Epoch 193:   4% 11/270 [00:08<-1:59:51, -26.18it/s, loss=0.0171, v_num=ypmf]Epoch 193:   4% 12/270 [00:09<-1:59:50, -25.09it/s, loss=0.0171, v_num=ypmf]Epoch 193:   4% 12/270 [00:09<-1:59:50, -25.09it/s, loss=0.0171, v_num=ypmf]Epoch 193:   4% 12/270 [00:09<-1:59:50, -24.59it/s, loss=0.0172, v_num=ypmf]Epoch 193:   5% 13/270 [00:09<-1:59:50, -23.49it/s, loss=0.0172, v_num=ypmf]Epoch 193:   5% 13/270 [00:09<-1:59:50, -23.49it/s, loss=0.0172, v_num=ypmf]Epoch 193:   5% 13/270 [00:09<-1:59:49, -23.05it/s, loss=0.0172, v_num=ypmf]Epoch 193:   5% 14/270 [00:10<-1:59:49, -22.15it/s, loss=0.0172, v_num=ypmf]Epoch 193:   5% 14/270 [00:10<-1:59:49, -22.15it/s, loss=0.0172, v_num=ypmf]Epoch 193:   5% 14/270 [00:10<-1:59:49, -21.77it/s, loss=0.0172, v_num=ypmf]Epoch 193:   6% 15/270 [00:11<-1:59:48, -19.99it/s, loss=0.0172, v_num=ypmf]Epoch 193:   6% 15/270 [00:11<-1:59:48, -19.99it/s, loss=0.0172, v_num=ypmf]Epoch 193:   6% 15/270 [00:11<-1:59:48, -19.73it/s, loss=0.0171, v_num=ypmf]Epoch 193:   6% 16/270 [00:11<-1:59:47, -18.97it/s, loss=0.0171, v_num=ypmf]Epoch 193:   6% 16/270 [00:11<-1:59:47, -18.97it/s, loss=0.0171, v_num=ypmf]Epoch 193:   6% 16/270 [00:12<-1:59:47, -18.65it/s, loss=0.0171, v_num=ypmf]Epoch 193:   6% 17/270 [00:12<-1:59:46, -17.72it/s, loss=0.0171, v_num=ypmf]Epoch 193:   6% 17/270 [00:12<-1:59:46, -17.72it/s, loss=0.0171, v_num=ypmf]Epoch 193:   6% 17/270 [00:12<-1:59:46, -17.52it/s, loss=0.017, v_num=ypmf] Epoch 193:   7% 18/270 [00:13<-1:59:46, -16.95it/s, loss=0.017, v_num=ypmf]Epoch 193:   7% 18/270 [00:13<-1:59:46, -16.95it/s, loss=0.017, v_num=ypmf]Epoch 193:   7% 18/270 [00:13<-1:59:45, -16.64it/s, loss=0.0171, v_num=ypmf]Epoch 193:   7% 19/270 [00:13<-1:59:45, -15.92it/s, loss=0.0171, v_num=ypmf]Epoch 193:   7% 19/270 [00:13<-1:59:45, -15.92it/s, loss=0.0171, v_num=ypmf]Epoch 193:   7% 19/270 [00:14<-1:59:45, -15.75it/s, loss=0.0171, v_num=ypmf]Epoch 193:   7% 20/270 [00:14<-1:59:44, -15.25it/s, loss=0.0171, v_num=ypmf]Epoch 193:   7% 20/270 [00:14<-1:59:44, -15.25it/s, loss=0.0171, v_num=ypmf]Epoch 193:   7% 20/270 [00:14<-1:59:44, -15.09it/s, loss=0.0171, v_num=ypmf]Epoch 193:   8% 21/270 [00:15<-1:59:43, -14.41it/s, loss=0.0171, v_num=ypmf]Epoch 193:   8% 21/270 [00:15<-1:59:43, -14.41it/s, loss=0.0171, v_num=ypmf]Epoch 193:   8% 21/270 [00:15<-1:59:43, -14.28it/s, loss=0.0171, v_num=ypmf]Epoch 193:   8% 22/270 [00:15<-1:59:43, -13.89it/s, loss=0.0171, v_num=ypmf]Epoch 193:   8% 22/270 [00:15<-1:59:43, -13.89it/s, loss=0.0171, v_num=ypmf]Epoch 193:   8% 22/270 [00:16<-1:59:42, -13.60it/s, loss=0.0169, v_num=ypmf]Epoch 193:   9% 23/270 [00:16<-1:59:42, -13.31it/s, loss=0.0169, v_num=ypmf]Epoch 193:   9% 23/270 [00:16<-1:59:42, -13.31it/s, loss=0.0169, v_num=ypmf]Epoch 193:   9% 23/270 [00:16<-1:59:42, -13.05it/s, loss=0.0171, v_num=ypmf]Epoch 193:   9% 24/270 [00:17<-1:59:41, -12.73it/s, loss=0.0171, v_num=ypmf]Epoch 193:   9% 24/270 [00:17<-1:59:41, -12.73it/s, loss=0.0171, v_num=ypmf]Epoch 193:   9% 24/270 [00:17<-1:59:40, -12.17it/s, loss=0.0172, v_num=ypmf]Epoch 193:   9% 25/270 [00:18<-1:59:40, -11.86it/s, loss=0.0172, v_num=ypmf]Epoch 193:   9% 25/270 [00:18<-1:59:40, -11.86it/s, loss=0.0172, v_num=ypmf]Epoch 193:   9% 25/270 [00:18<-1:59:40, -11.75it/s, loss=0.0173, v_num=ypmf]Epoch 193:  10% 26/270 [00:18<-1:59:39, -11.50it/s, loss=0.0173, v_num=ypmf]Epoch 193:  10% 26/270 [00:18<-1:59:39, -11.50it/s, loss=0.0173, v_num=ypmf]Epoch 193:  10% 26/270 [00:19<-1:59:38, -10.88it/s, loss=0.0174, v_num=ypmf]Epoch 193:  10% 27/270 [00:20<-1:59:38, -10.59it/s, loss=0.0174, v_num=ypmf]Epoch 193:  10% 27/270 [00:20<-1:59:38, -10.59it/s, loss=0.0174, v_num=ypmf]Epoch 193:  10% 27/270 [00:20<-1:59:37, -10.51it/s, loss=0.0174, v_num=ypmf]Epoch 193:  10% 28/270 [00:20<-1:59:37, -10.34it/s, loss=0.0174, v_num=ypmf]Epoch 193:  10% 28/270 [00:20<-1:59:37, -10.34it/s, loss=0.0174, v_num=ypmf]Epoch 193:  10% 28/270 [00:20<-1:59:37, -10.17it/s, loss=0.0175, v_num=ypmf]Epoch 193:  11% 29/270 [00:21<-1:59:36, -9.96it/s, loss=0.0175, v_num=ypmf] Epoch 193:  11% 29/270 [00:21<-1:59:36, -9.96it/s, loss=0.0175, v_num=ypmf]Epoch 193:  11% 29/270 [00:21<-1:59:36, -9.84it/s, loss=0.0177, v_num=ypmf]Epoch 193:  11% 30/270 [00:21<-1:59:36, -9.62it/s, loss=0.0177, v_num=ypmf]Epoch 193:  11% 30/270 [00:21<-1:59:36, -9.62it/s, loss=0.0177, v_num=ypmf]Epoch 193:  11% 30/270 [00:22<-1:59:35, -9.54it/s, loss=0.0177, v_num=ypmf]Epoch 193:  11% 31/270 [00:22<-1:59:35, -9.33it/s, loss=0.0177, v_num=ypmf]Epoch 193:  11% 31/270 [00:22<-1:59:35, -9.33it/s, loss=0.0177, v_num=ypmf]Epoch 193:  11% 31/270 [00:22<-1:59:35, -9.23it/s, loss=0.0177, v_num=ypmf]Epoch 193:  12% 32/270 [00:23<-1:59:34, -9.01it/s, loss=0.0177, v_num=ypmf]Epoch 193:  12% 32/270 [00:23<-1:59:34, -9.01it/s, loss=0.0177, v_num=ypmf]Epoch 193:  12% 32/270 [00:23<-1:59:34, -8.94it/s, loss=0.0176, v_num=ypmf]Epoch 193:  12% 33/270 [00:23<-1:59:33, -8.76it/s, loss=0.0176, v_num=ypmf]Epoch 193:  12% 33/270 [00:23<-1:59:33, -8.76it/s, loss=0.0176, v_num=ypmf]Epoch 193:  12% 33/270 [00:24<-1:59:33, -8.61it/s, loss=0.0176, v_num=ypmf]Epoch 193:  13% 34/270 [00:24<-1:59:33, -8.44it/s, loss=0.0176, v_num=ypmf]Epoch 193:  13% 34/270 [00:24<-1:59:33, -8.44it/s, loss=0.0176, v_num=ypmf]Epoch 193:  13% 34/270 [00:24<-1:59:32, -8.39it/s, loss=0.0175, v_num=ypmf]Epoch 193:  13% 35/270 [00:25<-1:59:32, -8.23it/s, loss=0.0175, v_num=ypmf]Epoch 193:  13% 35/270 [00:25<-1:59:32, -8.23it/s, loss=0.0175, v_num=ypmf]Epoch 193:  13% 35/270 [00:25<-1:59:32, -8.19it/s, loss=0.0177, v_num=ypmf]Epoch 193:  13% 36/270 [00:25<-1:59:31, -8.04it/s, loss=0.0177, v_num=ypmf]Epoch 193:  13% 36/270 [00:25<-1:59:31, -8.04it/s, loss=0.0177, v_num=ypmf]Epoch 193:  13% 36/270 [00:25<-1:59:31, -8.00it/s, loss=0.0176, v_num=ypmf]Epoch 193:  14% 37/270 [00:26<-1:59:31, -7.82it/s, loss=0.0176, v_num=ypmf]Epoch 193:  14% 37/270 [00:26<-1:59:31, -7.82it/s, loss=0.0176, v_num=ypmf]Epoch 193:  14% 37/270 [00:26<-1:59:30, -7.63it/s, loss=0.0176, v_num=ypmf]Epoch 193:  14% 38/270 [00:27<-1:59:30, -7.52it/s, loss=0.0176, v_num=ypmf]Epoch 193:  14% 38/270 [00:27<-1:59:30, -7.52it/s, loss=0.0176, v_num=ypmf]Epoch 193:  14% 38/270 [00:27<-1:59:29, -7.41it/s, loss=0.0177, v_num=ypmf]Epoch 193:  14% 39/270 [00:27<-1:59:29, -7.27it/s, loss=0.0177, v_num=ypmf]Epoch 193:  14% 39/270 [00:27<-1:59:29, -7.27it/s, loss=0.0177, v_num=ypmf]Epoch 193:  14% 39/270 [00:27<-1:59:29, -7.24it/s, loss=0.0176, v_num=ypmf]Epoch 193:  15% 40/270 [00:28<-1:59:28, -7.12it/s, loss=0.0176, v_num=ypmf]Epoch 193:  15% 40/270 [00:28<-1:59:28, -7.12it/s, loss=0.0176, v_num=ypmf]Epoch 193:  15% 40/270 [00:28<-1:59:28, -7.06it/s, loss=0.0176, v_num=ypmf]Epoch 193:  15% 41/270 [00:28<-1:59:27, -6.91it/s, loss=0.0176, v_num=ypmf]Epoch 193:  15% 41/270 [00:28<-1:59:27, -6.91it/s, loss=0.0176, v_num=ypmf]Epoch 193:  15% 41/270 [00:29<-1:59:27, -6.87it/s, loss=0.0176, v_num=ypmf]Epoch 193:  16% 42/270 [00:29<-1:59:27, -6.74it/s, loss=0.0176, v_num=ypmf]Epoch 193:  16% 42/270 [00:29<-1:59:27, -6.74it/s, loss=0.0176, v_num=ypmf]Epoch 193:  16% 42/270 [00:29<-1:59:26, -6.67it/s, loss=0.0176, v_num=ypmf]Epoch 193:  16% 43/270 [00:30<-1:59:26, -6.56it/s, loss=0.0176, v_num=ypmf]Epoch 193:  16% 43/270 [00:30<-1:59:26, -6.56it/s, loss=0.0176, v_num=ypmf]Epoch 193:  16% 43/270 [00:30<-1:59:26, -6.53it/s, loss=0.0174, v_num=ypmf]Epoch 193:  16% 44/270 [00:30<-1:59:25, -6.43it/s, loss=0.0174, v_num=ypmf]Epoch 193:  16% 44/270 [00:30<-1:59:25, -6.43it/s, loss=0.0174, v_num=ypmf]Epoch 193:  16% 44/270 [00:30<-1:59:25, -6.36it/s, loss=0.0173, v_num=ypmf]Epoch 193:  17% 45/270 [00:31<-1:59:24, -6.23it/s, loss=0.0173, v_num=ypmf]Epoch 193:  17% 45/270 [00:31<-1:59:24, -6.23it/s, loss=0.0173, v_num=ypmf]Epoch 193:  17% 45/270 [00:31<-1:59:24, -6.20it/s, loss=0.0173, v_num=ypmf]Epoch 193:  17% 46/270 [00:32<-1:59:24, -6.09it/s, loss=0.0173, v_num=ypmf]Epoch 193:  17% 46/270 [00:32<-1:59:24, -6.09it/s, loss=0.0173, v_num=ypmf]Epoch 193:  17% 46/270 [00:32<-1:59:24, -6.07it/s, loss=0.0173, v_num=ypmf]Epoch 193:  17% 47/270 [00:32<-1:59:23, -5.97it/s, loss=0.0173, v_num=ypmf]Epoch 193:  17% 47/270 [00:32<-1:59:23, -5.97it/s, loss=0.0173, v_num=ypmf]Epoch 193:  17% 47/270 [00:32<-1:59:23, -5.90it/s, loss=0.0172, v_num=ypmf]Epoch 193:  18% 48/270 [00:33<-1:59:22, -5.80it/s, loss=0.0172, v_num=ypmf]Epoch 193:  18% 48/270 [00:33<-1:59:22, -5.80it/s, loss=0.0172, v_num=ypmf]Epoch 193:  18% 48/270 [00:33<-1:59:22, -5.77it/s, loss=0.0171, v_num=ypmf]Epoch 193:  18% 49/270 [00:33<-1:59:22, -5.67it/s, loss=0.0171, v_num=ypmf]Epoch 193:  18% 49/270 [00:33<-1:59:22, -5.67it/s, loss=0.0171, v_num=ypmf]Epoch 193:  18% 49/270 [00:33<-1:59:21, -5.65it/s, loss=0.0168, v_num=ypmf]Epoch 193:  19% 50/270 [00:34<-1:59:21, -5.57it/s, loss=0.0168, v_num=ypmf]Epoch 193:  19% 50/270 [00:34<-1:59:21, -5.57it/s, loss=0.0168, v_num=ypmf]Epoch 193:  19% 50/270 [00:34<-1:59:21, -5.54it/s, loss=0.017, v_num=ypmf] Epoch 193:  19% 51/270 [00:34<-1:59:20, -5.46it/s, loss=0.017, v_num=ypmf]Epoch 193:  19% 51/270 [00:34<-1:59:20, -5.46it/s, loss=0.017, v_num=ypmf]Epoch 193:  19% 51/270 [00:34<-1:59:20, -5.44it/s, loss=0.017, v_num=ypmf]Epoch 193:  19% 52/270 [00:35<-1:59:20, -5.33it/s, loss=0.017, v_num=ypmf]Epoch 193:  19% 52/270 [00:35<-1:59:20, -5.33it/s, loss=0.017, v_num=ypmf]Epoch 193:  19% 52/270 [00:35<-1:59:19, -5.31it/s, loss=0.0171, v_num=ypmf]Epoch 193:  20% 53/270 [00:35<-1:59:19, -5.22it/s, loss=0.0171, v_num=ypmf]Epoch 193:  20% 53/270 [00:35<-1:59:19, -5.22it/s, loss=0.0171, v_num=ypmf]Epoch 193:  20% 53/270 [00:36<-1:59:19, -5.20it/s, loss=0.017, v_num=ypmf] Epoch 193:  20% 54/270 [00:36<-1:59:18, -5.12it/s, loss=0.017, v_num=ypmf]Epoch 193:  20% 54/270 [00:36<-1:59:18, -5.12it/s, loss=0.017, v_num=ypmf]Epoch 193:  20% 54/270 [00:36<-1:59:18, -5.06it/s, loss=0.0171, v_num=ypmf]Epoch 193:  20% 55/270 [00:37<-1:59:17, -4.99it/s, loss=0.0171, v_num=ypmf]Epoch 193:  20% 55/270 [00:37<-1:59:17, -4.99it/s, loss=0.0171, v_num=ypmf]Epoch 193:  20% 55/270 [00:37<-1:59:17, -4.94it/s, loss=0.017, v_num=ypmf] Epoch 193:  21% 56/270 [00:37<-1:59:17, -4.87it/s, loss=0.017, v_num=ypmf]Epoch 193:  21% 56/270 [00:37<-1:59:17, -4.87it/s, loss=0.017, v_num=ypmf]Epoch 193:  21% 56/270 [00:38<-1:59:16, -4.85it/s, loss=0.017, v_num=ypmf]Epoch 193:  21% 57/270 [00:38<-1:59:16, -4.77it/s, loss=0.017, v_num=ypmf]Epoch 193:  21% 57/270 [00:38<-1:59:16, -4.77it/s, loss=0.017, v_num=ypmf]Epoch 193:  21% 57/270 [00:38<-1:59:16, -4.73it/s, loss=0.0169, v_num=ypmf]Epoch 193:  21% 58/270 [00:39<-1:59:15, -4.66it/s, loss=0.0169, v_num=ypmf]Epoch 193:  21% 58/270 [00:39<-1:59:15, -4.66it/s, loss=0.0169, v_num=ypmf]Epoch 193:  21% 58/270 [00:39<-1:59:15, -4.64it/s, loss=0.0167, v_num=ypmf]Epoch 193:  22% 59/270 [00:39<-1:59:14, -4.56it/s, loss=0.0167, v_num=ypmf]Epoch 193:  22% 59/270 [00:39<-1:59:14, -4.56it/s, loss=0.0167, v_num=ypmf]Epoch 193:  22% 59/270 [00:40<-1:59:14, -4.54it/s, loss=0.0167, v_num=ypmf]Epoch 193:  22% 60/270 [00:40<-1:59:14, -4.48it/s, loss=0.0167, v_num=ypmf]Epoch 193:  22% 60/270 [00:40<-1:59:14, -4.48it/s, loss=0.0167, v_num=ypmf]Epoch 193:  22% 60/270 [00:40<-1:59:13, -4.47it/s, loss=0.0168, v_num=ypmf]Epoch 193:  23% 61/270 [00:40<-1:59:13, -4.40it/s, loss=0.0168, v_num=ypmf]Epoch 193:  23% 61/270 [00:40<-1:59:13, -4.40it/s, loss=0.0168, v_num=ypmf]Epoch 193:  23% 61/270 [00:41<-1:59:13, -4.39it/s, loss=0.0168, v_num=ypmf]Epoch 193:  23% 62/270 [00:41<-1:59:12, -4.32it/s, loss=0.0168, v_num=ypmf]Epoch 193:  23% 62/270 [00:41<-1:59:12, -4.32it/s, loss=0.0168, v_num=ypmf]Epoch 193:  23% 62/270 [00:41<-1:59:12, -4.30it/s, loss=0.0168, v_num=ypmf]Epoch 193:  23% 63/270 [00:41<-1:59:12, -4.24it/s, loss=0.0168, v_num=ypmf]Epoch 193:  23% 63/270 [00:41<-1:59:12, -4.24it/s, loss=0.0168, v_num=ypmf]Epoch 193:  23% 63/270 [00:42<-1:59:12, -4.22it/s, loss=0.0167, v_num=ypmf]Epoch 193:  24% 64/270 [00:42<-1:59:11, -4.16it/s, loss=0.0167, v_num=ypmf]Epoch 193:  24% 64/270 [00:42<-1:59:11, -4.16it/s, loss=0.0167, v_num=ypmf]Epoch 193:  24% 64/270 [00:42<-1:59:11, -4.13it/s, loss=0.0168, v_num=ypmf]Epoch 193:  24% 65/270 [00:43<-1:59:10, -4.07it/s, loss=0.0168, v_num=ypmf]Epoch 193:  24% 65/270 [00:43<-1:59:10, -4.07it/s, loss=0.0168, v_num=ypmf]Epoch 193:  24% 65/270 [00:43<-1:59:10, -4.05it/s, loss=0.0168, v_num=ypmf]Epoch 193:  24% 66/270 [00:43<-1:59:09, -3.99it/s, loss=0.0168, v_num=ypmf]Epoch 193:  24% 66/270 [00:43<-1:59:09, -3.99it/s, loss=0.0168, v_num=ypmf]Epoch 193:  24% 66/270 [00:43<-1:59:09, -3.98it/s, loss=0.0168, v_num=ypmf]Epoch 193:  25% 67/270 [00:44<-1:59:09, -3.93it/s, loss=0.0168, v_num=ypmf]Epoch 193:  25% 67/270 [00:44<-1:59:09, -3.93it/s, loss=0.0168, v_num=ypmf]Epoch 193:  25% 67/270 [00:44<-1:59:08, -3.90it/s, loss=0.017, v_num=ypmf] Epoch 193:  25% 68/270 [00:44<-1:59:08, -3.84it/s, loss=0.017, v_num=ypmf]Epoch 193:  25% 68/270 [00:44<-1:59:08, -3.84it/s, loss=0.017, v_num=ypmf]Epoch 193:  25% 68/270 [00:45<-1:59:08, -3.83it/s, loss=0.017, v_num=ypmf]Epoch 193:  26% 69/270 [00:45<-1:59:07, -3.77it/s, loss=0.017, v_num=ypmf]Epoch 193:  26% 69/270 [00:45<-1:59:07, -3.77it/s, loss=0.017, v_num=ypmf]Epoch 193:  26% 69/270 [00:45<-1:59:07, -3.76it/s, loss=0.017, v_num=ypmf]Epoch 193:  26% 70/270 [00:46<-1:59:07, -3.71it/s, loss=0.017, v_num=ypmf]Epoch 193:  26% 70/270 [00:46<-1:59:07, -3.71it/s, loss=0.017, v_num=ypmf]Epoch 193:  26% 70/270 [00:46<-1:59:06, -3.69it/s, loss=0.0168, v_num=ypmf]Epoch 193:  26% 71/270 [00:46<-1:59:06, -3.64it/s, loss=0.0168, v_num=ypmf]Epoch 193:  26% 71/270 [00:46<-1:59:06, -3.64it/s, loss=0.0168, v_num=ypmf]Epoch 193:  26% 71/270 [00:46<-1:59:06, -3.63it/s, loss=0.0169, v_num=ypmf]Epoch 193:  27% 72/270 [00:47<-1:59:05, -3.58it/s, loss=0.0169, v_num=ypmf]Epoch 193:  27% 72/270 [00:47<-1:59:05, -3.58it/s, loss=0.0169, v_num=ypmf]Epoch 193:  27% 72/270 [00:47<-1:59:05, -3.56it/s, loss=0.0169, v_num=ypmf]Epoch 193:  27% 73/270 [00:47<-1:59:04, -3.51it/s, loss=0.0169, v_num=ypmf]Epoch 193:  27% 73/270 [00:47<-1:59:04, -3.51it/s, loss=0.0169, v_num=ypmf]Epoch 193:  27% 73/270 [00:47<-1:59:04, -3.50it/s, loss=0.0169, v_num=ypmf]Epoch 193:  27% 74/270 [00:48<-1:59:04, -3.46it/s, loss=0.0169, v_num=ypmf]Epoch 193:  27% 74/270 [00:48<-1:59:04, -3.46it/s, loss=0.0169, v_num=ypmf]Epoch 193:  27% 74/270 [00:48<-1:59:04, -3.44it/s, loss=0.0169, v_num=ypmf]Epoch 193:  28% 75/270 [00:48<-1:59:03, -3.40it/s, loss=0.0169, v_num=ypmf]Epoch 193:  28% 75/270 [00:48<-1:59:03, -3.40it/s, loss=0.0169, v_num=ypmf]Epoch 193:  28% 75/270 [00:48<-1:59:03, -3.39it/s, loss=0.0169, v_num=ypmf]Epoch 193:  28% 76/270 [00:49<-1:59:02, -3.34it/s, loss=0.0169, v_num=ypmf]Epoch 193:  28% 76/270 [00:49<-1:59:02, -3.34it/s, loss=0.0169, v_num=ypmf]Epoch 193:  28% 76/270 [00:49<-1:59:02, -3.31it/s, loss=0.0169, v_num=ypmf]Epoch 193:  29% 77/270 [00:50<-1:59:02, -3.27it/s, loss=0.0169, v_num=ypmf]Epoch 193:  29% 77/270 [00:50<-1:59:02, -3.27it/s, loss=0.0169, v_num=ypmf]Epoch 193:  29% 77/270 [00:50<-1:59:01, -3.26it/s, loss=0.0172, v_num=ypmf]Epoch 193:  29% 78/270 [00:50<-1:59:01, -3.21it/s, loss=0.0172, v_num=ypmf]Epoch 193:  29% 78/270 [00:50<-1:59:01, -3.21it/s, loss=0.0172, v_num=ypmf]Epoch 193:  29% 78/270 [00:50<-1:59:00, -3.20it/s, loss=0.0171, v_num=ypmf]Epoch 193:  29% 79/270 [00:51<-1:59:00, -3.15it/s, loss=0.0171, v_num=ypmf]Epoch 193:  29% 79/270 [00:51<-1:59:00, -3.15it/s, loss=0.0171, v_num=ypmf]Epoch 193:  29% 79/270 [00:51<-1:59:00, -3.14it/s, loss=0.0171, v_num=ypmf]Epoch 193:  30% 80/270 [00:52<-1:58:58, -3.06it/s, loss=0.0171, v_num=ypmf]Epoch 193:  30% 80/270 [00:52<-1:58:58, -3.06it/s, loss=0.0171, v_num=ypmf]Epoch 193:  30% 80/270 [00:52<-1:58:58, -3.05it/s, loss=0.0171, v_num=ypmf]Epoch 193:  30% 81/270 [00:53<-1:58:58, -3.01it/s, loss=0.0171, v_num=ypmf]Epoch 193:  30% 81/270 [00:53<-1:58:58, -3.01it/s, loss=0.0171, v_num=ypmf]Epoch 193:  30% 81/270 [00:53<-1:58:58, -3.00it/s, loss=0.017, v_num=ypmf] Epoch 193:  30% 82/270 [00:53<-1:58:57, -2.96it/s, loss=0.017, v_num=ypmf]Epoch 193:  30% 82/270 [00:53<-1:58:57, -2.96it/s, loss=0.017, v_num=ypmf]Epoch 193:  30% 82/270 [00:53<-1:58:57, -2.96it/s, loss=0.0173, v_num=ypmf]Epoch 193:  31% 83/270 [00:54<-1:58:56, -2.92it/s, loss=0.0173, v_num=ypmf]Epoch 193:  31% 83/270 [00:54<-1:58:56, -2.92it/s, loss=0.0173, v_num=ypmf]Epoch 193:  31% 83/270 [00:54<-1:58:56, -2.91it/s, loss=0.0174, v_num=ypmf]Epoch 193:  31% 84/270 [00:54<-1:58:56, -2.87it/s, loss=0.0174, v_num=ypmf]Epoch 193:  31% 84/270 [00:54<-1:58:56, -2.87it/s, loss=0.0174, v_num=ypmf]Epoch 193:  31% 84/270 [00:54<-1:58:56, -2.86it/s, loss=0.0173, v_num=ypmf]Epoch 193:  31% 85/270 [00:55<-1:58:55, -2.82it/s, loss=0.0173, v_num=ypmf]Epoch 193:  31% 85/270 [00:55<-1:58:55, -2.82it/s, loss=0.0173, v_num=ypmf]Epoch 193:  31% 85/270 [00:55<-1:58:55, -2.81it/s, loss=0.0173, v_num=ypmf]Epoch 193:  32% 86/270 [00:55<-1:58:54, -2.78it/s, loss=0.0173, v_num=ypmf]Epoch 193:  32% 86/270 [00:55<-1:58:54, -2.78it/s, loss=0.0173, v_num=ypmf]Epoch 193:  32% 86/270 [00:55<-1:58:54, -2.77it/s, loss=0.0173, v_num=ypmf]Epoch 193:  32% 87/270 [00:56<-1:58:53, -2.72it/s, loss=0.0173, v_num=ypmf]Epoch 193:  32% 87/270 [00:56<-1:58:53, -2.72it/s, loss=0.0173, v_num=ypmf]Epoch 193:  32% 87/270 [00:56<-1:58:53, -2.71it/s, loss=0.017, v_num=ypmf] Epoch 193:  33% 88/270 [00:57<-1:58:53, -2.68it/s, loss=0.017, v_num=ypmf]Epoch 193:  33% 88/270 [00:57<-1:58:53, -2.68it/s, loss=0.017, v_num=ypmf]Epoch 193:  33% 88/270 [00:57<-1:58:52, -2.67it/s, loss=0.0171, v_num=ypmf]Epoch 193:  33% 89/270 [00:57<-1:58:52, -2.64it/s, loss=0.0171, v_num=ypmf]Epoch 193:  33% 89/270 [00:57<-1:58:52, -2.64it/s, loss=0.0171, v_num=ypmf]Epoch 193:  33% 89/270 [00:57<-1:58:52, -2.63it/s, loss=0.0172, v_num=ypmf]Epoch 193:  33% 90/270 [00:58<-1:58:51, -2.59it/s, loss=0.0172, v_num=ypmf]Epoch 193:  33% 90/270 [00:58<-1:58:51, -2.59it/s, loss=0.0172, v_num=ypmf]Epoch 193:  33% 90/270 [00:58<-1:58:51, -2.58it/s, loss=0.0173, v_num=ypmf]Epoch 193:  34% 91/270 [00:58<-1:58:50, -2.55it/s, loss=0.0173, v_num=ypmf]Epoch 193:  34% 91/270 [00:58<-1:58:50, -2.55it/s, loss=0.0173, v_num=ypmf]Epoch 193:  34% 91/270 [00:59<-1:58:50, -2.54it/s, loss=0.0172, v_num=ypmf]Epoch 193:  34% 92/270 [00:59<-1:58:49, -2.50it/s, loss=0.0172, v_num=ypmf]Epoch 193:  34% 92/270 [00:59<-1:58:49, -2.50it/s, loss=0.0172, v_num=ypmf]Epoch 193:  34% 92/270 [00:59<-1:58:49, -2.49it/s, loss=0.0173, v_num=ypmf]Epoch 193:  34% 93/270 [01:00<-1:58:49, -2.46it/s, loss=0.0173, v_num=ypmf]Epoch 193:  34% 93/270 [01:00<-1:58:49, -2.46it/s, loss=0.0173, v_num=ypmf]Epoch 193:  34% 93/270 [01:00<-1:58:48, -2.46it/s, loss=0.0174, v_num=ypmf]Epoch 193:  35% 94/270 [01:00<-1:58:48, -2.42it/s, loss=0.0174, v_num=ypmf]Epoch 193:  35% 94/270 [01:00<-1:58:48, -2.42it/s, loss=0.0174, v_num=ypmf]Epoch 193:  35% 94/270 [01:00<-1:58:48, -2.42it/s, loss=0.0173, v_num=ypmf]Epoch 193:  35% 95/270 [01:01<-1:58:47, -2.39it/s, loss=0.0173, v_num=ypmf]Epoch 193:  35% 95/270 [01:01<-1:58:47, -2.39it/s, loss=0.0173, v_num=ypmf]Epoch 193:  35% 95/270 [01:01<-1:58:47, -2.38it/s, loss=0.0173, v_num=ypmf]Epoch 193:  36% 96/270 [01:01<-1:58:46, -2.35it/s, loss=0.0173, v_num=ypmf]Epoch 193:  36% 96/270 [01:01<-1:58:46, -2.35it/s, loss=0.0173, v_num=ypmf]Epoch 193:  36% 96/270 [01:02<-1:58:46, -2.33it/s, loss=0.0173, v_num=ypmf]Epoch 193:  36% 97/270 [01:02<-1:58:45, -2.30it/s, loss=0.0173, v_num=ypmf]Epoch 193:  36% 97/270 [01:02<-1:58:45, -2.30it/s, loss=0.0173, v_num=ypmf]Epoch 193:  36% 97/270 [01:02<-1:58:45, -2.29it/s, loss=0.0171, v_num=ypmf]Epoch 193:  36% 98/270 [01:03<-1:58:44, -2.26it/s, loss=0.0171, v_num=ypmf]Epoch 193:  36% 98/270 [01:03<-1:58:44, -2.26it/s, loss=0.0171, v_num=ypmf]Epoch 193:  36% 98/270 [01:03<-1:58:44, -2.26it/s, loss=0.0172, v_num=ypmf]Epoch 193:  37% 99/270 [01:03<-1:58:43, -2.22it/s, loss=0.0172, v_num=ypmf]Epoch 193:  37% 99/270 [01:03<-1:58:43, -2.22it/s, loss=0.0172, v_num=ypmf]Epoch 193:  37% 99/270 [01:04<-1:58:43, -2.21it/s, loss=0.0172, v_num=ypmf]Epoch 193:  37% 100/270 [01:04<-1:58:43, -2.18it/s, loss=0.0172, v_num=ypmf]Epoch 193:  37% 100/270 [01:04<-1:58:43, -2.18it/s, loss=0.0172, v_num=ypmf]Epoch 193:  37% 100/270 [01:04<-1:58:42, -2.18it/s, loss=0.0171, v_num=ypmf]Epoch 193:  37% 101/270 [01:05<-1:58:42, -2.15it/s, loss=0.0171, v_num=ypmf]Epoch 193:  37% 101/270 [01:05<-1:58:42, -2.15it/s, loss=0.0171, v_num=ypmf]Epoch 193:  37% 101/270 [01:05<-1:58:42, -2.14it/s, loss=0.0171, v_num=ypmf]Epoch 193:  38% 102/270 [01:05<-1:58:41, -2.11it/s, loss=0.0171, v_num=ypmf]Epoch 193:  38% 102/270 [01:05<-1:58:41, -2.11it/s, loss=0.0171, v_num=ypmf]Epoch 193:  38% 102/270 [01:06<-1:58:41, -2.11it/s, loss=0.017, v_num=ypmf] Epoch 193:  38% 103/270 [01:06<-1:58:40, -2.08it/s, loss=0.017, v_num=ypmf]Epoch 193:  38% 103/270 [01:06<-1:58:40, -2.08it/s, loss=0.017, v_num=ypmf]Epoch 193:  38% 103/270 [01:06<-1:58:40, -2.07it/s, loss=0.017, v_num=ypmf]Epoch 193:  39% 104/270 [01:07<-1:58:39, -2.04it/s, loss=0.017, v_num=ypmf]Epoch 193:  39% 104/270 [01:07<-1:58:39, -2.04it/s, loss=0.017, v_num=ypmf]Epoch 193:  39% 104/270 [01:07<-1:58:39, -2.04it/s, loss=0.017, v_num=ypmf]Epoch 193:  39% 105/270 [01:07<-1:58:39, -2.01it/s, loss=0.017, v_num=ypmf]Epoch 193:  39% 105/270 [01:07<-1:58:39, -2.01it/s, loss=0.017, v_num=ypmf]Epoch 193:  39% 105/270 [01:07<-1:58:38, -2.01it/s, loss=0.017, v_num=ypmf]Epoch 193:  39% 106/270 [01:08<-1:58:38, -1.98it/s, loss=0.017, v_num=ypmf]Epoch 193:  39% 106/270 [01:08<-1:58:38, -1.98it/s, loss=0.017, v_num=ypmf]Epoch 193:  39% 106/270 [01:08<-1:58:38, -1.98it/s, loss=0.017, v_num=ypmf]Epoch 193:  40% 107/270 [01:08<-1:58:37, -1.95it/s, loss=0.017, v_num=ypmf]Epoch 193:  40% 107/270 [01:08<-1:58:37, -1.95it/s, loss=0.017, v_num=ypmf]Epoch 193:  40% 107/270 [01:08<-1:58:37, -1.94it/s, loss=0.0171, v_num=ypmf]Epoch 193:  40% 108/270 [01:09<-1:58:36, -1.92it/s, loss=0.0171, v_num=ypmf]Epoch 193:  40% 108/270 [01:09<-1:58:36, -1.92it/s, loss=0.0171, v_num=ypmf]Epoch 193:  40% 108/270 [01:09<-1:58:36, -1.91it/s, loss=0.0169, v_num=ypmf]Epoch 193:  40% 109/270 [01:10<-1:58:35, -1.88it/s, loss=0.0169, v_num=ypmf]Epoch 193:  40% 109/270 [01:10<-1:58:35, -1.88it/s, loss=0.0169, v_num=ypmf]Epoch 193:  40% 109/270 [01:10<-1:58:35, -1.88it/s, loss=0.0168, v_num=ypmf]Epoch 193:  41% 110/270 [01:10<-1:58:34, -1.85it/s, loss=0.0168, v_num=ypmf]Epoch 193:  41% 110/270 [01:10<-1:58:34, -1.85it/s, loss=0.0168, v_num=ypmf]Epoch 193:  41% 110/270 [01:10<-1:58:34, -1.85it/s, loss=0.0167, v_num=ypmf]Epoch 193:  41% 111/270 [01:11<-1:58:33, -1.83it/s, loss=0.0167, v_num=ypmf]Epoch 193:  41% 111/270 [01:11<-1:58:33, -1.83it/s, loss=0.0167, v_num=ypmf]Epoch 193:  41% 111/270 [01:11<-1:58:33, -1.82it/s, loss=0.0166, v_num=ypmf]Epoch 193:  41% 112/270 [01:12<-1:58:32, -1.79it/s, loss=0.0166, v_num=ypmf]Epoch 193:  41% 112/270 [01:12<-1:58:32, -1.79it/s, loss=0.0166, v_num=ypmf]Epoch 193:  41% 112/270 [01:12<-1:58:32, -1.79it/s, loss=0.0165, v_num=ypmf]Epoch 193:  42% 113/270 [01:12<-1:58:31, -1.76it/s, loss=0.0165, v_num=ypmf]Epoch 193:  42% 113/270 [01:12<-1:58:31, -1.76it/s, loss=0.0165, v_num=ypmf]Epoch 193:  42% 113/270 [01:12<-1:58:31, -1.76it/s, loss=0.0164, v_num=ypmf]Epoch 193:  42% 114/270 [01:13<-1:58:31, -1.74it/s, loss=0.0164, v_num=ypmf]Epoch 193:  42% 114/270 [01:13<-1:58:31, -1.74it/s, loss=0.0164, v_num=ypmf]Epoch 193:  42% 114/270 [01:13<-1:58:30, -1.73it/s, loss=0.0163, v_num=ypmf]Epoch 193:  43% 115/270 [01:13<-1:58:30, -1.71it/s, loss=0.0163, v_num=ypmf]Epoch 193:  43% 115/270 [01:13<-1:58:30, -1.71it/s, loss=0.0163, v_num=ypmf]Epoch 193:  43% 115/270 [01:13<-1:58:30, -1.71it/s, loss=0.0163, v_num=ypmf]Epoch 193:  43% 116/270 [01:14<-1:58:29, -1.68it/s, loss=0.0163, v_num=ypmf]Epoch 193:  43% 116/270 [01:14<-1:58:29, -1.68it/s, loss=0.0163, v_num=ypmf]Epoch 193:  43% 116/270 [01:14<-1:58:29, -1.68it/s, loss=0.0163, v_num=ypmf]Epoch 193:  43% 117/270 [01:14<-1:58:28, -1.66it/s, loss=0.0163, v_num=ypmf]Epoch 193:  43% 117/270 [01:14<-1:58:28, -1.66it/s, loss=0.0163, v_num=ypmf]Epoch 193:  43% 117/270 [01:14<-1:58:28, -1.65it/s, loss=0.0164, v_num=ypmf]Epoch 193:  44% 118/270 [01:15<-1:58:27, -1.63it/s, loss=0.0164, v_num=ypmf]Epoch 193:  44% 118/270 [01:15<-1:58:27, -1.63it/s, loss=0.0164, v_num=ypmf]Epoch 193:  44% 118/270 [01:15<-1:58:27, -1.62it/s, loss=0.0163, v_num=ypmf]Epoch 193:  44% 119/270 [01:16<-1:58:26, -1.60it/s, loss=0.0163, v_num=ypmf]Epoch 193:  44% 119/270 [01:16<-1:58:26, -1.60it/s, loss=0.0163, v_num=ypmf]Epoch 193:  44% 119/270 [01:16<-1:58:26, -1.60it/s, loss=0.0163, v_num=ypmf]Epoch 193:  44% 120/270 [01:16<-1:58:26, -1.58it/s, loss=0.0163, v_num=ypmf]Epoch 193:  44% 120/270 [01:16<-1:58:26, -1.58it/s, loss=0.0163, v_num=ypmf]Epoch 193:  44% 120/270 [01:16<-1:58:25, -1.58it/s, loss=0.0164, v_num=ypmf]Epoch 193:  45% 121/270 [01:17<-1:58:25, -1.56it/s, loss=0.0164, v_num=ypmf]Epoch 193:  45% 121/270 [01:17<-1:58:25, -1.56it/s, loss=0.0164, v_num=ypmf]Epoch 193:  45% 121/270 [01:17<-1:58:24, -1.55it/s, loss=0.0164, v_num=ypmf]Epoch 193:  45% 122/270 [01:17<-1:58:24, -1.53it/s, loss=0.0164, v_num=ypmf]Epoch 193:  45% 122/270 [01:17<-1:58:24, -1.53it/s, loss=0.0164, v_num=ypmf]Epoch 193:  45% 122/270 [01:17<-1:58:24, -1.53it/s, loss=0.0164, v_num=ypmf]Epoch 193:  46% 123/270 [01:18<-1:58:23, -1.51it/s, loss=0.0164, v_num=ypmf]Epoch 193:  46% 123/270 [01:18<-1:58:23, -1.51it/s, loss=0.0164, v_num=ypmf]Epoch 193:  46% 123/270 [01:18<-1:58:23, -1.50it/s, loss=0.0165, v_num=ypmf]Epoch 193:  46% 124/270 [01:18<-1:58:22, -1.48it/s, loss=0.0165, v_num=ypmf]Epoch 193:  46% 124/270 [01:18<-1:58:22, -1.48it/s, loss=0.0165, v_num=ypmf]Epoch 193:  46% 124/270 [01:19<-1:58:22, -1.48it/s, loss=0.0165, v_num=ypmf]Epoch 193:  46% 125/270 [01:19<-1:58:21, -1.46it/s, loss=0.0165, v_num=ypmf]Epoch 193:  46% 125/270 [01:19<-1:58:21, -1.46it/s, loss=0.0165, v_num=ypmf]Epoch 193:  46% 125/270 [01:19<-1:58:21, -1.46it/s, loss=0.0166, v_num=ypmf]Epoch 193:  47% 126/270 [01:20<-1:58:20, -1.44it/s, loss=0.0166, v_num=ypmf]Epoch 193:  47% 126/270 [01:20<-1:58:20, -1.44it/s, loss=0.0166, v_num=ypmf]Epoch 193:  47% 126/270 [01:20<-1:58:20, -1.43it/s, loss=0.0166, v_num=ypmf]Epoch 193:  47% 127/270 [01:20<-1:58:19, -1.41it/s, loss=0.0166, v_num=ypmf]Epoch 193:  47% 127/270 [01:20<-1:58:19, -1.41it/s, loss=0.0166, v_num=ypmf]Epoch 193:  47% 127/270 [01:21<-1:58:19, -1.41it/s, loss=0.0165, v_num=ypmf]Epoch 193:  47% 128/270 [01:21<-1:58:18, -1.39it/s, loss=0.0165, v_num=ypmf]Epoch 193:  47% 128/270 [01:21<-1:58:18, -1.39it/s, loss=0.0165, v_num=ypmf]Epoch 193:  47% 128/270 [01:21<-1:58:18, -1.39it/s, loss=0.0165, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 273848. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 356016. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 352095. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 232997. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 337585. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 330446. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 273998. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319518. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 271962. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 346044. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 271471. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 310243. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 247709. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 322854. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 362798. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 344029. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 295625. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 318206. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 360587. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 381581. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 335317. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 315949. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 374205. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 271257. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 284973. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 193:  48% 129/270 [01:21<-1:58:17, -1.37it/s, loss=0.0165, v_num=ypmf]Epoch 193:  48% 129/270 [01:21<-1:58:17, -1.37it/s, loss=0.0165, v_num=ypmf]Epoch 193:  48% 129/270 [01:22<-1:58:17, -1.36it/s, loss=0.0167, v_num=ypmf]Epoch 193:  48% 130/270 [01:22<-1:58:16, -1.35it/s, loss=0.0167, v_num=ypmf]Epoch 193:  48% 130/270 [01:22<-1:58:16, -1.35it/s, loss=0.0167, v_num=ypmf]Epoch 193:  48% 130/270 [01:22<-1:58:16, -1.34it/s, loss=0.0168, v_num=ypmf]Epoch 193:  49% 131/270 [01:23<-1:58:15, -1.32it/s, loss=0.0168, v_num=ypmf]Epoch 193:  49% 131/270 [01:23<-1:58:15, -1.32it/s, loss=0.0168, v_num=ypmf]Epoch 193:  49% 131/270 [01:23<-1:58:15, -1.32it/s, loss=0.0169, v_num=ypmf]Epoch 193:  49% 132/270 [01:23<-1:58:14, -1.30it/s, loss=0.0169, v_num=ypmf]Epoch 193:  49% 132/270 [01:23<-1:58:14, -1.30it/s, loss=0.0169, v_num=ypmf]Epoch 193:  49% 132/270 [01:23<-1:58:14, -1.30it/s, loss=0.0171, v_num=ypmf]Epoch 193:  49% 133/270 [01:24<-1:58:13, -1.28it/s, loss=0.0171, v_num=ypmf]Epoch 193:  49% 133/270 [01:24<-1:58:13, -1.28it/s, loss=0.0171, v_num=ypmf]Epoch 193:  49% 133/270 [01:24<-1:58:13, -1.28it/s, loss=0.0171, v_num=ypmf]Epoch 193:  50% 134/270 [01:24<-1:58:12, -1.26it/s, loss=0.0171, v_num=ypmf]Epoch 193:  50% 134/270 [01:24<-1:58:12, -1.26it/s, loss=0.0171, v_num=ypmf]Epoch 193:  50% 134/270 [01:25<-1:58:12, -1.26it/s, loss=0.0171, v_num=ypmf]Epoch 193:  50% 135/270 [01:25<-1:58:12, -1.24it/s, loss=0.0171, v_num=ypmf]Epoch 193:  50% 135/270 [01:25<-1:58:12, -1.24it/s, loss=0.0171, v_num=ypmf]Epoch 193:  50% 135/270 [01:25<-1:58:11, -1.24it/s, loss=0.0171, v_num=ypmf]Epoch 193:  50% 136/270 [01:25<-1:58:11, -1.22it/s, loss=0.0171, v_num=ypmf]Epoch 193:  50% 136/270 [01:25<-1:58:11, -1.22it/s, loss=0.0171, v_num=ypmf]Epoch 193:  50% 136/270 [01:26<-1:58:10, -1.22it/s, loss=0.0172, v_num=ypmf]Epoch 193:  51% 137/270 [01:26<-1:58:10, -1.20it/s, loss=0.0172, v_num=ypmf]Epoch 193:  51% 137/270 [01:26<-1:58:10, -1.20it/s, loss=0.0172, v_num=ypmf]Epoch 193:  51% 137/270 [01:26<-1:58:09, -1.20it/s, loss=0.0172, v_num=ypmf]Epoch 193:  51% 138/270 [01:27<-1:58:09, -1.18it/s, loss=0.0172, v_num=ypmf]Epoch 193:  51% 138/270 [01:27<-1:58:09, -1.18it/s, loss=0.0172, v_num=ypmf]Epoch 193:  51% 138/270 [01:27<-1:58:09, -1.18it/s, loss=0.0173, v_num=ypmf]Epoch 193:  51% 139/270 [01:27<-1:58:08, -1.16it/s, loss=0.0173, v_num=ypmf]Epoch 193:  51% 139/270 [01:27<-1:58:08, -1.16it/s, loss=0.0173, v_num=ypmf]Epoch 193:  51% 139/270 [01:27<-1:58:08, -1.16it/s, loss=0.0172, v_num=ypmf]Epoch 193:  52% 140/270 [01:28<-1:58:07, -1.14it/s, loss=0.0172, v_num=ypmf]Epoch 193:  52% 140/270 [01:28<-1:58:07, -1.14it/s, loss=0.0172, v_num=ypmf]Epoch 193:  52% 140/270 [01:28<-1:58:07, -1.14it/s, loss=0.0171, v_num=ypmf]Epoch 193:  52% 141/270 [01:28<-1:58:06, -1.13it/s, loss=0.0171, v_num=ypmf]Epoch 193:  52% 141/270 [01:28<-1:58:06, -1.13it/s, loss=0.0171, v_num=ypmf]Epoch 193:  52% 141/270 [01:28<-1:58:06, -1.12it/s, loss=0.0173, v_num=ypmf]Epoch 193:  53% 142/270 [01:29<-1:58:05, -1.11it/s, loss=0.0173, v_num=ypmf]Epoch 193:  53% 142/270 [01:29<-1:58:05, -1.11it/s, loss=0.0173, v_num=ypmf]Epoch 193:  53% 142/270 [01:29<-1:58:05, -1.11it/s, loss=0.0172, v_num=ypmf]Epoch 193:  53% 143/270 [01:29<-1:58:04, -1.09it/s, loss=0.0172, v_num=ypmf]Epoch 193:  53% 143/270 [01:29<-1:58:04, -1.09it/s, loss=0.0172, v_num=ypmf]Epoch 193:  53% 143/270 [01:30<-1:58:04, -1.09it/s, loss=0.0173, v_num=ypmf]Epoch 193:  53% 144/270 [01:30<-1:58:03, -1.07it/s, loss=0.0173, v_num=ypmf]Epoch 193:  53% 144/270 [01:30<-1:58:03, -1.07it/s, loss=0.0173, v_num=ypmf]Epoch 193:  53% 144/270 [01:30<-1:58:03, -1.07it/s, loss=0.0172, v_num=ypmf]Epoch 193:  54% 145/270 [01:30<-1:58:02, -1.06it/s, loss=0.0172, v_num=ypmf]Epoch 193:  54% 145/270 [01:30<-1:58:02, -1.06it/s, loss=0.0172, v_num=ypmf]Epoch 193:  54% 145/270 [01:32<-1:58:01, -1.04it/s, loss=0.0172, v_num=ypmf]Epoch 193:  54% 146/270 [01:32<-1:58:00, -1.03it/s, loss=0.0172, v_num=ypmf]Epoch 193:  54% 146/270 [01:32<-1:58:00, -1.03it/s, loss=0.0172, v_num=ypmf]Epoch 193:  54% 146/270 [01:32<-1:58:00, -1.03it/s, loss=0.0172, v_num=ypmf]Epoch 193:  54% 147/270 [01:32<-1:57:59, -1.01it/s, loss=0.0172, v_num=ypmf]Epoch 193:  54% 147/270 [01:32<-1:57:59, -1.01it/s, loss=0.0172, v_num=ypmf]Epoch 193:  54% 147/270 [01:33<-1:57:59, -1.01it/s, loss=0.0173, v_num=ypmf]Epoch 193:  55% 148/270 [01:33<-1:57:58, -0.99it/s, loss=0.0173, v_num=ypmf]Epoch 193:  55% 148/270 [01:33<-1:57:58, -0.99it/s, loss=0.0173, v_num=ypmf]Epoch 193:  55% 148/270 [01:33<-1:57:58, -0.99it/s, loss=0.0172, v_num=ypmf]Epoch 193:  55% 149/270 [01:34<-1:57:57, -0.98it/s, loss=0.0172, v_num=ypmf]Epoch 193:  55% 149/270 [01:34<-1:57:57, -0.98it/s, loss=0.0172, v_num=ypmf]Epoch 193:  55% 149/270 [01:34<-1:57:56, -0.98it/s, loss=0.0171, v_num=ypmf]Epoch 193:  56% 150/270 [01:34<-1:57:56, -0.96it/s, loss=0.0171, v_num=ypmf]Epoch 193:  56% 150/270 [01:34<-1:57:56, -0.96it/s, loss=0.0171, v_num=ypmf]Epoch 193:  56% 150/270 [01:34<-1:57:55, -0.96it/s, loss=0.017, v_num=ypmf] Epoch 193:  56% 151/270 [01:35<-1:57:54, -0.94it/s, loss=0.017, v_num=ypmf]Epoch 193:  56% 151/270 [01:35<-1:57:54, -0.94it/s, loss=0.017, v_num=ypmf]Epoch 193:  56% 151/270 [01:35<-1:57:54, -0.94it/s, loss=0.017, v_num=ypmf]Epoch 193:  56% 152/270 [01:35<-1:57:53, -0.93it/s, loss=0.017, v_num=ypmf]Epoch 193:  56% 152/270 [01:35<-1:57:53, -0.93it/s, loss=0.017, v_num=ypmf]Epoch 193:  56% 152/270 [01:36<-1:57:53, -0.93it/s, loss=0.017, v_num=ypmf]Epoch 193:  57% 153/270 [01:36<-1:57:52, -0.91it/s, loss=0.017, v_num=ypmf]Epoch 193:  57% 153/270 [01:36<-1:57:52, -0.91it/s, loss=0.017, v_num=ypmf]Epoch 193:  57% 153/270 [01:36<-1:57:52, -0.91it/s, loss=0.017, v_num=ypmf]Epoch 193:  57% 154/270 [01:37<-1:57:51, -0.90it/s, loss=0.017, v_num=ypmf]Epoch 193:  57% 154/270 [01:37<-1:57:51, -0.90it/s, loss=0.017, v_num=ypmf]Epoch 193:  57% 154/270 [01:37<-1:57:51, -0.89it/s, loss=0.017, v_num=ypmf]Epoch 193:  57% 155/270 [01:37<-1:57:50, -0.88it/s, loss=0.017, v_num=ypmf]Epoch 193:  57% 155/270 [01:37<-1:57:50, -0.88it/s, loss=0.017, v_num=ypmf]Epoch 193:  57% 155/270 [01:37<-1:57:50, -0.88it/s, loss=0.017, v_num=ypmf]Epoch 193:  58% 156/270 [01:38<-1:57:49, -0.87it/s, loss=0.017, v_num=ypmf]Epoch 193:  58% 156/270 [01:38<-1:57:49, -0.87it/s, loss=0.017, v_num=ypmf]Epoch 193:  58% 156/270 [01:38<-1:57:48, -0.86it/s, loss=0.017, v_num=ypmf]Epoch 193:  58% 157/270 [01:38<-1:57:47, -0.85it/s, loss=0.017, v_num=ypmf]Epoch 193:  58% 157/270 [01:38<-1:57:47, -0.85it/s, loss=0.017, v_num=ypmf]Epoch 193:  58% 157/270 [01:39<-1:57:47, -0.85it/s, loss=0.0169, v_num=ypmf]Epoch 193:  59% 158/270 [01:39<-1:57:46, -0.83it/s, loss=0.0169, v_num=ypmf]Epoch 193:  59% 158/270 [01:39<-1:57:46, -0.83it/s, loss=0.0169, v_num=ypmf]Epoch 193:  59% 158/270 [01:39<-1:57:46, -0.83it/s, loss=0.0169, v_num=ypmf]Epoch 193:  59% 159/270 [01:40<-1:57:45, -0.82it/s, loss=0.0169, v_num=ypmf]Epoch 193:  59% 159/270 [01:40<-1:57:45, -0.82it/s, loss=0.0169, v_num=ypmf]Epoch 193:  59% 159/270 [01:40<-1:57:45, -0.82it/s, loss=0.017, v_num=ypmf] Epoch 193:  59% 160/270 [01:40<-1:57:44, -0.80it/s, loss=0.017, v_num=ypmf]Epoch 193:  59% 160/270 [01:40<-1:57:44, -0.80it/s, loss=0.017, v_num=ypmf]Epoch 193:  59% 160/270 [01:40<-1:57:43, -0.80it/s, loss=0.0171, v_num=ypmf]Epoch 193:  60% 161/270 [01:41<-1:57:43, -0.79it/s, loss=0.0171, v_num=ypmf]Epoch 193:  60% 161/270 [01:41<-1:57:43, -0.79it/s, loss=0.0171, v_num=ypmf]Epoch 193:  60% 161/270 [01:41<-1:57:42, -0.79it/s, loss=0.0169, v_num=ypmf]Epoch 193:  60% 162/270 [01:41<-1:57:41, -0.77it/s, loss=0.0169, v_num=ypmf]Epoch 193:  60% 162/270 [01:41<-1:57:41, -0.77it/s, loss=0.0169, v_num=ypmf]Epoch 193:  60% 162/270 [01:42<-1:57:41, -0.77it/s, loss=0.0168, v_num=ypmf]Epoch 193:  60% 163/270 [01:42<-1:57:40, -0.76it/s, loss=0.0168, v_num=ypmf]Epoch 193:  60% 163/270 [01:42<-1:57:40, -0.76it/s, loss=0.0168, v_num=ypmf]Epoch 193:  60% 163/270 [01:42<-1:57:40, -0.76it/s, loss=0.0167, v_num=ypmf]Epoch 193:  61% 164/270 [01:42<-1:57:39, -0.75it/s, loss=0.0167, v_num=ypmf]Epoch 193:  61% 164/270 [01:42<-1:57:39, -0.75it/s, loss=0.0167, v_num=ypmf]Epoch 193:  61% 164/270 [01:43<-1:57:38, -0.75it/s, loss=0.0167, v_num=ypmf]Epoch 193:  61% 165/270 [01:43<-1:57:37, -0.73it/s, loss=0.0167, v_num=ypmf]Epoch 193:  61% 165/270 [01:43<-1:57:37, -0.73it/s, loss=0.0167, v_num=ypmf]Epoch 193:  61% 165/270 [01:43<-1:57:37, -0.73it/s, loss=0.0166, v_num=ypmf]Epoch 193:  61% 166/270 [01:44<-1:57:36, -0.72it/s, loss=0.0166, v_num=ypmf]Epoch 193:  61% 166/270 [01:44<-1:57:36, -0.72it/s, loss=0.0166, v_num=ypmf]Epoch 193:  61% 166/270 [01:44<-1:57:36, -0.72it/s, loss=0.0166, v_num=ypmf]Epoch 193:  62% 167/270 [01:44<-1:57:34, -0.70it/s, loss=0.0166, v_num=ypmf]Epoch 193:  62% 167/270 [01:44<-1:57:34, -0.70it/s, loss=0.0166, v_num=ypmf]Epoch 193:  62% 167/270 [01:45<-1:57:34, -0.70it/s, loss=0.0165, v_num=ypmf]Epoch 193:  62% 168/270 [01:45<-1:57:33, -0.69it/s, loss=0.0165, v_num=ypmf]Epoch 193:  62% 168/270 [01:45<-1:57:33, -0.69it/s, loss=0.0165, v_num=ypmf]Epoch 193:  62% 168/270 [01:45<-1:57:33, -0.69it/s, loss=0.0166, v_num=ypmf]Epoch 193:  63% 169/270 [01:46<-1:57:31, -0.68it/s, loss=0.0166, v_num=ypmf]Epoch 193:  63% 169/270 [01:46<-1:57:31, -0.68it/s, loss=0.0166, v_num=ypmf]Epoch 193:  63% 169/270 [01:46<-1:57:31, -0.68it/s, loss=0.0166, v_num=ypmf]Epoch 193:  63% 170/270 [01:46<-1:57:30, -0.66it/s, loss=0.0166, v_num=ypmf]Epoch 193:  63% 170/270 [01:46<-1:57:30, -0.66it/s, loss=0.0166, v_num=ypmf]Epoch 193:  63% 170/270 [01:46<-1:57:30, -0.66it/s, loss=0.0165, v_num=ypmf]Epoch 193:  63% 171/270 [01:47<-1:57:29, -0.65it/s, loss=0.0165, v_num=ypmf]Epoch 193:  63% 171/270 [01:47<-1:57:29, -0.65it/s, loss=0.0165, v_num=ypmf]Epoch 193:  63% 171/270 [01:47<-1:57:28, -0.65it/s, loss=0.0165, v_num=ypmf]Epoch 193:  64% 172/270 [01:47<-1:57:27, -0.64it/s, loss=0.0165, v_num=ypmf]Epoch 193:  64% 172/270 [01:47<-1:57:27, -0.64it/s, loss=0.0165, v_num=ypmf]Epoch 193:  64% 172/270 [01:48<-1:57:27, -0.64it/s, loss=0.0164, v_num=ypmf]Epoch 193:  64% 173/270 [01:48<-1:57:26, -0.63it/s, loss=0.0164, v_num=ypmf]Epoch 193:  64% 173/270 [01:48<-1:57:26, -0.63it/s, loss=0.0164, v_num=ypmf]Epoch 193:  64% 173/270 [01:48<-1:57:26, -0.63it/s, loss=0.0164, v_num=ypmf]Epoch 193:  64% 174/270 [01:48<-1:57:24, -0.61it/s, loss=0.0164, v_num=ypmf]Epoch 193:  64% 174/270 [01:48<-1:57:24, -0.61it/s, loss=0.0164, v_num=ypmf]Epoch 193:  64% 174/270 [01:49<-1:57:24, -0.61it/s, loss=0.0164, v_num=ypmf]Epoch 193:  65% 175/270 [01:49<-1:57:23, -0.60it/s, loss=0.0164, v_num=ypmf]Epoch 193:  65% 175/270 [01:49<-1:57:23, -0.60it/s, loss=0.0164, v_num=ypmf]Epoch 193:  65% 175/270 [01:49<-1:57:23, -0.60it/s, loss=0.0165, v_num=ypmf]Epoch 193:  65% 176/270 [01:50<-1:57:21, -0.59it/s, loss=0.0165, v_num=ypmf]Epoch 193:  65% 176/270 [01:50<-1:57:21, -0.59it/s, loss=0.0165, v_num=ypmf]Epoch 193:  65% 176/270 [01:50<-1:57:21, -0.59it/s, loss=0.0165, v_num=ypmf]Epoch 193:  66% 177/270 [01:50<-1:57:20, -0.58it/s, loss=0.0165, v_num=ypmf]Epoch 193:  66% 177/270 [01:50<-1:57:20, -0.58it/s, loss=0.0165, v_num=ypmf]Epoch 193:  66% 177/270 [01:50<-1:57:19, -0.58it/s, loss=0.0165, v_num=ypmf]Epoch 193:  66% 178/270 [01:51<-1:57:18, -0.57it/s, loss=0.0165, v_num=ypmf]Epoch 193:  66% 178/270 [01:51<-1:57:18, -0.57it/s, loss=0.0165, v_num=ypmf]Epoch 193:  66% 178/270 [01:51<-1:57:18, -0.57it/s, loss=0.0164, v_num=ypmf]Epoch 193:  66% 179/270 [01:51<-1:57:16, -0.55it/s, loss=0.0164, v_num=ypmf]Epoch 193:  66% 179/270 [01:51<-1:57:16, -0.55it/s, loss=0.0164, v_num=ypmf]Epoch 193:  66% 179/270 [01:52<-1:57:16, -0.55it/s, loss=0.0164, v_num=ypmf]Epoch 193:  67% 180/270 [01:52<-1:57:15, -0.54it/s, loss=0.0164, v_num=ypmf]Epoch 193:  67% 180/270 [01:52<-1:57:15, -0.54it/s, loss=0.0164, v_num=ypmf]Epoch 193:  67% 180/270 [01:52<-1:57:14, -0.54it/s, loss=0.0166, v_num=ypmf]Epoch 193:  67% 181/270 [01:53<-1:57:13, -0.53it/s, loss=0.0166, v_num=ypmf]Epoch 193:  67% 181/270 [01:53<-1:57:13, -0.53it/s, loss=0.0166, v_num=ypmf]Epoch 193:  67% 181/270 [01:53<-1:57:12, -0.53it/s, loss=0.0167, v_num=ypmf]Epoch 193:  67% 182/270 [01:53<-1:57:11, -0.52it/s, loss=0.0167, v_num=ypmf]Epoch 193:  67% 182/270 [01:53<-1:57:11, -0.52it/s, loss=0.0167, v_num=ypmf]Epoch 193:  67% 182/270 [01:54<-1:57:10, -0.52it/s, loss=0.0167, v_num=ypmf]Epoch 193:  68% 183/270 [01:54<-1:57:09, -0.51it/s, loss=0.0167, v_num=ypmf]Epoch 193:  68% 183/270 [01:54<-1:57:09, -0.51it/s, loss=0.0167, v_num=ypmf]Epoch 193:  68% 183/270 [01:54<-1:57:08, -0.51it/s, loss=0.0168, v_num=ypmf]Epoch 193:  68% 184/270 [01:55<-1:57:07, -0.49it/s, loss=0.0168, v_num=ypmf]Epoch 193:  68% 184/270 [01:55<-1:57:07, -0.49it/s, loss=0.0168, v_num=ypmf]Epoch 193:  68% 184/270 [01:55<-1:57:06, -0.49it/s, loss=0.0168, v_num=ypmf]Epoch 193:  69% 185/270 [01:55<-1:57:05, -0.48it/s, loss=0.0168, v_num=ypmf]Epoch 193:  69% 185/270 [01:55<-1:57:05, -0.48it/s, loss=0.0168, v_num=ypmf]Epoch 193:  69% 185/270 [01:55<-1:57:04, -0.48it/s, loss=0.017, v_num=ypmf] Epoch 193:  69% 186/270 [01:56<-1:57:03, -0.47it/s, loss=0.017, v_num=ypmf]Epoch 193:  69% 186/270 [01:56<-1:57:03, -0.47it/s, loss=0.017, v_num=ypmf]Epoch 193:  69% 186/270 [01:56<-1:57:02, -0.47it/s, loss=0.0169, v_num=ypmf]Epoch 193:  69% 187/270 [01:56<-1:57:01, -0.46it/s, loss=0.0169, v_num=ypmf]Epoch 193:  69% 187/270 [01:56<-1:57:01, -0.46it/s, loss=0.0169, v_num=ypmf]Epoch 193:  69% 187/270 [01:57<-1:57:00, -0.46it/s, loss=0.0169, v_num=ypmf]Epoch 193:  70% 188/270 [01:57<-1:56:59, -0.45it/s, loss=0.0169, v_num=ypmf]Epoch 193:  70% 188/270 [01:57<-1:56:59, -0.45it/s, loss=0.0169, v_num=ypmf]Epoch 193:  70% 188/270 [01:57<-1:56:58, -0.45it/s, loss=0.017, v_num=ypmf] Epoch 193:  70% 189/270 [01:58<-1:56:57, -0.44it/s, loss=0.017, v_num=ypmf]Epoch 193:  70% 189/270 [01:58<-1:56:57, -0.44it/s, loss=0.017, v_num=ypmf]Epoch 193:  70% 189/270 [01:58<-1:56:56, -0.44it/s, loss=0.017, v_num=ypmf]Epoch 193:  70% 190/270 [01:58<-1:56:55, -0.43it/s, loss=0.017, v_num=ypmf]Epoch 193:  70% 190/270 [01:58<-1:56:55, -0.43it/s, loss=0.017, v_num=ypmf]Epoch 193:  70% 190/270 [01:58<-1:56:54, -0.43it/s, loss=0.0171, v_num=ypmf]Epoch 193:  71% 191/270 [01:59<-1:56:52, -0.42it/s, loss=0.0171, v_num=ypmf]Epoch 193:  71% 191/270 [01:59<-1:56:52, -0.42it/s, loss=0.0171, v_num=ypmf]Epoch 193:  71% 191/270 [01:59<-1:56:52, -0.42it/s, loss=0.0172, v_num=ypmf]Epoch 193:  71% 192/270 [01:59<-1:56:50, -0.41it/s, loss=0.0172, v_num=ypmf]Epoch 193:  71% 192/270 [01:59<-1:56:50, -0.41it/s, loss=0.0172, v_num=ypmf]Epoch 193:  71% 192/270 [01:59<-1:56:50, -0.41it/s, loss=0.0173, v_num=ypmf]Epoch 193:  71% 193/270 [02:00<-1:56:48, -0.40it/s, loss=0.0173, v_num=ypmf]Epoch 193:  71% 193/270 [02:00<-1:56:48, -0.40it/s, loss=0.0173, v_num=ypmf]Epoch 193:  71% 193/270 [02:00<-1:56:47, -0.40it/s, loss=0.0172, v_num=ypmf]Epoch 193:  72% 194/270 [02:00<-1:56:45, -0.39it/s, loss=0.0172, v_num=ypmf]Epoch 193:  72% 194/270 [02:00<-1:56:45, -0.39it/s, loss=0.0172, v_num=ypmf]Epoch 193:  72% 194/270 [02:01<-1:56:45, -0.39it/s, loss=0.0172, v_num=ypmf]Epoch 193:  72% 195/270 [02:01<-1:56:43, -0.38it/s, loss=0.0172, v_num=ypmf]Epoch 193:  72% 195/270 [02:01<-1:56:43, -0.38it/s, loss=0.0172, v_num=ypmf]Epoch 193:  72% 195/270 [02:01<-1:56:42, -0.38it/s, loss=0.0173, v_num=ypmf]Epoch 193:  73% 196/270 [02:02<-1:56:40, -0.37it/s, loss=0.0173, v_num=ypmf]Epoch 193:  73% 196/270 [02:02<-1:56:40, -0.37it/s, loss=0.0173, v_num=ypmf]Epoch 193:  73% 196/270 [02:02<-1:56:39, -0.37it/s, loss=0.0172, v_num=ypmf]Epoch 193:  73% 197/270 [02:02<-1:56:37, -0.36it/s, loss=0.0172, v_num=ypmf]Epoch 193:  73% 197/270 [02:02<-1:56:37, -0.36it/s, loss=0.0172, v_num=ypmf]Epoch 193:  73% 197/270 [02:02<-1:56:37, -0.36it/s, loss=0.0172, v_num=ypmf]Epoch 193:  73% 198/270 [02:03<-1:56:34, -0.35it/s, loss=0.0172, v_num=ypmf]Epoch 193:  73% 198/270 [02:03<-1:56:34, -0.35it/s, loss=0.0172, v_num=ypmf]Epoch 193:  73% 198/270 [02:03<-1:56:34, -0.35it/s, loss=0.0172, v_num=ypmf]Epoch 193:  74% 199/270 [02:03<-1:56:31, -0.34it/s, loss=0.0172, v_num=ypmf]Epoch 193:  74% 199/270 [02:03<-1:56:31, -0.34it/s, loss=0.0172, v_num=ypmf]Epoch 193:  74% 199/270 [02:03<-1:56:31, -0.34it/s, loss=0.0172, v_num=ypmf]Epoch 193:  74% 200/270 [02:04<-1:56:28, -0.33it/s, loss=0.0172, v_num=ypmf]Epoch 193:  74% 200/270 [02:04<-1:56:28, -0.33it/s, loss=0.0172, v_num=ypmf]Epoch 193:  74% 200/270 [02:04<-1:56:28, -0.33it/s, loss=0.0169, v_num=ypmf]Epoch 193:  74% 201/270 [02:05<-1:56:25, -0.32it/s, loss=0.0169, v_num=ypmf]Epoch 193:  74% 201/270 [02:05<-1:56:25, -0.32it/s, loss=0.0169, v_num=ypmf]Epoch 193:  74% 201/270 [02:05<-1:56:24, -0.32it/s, loss=0.017, v_num=ypmf] Epoch 193:  75% 202/270 [02:05<-1:56:21, -0.31it/s, loss=0.017, v_num=ypmf]Epoch 193:  75% 202/270 [02:05<-1:56:21, -0.31it/s, loss=0.017, v_num=ypmf]Epoch 193:  75% 202/270 [02:05<-1:56:21, -0.31it/s, loss=0.0169, v_num=ypmf]Epoch 193:  75% 203/270 [02:06<-1:56:18, -0.30it/s, loss=0.0169, v_num=ypmf]Epoch 193:  75% 203/270 [02:06<-1:56:18, -0.30it/s, loss=0.0169, v_num=ypmf]Epoch 193:  75% 203/270 [02:06<-1:56:18, -0.30it/s, loss=0.0168, v_num=ypmf]Epoch 193:  76% 204/270 [02:06<-1:56:14, -0.29it/s, loss=0.0168, v_num=ypmf]Epoch 193:  76% 204/270 [02:06<-1:56:14, -0.29it/s, loss=0.0168, v_num=ypmf]Epoch 193:  76% 204/270 [02:07<-1:56:14, -0.29it/s, loss=0.0169, v_num=ypmf]Epoch 193:  76% 205/270 [02:07<-1:56:10, -0.28it/s, loss=0.0169, v_num=ypmf]Epoch 193:  76% 205/270 [02:07<-1:56:10, -0.28it/s, loss=0.0169, v_num=ypmf]Epoch 193:  76% 205/270 [02:07<-1:56:10, -0.28it/s, loss=0.0168, v_num=ypmf]Epoch 193:  76% 206/270 [02:08<-1:56:06, -0.27it/s, loss=0.0168, v_num=ypmf]Epoch 193:  76% 206/270 [02:08<-1:56:06, -0.27it/s, loss=0.0168, v_num=ypmf]Epoch 193:  76% 206/270 [02:08<-1:56:06, -0.27it/s, loss=0.0169, v_num=ypmf]Epoch 193:  77% 207/270 [02:08<-1:56:02, -0.26it/s, loss=0.0169, v_num=ypmf]Epoch 193:  77% 207/270 [02:08<-1:56:02, -0.26it/s, loss=0.0169, v_num=ypmf]Epoch 193:  77% 207/270 [02:08<-1:56:02, -0.26it/s, loss=0.017, v_num=ypmf] Epoch 193:  77% 208/270 [02:09<-1:55:58, -0.26it/s, loss=0.017, v_num=ypmf]Epoch 193:  77% 208/270 [02:09<-1:55:58, -0.26it/s, loss=0.017, v_num=ypmf]Epoch 193:  77% 208/270 [02:09<-1:55:57, -0.25it/s, loss=0.0169, v_num=ypmf]Epoch 193:  77% 209/270 [02:09<-1:55:53, -0.25it/s, loss=0.0169, v_num=ypmf]Epoch 193:  77% 209/270 [02:09<-1:55:53, -0.25it/s, loss=0.0169, v_num=ypmf]Epoch 193:  77% 209/270 [02:10<-1:55:52, -0.25it/s, loss=0.0169, v_num=ypmf]Epoch 193:  78% 210/270 [02:10<-1:55:48, -0.24it/s, loss=0.0169, v_num=ypmf]Epoch 193:  78% 210/270 [02:10<-1:55:48, -0.24it/s, loss=0.0169, v_num=ypmf]Epoch 193:  78% 210/270 [02:11<-1:55:45, -0.24it/s, loss=0.0168, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 310836. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 331756. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 294647. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 286860. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 279492. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308440. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 291797. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308106. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 345306. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 378155. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 335232. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 321248. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 300867. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 252439. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 354324. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 342558. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 238114. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 288279. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308349. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 269591. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 302257. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 354960. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 288117. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 300060. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 326414. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 193:  78% 211/270 [02:12<-1:55:40, -0.23it/s, loss=0.0168, v_num=ypmf]Epoch 193:  78% 211/270 [02:12<-1:55:40, -0.23it/s, loss=0.0168, v_num=ypmf]Epoch 193:  78% 211/270 [02:12<-1:55:40, -0.23it/s, loss=0.0167, v_num=ypmf]Epoch 193:  79% 212/270 [02:12<-1:55:35, -0.22it/s, loss=0.0167, v_num=ypmf]Epoch 193:  79% 212/270 [02:12<-1:55:35, -0.22it/s, loss=0.0167, v_num=ypmf]Epoch 193:  79% 212/270 [02:13<-1:55:34, -0.22it/s, loss=0.0168, v_num=ypmf]Epoch 193:  79% 213/270 [02:13<-1:55:29, -0.21it/s, loss=0.0168, v_num=ypmf]Epoch 193:  79% 213/270 [02:13<-1:55:29, -0.21it/s, loss=0.0168, v_num=ypmf]Epoch 193:  79% 213/270 [02:13<-1:55:28, -0.21it/s, loss=0.0168, v_num=ypmf]Epoch 193:  79% 214/270 [02:14<-1:55:22, -0.20it/s, loss=0.0168, v_num=ypmf]Epoch 193:  79% 214/270 [02:14<-1:55:22, -0.20it/s, loss=0.0168, v_num=ypmf]Epoch 193:  79% 214/270 [02:14<-1:55:22, -0.20it/s, loss=0.0168, v_num=ypmf]Epoch 193:  80% 215/270 [02:14<-1:55:16, -0.19it/s, loss=0.0168, v_num=ypmf]Epoch 193:  80% 215/270 [02:14<-1:55:16, -0.19it/s, loss=0.0168, v_num=ypmf]Epoch 193:  80% 215/270 [02:15<-1:55:15, -0.19it/s, loss=0.0167, v_num=ypmf]Epoch 193:  80% 216/270 [02:15<-1:55:07, -0.18it/s, loss=0.0167, v_num=ypmf]Epoch 193:  80% 216/270 [02:15<-1:55:07, -0.18it/s, loss=0.0167, v_num=ypmf]Epoch 193:  80% 216/270 [02:15<-1:55:07, -0.18it/s, loss=0.0167, v_num=ypmf]Epoch 193:  80% 217/270 [02:16<-1:55:00, -0.18it/s, loss=0.0167, v_num=ypmf]Epoch 193:  80% 217/270 [02:16<-1:55:00, -0.18it/s, loss=0.0167, v_num=ypmf]Epoch 193:  80% 217/270 [02:16<-1:54:59, -0.18it/s, loss=0.0167, v_num=ypmf]Epoch 193:  81% 218/270 [02:16<-1:54:51, -0.17it/s, loss=0.0167, v_num=ypmf]Epoch 193:  81% 218/270 [02:16<-1:54:51, -0.17it/s, loss=0.0167, v_num=ypmf]Epoch 193:  81% 218/270 [02:16<-1:54:51, -0.17it/s, loss=0.0167, v_num=ypmf]Epoch 193:  81% 219/270 [02:17<-1:54:42, -0.16it/s, loss=0.0167, v_num=ypmf]Epoch 193:  81% 219/270 [02:17<-1:54:42, -0.16it/s, loss=0.0167, v_num=ypmf]Epoch 193:  81% 219/270 [02:17<-1:54:41, -0.16it/s, loss=0.0167, v_num=ypmf]Epoch 193:  81% 220/270 [02:18<-1:54:32, -0.15it/s, loss=0.0167, v_num=ypmf]Epoch 193:  81% 220/270 [02:18<-1:54:32, -0.15it/s, loss=0.0167, v_num=ypmf]Epoch 193:  81% 220/270 [02:18<-1:54:31, -0.15it/s, loss=0.0167, v_num=ypmf]Epoch 193:  82% 221/270 [02:18<-1:54:21, -0.14it/s, loss=0.0167, v_num=ypmf]Epoch 193:  82% 221/270 [02:18<-1:54:21, -0.14it/s, loss=0.0167, v_num=ypmf]Epoch 193:  82% 221/270 [02:18<-1:54:21, -0.14it/s, loss=0.0169, v_num=ypmf]Epoch 193:  82% 222/270 [02:19<-1:54:09, -0.14it/s, loss=0.0169, v_num=ypmf]Epoch 193:  82% 222/270 [02:19<-1:54:09, -0.14it/s, loss=0.0169, v_num=ypmf]Epoch 193:  82% 222/270 [02:19<-1:54:09, -0.14it/s, loss=0.0169, v_num=ypmf]Epoch 193:  83% 223/270 [02:19<-1:53:56, -0.13it/s, loss=0.0169, v_num=ypmf]Epoch 193:  83% 223/270 [02:19<-1:53:56, -0.13it/s, loss=0.0169, v_num=ypmf]Epoch 193:  83% 223/270 [02:19<-1:53:56, -0.13it/s, loss=0.0169, v_num=ypmf]Epoch 193:  83% 224/270 [02:20<-1:53:41, -0.12it/s, loss=0.0169, v_num=ypmf]Epoch 193:  83% 224/270 [02:20<-1:53:41, -0.12it/s, loss=0.0169, v_num=ypmf]Epoch 193:  83% 224/270 [02:20<-1:53:41, -0.12it/s, loss=0.0168, v_num=ypmf]Epoch 193:  83% 225/270 [02:20<-1:53:25, -0.11it/s, loss=0.0168, v_num=ypmf]Epoch 193:  83% 225/270 [02:20<-1:53:25, -0.11it/s, loss=0.0168, v_num=ypmf]Epoch 193:  83% 225/270 [02:20<-1:53:24, -0.11it/s, loss=0.0168, v_num=ypmf]Epoch 193:  84% 226/270 [02:21<-1:53:06, -0.11it/s, loss=0.0168, v_num=ypmf]Epoch 193:  84% 226/270 [02:21<-1:53:06, -0.11it/s, loss=0.0168, v_num=ypmf]Epoch 193:  84% 226/270 [02:21<-1:53:05, -0.11it/s, loss=0.0168, v_num=ypmf]Epoch 193:  84% 227/270 [02:21<-1:52:45, -0.10it/s, loss=0.0168, v_num=ypmf]Epoch 193:  84% 227/270 [02:21<-1:52:45, -0.10it/s, loss=0.0168, v_num=ypmf]Epoch 193:  84% 227/270 [02:22<-1:52:44, -0.10it/s, loss=0.0167, v_num=ypmf]Epoch 193:  84% 228/270 [02:22<-1:52:21, -0.09it/s, loss=0.0167, v_num=ypmf]Epoch 193:  84% 228/270 [02:22<-1:52:21, -0.09it/s, loss=0.0167, v_num=ypmf]Epoch 193:  84% 228/270 [02:22<-1:52:20, -0.09it/s, loss=0.0167, v_num=ypmf]Epoch 193:  85% 229/270 [02:22<-1:51:52, -0.08it/s, loss=0.0167, v_num=ypmf]Epoch 193:  85% 229/270 [02:22<-1:51:52, -0.08it/s, loss=0.0167, v_num=ypmf]Epoch 193:  85% 229/270 [02:23<-1:51:51, -0.08it/s, loss=0.0167, v_num=ypmf]Epoch 193:  85% 230/270 [02:23<-1:51:18, -0.08it/s, loss=0.0167, v_num=ypmf]Epoch 193:  85% 230/270 [02:23<-1:51:18, -0.08it/s, loss=0.0167, v_num=ypmf]Epoch 193:  85% 230/270 [02:23<-1:51:18, -0.08it/s, loss=0.0167, v_num=ypmf]Epoch 193:  86% 231/270 [02:24<-1:50:39, -0.07it/s, loss=0.0167, v_num=ypmf]Epoch 193:  86% 231/270 [02:24<-1:50:39, -0.07it/s, loss=0.0167, v_num=ypmf]Epoch 193:  86% 231/270 [02:24<-1:50:38, -0.07it/s, loss=0.0167, v_num=ypmf]Epoch 193:  86% 232/270 [02:24<-1:49:50, -0.06it/s, loss=0.0167, v_num=ypmf]Epoch 193:  86% 232/270 [02:24<-1:49:50, -0.06it/s, loss=0.0167, v_num=ypmf]Epoch 193:  86% 232/270 [02:24<-1:49:49, -0.06it/s, loss=0.0166, v_num=ypmf]Epoch 193:  86% 233/270 [02:25<-1:48:46, -0.05it/s, loss=0.0166, v_num=ypmf]Epoch 193:  86% 233/270 [02:25<-1:48:46, -0.05it/s, loss=0.0166, v_num=ypmf]Epoch 193:  86% 233/270 [02:25<-1:48:46, -0.05it/s, loss=0.0166, v_num=ypmf]Epoch 193:  87% 234/270 [02:26<-1:47:29, -0.05it/s, loss=0.0166, v_num=ypmf]Epoch 193:  87% 234/270 [02:26<-1:47:29, -0.05it/s, loss=0.0166, v_num=ypmf]Epoch 193:  87% 234/270 [02:26<-1:47:27, -0.05it/s, loss=0.0166, v_num=ypmf]Epoch 193:  87% 235/270 [02:26<-1:45:44, -0.04it/s, loss=0.0166, v_num=ypmf]Epoch 193:  87% 235/270 [02:26<-1:45:44, -0.04it/s, loss=0.0166, v_num=ypmf]Epoch 193:  87% 235/270 [02:27<-1:45:43, -0.04it/s, loss=0.0166, v_num=ypmf]Epoch 193:  87% 236/270 [02:27<-1:43:19, -0.03it/s, loss=0.0166, v_num=ypmf]Epoch 193:  87% 236/270 [02:27<-1:43:19, -0.03it/s, loss=0.0166, v_num=ypmf]Epoch 193:  87% 236/270 [02:27<-1:43:17, -0.03it/s, loss=0.0167, v_num=ypmf]Epoch 193:  88% 237/270 [02:27<-1:39:40, -0.03it/s, loss=0.0167, v_num=ypmf]Epoch 193:  88% 237/270 [02:27<-1:39:40, -0.03it/s, loss=0.0167, v_num=ypmf]Epoch 193:  88% 237/270 [02:28<-1:39:39, -0.03it/s, loss=0.0168, v_num=ypmf]Epoch 193:  88% 238/270 [02:28<-1:33:38, -0.02it/s, loss=0.0168, v_num=ypmf]Epoch 193:  88% 238/270 [02:28<-1:33:38, -0.02it/s, loss=0.0168, v_num=ypmf]Epoch 193:  88% 238/270 [02:28<-1:33:35, -0.02it/s, loss=0.0168, v_num=ypmf]Epoch 193:  89% 239/270 [02:28<-1:21:32, -0.01it/s, loss=0.0168, v_num=ypmf]Epoch 193:  89% 239/270 [02:28<-1:21:32, -0.01it/s, loss=0.0168, v_num=ypmf]Epoch 193:  89% 239/270 [02:29<-1:21:28, -0.01it/s, loss=0.0169, v_num=ypmf]Epoch 193:  89% 240/270 [02:29<-2:45:11, -0.01it/s, loss=0.0169, v_num=ypmf]Epoch 193:  89% 240/270 [02:29<-2:45:11, -0.01it/s, loss=0.0169, v_num=ypmf]Epoch 193:  89% 240/270 [02:29<-2:45:03, -0.01it/s, loss=0.0169, v_num=ypmf]Epoch 193:  89% 241/270 [02:30<?, ?it/s, loss=0.0169, v_num=ypmf]           Epoch 193:  89% 241/270 [02:30<?, ?it/s, loss=0.0169, v_num=ypmf]Epoch 193:  89% 241/270 [02:30<?, ?it/s, loss=0.0168, v_num=ypmf]Epoch 193:  90% 242/270 [02:30<1:10:24, 150.86s/it, loss=0.0168, v_num=ypmf]Epoch 193:  90% 242/270 [02:30<1:10:24, 150.86s/it, loss=0.0168, v_num=ypmf]Epoch 193:  90% 242/270 [02:31<1:10:30, 151.09s/it, loss=0.0169, v_num=ypmf]Epoch 193:  90% 243/270 [02:31<34:05, 75.76s/it, loss=0.0169, v_num=ypmf]   Epoch 193:  90% 243/270 [02:31<34:05, 75.76s/it, loss=0.0169, v_num=ypmf]Epoch 193:  90% 243/270 [02:31<34:08, 75.88s/it, loss=0.0168, v_num=ypmf]Epoch 193:  90% 244/270 [02:32<21:58, 50.73s/it, loss=0.0168, v_num=ypmf]Epoch 193:  90% 244/270 [02:32<21:58, 50.73s/it, loss=0.0168, v_num=ypmf]Epoch 193:  90% 244/270 [02:32<22:00, 50.78s/it, loss=0.0169, v_num=ypmf]Epoch 193:  91% 245/270 [02:32<15:54, 38.18s/it, loss=0.0169, v_num=ypmf]Epoch 193:  91% 245/270 [02:32<15:54, 38.18s/it, loss=0.0169, v_num=ypmf]Epoch 193:  91% 245/270 [02:32<15:55, 38.23s/it, loss=0.0169, v_num=ypmf]Epoch 193:  91% 246/270 [02:33<12:16, 30.67s/it, loss=0.0169, v_num=ypmf]Epoch 193:  91% 246/270 [02:33<12:16, 30.67s/it, loss=0.0169, v_num=ypmf]Epoch 193:  91% 246/270 [02:33<12:16, 30.70s/it, loss=0.017, v_num=ypmf] Epoch 193:  91% 247/270 [02:33<09:49, 25.63s/it, loss=0.017, v_num=ypmf]Epoch 193:  91% 247/270 [02:33<09:49, 25.63s/it, loss=0.017, v_num=ypmf]Epoch 193:  91% 247/270 [02:34<09:50, 25.70s/it, loss=0.017, v_num=ypmf]Epoch 193:  92% 248/270 [02:34<08:06, 22.11s/it, loss=0.017, v_num=ypmf]Epoch 193:  92% 248/270 [02:34<08:06, 22.11s/it, loss=0.017, v_num=ypmf]Epoch 193:  92% 248/270 [02:34<08:06, 22.13s/it, loss=0.017, v_num=ypmf]Epoch 193:  92% 249/270 [02:35<06:47, 19.40s/it, loss=0.017, v_num=ypmf]Epoch 193:  92% 249/270 [02:35<06:47, 19.40s/it, loss=0.017, v_num=ypmf]Epoch 193:  92% 249/270 [02:35<06:48, 19.45s/it, loss=0.0171, v_num=ypmf]Epoch 193:  93% 250/270 [02:36<05:46, 17.35s/it, loss=0.0171, v_num=ypmf]Epoch 193:  93% 250/270 [02:36<05:46, 17.35s/it, loss=0.0171, v_num=ypmf]Epoch 193:  93% 250/270 [02:36<05:47, 17.36s/it, loss=0.0171, v_num=ypmf]
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 265860. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 323838. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 269855. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 285897. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 275538. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 281964. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 403513. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Validation: 0it [00:00, ?it/s][A
Validation:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.29it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.29it/s][AEpoch 193:  93% 251/270 [02:37<04:58, 15.72s/it, loss=0.0171, v_num=ypmf]Epoch 193:  93% 251/270 [02:37<04:58, 15.72s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  10% 2/20 [00:01<00:17,  1.04it/s][A
Validation DataLoader 0:  10% 2/20 [00:01<00:17,  1.04it/s][AEpoch 193:  93% 252/270 [02:38<04:19, 14.41s/it, loss=0.0171, v_num=ypmf]Epoch 193:  93% 252/270 [02:38<04:19, 14.41s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  15% 3/20 [00:03<00:22,  1.34s/it][A
Validation DataLoader 0:  15% 3/20 [00:03<00:22,  1.34s/it][AEpoch 193:  94% 253/270 [02:40<03:47, 13.36s/it, loss=0.0171, v_num=ypmf]Epoch 193:  94% 253/270 [02:40<03:47, 13.36s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  20% 4/20 [00:04<00:17,  1.09s/it][A
Validation DataLoader 0:  20% 4/20 [00:04<00:17,  1.09s/it][AEpoch 193:  94% 254/270 [02:40<03:18, 12.38s/it, loss=0.0171, v_num=ypmf]Epoch 193:  94% 254/270 [02:40<03:18, 12.38s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  25% 5/20 [00:05<00:18,  1.22s/it][A
Validation DataLoader 0:  25% 5/20 [00:05<00:18,  1.22s/it][AEpoch 193:  94% 255/270 [02:42<02:54, 11.60s/it, loss=0.0171, v_num=ypmf]Epoch 193:  94% 255/270 [02:42<02:54, 11.60s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  30% 6/20 [00:07<00:18,  1.31s/it][A
Validation DataLoader 0:  30% 6/20 [00:07<00:18,  1.31s/it][AEpoch 193:  95% 256/270 [02:43<02:33, 10.93s/it, loss=0.0171, v_num=ypmf]Epoch 193:  95% 256/270 [02:43<02:33, 10.93s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  35% 7/20 [00:09<00:20,  1.56s/it][A
Validation DataLoader 0:  35% 7/20 [00:09<00:20,  1.56s/it][AEpoch 193:  95% 257/270 [02:46<02:14, 10.38s/it, loss=0.0171, v_num=ypmf]Epoch 193:  95% 257/270 [02:46<02:14, 10.38s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  40% 8/20 [00:11<00:19,  1.64s/it][A
Validation DataLoader 0:  40% 8/20 [00:11<00:19,  1.64s/it][AEpoch 193:  96% 258/270 [02:47<01:58,  9.87s/it, loss=0.0171, v_num=ypmf]Epoch 193:  96% 258/270 [02:47<01:58,  9.87s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  45% 9/20 [00:11<00:14,  1.35s/it][A
Validation DataLoader 0:  45% 9/20 [00:11<00:14,  1.35s/it][AEpoch 193:  96% 259/270 [02:48<01:42,  9.36s/it, loss=0.0171, v_num=ypmf]Epoch 193:  96% 259/270 [02:48<01:42,  9.36s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  50% 10/20 [00:12<00:11,  1.17s/it][A
Validation DataLoader 0:  50% 10/20 [00:12<00:11,  1.17s/it][AEpoch 193:  96% 260/270 [02:49<01:29,  8.91s/it, loss=0.0171, v_num=ypmf]Epoch 193:  96% 260/270 [02:49<01:29,  8.91s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  55% 11/20 [00:13<00:09,  1.03s/it][A
Validation DataLoader 0:  55% 11/20 [00:13<00:09,  1.03s/it][AEpoch 193:  97% 261/270 [02:50<01:16,  8.50s/it, loss=0.0171, v_num=ypmf]Epoch 193:  97% 261/270 [02:50<01:16,  8.50s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  60% 12/20 [00:14<00:09,  1.18s/it][A
Validation DataLoader 0:  60% 12/20 [00:14<00:09,  1.18s/it][AEpoch 193:  97% 262/270 [02:51<01:05,  8.17s/it, loss=0.0171, v_num=ypmf]Epoch 193:  97% 262/270 [02:51<01:05,  8.17s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  65% 13/20 [00:15<00:07,  1.07s/it][A
Validation DataLoader 0:  65% 13/20 [00:15<00:07,  1.07s/it][AEpoch 193:  97% 263/270 [02:52<00:54,  7.83s/it, loss=0.0171, v_num=ypmf]Epoch 193:  97% 263/270 [02:52<00:54,  7.83s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  70% 14/20 [00:16<00:05,  1.05it/s][A
Validation DataLoader 0:  70% 14/20 [00:16<00:05,  1.05it/s][AEpoch 193:  98% 264/270 [02:53<00:45,  7.52s/it, loss=0.0171, v_num=ypmf]Epoch 193:  98% 264/270 [02:53<00:45,  7.52s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  75% 15/20 [00:17<00:05,  1.09s/it][A
Validation DataLoader 0:  75% 15/20 [00:17<00:05,  1.09s/it][AEpoch 193:  98% 265/270 [02:54<00:36,  7.27s/it, loss=0.0171, v_num=ypmf]Epoch 193:  98% 265/270 [02:54<00:36,  7.27s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  80% 16/20 [00:18<00:04,  1.06s/it][A
Validation DataLoader 0:  80% 16/20 [00:18<00:04,  1.06s/it][AEpoch 193:  99% 266/270 [02:55<00:28,  7.02s/it, loss=0.0171, v_num=ypmf]Epoch 193:  99% 266/270 [02:55<00:28,  7.02s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  85% 17/20 [00:19<00:03,  1.10s/it][A
Validation DataLoader 0:  85% 17/20 [00:19<00:03,  1.10s/it][AEpoch 193:  99% 267/270 [02:56<00:20,  6.79s/it, loss=0.0171, v_num=ypmf]Epoch 193:  99% 267/270 [02:56<00:20,  6.79s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  90% 18/20 [00:20<00:02,  1.08s/it][A
Validation DataLoader 0:  90% 18/20 [00:20<00:02,  1.08s/it][AEpoch 193:  99% 268/270 [02:57<00:13,  6.58s/it, loss=0.0171, v_num=ypmf]Epoch 193:  99% 268/270 [02:57<00:13,  6.58s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  95% 19/20 [00:22<00:01,  1.28s/it][A
Validation DataLoader 0:  95% 19/20 [00:22<00:01,  1.28s/it][AEpoch 193: 100% 269/270 [02:59<00:06,  6.41s/it, loss=0.0171, v_num=ypmf]Epoch 193: 100% 269/270 [02:59<00:06,  6.41s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0: 100% 20/20 [00:23<00:00,  1.11s/it][A
Validation DataLoader 0: 100% 20/20 [00:23<00:00,  1.11s/it][AEpoch 193: 100% 270/270 [03:00<00:00,  6.21s/it, loss=0.0171, v_num=ypmf]Epoch 193: 100% 270/270 [03:00<00:00,  6.21s/it, loss=0.0171, v_num=ypmf]Epoch 193: 100% 270/270 [03:03<00:00,  6.32s/it, loss=0.0171, v_num=ypmf]
                                                            [AEpoch 193: 100% 270/270 [03:03<00:00,  6.32s/it, loss=0.0171, v_num=ypmf]Epoch 193:   0% 0/270 [00:00<00:00, -5710888.50it/s, loss=0.0171, v_num=ypmf]Epoch 194:   0% 0/270 [00:00<00:00, -1421697.98it/s, loss=0.0171, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 194:   0% 1/270 [00:01<-1:59:59, -156.35it/s, loss=0.0171, v_num=ypmf] Epoch 194:   0% 1/270 [00:01<-1:59:59, -156.33it/s, loss=0.0171, v_num=ypmf]Epoch 194:   0% 1/270 [00:02<-1:59:58, -98.53it/s, loss=0.0171, v_num=ypmf] Epoch 194:   1% 2/270 [00:02<-1:59:57, -84.67it/s, loss=0.0171, v_num=ypmf]Epoch 194:   1% 2/270 [00:02<-1:59:57, -84.67it/s, loss=0.0171, v_num=ypmf]Epoch 194:   1% 2/270 [00:02<-1:59:57, -81.16it/s, loss=0.0172, v_num=ypmf]Epoch 194:   1% 3/270 [00:03<-1:59:57, -70.09it/s, loss=0.0172, v_num=ypmf]Epoch 194:   1% 3/270 [00:03<-1:59:57, -70.08it/s, loss=0.0172, v_num=ypmf]Epoch 194:   1% 3/270 [00:03<-1:59:57, -67.29it/s, loss=0.0173, v_num=ypmf]Epoch 194:   1% 4/270 [00:03<-1:59:56, -60.76it/s, loss=0.0173, v_num=ypmf]Epoch 194:   1% 4/270 [00:03<-1:59:56, -60.76it/s, loss=0.0173, v_num=ypmf]Epoch 194:   1% 4/270 [00:04<-1:59:56, -57.22it/s, loss=0.0173, v_num=ypmf]Epoch 194:   2% 5/270 [00:04<-1:59:55, -51.28it/s, loss=0.0173, v_num=ypmf]Epoch 194:   2% 5/270 [00:04<-1:59:55, -51.28it/s, loss=0.0173, v_num=ypmf]Epoch 194:   2% 5/270 [00:04<-1:59:55, -49.68it/s, loss=0.0172, v_num=ypmf]Epoch 194:   2% 6/270 [00:05<-1:59:55, -46.14it/s, loss=0.0172, v_num=ypmf]Epoch 194:   2% 6/270 [00:05<-1:59:55, -46.14it/s, loss=0.0172, v_num=ypmf]Epoch 194:   2% 6/270 [00:05<-1:59:55, -44.71it/s, loss=0.017, v_num=ypmf] Epoch 194:   3% 7/270 [00:05<-1:59:54, -41.57it/s, loss=0.017, v_num=ypmf]Epoch 194:   3% 7/270 [00:05<-1:59:54, -41.57it/s, loss=0.017, v_num=ypmf]Epoch 194:   3% 7/270 [00:05<-1:59:54, -40.03it/s, loss=0.0169, v_num=ypmf]Epoch 194:   3% 8/270 [00:06<-1:59:53, -37.43it/s, loss=0.0169, v_num=ypmf]Epoch 194:   3% 8/270 [00:06<-1:59:53, -37.43it/s, loss=0.0169, v_num=ypmf]Epoch 194:   3% 8/270 [00:06<-1:59:53, -36.43it/s, loss=0.0169, v_num=ypmf]Epoch 194:   3% 9/270 [00:06<-1:59:53, -33.82it/s, loss=0.0169, v_num=ypmf]Epoch 194:   3% 9/270 [00:06<-1:59:53, -33.82it/s, loss=0.0169, v_num=ypmf]Epoch 194:   3% 9/270 [00:07<-1:59:53, -33.12it/s, loss=0.0169, v_num=ypmf]Epoch 194:   4% 10/270 [00:07<-1:59:52, -31.58it/s, loss=0.0169, v_num=ypmf]Epoch 194:   4% 10/270 [00:07<-1:59:52, -31.58it/s, loss=0.0169, v_num=ypmf]Epoch 194:   4% 10/270 [00:07<-1:59:52, -30.33it/s, loss=0.0168, v_num=ypmf]Epoch 194:   4% 11/270 [00:07<-1:59:52, -29.03it/s, loss=0.0168, v_num=ypmf]Epoch 194:   4% 11/270 [00:07<-1:59:52, -29.03it/s, loss=0.0168, v_num=ypmf]Epoch 194:   4% 11/270 [00:08<-1:59:51, -28.50it/s, loss=0.0169, v_num=ypmf]Epoch 194:   4% 12/270 [00:08<-1:59:51, -27.08it/s, loss=0.0169, v_num=ypmf]Epoch 194:   4% 12/270 [00:08<-1:59:51, -27.08it/s, loss=0.0169, v_num=ypmf]Epoch 194:   4% 12/270 [00:08<-1:59:51, -26.30it/s, loss=0.0169, v_num=ypmf]Epoch 194:   5% 13/270 [00:09<-1:59:50, -25.14it/s, loss=0.0169, v_num=ypmf]Epoch 194:   5% 13/270 [00:09<-1:59:50, -25.14it/s, loss=0.0169, v_num=ypmf]Epoch 194:   5% 13/270 [00:09<-1:59:50, -24.77it/s, loss=0.0169, v_num=ypmf]Epoch 194:   5% 14/270 [00:09<-1:59:50, -23.35it/s, loss=0.0169, v_num=ypmf]Epoch 194:   5% 14/270 [00:09<-1:59:50, -23.35it/s, loss=0.0169, v_num=ypmf]Epoch 194:   5% 14/270 [00:09<-1:59:49, -23.01it/s, loss=0.0169, v_num=ypmf]Epoch 194:   6% 15/270 [00:10<-1:59:49, -21.99it/s, loss=0.0169, v_num=ypmf]Epoch 194:   6% 15/270 [00:10<-1:59:49, -21.99it/s, loss=0.0169, v_num=ypmf]Epoch 194:   6% 15/270 [00:10<-1:59:49, -21.70it/s, loss=0.017, v_num=ypmf] Epoch 194:   6% 16/270 [00:10<-1:59:48, -20.60it/s, loss=0.017, v_num=ypmf]Epoch 194:   6% 16/270 [00:10<-1:59:48, -20.60it/s, loss=0.017, v_num=ypmf]Epoch 194:   6% 16/270 [00:10<-1:59:48, -20.58it/s, loss=0.0169, v_num=ypmf]Epoch 194:   6% 17/270 [00:11<-1:59:48, -20.01it/s, loss=0.0169, v_num=ypmf]Epoch 194:   6% 17/270 [00:11<-1:59:48, -20.01it/s, loss=0.0169, v_num=ypmf]Epoch 194:   6% 17/270 [00:11<-1:59:48, -19.58it/s, loss=0.0171, v_num=ypmf]Epoch 194:   7% 18/270 [00:11<-1:59:47, -18.94it/s, loss=0.0171, v_num=ypmf]Epoch 194:   7% 18/270 [00:11<-1:59:47, -18.94it/s, loss=0.0171, v_num=ypmf]Epoch 194:   7% 18/270 [00:11<-1:59:47, -18.65it/s, loss=0.0172, v_num=ypmf]Epoch 194:   7% 19/270 [00:12<-1:59:47, -18.19it/s, loss=0.0172, v_num=ypmf]Epoch 194:   7% 19/270 [00:12<-1:59:47, -18.19it/s, loss=0.0172, v_num=ypmf]Epoch 194:   7% 19/270 [00:12<-1:59:46, -17.72it/s, loss=0.0172, v_num=ypmf]Epoch 194:   7% 20/270 [00:12<-1:59:46, -17.06it/s, loss=0.0172, v_num=ypmf]Epoch 194:   7% 20/270 [00:12<-1:59:46, -17.06it/s, loss=0.0172, v_num=ypmf]Epoch 194:   7% 20/270 [00:13<-1:59:46, -16.87it/s, loss=0.0173, v_num=ypmf]Epoch 194:   8% 21/270 [00:13<-1:59:45, -16.42it/s, loss=0.0173, v_num=ypmf]Epoch 194:   8% 21/270 [00:13<-1:59:45, -16.42it/s, loss=0.0173, v_num=ypmf]Epoch 194:   8% 21/270 [00:13<-1:59:45, -16.03it/s, loss=0.0173, v_num=ypmf]Epoch 194:   8% 22/270 [00:14<-1:59:45, -15.56it/s, loss=0.0173, v_num=ypmf]Epoch 194:   8% 22/270 [00:14<-1:59:45, -15.56it/s, loss=0.0173, v_num=ypmf]Epoch 194:   8% 22/270 [00:14<-1:59:44, -15.24it/s, loss=0.0173, v_num=ypmf]Epoch 194:   9% 23/270 [00:14<-1:59:44, -14.80it/s, loss=0.0173, v_num=ypmf]Epoch 194:   9% 23/270 [00:14<-1:59:44, -14.80it/s, loss=0.0173, v_num=ypmf]Epoch 194:   9% 23/270 [00:14<-1:59:44, -14.66it/s, loss=0.0173, v_num=ypmf]Epoch 194:   9% 24/270 [00:15<-1:59:43, -14.25it/s, loss=0.0173, v_num=ypmf]Epoch 194:   9% 24/270 [00:15<-1:59:43, -14.25it/s, loss=0.0173, v_num=ypmf]Epoch 194:   9% 24/270 [00:16<-1:59:42, -13.03it/s, loss=0.0172, v_num=ypmf]Epoch 194:   9% 25/270 [00:17<-1:59:41, -12.69it/s, loss=0.0172, v_num=ypmf]Epoch 194:   9% 25/270 [00:17<-1:59:41, -12.69it/s, loss=0.0172, v_num=ypmf]Epoch 194:   9% 25/270 [00:17<-1:59:41, -12.59it/s, loss=0.0172, v_num=ypmf]Epoch 194:  10% 26/270 [00:17<-1:59:41, -12.21it/s, loss=0.0172, v_num=ypmf]Epoch 194:  10% 26/270 [00:17<-1:59:41, -12.20it/s, loss=0.0172, v_num=ypmf]Epoch 194:  10% 26/270 [00:17<-1:59:40, -12.10it/s, loss=0.0172, v_num=ypmf]Epoch 194:  10% 27/270 [00:18<-1:59:40, -11.76it/s, loss=0.0172, v_num=ypmf]Epoch 194:  10% 27/270 [00:18<-1:59:40, -11.76it/s, loss=0.0172, v_num=ypmf]Epoch 194:  10% 27/270 [00:18<-1:59:40, -11.58it/s, loss=0.0172, v_num=ypmf]Epoch 194:  10% 28/270 [00:18<-1:59:39, -11.24it/s, loss=0.0172, v_num=ypmf]Epoch 194:  10% 28/270 [00:18<-1:59:39, -11.24it/s, loss=0.0172, v_num=ypmf]Epoch 194:  10% 28/270 [00:19<-1:59:39, -11.15it/s, loss=0.0172, v_num=ypmf]Epoch 194:  11% 29/270 [00:19<-1:59:38, -10.83it/s, loss=0.0172, v_num=ypmf]Epoch 194:  11% 29/270 [00:19<-1:59:38, -10.83it/s, loss=0.0172, v_num=ypmf]Epoch 194:  11% 29/270 [00:19<-1:59:38, -10.74it/s, loss=0.0171, v_num=ypmf]Epoch 194:  11% 30/270 [00:20<-1:59:38, -10.50it/s, loss=0.0171, v_num=ypmf]Epoch 194:  11% 30/270 [00:20<-1:59:38, -10.50it/s, loss=0.0171, v_num=ypmf]Epoch 194:  11% 30/270 [00:20<-1:59:38, -10.44it/s, loss=0.0171, v_num=ypmf]Epoch 194:  11% 31/270 [00:20<-1:59:37, -10.17it/s, loss=0.0171, v_num=ypmf]Epoch 194:  11% 31/270 [00:20<-1:59:37, -10.17it/s, loss=0.0171, v_num=ypmf]Epoch 194:  11% 31/270 [00:20<-1:59:37, -10.09it/s, loss=0.0169, v_num=ypmf]Epoch 194:  12% 32/270 [00:21<-1:59:36, -9.86it/s, loss=0.0169, v_num=ypmf] Epoch 194:  12% 32/270 [00:21<-1:59:36, -9.86it/s, loss=0.0169, v_num=ypmf]Epoch 194:  12% 32/270 [00:21<-1:59:36, -9.68it/s, loss=0.017, v_num=ypmf] Epoch 194:  12% 33/270 [00:22<-1:59:35, -9.43it/s, loss=0.017, v_num=ypmf]Epoch 194:  12% 33/270 [00:22<-1:59:35, -9.43it/s, loss=0.017, v_num=ypmf]Epoch 194:  12% 33/270 [00:22<-1:59:35, -9.33it/s, loss=0.0169, v_num=ypmf]Epoch 194:  13% 34/270 [00:22<-1:59:35, -9.10it/s, loss=0.0169, v_num=ypmf]Epoch 194:  13% 34/270 [00:22<-1:59:35, -9.10it/s, loss=0.0169, v_num=ypmf]Epoch 194:  13% 34/270 [00:22<-1:59:34, -9.03it/s, loss=0.0169, v_num=ypmf]Epoch 194:  13% 35/270 [00:23<-1:59:34, -8.84it/s, loss=0.0169, v_num=ypmf]Epoch 194:  13% 35/270 [00:23<-1:59:34, -8.84it/s, loss=0.0169, v_num=ypmf]Epoch 194:  13% 35/270 [00:23<-1:59:34, -8.74it/s, loss=0.0167, v_num=ypmf]Epoch 194:  13% 36/270 [00:24<-1:59:33, -8.38it/s, loss=0.0167, v_num=ypmf]Epoch 194:  13% 36/270 [00:24<-1:59:33, -8.38it/s, loss=0.0167, v_num=ypmf]Epoch 194:  13% 36/270 [00:24<-1:59:32, -8.34it/s, loss=0.0168, v_num=ypmf]Epoch 194:  14% 37/270 [00:24<-1:59:32, -8.19it/s, loss=0.0168, v_num=ypmf]Epoch 194:  14% 37/270 [00:24<-1:59:32, -8.19it/s, loss=0.0168, v_num=ypmf]Epoch 194:  14% 37/270 [00:25<-1:59:32, -8.07it/s, loss=0.0168, v_num=ypmf]Epoch 194:  14% 38/270 [00:25<-1:59:31, -7.92it/s, loss=0.0168, v_num=ypmf]Epoch 194:  14% 38/270 [00:25<-1:59:31, -7.92it/s, loss=0.0168, v_num=ypmf]Epoch 194:  14% 38/270 [00:25<-1:59:31, -7.83it/s, loss=0.0167, v_num=ypmf]Epoch 194:  14% 39/270 [00:26<-1:59:30, -7.68it/s, loss=0.0167, v_num=ypmf]Epoch 194:  14% 39/270 [00:26<-1:59:30, -7.68it/s, loss=0.0167, v_num=ypmf]Epoch 194:  14% 39/270 [00:26<-1:59:30, -7.57it/s, loss=0.0166, v_num=ypmf]Epoch 194:  15% 40/270 [00:27<-1:59:30, -7.43it/s, loss=0.0166, v_num=ypmf]Epoch 194:  15% 40/270 [00:27<-1:59:30, -7.43it/s, loss=0.0166, v_num=ypmf]Epoch 194:  15% 40/270 [00:27<-1:59:29, -7.35it/s, loss=0.0166, v_num=ypmf]Epoch 194:  15% 41/270 [00:27<-1:59:29, -7.16it/s, loss=0.0166, v_num=ypmf]Epoch 194:  15% 41/270 [00:27<-1:59:29, -7.16it/s, loss=0.0166, v_num=ypmf]Epoch 194:  15% 41/270 [00:27<-1:59:29, -7.16it/s, loss=0.0166, v_num=ypmf]Epoch 194:  16% 42/270 [00:28<-1:59:28, -7.02it/s, loss=0.0166, v_num=ypmf]Epoch 194:  16% 42/270 [00:28<-1:59:28, -7.02it/s, loss=0.0166, v_num=ypmf]Epoch 194:  16% 42/270 [00:28<-1:59:28, -6.98it/s, loss=0.0165, v_num=ypmf]Epoch 194:  16% 43/270 [00:28<-1:59:27, -6.84it/s, loss=0.0165, v_num=ypmf]Epoch 194:  16% 43/270 [00:28<-1:59:27, -6.84it/s, loss=0.0165, v_num=ypmf]Epoch 194:  16% 43/270 [00:29<-1:59:27, -6.81it/s, loss=0.0165, v_num=ypmf]Epoch 194:  16% 44/270 [00:29<-1:59:27, -6.70it/s, loss=0.0165, v_num=ypmf]Epoch 194:  16% 44/270 [00:29<-1:59:27, -6.70it/s, loss=0.0165, v_num=ypmf]Epoch 194:  16% 44/270 [00:29<-1:59:26, -6.57it/s, loss=0.0167, v_num=ypmf]Epoch 194:  17% 45/270 [00:30<-1:59:26, -6.45it/s, loss=0.0167, v_num=ypmf]Epoch 194:  17% 45/270 [00:30<-1:59:26, -6.45it/s, loss=0.0167, v_num=ypmf]Epoch 194:  17% 45/270 [00:30<-1:59:25, -6.42it/s, loss=0.0167, v_num=ypmf]Epoch 194:  17% 46/270 [00:30<-1:59:25, -6.33it/s, loss=0.0167, v_num=ypmf]Epoch 194:  17% 46/270 [00:30<-1:59:25, -6.33it/s, loss=0.0167, v_num=ypmf]Epoch 194:  17% 46/270 [00:31<-1:59:25, -6.27it/s, loss=0.0169, v_num=ypmf]Epoch 194:  17% 47/270 [00:31<-1:59:24, -6.16it/s, loss=0.0169, v_num=ypmf]Epoch 194:  17% 47/270 [00:31<-1:59:24, -6.16it/s, loss=0.0169, v_num=ypmf]Epoch 194:  17% 47/270 [00:31<-1:59:24, -6.14it/s, loss=0.017, v_num=ypmf] Epoch 194:  18% 48/270 [00:31<-1:59:24, -6.05it/s, loss=0.017, v_num=ypmf]Epoch 194:  18% 48/270 [00:31<-1:59:24, -6.05it/s, loss=0.017, v_num=ypmf]Epoch 194:  18% 48/270 [00:32<-1:59:23, -5.98it/s, loss=0.0171, v_num=ypmf]Epoch 194:  18% 49/270 [00:32<-1:59:23, -5.88it/s, loss=0.0171, v_num=ypmf]Epoch 194:  18% 49/270 [00:32<-1:59:23, -5.88it/s, loss=0.0171, v_num=ypmf]Epoch 194:  18% 49/270 [00:32<-1:59:23, -5.85it/s, loss=0.0171, v_num=ypmf]Epoch 194:  19% 50/270 [00:33<-1:59:22, -5.75it/s, loss=0.0171, v_num=ypmf]Epoch 194:  19% 50/270 [00:33<-1:59:22, -5.75it/s, loss=0.0171, v_num=ypmf]Epoch 194:  19% 50/270 [00:33<-1:59:22, -5.69it/s, loss=0.017, v_num=ypmf] Epoch 194:  19% 51/270 [00:34<-1:59:21, -5.57it/s, loss=0.017, v_num=ypmf]Epoch 194:  19% 51/270 [00:34<-1:59:21, -5.57it/s, loss=0.017, v_num=ypmf]Epoch 194:  19% 51/270 [00:34<-1:59:21, -5.54it/s, loss=0.017, v_num=ypmf]Epoch 194:  19% 52/270 [00:34<-1:59:20, -5.43it/s, loss=0.017, v_num=ypmf]Epoch 194:  19% 52/270 [00:34<-1:59:20, -5.43it/s, loss=0.017, v_num=ypmf]Epoch 194:  19% 52/270 [00:34<-1:59:20, -5.40it/s, loss=0.0169, v_num=ypmf]Epoch 194:  20% 53/270 [00:35<-1:59:20, -5.31it/s, loss=0.0169, v_num=ypmf]Epoch 194:  20% 53/270 [00:35<-1:59:20, -5.31it/s, loss=0.0169, v_num=ypmf]Epoch 194:  20% 53/270 [00:35<-1:59:20, -5.30it/s, loss=0.0169, v_num=ypmf]Epoch 194:  20% 54/270 [00:35<-1:59:19, -5.21it/s, loss=0.0169, v_num=ypmf]Epoch 194:  20% 54/270 [00:35<-1:59:19, -5.21it/s, loss=0.0169, v_num=ypmf]Epoch 194:  20% 54/270 [00:36<-1:59:19, -5.18it/s, loss=0.017, v_num=ypmf] Epoch 194:  20% 55/270 [00:36<-1:59:18, -5.10it/s, loss=0.017, v_num=ypmf]Epoch 194:  20% 55/270 [00:36<-1:59:18, -5.10it/s, loss=0.017, v_num=ypmf]Epoch 194:  20% 55/270 [00:36<-1:59:18, -5.07it/s, loss=0.0171, v_num=ypmf]Epoch 194:  21% 56/270 [00:37<-1:59:18, -5.00it/s, loss=0.0171, v_num=ypmf]Epoch 194:  21% 56/270 [00:37<-1:59:18, -5.00it/s, loss=0.0171, v_num=ypmf]Epoch 194:  21% 56/270 [00:37<-1:59:17, -4.96it/s, loss=0.0171, v_num=ypmf]Epoch 194:  21% 57/270 [00:37<-1:59:17, -4.89it/s, loss=0.0171, v_num=ypmf]Epoch 194:  21% 57/270 [00:37<-1:59:17, -4.89it/s, loss=0.0171, v_num=ypmf]Epoch 194:  21% 57/270 [00:37<-1:59:17, -4.86it/s, loss=0.0169, v_num=ypmf]Epoch 194:  21% 58/270 [00:38<-1:59:16, -4.77it/s, loss=0.0169, v_num=ypmf]Epoch 194:  21% 58/270 [00:38<-1:59:16, -4.77it/s, loss=0.0169, v_num=ypmf]Epoch 194:  21% 58/270 [00:38<-1:59:16, -4.75it/s, loss=0.0168, v_num=ypmf]Epoch 194:  22% 59/270 [00:39<-1:59:15, -4.67it/s, loss=0.0168, v_num=ypmf]Epoch 194:  22% 59/270 [00:39<-1:59:15, -4.67it/s, loss=0.0168, v_num=ypmf]Epoch 194:  22% 59/270 [00:39<-1:59:15, -4.65it/s, loss=0.0169, v_num=ypmf]Epoch 194:  22% 60/270 [00:39<-1:59:15, -4.59it/s, loss=0.0169, v_num=ypmf]Epoch 194:  22% 60/270 [00:39<-1:59:15, -4.59it/s, loss=0.0169, v_num=ypmf]Epoch 194:  22% 60/270 [00:39<-1:59:14, -4.55it/s, loss=0.0169, v_num=ypmf]Epoch 194:  23% 61/270 [00:40<-1:59:14, -4.49it/s, loss=0.0169, v_num=ypmf]Epoch 194:  23% 61/270 [00:40<-1:59:14, -4.49it/s, loss=0.0169, v_num=ypmf]Epoch 194:  23% 61/270 [00:40<-1:59:14, -4.46it/s, loss=0.0169, v_num=ypmf]Epoch 194:  23% 62/270 [00:40<-1:59:13, -4.40it/s, loss=0.0169, v_num=ypmf]Epoch 194:  23% 62/270 [00:40<-1:59:13, -4.40it/s, loss=0.0169, v_num=ypmf]Epoch 194:  23% 62/270 [00:40<-1:59:13, -4.37it/s, loss=0.0169, v_num=ypmf]Epoch 194:  23% 63/270 [00:41<-1:59:12, -4.27it/s, loss=0.0169, v_num=ypmf]Epoch 194:  23% 63/270 [00:41<-1:59:12, -4.27it/s, loss=0.0169, v_num=ypmf]Epoch 194:  23% 63/270 [00:41<-1:59:12, -4.26it/s, loss=0.017, v_num=ypmf] Epoch 194:  24% 64/270 [00:42<-1:59:11, -4.20it/s, loss=0.017, v_num=ypmf]Epoch 194:  24% 64/270 [00:42<-1:59:11, -4.20it/s, loss=0.017, v_num=ypmf]Epoch 194:  24% 64/270 [00:42<-1:59:11, -4.19it/s, loss=0.0169, v_num=ypmf]Epoch 194:  24% 65/270 [00:42<-1:59:11, -4.13it/s, loss=0.0169, v_num=ypmf]Epoch 194:  24% 65/270 [00:42<-1:59:11, -4.13it/s, loss=0.0169, v_num=ypmf]Epoch 194:  24% 65/270 [00:42<-1:59:11, -4.10it/s, loss=0.0169, v_num=ypmf]Epoch 194:  24% 66/270 [00:43<-1:59:10, -4.02it/s, loss=0.0169, v_num=ypmf]Epoch 194:  24% 66/270 [00:43<-1:59:10, -4.02it/s, loss=0.0169, v_num=ypmf]Epoch 194:  24% 66/270 [00:43<-1:59:10, -4.01it/s, loss=0.0168, v_num=ypmf]Epoch 194:  25% 67/270 [00:43<-1:59:09, -3.95it/s, loss=0.0168, v_num=ypmf]Epoch 194:  25% 67/270 [00:43<-1:59:09, -3.95it/s, loss=0.0168, v_num=ypmf]Epoch 194:  25% 67/270 [00:44<-1:59:09, -3.93it/s, loss=0.0167, v_num=ypmf]Epoch 194:  25% 68/270 [00:44<-1:59:08, -3.88it/s, loss=0.0167, v_num=ypmf]Epoch 194:  25% 68/270 [00:44<-1:59:08, -3.88it/s, loss=0.0167, v_num=ypmf]Epoch 194:  25% 68/270 [00:44<-1:59:08, -3.87it/s, loss=0.0167, v_num=ypmf]Epoch 194:  26% 69/270 [00:45<-1:59:08, -3.81it/s, loss=0.0167, v_num=ypmf]Epoch 194:  26% 69/270 [00:45<-1:59:08, -3.81it/s, loss=0.0167, v_num=ypmf]Epoch 194:  26% 69/270 [00:45<-1:59:08, -3.80it/s, loss=0.0168, v_num=ypmf]Epoch 194:  26% 70/270 [00:45<-1:59:07, -3.75it/s, loss=0.0168, v_num=ypmf]Epoch 194:  26% 70/270 [00:45<-1:59:07, -3.75it/s, loss=0.0168, v_num=ypmf]Epoch 194:  26% 70/270 [00:45<-1:59:07, -3.73it/s, loss=0.017, v_num=ypmf] Epoch 194:  26% 71/270 [00:46<-1:59:06, -3.68it/s, loss=0.017, v_num=ypmf]Epoch 194:  26% 71/270 [00:46<-1:59:06, -3.68it/s, loss=0.017, v_num=ypmf]Epoch 194:  26% 71/270 [00:46<-1:59:06, -3.65it/s, loss=0.017, v_num=ypmf]Epoch 194:  27% 72/270 [00:46<-1:59:05, -3.60it/s, loss=0.017, v_num=ypmf]Epoch 194:  27% 72/270 [00:46<-1:59:05, -3.60it/s, loss=0.017, v_num=ypmf]Epoch 194:  27% 72/270 [00:47<-1:59:05, -3.59it/s, loss=0.0171, v_num=ypmf]Epoch 194:  27% 73/270 [00:47<-1:59:05, -3.53it/s, loss=0.0171, v_num=ypmf]Epoch 194:  27% 73/270 [00:47<-1:59:05, -3.53it/s, loss=0.0171, v_num=ypmf]Epoch 194:  27% 73/270 [00:47<-1:59:05, -3.52it/s, loss=0.0171, v_num=ypmf]Epoch 194:  27% 74/270 [00:48<-1:59:04, -3.47it/s, loss=0.0171, v_num=ypmf]Epoch 194:  27% 74/270 [00:48<-1:59:04, -3.47it/s, loss=0.0171, v_num=ypmf]Epoch 194:  27% 74/270 [00:48<-1:59:04, -3.46it/s, loss=0.0171, v_num=ypmf]Epoch 194:  28% 75/270 [00:48<-1:59:03, -3.42it/s, loss=0.0171, v_num=ypmf]Epoch 194:  28% 75/270 [00:48<-1:59:03, -3.42it/s, loss=0.0171, v_num=ypmf]Epoch 194:  28% 75/270 [00:48<-1:59:03, -3.41it/s, loss=0.017, v_num=ypmf] Epoch 194:  28% 76/270 [00:49<-1:59:03, -3.36it/s, loss=0.017, v_num=ypmf]Epoch 194:  28% 76/270 [00:49<-1:59:03, -3.36it/s, loss=0.017, v_num=ypmf]Epoch 194:  28% 76/270 [00:49<-1:59:03, -3.35it/s, loss=0.017, v_num=ypmf]Epoch 194:  29% 77/270 [00:49<-1:59:02, -3.30it/s, loss=0.017, v_num=ypmf]Epoch 194:  29% 77/270 [00:49<-1:59:02, -3.30it/s, loss=0.017, v_num=ypmf]Epoch 194:  29% 77/270 [00:49<-1:59:02, -3.29it/s, loss=0.0169, v_num=ypmf]Epoch 194:  29% 78/270 [00:50<-1:59:01, -3.24it/s, loss=0.0169, v_num=ypmf]Epoch 194:  29% 78/270 [00:50<-1:59:01, -3.24it/s, loss=0.0169, v_num=ypmf]Epoch 194:  29% 78/270 [00:50<-1:59:01, -3.23it/s, loss=0.017, v_num=ypmf] Epoch 194:  29% 79/270 [00:50<-1:59:01, -3.19it/s, loss=0.017, v_num=ypmf]Epoch 194:  29% 79/270 [00:50<-1:59:01, -3.19it/s, loss=0.017, v_num=ypmf]Epoch 194:  29% 79/270 [00:51<-1:59:00, -3.18it/s, loss=0.0168, v_num=ypmf]Epoch 194:  30% 80/270 [00:51<-1:59:00, -3.13it/s, loss=0.0168, v_num=ypmf]Epoch 194:  30% 80/270 [00:51<-1:59:00, -3.13it/s, loss=0.0168, v_num=ypmf]Epoch 194:  30% 80/270 [00:52<-1:58:58, -3.04it/s, loss=0.0168, v_num=ypmf]Epoch 194:  30% 81/270 [00:53<-1:58:57, -3.00it/s, loss=0.0168, v_num=ypmf]Epoch 194:  30% 81/270 [00:53<-1:58:57, -3.00it/s, loss=0.0168, v_num=ypmf]Epoch 194:  30% 81/270 [00:53<-1:58:57, -2.99it/s, loss=0.0167, v_num=ypmf]Epoch 194:  30% 82/270 [00:54<-1:58:57, -2.94it/s, loss=0.0167, v_num=ypmf]Epoch 194:  30% 82/270 [00:54<-1:58:57, -2.94it/s, loss=0.0167, v_num=ypmf]Epoch 194:  30% 82/270 [00:54<-1:58:56, -2.93it/s, loss=0.0166, v_num=ypmf]Epoch 194:  31% 83/270 [00:54<-1:58:56, -2.89it/s, loss=0.0166, v_num=ypmf]Epoch 194:  31% 83/270 [00:54<-1:58:56, -2.89it/s, loss=0.0166, v_num=ypmf]Epoch 194:  31% 83/270 [00:54<-1:58:56, -2.88it/s, loss=0.0165, v_num=ypmf]Epoch 194:  31% 84/270 [00:55<-1:58:55, -2.84it/s, loss=0.0165, v_num=ypmf]Epoch 194:  31% 84/270 [00:55<-1:58:55, -2.84it/s, loss=0.0165, v_num=ypmf]Epoch 194:  31% 84/270 [00:55<-1:58:55, -2.84it/s, loss=0.0165, v_num=ypmf]Epoch 194:  31% 85/270 [00:55<-1:58:54, -2.80it/s, loss=0.0165, v_num=ypmf]Epoch 194:  31% 85/270 [00:55<-1:58:54, -2.80it/s, loss=0.0165, v_num=ypmf]Epoch 194:  31% 85/270 [00:55<-1:58:54, -2.79it/s, loss=0.0164, v_num=ypmf]Epoch 194:  32% 86/270 [00:56<-1:58:54, -2.76it/s, loss=0.0164, v_num=ypmf]Epoch 194:  32% 86/270 [00:56<-1:58:54, -2.76it/s, loss=0.0164, v_num=ypmf]Epoch 194:  32% 86/270 [00:57<-1:58:52, -2.69it/s, loss=0.0165, v_num=ypmf]Epoch 194:  32% 87/270 [00:57<-1:58:52, -2.66it/s, loss=0.0165, v_num=ypmf]Epoch 194:  32% 87/270 [00:57<-1:58:52, -2.66it/s, loss=0.0165, v_num=ypmf]Epoch 194:  32% 87/270 [00:58<-1:58:51, -2.65it/s, loss=0.0164, v_num=ypmf]Epoch 194:  33% 88/270 [00:58<-1:58:51, -2.62it/s, loss=0.0164, v_num=ypmf]Epoch 194:  33% 88/270 [00:58<-1:58:51, -2.62it/s, loss=0.0164, v_num=ypmf]Epoch 194:  33% 88/270 [01:00<-1:58:49, -2.53it/s, loss=0.0164, v_num=ypmf]Epoch 194:  33% 89/270 [01:00<-1:58:48, -2.50it/s, loss=0.0164, v_num=ypmf]Epoch 194:  33% 89/270 [01:00<-1:58:48, -2.50it/s, loss=0.0164, v_num=ypmf]Epoch 194:  33% 89/270 [01:01<-1:58:48, -2.49it/s, loss=0.0164, v_num=ypmf]Epoch 194:  33% 90/270 [01:01<-1:58:47, -2.46it/s, loss=0.0164, v_num=ypmf]Epoch 194:  33% 90/270 [01:01<-1:58:47, -2.46it/s, loss=0.0164, v_num=ypmf]Epoch 194:  33% 90/270 [01:01<-1:58:47, -2.45it/s, loss=0.0164, v_num=ypmf]Epoch 194:  34% 91/270 [01:02<-1:58:46, -2.42it/s, loss=0.0164, v_num=ypmf]Epoch 194:  34% 91/270 [01:02<-1:58:46, -2.42it/s, loss=0.0164, v_num=ypmf]Epoch 194:  34% 91/270 [01:02<-1:58:46, -2.42it/s, loss=0.0163, v_num=ypmf]Epoch 194:  34% 92/270 [01:02<-1:58:46, -2.38it/s, loss=0.0163, v_num=ypmf]Epoch 194:  34% 92/270 [01:02<-1:58:46, -2.38it/s, loss=0.0163, v_num=ypmf]Epoch 194:  34% 92/270 [01:02<-1:58:46, -2.38it/s, loss=0.0162, v_num=ypmf]Epoch 194:  34% 93/270 [01:02<-1:58:45, -2.35it/s, loss=0.0162, v_num=ypmf]Epoch 194:  34% 93/270 [01:02<-1:58:45, -2.35it/s, loss=0.0162, v_num=ypmf]Epoch 194:  34% 93/270 [01:03<-1:58:45, -2.34it/s, loss=0.0162, v_num=ypmf]Epoch 194:  35% 94/270 [01:03<-1:58:44, -2.30it/s, loss=0.0162, v_num=ypmf]Epoch 194:  35% 94/270 [01:03<-1:58:44, -2.30it/s, loss=0.0162, v_num=ypmf]Epoch 194:  35% 94/270 [01:04<-1:58:44, -2.29it/s, loss=0.0161, v_num=ypmf]Epoch 194:  35% 95/270 [01:04<-1:58:43, -2.26it/s, loss=0.0161, v_num=ypmf]Epoch 194:  35% 95/270 [01:04<-1:58:43, -2.26it/s, loss=0.0161, v_num=ypmf]Epoch 194:  35% 95/270 [01:04<-1:58:43, -2.26it/s, loss=0.016, v_num=ypmf] Epoch 194:  36% 96/270 [01:05<-1:58:42, -2.23it/s, loss=0.016, v_num=ypmf]Epoch 194:  36% 96/270 [01:05<-1:58:42, -2.23it/s, loss=0.016, v_num=ypmf]Epoch 194:  36% 96/270 [01:05<-1:58:42, -2.22it/s, loss=0.0161, v_num=ypmf]Epoch 194:  36% 97/270 [01:05<-1:58:42, -2.19it/s, loss=0.0161, v_num=ypmf]Epoch 194:  36% 97/270 [01:05<-1:58:42, -2.19it/s, loss=0.0161, v_num=ypmf]Epoch 194:  36% 97/270 [01:05<-1:58:41, -2.19it/s, loss=0.0162, v_num=ypmf]Epoch 194:  36% 98/270 [01:06<-1:58:41, -2.16it/s, loss=0.0162, v_num=ypmf]Epoch 194:  36% 98/270 [01:06<-1:58:41, -2.16it/s, loss=0.0162, v_num=ypmf]Epoch 194:  36% 98/270 [01:06<-1:58:41, -2.15it/s, loss=0.0164, v_num=ypmf]Epoch 194:  37% 99/270 [01:06<-1:58:40, -2.12it/s, loss=0.0164, v_num=ypmf]Epoch 194:  37% 99/270 [01:06<-1:58:40, -2.12it/s, loss=0.0164, v_num=ypmf]Epoch 194:  37% 99/270 [01:06<-1:58:40, -2.12it/s, loss=0.0163, v_num=ypmf]Epoch 194:  37% 100/270 [01:07<-1:58:39, -2.09it/s, loss=0.0163, v_num=ypmf]Epoch 194:  37% 100/270 [01:07<-1:58:39, -2.09it/s, loss=0.0163, v_num=ypmf]Epoch 194:  37% 100/270 [01:07<-1:58:39, -2.09it/s, loss=0.0165, v_num=ypmf]Epoch 194:  37% 101/270 [01:07<-1:58:39, -2.06it/s, loss=0.0165, v_num=ypmf]Epoch 194:  37% 101/270 [01:07<-1:58:39, -2.06it/s, loss=0.0165, v_num=ypmf]Epoch 194:  37% 101/270 [01:08<-1:58:38, -2.06it/s, loss=0.0165, v_num=ypmf]Epoch 194:  38% 102/270 [01:08<-1:58:38, -2.03it/s, loss=0.0165, v_num=ypmf]Epoch 194:  38% 102/270 [01:08<-1:58:38, -2.03it/s, loss=0.0165, v_num=ypmf]Epoch 194:  38% 102/270 [01:08<-1:58:38, -2.03it/s, loss=0.0166, v_num=ypmf]Epoch 194:  38% 103/270 [01:08<-1:58:37, -2.00it/s, loss=0.0166, v_num=ypmf]Epoch 194:  38% 103/270 [01:08<-1:58:37, -2.00it/s, loss=0.0166, v_num=ypmf]Epoch 194:  38% 103/270 [01:09<-1:58:37, -2.00it/s, loss=0.0166, v_num=ypmf]Epoch 194:  39% 104/270 [01:09<-1:58:36, -1.96it/s, loss=0.0166, v_num=ypmf]Epoch 194:  39% 104/270 [01:09<-1:58:36, -1.96it/s, loss=0.0166, v_num=ypmf]Epoch 194:  39% 104/270 [01:09<-1:58:36, -1.96it/s, loss=0.0167, v_num=ypmf]Epoch 194:  39% 105/270 [01:10<-1:58:35, -1.94it/s, loss=0.0167, v_num=ypmf]Epoch 194:  39% 105/270 [01:10<-1:58:35, -1.94it/s, loss=0.0167, v_num=ypmf]Epoch 194:  39% 105/270 [01:10<-1:58:35, -1.93it/s, loss=0.0168, v_num=ypmf]Epoch 194:  39% 106/270 [01:10<-1:58:34, -1.90it/s, loss=0.0168, v_num=ypmf]Epoch 194:  39% 106/270 [01:10<-1:58:34, -1.90it/s, loss=0.0168, v_num=ypmf]Epoch 194:  39% 106/270 [01:11<-1:58:34, -1.90it/s, loss=0.0167, v_num=ypmf]Epoch 194:  40% 107/270 [01:11<-1:58:34, -1.88it/s, loss=0.0167, v_num=ypmf]Epoch 194:  40% 107/270 [01:11<-1:58:34, -1.88it/s, loss=0.0167, v_num=ypmf]Epoch 194:  40% 107/270 [01:11<-1:58:33, -1.87it/s, loss=0.0167, v_num=ypmf]Epoch 194:  40% 108/270 [01:12<-1:58:33, -1.85it/s, loss=0.0167, v_num=ypmf]Epoch 194:  40% 108/270 [01:12<-1:58:33, -1.85it/s, loss=0.0167, v_num=ypmf]Epoch 194:  40% 108/270 [01:12<-1:58:33, -1.84it/s, loss=0.0167, v_num=ypmf]Epoch 194:  40% 109/270 [01:12<-1:58:32, -1.82it/s, loss=0.0167, v_num=ypmf]Epoch 194:  40% 109/270 [01:12<-1:58:32, -1.82it/s, loss=0.0167, v_num=ypmf]Epoch 194:  40% 109/270 [01:12<-1:58:32, -1.81it/s, loss=0.0166, v_num=ypmf]Epoch 194:  41% 110/270 [01:13<-1:58:31, -1.79it/s, loss=0.0166, v_num=ypmf]Epoch 194:  41% 110/270 [01:13<-1:58:31, -1.79it/s, loss=0.0166, v_num=ypmf]Epoch 194:  41% 110/270 [01:13<-1:58:31, -1.78it/s, loss=0.0166, v_num=ypmf]Epoch 194:  41% 111/270 [01:13<-1:58:30, -1.76it/s, loss=0.0166, v_num=ypmf]Epoch 194:  41% 111/270 [01:13<-1:58:30, -1.76it/s, loss=0.0166, v_num=ypmf]Epoch 194:  41% 111/270 [01:13<-1:58:30, -1.76it/s, loss=0.0167, v_num=ypmf]Epoch 194:  41% 112/270 [01:14<-1:58:30, -1.74it/s, loss=0.0167, v_num=ypmf]Epoch 194:  41% 112/270 [01:14<-1:58:30, -1.74it/s, loss=0.0167, v_num=ypmf]Epoch 194:  41% 112/270 [01:14<-1:58:29, -1.73it/s, loss=0.0168, v_num=ypmf]Epoch 194:  42% 113/270 [01:14<-1:58:29, -1.71it/s, loss=0.0168, v_num=ypmf]Epoch 194:  42% 113/270 [01:14<-1:58:29, -1.71it/s, loss=0.0168, v_num=ypmf]Epoch 194:  42% 113/270 [01:14<-1:58:29, -1.71it/s, loss=0.0169, v_num=ypmf]Epoch 194:  42% 114/270 [01:15<-1:58:28, -1.69it/s, loss=0.0169, v_num=ypmf]Epoch 194:  42% 114/270 [01:15<-1:58:28, -1.69it/s, loss=0.0169, v_num=ypmf]Epoch 194:  42% 114/270 [01:15<-1:58:28, -1.68it/s, loss=0.0169, v_num=ypmf]Epoch 194:  43% 115/270 [01:15<-1:58:27, -1.66it/s, loss=0.0169, v_num=ypmf]Epoch 194:  43% 115/270 [01:15<-1:58:27, -1.66it/s, loss=0.0169, v_num=ypmf]Epoch 194:  43% 115/270 [01:16<-1:58:27, -1.66it/s, loss=0.0169, v_num=ypmf]Epoch 194:  43% 116/270 [01:16<-1:58:26, -1.63it/s, loss=0.0169, v_num=ypmf]Epoch 194:  43% 116/270 [01:16<-1:58:26, -1.63it/s, loss=0.0169, v_num=ypmf]Epoch 194:  43% 116/270 [01:16<-1:58:26, -1.63it/s, loss=0.017, v_num=ypmf] Epoch 194:  43% 117/270 [01:17<-1:58:25, -1.61it/s, loss=0.017, v_num=ypmf]Epoch 194:  43% 117/270 [01:17<-1:58:25, -1.61it/s, loss=0.017, v_num=ypmf]Epoch 194:  43% 117/270 [01:18<-1:58:24, -1.59it/s, loss=0.0169, v_num=ypmf]Epoch 194:  44% 118/270 [01:18<-1:58:24, -1.57it/s, loss=0.0169, v_num=ypmf]Epoch 194:  44% 118/270 [01:18<-1:58:24, -1.57it/s, loss=0.0169, v_num=ypmf]Epoch 194:  44% 118/270 [01:18<-1:58:23, -1.56it/s, loss=0.0167, v_num=ypmf]Epoch 194:  44% 119/270 [01:18<-1:58:23, -1.54it/s, loss=0.0167, v_num=ypmf]Epoch 194:  44% 119/270 [01:18<-1:58:23, -1.54it/s, loss=0.0167, v_num=ypmf]Epoch 194:  44% 119/270 [01:19<-1:58:23, -1.54it/s, loss=0.0168, v_num=ypmf]Epoch 194:  44% 120/270 [01:19<-1:58:22, -1.52it/s, loss=0.0168, v_num=ypmf]Epoch 194:  44% 120/270 [01:19<-1:58:22, -1.52it/s, loss=0.0168, v_num=ypmf]Epoch 194:  44% 120/270 [01:19<-1:58:22, -1.52it/s, loss=0.0167, v_num=ypmf]Epoch 194:  45% 121/270 [01:20<-1:58:21, -1.50it/s, loss=0.0167, v_num=ypmf]Epoch 194:  45% 121/270 [01:20<-1:58:21, -1.50it/s, loss=0.0167, v_num=ypmf]Epoch 194:  45% 121/270 [01:20<-1:58:21, -1.49it/s, loss=0.0168, v_num=ypmf]Epoch 194:  45% 122/270 [01:20<-1:58:20, -1.47it/s, loss=0.0168, v_num=ypmf]Epoch 194:  45% 122/270 [01:20<-1:58:20, -1.47it/s, loss=0.0168, v_num=ypmf]Epoch 194:  45% 122/270 [01:20<-1:58:20, -1.47it/s, loss=0.0168, v_num=ypmf]Epoch 194:  46% 123/270 [01:21<-1:58:19, -1.45it/s, loss=0.0168, v_num=ypmf]Epoch 194:  46% 123/270 [01:21<-1:58:19, -1.45it/s, loss=0.0168, v_num=ypmf]Epoch 194:  46% 123/270 [01:21<-1:58:19, -1.45it/s, loss=0.0168, v_num=ypmf]Epoch 194:  46% 124/270 [01:21<-1:58:18, -1.43it/s, loss=0.0168, v_num=ypmf]Epoch 194:  46% 124/270 [01:21<-1:58:18, -1.43it/s, loss=0.0168, v_num=ypmf]Epoch 194:  46% 124/270 [01:22<-1:58:18, -1.43it/s, loss=0.0168, v_num=ypmf]Epoch 194:  46% 125/270 [01:22<-1:58:17, -1.41it/s, loss=0.0168, v_num=ypmf]Epoch 194:  46% 125/270 [01:22<-1:58:17, -1.41it/s, loss=0.0168, v_num=ypmf]Epoch 194:  46% 125/270 [01:22<-1:58:17, -1.40it/s, loss=0.0167, v_num=ypmf]Epoch 194:  47% 126/270 [01:23<-1:58:16, -1.38it/s, loss=0.0167, v_num=ypmf]Epoch 194:  47% 126/270 [01:23<-1:58:16, -1.38it/s, loss=0.0167, v_num=ypmf]Epoch 194:  47% 126/270 [01:23<-1:58:16, -1.38it/s, loss=0.0167, v_num=ypmf]Epoch 194:  47% 127/270 [01:23<-1:58:16, -1.36it/s, loss=0.0167, v_num=ypmf]Epoch 194:  47% 127/270 [01:23<-1:58:16, -1.36it/s, loss=0.0167, v_num=ypmf]Epoch 194:  47% 127/270 [01:23<-1:58:15, -1.36it/s, loss=0.0168, v_num=ypmf]Epoch 194:  47% 128/270 [01:24<-1:58:14, -1.34it/s, loss=0.0168, v_num=ypmf]Epoch 194:  47% 128/270 [01:24<-1:58:14, -1.34it/s, loss=0.0168, v_num=ypmf]Epoch 194:  47% 128/270 [01:24<-1:58:14, -1.34it/s, loss=0.0168, v_num=ypmf]Epoch 194:  48% 129/270 [01:24<-1:58:14, -1.32it/s, loss=0.0168, v_num=ypmf]Epoch 194:  48% 129/270 [01:24<-1:58:14, -1.32it/s, loss=0.0168, v_num=ypmf]Epoch 194:  48% 129/270 [01:25<-1:58:13, -1.32it/s, loss=0.0169, v_num=ypmf]Epoch 194:  48% 130/270 [01:25<-1:58:13, -1.30it/s, loss=0.0169, v_num=ypmf]Epoch 194:  48% 130/270 [01:25<-1:58:13, -1.30it/s, loss=0.0169, v_num=ypmf]Epoch 194:  48% 130/270 [01:25<-1:58:12, -1.29it/s, loss=0.0168, v_num=ypmf]Epoch 194:  49% 131/270 [01:26<-1:58:12, -1.28it/s, loss=0.0168, v_num=ypmf]Epoch 194:  49% 131/270 [01:26<-1:58:12, -1.28it/s, loss=0.0168, v_num=ypmf]Epoch 194:  49% 131/270 [01:26<-1:58:11, -1.27it/s, loss=0.0168, v_num=ypmf]Epoch 194:  49% 132/270 [01:26<-1:58:11, -1.26it/s, loss=0.0168, v_num=ypmf]Epoch 194:  49% 132/270 [01:26<-1:58:11, -1.26it/s, loss=0.0168, v_num=ypmf]Epoch 194:  49% 132/270 [01:26<-1:58:10, -1.25it/s, loss=0.0167, v_num=ypmf]Epoch 194:  49% 133/270 [01:27<-1:58:10, -1.24it/s, loss=0.0167, v_num=ypmf]Epoch 194:  49% 133/270 [01:27<-1:58:10, -1.24it/s, loss=0.0167, v_num=ypmf]Epoch 194:  49% 133/270 [01:27<-1:58:10, -1.24it/s, loss=0.0168, v_num=ypmf]Epoch 194:  50% 134/270 [01:27<-1:58:09, -1.22it/s, loss=0.0168, v_num=ypmf]Epoch 194:  50% 134/270 [01:27<-1:58:09, -1.22it/s, loss=0.0168, v_num=ypmf]Epoch 194:  50% 134/270 [01:28<-1:58:09, -1.22it/s, loss=0.0167, v_num=ypmf]Epoch 194:  50% 135/270 [01:28<-1:58:08, -1.20it/s, loss=0.0167, v_num=ypmf]Epoch 194:  50% 135/270 [01:28<-1:58:08, -1.20it/s, loss=0.0167, v_num=ypmf]Epoch 194:  50% 135/270 [01:28<-1:58:08, -1.20it/s, loss=0.0168, v_num=ypmf]Epoch 194:  50% 136/270 [01:29<-1:58:07, -1.18it/s, loss=0.0168, v_num=ypmf]Epoch 194:  50% 136/270 [01:29<-1:58:07, -1.18it/s, loss=0.0168, v_num=ypmf]Epoch 194:  50% 136/270 [01:29<-1:58:07, -1.18it/s, loss=0.0168, v_num=ypmf]Epoch 194:  51% 137/270 [01:29<-1:58:06, -1.16it/s, loss=0.0168, v_num=ypmf]Epoch 194:  51% 137/270 [01:29<-1:58:06, -1.16it/s, loss=0.0168, v_num=ypmf]Epoch 194:  51% 137/270 [01:29<-1:58:06, -1.16it/s, loss=0.0168, v_num=ypmf]Epoch 194:  51% 138/270 [01:30<-1:58:05, -1.14it/s, loss=0.0168, v_num=ypmf]Epoch 194:  51% 138/270 [01:30<-1:58:05, -1.14it/s, loss=0.0168, v_num=ypmf]Epoch 194:  51% 138/270 [01:30<-1:58:05, -1.14it/s, loss=0.0168, v_num=ypmf]Epoch 194:  51% 139/270 [01:30<-1:58:04, -1.12it/s, loss=0.0168, v_num=ypmf]Epoch 194:  51% 139/270 [01:30<-1:58:04, -1.12it/s, loss=0.0168, v_num=ypmf]Epoch 194:  51% 139/270 [01:30<-1:58:04, -1.12it/s, loss=0.0168, v_num=ypmf]Epoch 194:  52% 140/270 [01:31<-1:58:03, -1.11it/s, loss=0.0168, v_num=ypmf]Epoch 194:  52% 140/270 [01:31<-1:58:03, -1.11it/s, loss=0.0168, v_num=ypmf]Epoch 194:  52% 140/270 [01:31<-1:58:03, -1.10it/s, loss=0.0169, v_num=ypmf]Epoch 194:  52% 141/270 [01:32<-1:58:02, -1.09it/s, loss=0.0169, v_num=ypmf]Epoch 194:  52% 141/270 [01:32<-1:58:02, -1.09it/s, loss=0.0169, v_num=ypmf]Epoch 194:  52% 141/270 [01:32<-1:58:02, -1.08it/s, loss=0.0167, v_num=ypmf]Epoch 194:  53% 142/270 [01:32<-1:58:01, -1.07it/s, loss=0.0167, v_num=ypmf]Epoch 194:  53% 142/270 [01:32<-1:58:01, -1.07it/s, loss=0.0167, v_num=ypmf]Epoch 194:  53% 142/270 [01:32<-1:58:01, -1.07it/s, loss=0.0167, v_num=ypmf]Epoch 194:  53% 143/270 [01:33<-1:58:00, -1.05it/s, loss=0.0167, v_num=ypmf]Epoch 194:  53% 143/270 [01:33<-1:58:00, -1.05it/s, loss=0.0167, v_num=ypmf]Epoch 194:  53% 143/270 [01:33<-1:58:00, -1.05it/s, loss=0.0167, v_num=ypmf]Epoch 194:  53% 144/270 [01:33<-1:57:59, -1.04it/s, loss=0.0167, v_num=ypmf]Epoch 194:  53% 144/270 [01:33<-1:57:59, -1.04it/s, loss=0.0167, v_num=ypmf]Epoch 194:  53% 144/270 [01:33<-1:57:59, -1.03it/s, loss=0.0166, v_num=ypmf]Epoch 194:  54% 145/270 [01:34<-1:57:58, -1.02it/s, loss=0.0166, v_num=ypmf]Epoch 194:  54% 145/270 [01:34<-1:57:58, -1.02it/s, loss=0.0166, v_num=ypmf]Epoch 194:  54% 145/270 [01:34<-1:57:58, -1.02it/s, loss=0.0167, v_num=ypmf]Epoch 194:  54% 146/270 [01:34<-1:57:57, -1.00it/s, loss=0.0167, v_num=ypmf]Epoch 194:  54% 146/270 [01:34<-1:57:57, -1.00it/s, loss=0.0167, v_num=ypmf]Epoch 194:  54% 146/270 [01:34<-1:57:57, -1.00it/s, loss=0.0168, v_num=ypmf]Epoch 194:  54% 147/270 [01:35<-1:57:56, -0.99it/s, loss=0.0168, v_num=ypmf]Epoch 194:  54% 147/270 [01:35<-1:57:56, -0.99it/s, loss=0.0168, v_num=ypmf]Epoch 194:  54% 147/270 [01:35<-1:57:56, -0.98it/s, loss=0.0168, v_num=ypmf]Epoch 194:  55% 148/270 [01:35<-1:57:55, -0.97it/s, loss=0.0168, v_num=ypmf]Epoch 194:  55% 148/270 [01:35<-1:57:55, -0.97it/s, loss=0.0168, v_num=ypmf]Epoch 194:  55% 148/270 [01:36<-1:57:55, -0.97it/s, loss=0.0168, v_num=ypmf]Epoch 194:  55% 149/270 [01:36<-1:57:54, -0.95it/s, loss=0.0168, v_num=ypmf]Epoch 194:  55% 149/270 [01:36<-1:57:54, -0.95it/s, loss=0.0168, v_num=ypmf]Epoch 194:  55% 149/270 [01:36<-1:57:54, -0.95it/s, loss=0.0167, v_num=ypmf]Epoch 194:  56% 150/270 [01:36<-1:57:53, -0.94it/s, loss=0.0167, v_num=ypmf]Epoch 194:  56% 150/270 [01:36<-1:57:53, -0.94it/s, loss=0.0167, v_num=ypmf]Epoch 194:  56% 150/270 [01:37<-1:57:52, -0.94it/s, loss=0.0168, v_num=ypmf]Epoch 194:  56% 151/270 [01:37<-1:57:51, -0.92it/s, loss=0.0168, v_num=ypmf]Epoch 194:  56% 151/270 [01:37<-1:57:51, -0.92it/s, loss=0.0168, v_num=ypmf]Epoch 194:  56% 151/270 [01:37<-1:57:51, -0.92it/s, loss=0.0168, v_num=ypmf]Epoch 194:  56% 152/270 [01:38<-1:57:50, -0.91it/s, loss=0.0168, v_num=ypmf]Epoch 194:  56% 152/270 [01:38<-1:57:50, -0.91it/s, loss=0.0168, v_num=ypmf]Epoch 194:  56% 152/270 [01:38<-1:57:50, -0.90it/s, loss=0.0167, v_num=ypmf]Epoch 194:  57% 153/270 [01:38<-1:57:49, -0.89it/s, loss=0.0167, v_num=ypmf]Epoch 194:  57% 153/270 [01:38<-1:57:49, -0.89it/s, loss=0.0167, v_num=ypmf]Epoch 194:  57% 153/270 [01:38<-1:57:49, -0.89it/s, loss=0.0167, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 298664. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 307095. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 338502. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301965. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 295363. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 244018. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 343407. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 276155. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 314032. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 311279. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 325138. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 298110. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 323681. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 337631. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 262481. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 278520. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 314262. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 313967. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 343690. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 290565. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 309378. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 258278. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 244874. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308646. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 324318. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 194:  57% 154/270 [01:39<-1:57:48, -0.88it/s, loss=0.0167, v_num=ypmf]Epoch 194:  57% 154/270 [01:39<-1:57:48, -0.88it/s, loss=0.0167, v_num=ypmf]Epoch 194:  57% 154/270 [01:39<-1:57:48, -0.87it/s, loss=0.0167, v_num=ypmf]Epoch 194:  57% 155/270 [01:39<-1:57:47, -0.86it/s, loss=0.0167, v_num=ypmf]Epoch 194:  57% 155/270 [01:39<-1:57:47, -0.86it/s, loss=0.0167, v_num=ypmf]Epoch 194:  57% 155/270 [01:40<-1:57:47, -0.86it/s, loss=0.0167, v_num=ypmf]Epoch 194:  58% 156/270 [01:40<-1:57:46, -0.85it/s, loss=0.0167, v_num=ypmf]Epoch 194:  58% 156/270 [01:40<-1:57:46, -0.85it/s, loss=0.0167, v_num=ypmf]Epoch 194:  58% 156/270 [01:40<-1:57:45, -0.84it/s, loss=0.0167, v_num=ypmf]Epoch 194:  58% 157/270 [01:41<-1:57:44, -0.83it/s, loss=0.0167, v_num=ypmf]Epoch 194:  58% 157/270 [01:41<-1:57:44, -0.83it/s, loss=0.0167, v_num=ypmf]Epoch 194:  58% 157/270 [01:41<-1:57:44, -0.83it/s, loss=0.0167, v_num=ypmf]Epoch 194:  59% 158/270 [01:41<-1:57:43, -0.82it/s, loss=0.0167, v_num=ypmf]Epoch 194:  59% 158/270 [01:41<-1:57:43, -0.82it/s, loss=0.0167, v_num=ypmf]Epoch 194:  59% 158/270 [01:41<-1:57:43, -0.81it/s, loss=0.0167, v_num=ypmf]Epoch 194:  59% 159/270 [01:42<-1:57:42, -0.80it/s, loss=0.0167, v_num=ypmf]Epoch 194:  59% 159/270 [01:42<-1:57:42, -0.80it/s, loss=0.0167, v_num=ypmf]Epoch 194:  59% 159/270 [01:42<-1:57:42, -0.80it/s, loss=0.0167, v_num=ypmf]Epoch 194:  59% 160/270 [01:42<-1:57:41, -0.79it/s, loss=0.0167, v_num=ypmf]Epoch 194:  59% 160/270 [01:42<-1:57:41, -0.79it/s, loss=0.0167, v_num=ypmf]Epoch 194:  59% 160/270 [01:43<-1:57:41, -0.79it/s, loss=0.0165, v_num=ypmf]Epoch 194:  60% 161/270 [01:43<-1:57:40, -0.77it/s, loss=0.0165, v_num=ypmf]Epoch 194:  60% 161/270 [01:43<-1:57:40, -0.77it/s, loss=0.0165, v_num=ypmf]Epoch 194:  60% 161/270 [01:43<-1:57:39, -0.77it/s, loss=0.0166, v_num=ypmf]Epoch 194:  60% 162/270 [01:44<-1:57:38, -0.76it/s, loss=0.0166, v_num=ypmf]Epoch 194:  60% 162/270 [01:44<-1:57:38, -0.76it/s, loss=0.0166, v_num=ypmf]Epoch 194:  60% 162/270 [01:44<-1:57:38, -0.76it/s, loss=0.0167, v_num=ypmf]Epoch 194:  60% 163/270 [01:44<-1:57:37, -0.75it/s, loss=0.0167, v_num=ypmf]Epoch 194:  60% 163/270 [01:44<-1:57:37, -0.75it/s, loss=0.0167, v_num=ypmf]Epoch 194:  60% 163/270 [01:44<-1:57:37, -0.74it/s, loss=0.0167, v_num=ypmf]Epoch 194:  61% 164/270 [01:45<-1:57:36, -0.73it/s, loss=0.0167, v_num=ypmf]Epoch 194:  61% 164/270 [01:45<-1:57:36, -0.73it/s, loss=0.0167, v_num=ypmf]Epoch 194:  61% 164/270 [01:45<-1:57:36, -0.73it/s, loss=0.0168, v_num=ypmf]Epoch 194:  61% 165/270 [01:45<-1:57:35, -0.72it/s, loss=0.0168, v_num=ypmf]Epoch 194:  61% 165/270 [01:45<-1:57:35, -0.72it/s, loss=0.0168, v_num=ypmf]Epoch 194:  61% 165/270 [01:45<-1:57:34, -0.72it/s, loss=0.0166, v_num=ypmf]Epoch 194:  61% 166/270 [01:46<-1:57:33, -0.71it/s, loss=0.0166, v_num=ypmf]Epoch 194:  61% 166/270 [01:46<-1:57:33, -0.71it/s, loss=0.0166, v_num=ypmf]Epoch 194:  61% 166/270 [01:46<-1:57:33, -0.71it/s, loss=0.0165, v_num=ypmf]Epoch 194:  62% 167/270 [01:46<-1:57:32, -0.69it/s, loss=0.0165, v_num=ypmf]Epoch 194:  62% 167/270 [01:46<-1:57:32, -0.69it/s, loss=0.0165, v_num=ypmf]Epoch 194:  62% 167/270 [01:46<-1:57:32, -0.69it/s, loss=0.0164, v_num=ypmf]Epoch 194:  62% 168/270 [01:47<-1:57:31, -0.68it/s, loss=0.0164, v_num=ypmf]Epoch 194:  62% 168/270 [01:47<-1:57:31, -0.68it/s, loss=0.0164, v_num=ypmf]Epoch 194:  62% 168/270 [01:47<-1:57:30, -0.68it/s, loss=0.0164, v_num=ypmf]Epoch 194:  63% 169/270 [01:47<-1:57:29, -0.67it/s, loss=0.0164, v_num=ypmf]Epoch 194:  63% 169/270 [01:47<-1:57:29, -0.67it/s, loss=0.0164, v_num=ypmf]Epoch 194:  63% 169/270 [01:47<-1:57:29, -0.67it/s, loss=0.0165, v_num=ypmf]Epoch 194:  63% 170/270 [01:48<-1:57:28, -0.65it/s, loss=0.0165, v_num=ypmf]Epoch 194:  63% 170/270 [01:48<-1:57:28, -0.65it/s, loss=0.0165, v_num=ypmf]Epoch 194:  63% 170/270 [01:48<-1:57:28, -0.65it/s, loss=0.0164, v_num=ypmf]Epoch 194:  63% 171/270 [01:49<-1:57:26, -0.64it/s, loss=0.0164, v_num=ypmf]Epoch 194:  63% 171/270 [01:49<-1:57:26, -0.64it/s, loss=0.0164, v_num=ypmf]Epoch 194:  63% 171/270 [01:49<-1:57:26, -0.64it/s, loss=0.0165, v_num=ypmf]Epoch 194:  64% 172/270 [01:49<-1:57:25, -0.63it/s, loss=0.0165, v_num=ypmf]Epoch 194:  64% 172/270 [01:49<-1:57:25, -0.63it/s, loss=0.0165, v_num=ypmf]Epoch 194:  64% 172/270 [01:49<-1:57:25, -0.63it/s, loss=0.0165, v_num=ypmf]Epoch 194:  64% 173/270 [01:50<-1:57:23, -0.62it/s, loss=0.0165, v_num=ypmf]Epoch 194:  64% 173/270 [01:50<-1:57:23, -0.62it/s, loss=0.0165, v_num=ypmf]Epoch 194:  64% 173/270 [01:50<-1:57:23, -0.62it/s, loss=0.0165, v_num=ypmf]Epoch 194:  64% 174/270 [01:50<-1:57:22, -0.61it/s, loss=0.0165, v_num=ypmf]Epoch 194:  64% 174/270 [01:50<-1:57:22, -0.61it/s, loss=0.0165, v_num=ypmf]Epoch 194:  64% 174/270 [01:50<-1:57:22, -0.60it/s, loss=0.0165, v_num=ypmf]Epoch 194:  65% 175/270 [01:51<-1:57:20, -0.59it/s, loss=0.0165, v_num=ypmf]Epoch 194:  65% 175/270 [01:51<-1:57:20, -0.59it/s, loss=0.0165, v_num=ypmf]Epoch 194:  65% 175/270 [01:51<-1:57:20, -0.59it/s, loss=0.0165, v_num=ypmf]Epoch 194:  65% 176/270 [01:52<-1:57:18, -0.58it/s, loss=0.0165, v_num=ypmf]Epoch 194:  65% 176/270 [01:52<-1:57:18, -0.58it/s, loss=0.0165, v_num=ypmf]Epoch 194:  65% 176/270 [01:52<-1:57:18, -0.58it/s, loss=0.0165, v_num=ypmf]Epoch 194:  66% 177/270 [01:52<-1:57:16, -0.57it/s, loss=0.0165, v_num=ypmf]Epoch 194:  66% 177/270 [01:52<-1:57:16, -0.57it/s, loss=0.0165, v_num=ypmf]Epoch 194:  66% 177/270 [01:53<-1:57:16, -0.57it/s, loss=0.0165, v_num=ypmf]Epoch 194:  66% 178/270 [01:53<-1:57:15, -0.56it/s, loss=0.0165, v_num=ypmf]Epoch 194:  66% 178/270 [01:53<-1:57:15, -0.56it/s, loss=0.0165, v_num=ypmf]Epoch 194:  66% 178/270 [01:53<-1:57:14, -0.55it/s, loss=0.0165, v_num=ypmf]Epoch 194:  66% 179/270 [01:54<-1:57:13, -0.54it/s, loss=0.0165, v_num=ypmf]Epoch 194:  66% 179/270 [01:54<-1:57:13, -0.54it/s, loss=0.0165, v_num=ypmf]Epoch 194:  66% 179/270 [01:54<-1:57:13, -0.54it/s, loss=0.0166, v_num=ypmf]Epoch 194:  67% 180/270 [01:54<-1:57:11, -0.53it/s, loss=0.0166, v_num=ypmf]Epoch 194:  67% 180/270 [01:54<-1:57:11, -0.53it/s, loss=0.0166, v_num=ypmf]Epoch 194:  67% 180/270 [01:54<-1:57:11, -0.53it/s, loss=0.0166, v_num=ypmf]Epoch 194:  67% 181/270 [01:55<-1:57:10, -0.52it/s, loss=0.0166, v_num=ypmf]Epoch 194:  67% 181/270 [01:55<-1:57:10, -0.52it/s, loss=0.0166, v_num=ypmf]Epoch 194:  67% 181/270 [01:55<-1:57:09, -0.52it/s, loss=0.0166, v_num=ypmf]Epoch 194:  67% 182/270 [01:55<-1:57:08, -0.51it/s, loss=0.0166, v_num=ypmf]Epoch 194:  67% 182/270 [01:55<-1:57:08, -0.51it/s, loss=0.0166, v_num=ypmf]Epoch 194:  67% 182/270 [01:55<-1:57:08, -0.51it/s, loss=0.0166, v_num=ypmf]Epoch 194:  68% 183/270 [01:56<-1:57:06, -0.50it/s, loss=0.0166, v_num=ypmf]Epoch 194:  68% 183/270 [01:56<-1:57:06, -0.50it/s, loss=0.0166, v_num=ypmf]Epoch 194:  68% 183/270 [01:56<-1:57:06, -0.50it/s, loss=0.0165, v_num=ypmf]Epoch 194:  68% 184/270 [01:56<-1:57:04, -0.49it/s, loss=0.0165, v_num=ypmf]Epoch 194:  68% 184/270 [01:56<-1:57:04, -0.49it/s, loss=0.0165, v_num=ypmf]Epoch 194:  68% 184/270 [01:57<-1:57:04, -0.49it/s, loss=0.0167, v_num=ypmf]Epoch 194:  69% 185/270 [01:57<-1:57:02, -0.48it/s, loss=0.0167, v_num=ypmf]Epoch 194:  69% 185/270 [01:57<-1:57:02, -0.48it/s, loss=0.0167, v_num=ypmf]Epoch 194:  69% 185/270 [01:57<-1:57:02, -0.48it/s, loss=0.0168, v_num=ypmf]Epoch 194:  69% 186/270 [01:58<-1:57:00, -0.47it/s, loss=0.0168, v_num=ypmf]Epoch 194:  69% 186/270 [01:58<-1:57:00, -0.47it/s, loss=0.0168, v_num=ypmf]Epoch 194:  69% 186/270 [01:58<-1:57:00, -0.47it/s, loss=0.0169, v_num=ypmf]Epoch 194:  69% 187/270 [01:58<-1:56:58, -0.46it/s, loss=0.0169, v_num=ypmf]Epoch 194:  69% 187/270 [01:58<-1:56:58, -0.46it/s, loss=0.0169, v_num=ypmf]Epoch 194:  69% 187/270 [01:59<-1:56:56, -0.45it/s, loss=0.0169, v_num=ypmf]Epoch 194:  70% 188/270 [02:00<-1:56:55, -0.44it/s, loss=0.0169, v_num=ypmf]Epoch 194:  70% 188/270 [02:00<-1:56:55, -0.44it/s, loss=0.0169, v_num=ypmf]Epoch 194:  70% 188/270 [02:00<-1:56:54, -0.44it/s, loss=0.017, v_num=ypmf] Epoch 194:  70% 189/270 [02:00<-1:56:52, -0.43it/s, loss=0.017, v_num=ypmf]Epoch 194:  70% 189/270 [02:00<-1:56:52, -0.43it/s, loss=0.017, v_num=ypmf]Epoch 194:  70% 189/270 [02:00<-1:56:52, -0.43it/s, loss=0.017, v_num=ypmf]Epoch 194:  70% 190/270 [02:01<-1:56:50, -0.42it/s, loss=0.017, v_num=ypmf]Epoch 194:  70% 190/270 [02:01<-1:56:50, -0.42it/s, loss=0.017, v_num=ypmf]Epoch 194:  70% 190/270 [02:01<-1:56:50, -0.42it/s, loss=0.017, v_num=ypmf]Epoch 194:  71% 191/270 [02:01<-1:56:48, -0.41it/s, loss=0.017, v_num=ypmf]Epoch 194:  71% 191/270 [02:01<-1:56:48, -0.41it/s, loss=0.017, v_num=ypmf]Epoch 194:  71% 191/270 [02:01<-1:56:48, -0.41it/s, loss=0.017, v_num=ypmf]Epoch 194:  71% 192/270 [02:02<-1:56:46, -0.40it/s, loss=0.017, v_num=ypmf]Epoch 194:  71% 192/270 [02:02<-1:56:46, -0.40it/s, loss=0.017, v_num=ypmf]Epoch 194:  71% 192/270 [02:02<-1:56:46, -0.40it/s, loss=0.017, v_num=ypmf]Epoch 194:  71% 193/270 [02:02<-1:56:44, -0.39it/s, loss=0.017, v_num=ypmf]Epoch 194:  71% 193/270 [02:02<-1:56:44, -0.39it/s, loss=0.017, v_num=ypmf]Epoch 194:  71% 193/270 [02:02<-1:56:43, -0.39it/s, loss=0.0171, v_num=ypmf]Epoch 194:  72% 194/270 [02:03<-1:56:41, -0.38it/s, loss=0.0171, v_num=ypmf]Epoch 194:  72% 194/270 [02:03<-1:56:41, -0.38it/s, loss=0.0171, v_num=ypmf]Epoch 194:  72% 194/270 [02:03<-1:56:41, -0.38it/s, loss=0.017, v_num=ypmf] Epoch 194:  72% 195/270 [02:03<-1:56:39, -0.37it/s, loss=0.017, v_num=ypmf]Epoch 194:  72% 195/270 [02:03<-1:56:39, -0.37it/s, loss=0.017, v_num=ypmf]Epoch 194:  72% 195/270 [02:04<-1:56:38, -0.37it/s, loss=0.0171, v_num=ypmf]Epoch 194:  73% 196/270 [02:04<-1:56:36, -0.36it/s, loss=0.0171, v_num=ypmf]Epoch 194:  73% 196/270 [02:04<-1:56:36, -0.36it/s, loss=0.0171, v_num=ypmf]Epoch 194:  73% 196/270 [02:04<-1:56:36, -0.36it/s, loss=0.0171, v_num=ypmf]Epoch 194:  73% 197/270 [02:04<-1:56:33, -0.35it/s, loss=0.0171, v_num=ypmf]Epoch 194:  73% 197/270 [02:04<-1:56:33, -0.35it/s, loss=0.0171, v_num=ypmf]Epoch 194:  73% 197/270 [02:05<-1:56:33, -0.35it/s, loss=0.0171, v_num=ypmf]Epoch 194:  73% 198/270 [02:05<-1:56:30, -0.34it/s, loss=0.0171, v_num=ypmf]Epoch 194:  73% 198/270 [02:05<-1:56:30, -0.34it/s, loss=0.0171, v_num=ypmf]Epoch 194:  73% 198/270 [02:05<-1:56:30, -0.34it/s, loss=0.0172, v_num=ypmf]Epoch 194:  74% 199/270 [02:06<-1:56:27, -0.33it/s, loss=0.0172, v_num=ypmf]Epoch 194:  74% 199/270 [02:06<-1:56:27, -0.33it/s, loss=0.0172, v_num=ypmf]Epoch 194:  74% 199/270 [02:06<-1:56:27, -0.33it/s, loss=0.0171, v_num=ypmf]Epoch 194:  74% 200/270 [02:06<-1:56:24, -0.32it/s, loss=0.0171, v_num=ypmf]Epoch 194:  74% 200/270 [02:06<-1:56:24, -0.32it/s, loss=0.0171, v_num=ypmf]Epoch 194:  74% 200/270 [02:06<-1:56:24, -0.32it/s, loss=0.0172, v_num=ypmf]Epoch 194:  74% 201/270 [02:07<-1:56:21, -0.31it/s, loss=0.0172, v_num=ypmf]Epoch 194:  74% 201/270 [02:07<-1:56:21, -0.31it/s, loss=0.0172, v_num=ypmf]Epoch 194:  74% 201/270 [02:07<-1:56:21, -0.31it/s, loss=0.0171, v_num=ypmf]Epoch 194:  75% 202/270 [02:07<-1:56:18, -0.31it/s, loss=0.0171, v_num=ypmf]Epoch 194:  75% 202/270 [02:07<-1:56:18, -0.31it/s, loss=0.0171, v_num=ypmf]Epoch 194:  75% 202/270 [02:08<-1:56:17, -0.30it/s, loss=0.0172, v_num=ypmf]Epoch 194:  75% 203/270 [02:08<-1:56:14, -0.30it/s, loss=0.0172, v_num=ypmf]Epoch 194:  75% 203/270 [02:08<-1:56:14, -0.30it/s, loss=0.0172, v_num=ypmf]Epoch 194:  75% 203/270 [02:08<-1:56:14, -0.30it/s, loss=0.0172, v_num=ypmf]Epoch 194:  76% 204/270 [02:08<-1:56:10, -0.29it/s, loss=0.0172, v_num=ypmf]Epoch 194:  76% 204/270 [02:08<-1:56:10, -0.29it/s, loss=0.0172, v_num=ypmf]Epoch 194:  76% 204/270 [02:09<-1:56:10, -0.29it/s, loss=0.0171, v_num=ypmf]Epoch 194:  76% 205/270 [02:09<-1:56:06, -0.28it/s, loss=0.0171, v_num=ypmf]Epoch 194:  76% 205/270 [02:09<-1:56:06, -0.28it/s, loss=0.0171, v_num=ypmf]Epoch 194:  76% 205/270 [02:09<-1:56:06, -0.28it/s, loss=0.0171, v_num=ypmf]Epoch 194:  76% 206/270 [02:10<-1:56:02, -0.27it/s, loss=0.0171, v_num=ypmf]Epoch 194:  76% 206/270 [02:10<-1:56:02, -0.27it/s, loss=0.0171, v_num=ypmf]Epoch 194:  76% 206/270 [02:10<-1:56:02, -0.27it/s, loss=0.0171, v_num=ypmf]Epoch 194:  77% 207/270 [02:10<-1:55:58, -0.26it/s, loss=0.0171, v_num=ypmf]Epoch 194:  77% 207/270 [02:10<-1:55:58, -0.26it/s, loss=0.0171, v_num=ypmf]Epoch 194:  77% 207/270 [02:11<-1:55:57, -0.26it/s, loss=0.0173, v_num=ypmf]Epoch 194:  77% 208/270 [02:11<-1:55:53, -0.25it/s, loss=0.0173, v_num=ypmf]Epoch 194:  77% 208/270 [02:11<-1:55:53, -0.25it/s, loss=0.0173, v_num=ypmf]Epoch 194:  77% 208/270 [02:12<-1:55:52, -0.25it/s, loss=0.0172, v_num=ypmf]Epoch 194:  77% 209/270 [02:12<-1:55:48, -0.24it/s, loss=0.0172, v_num=ypmf]Epoch 194:  77% 209/270 [02:12<-1:55:48, -0.24it/s, loss=0.0172, v_num=ypmf]Epoch 194:  77% 209/270 [02:12<-1:55:48, -0.24it/s, loss=0.0172, v_num=ypmf]Epoch 194:  78% 210/270 [02:13<-1:55:43, -0.23it/s, loss=0.0172, v_num=ypmf]Epoch 194:  78% 210/270 [02:13<-1:55:43, -0.23it/s, loss=0.0172, v_num=ypmf]Epoch 194:  78% 210/270 [02:13<-1:55:42, -0.23it/s, loss=0.0171, v_num=ypmf]Epoch 194:  78% 211/270 [02:13<-1:55:38, -0.22it/s, loss=0.0171, v_num=ypmf]Epoch 194:  78% 211/270 [02:13<-1:55:38, -0.22it/s, loss=0.0171, v_num=ypmf]Epoch 194:  78% 211/270 [02:13<-1:55:37, -0.22it/s, loss=0.0172, v_num=ypmf]Epoch 194:  79% 212/270 [02:14<-1:55:32, -0.22it/s, loss=0.0172, v_num=ypmf]Epoch 194:  79% 212/270 [02:14<-1:55:32, -0.22it/s, loss=0.0172, v_num=ypmf]Epoch 194:  79% 212/270 [02:14<-1:55:32, -0.22it/s, loss=0.0171, v_num=ypmf]Epoch 194:  79% 213/270 [02:14<-1:55:26, -0.21it/s, loss=0.0171, v_num=ypmf]Epoch 194:  79% 213/270 [02:14<-1:55:26, -0.21it/s, loss=0.0171, v_num=ypmf]Epoch 194:  79% 213/270 [02:15<-1:55:26, -0.21it/s, loss=0.0172, v_num=ypmf]Epoch 194:  79% 214/270 [02:15<-1:55:20, -0.20it/s, loss=0.0172, v_num=ypmf]Epoch 194:  79% 214/270 [02:15<-1:55:20, -0.20it/s, loss=0.0172, v_num=ypmf]Epoch 194:  79% 214/270 [02:15<-1:55:19, -0.20it/s, loss=0.0172, v_num=ypmf]Epoch 194:  80% 215/270 [02:16<-1:55:13, -0.19it/s, loss=0.0172, v_num=ypmf]Epoch 194:  80% 215/270 [02:16<-1:55:13, -0.19it/s, loss=0.0172, v_num=ypmf]Epoch 194:  80% 215/270 [02:16<-1:55:12, -0.19it/s, loss=0.0172, v_num=ypmf]Epoch 194:  80% 216/270 [02:16<-1:55:05, -0.18it/s, loss=0.0172, v_num=ypmf]Epoch 194:  80% 216/270 [02:16<-1:55:05, -0.18it/s, loss=0.0172, v_num=ypmf]Epoch 194:  80% 216/270 [02:16<-1:55:05, -0.18it/s, loss=0.017, v_num=ypmf] Epoch 194:  80% 217/270 [02:17<-1:54:58, -0.17it/s, loss=0.017, v_num=ypmf]Epoch 194:  80% 217/270 [02:17<-1:54:58, -0.17it/s, loss=0.017, v_num=ypmf]Epoch 194:  80% 217/270 [02:17<-1:54:57, -0.17it/s, loss=0.0171, v_num=ypmf]Epoch 194:  81% 218/270 [02:17<-1:54:49, -0.17it/s, loss=0.0171, v_num=ypmf]Epoch 194:  81% 218/270 [02:17<-1:54:49, -0.17it/s, loss=0.0171, v_num=ypmf]Epoch 194:  81% 218/270 [02:17<-1:54:49, -0.17it/s, loss=0.0169, v_num=ypmf]Epoch 194:  81% 219/270 [02:18<-1:54:39, -0.16it/s, loss=0.0169, v_num=ypmf]Epoch 194:  81% 219/270 [02:18<-1:54:39, -0.16it/s, loss=0.0169, v_num=ypmf]Epoch 194:  81% 219/270 [02:18<-1:54:39, -0.16it/s, loss=0.017, v_num=ypmf] Epoch 194:  81% 220/270 [02:19<-1:54:29, -0.15it/s, loss=0.017, v_num=ypmf]Epoch 194:  81% 220/270 [02:19<-1:54:29, -0.15it/s, loss=0.017, v_num=ypmf]Epoch 194:  81% 220/270 [02:19<-1:54:29, -0.15it/s, loss=0.017, v_num=ypmf]Epoch 194:  82% 221/270 [02:19<-1:54:18, -0.14it/s, loss=0.017, v_num=ypmf]Epoch 194:  82% 221/270 [02:19<-1:54:18, -0.14it/s, loss=0.017, v_num=ypmf]Epoch 194:  82% 221/270 [02:19<-1:54:18, -0.14it/s, loss=0.017, v_num=ypmf]Epoch 194:  82% 222/270 [02:20<-1:54:06, -0.14it/s, loss=0.017, v_num=ypmf]Epoch 194:  82% 222/270 [02:20<-1:54:06, -0.14it/s, loss=0.017, v_num=ypmf]Epoch 194:  82% 222/270 [02:20<-1:54:06, -0.14it/s, loss=0.0172, v_num=ypmf]Epoch 194:  83% 223/270 [02:20<-1:53:53, -0.13it/s, loss=0.0172, v_num=ypmf]Epoch 194:  83% 223/270 [02:20<-1:53:53, -0.13it/s, loss=0.0172, v_num=ypmf]Epoch 194:  83% 223/270 [02:20<-1:53:52, -0.13it/s, loss=0.0171, v_num=ypmf]Epoch 194:  83% 224/270 [02:21<-1:53:38, -0.12it/s, loss=0.0171, v_num=ypmf]Epoch 194:  83% 224/270 [02:21<-1:53:38, -0.12it/s, loss=0.0171, v_num=ypmf]Epoch 194:  83% 224/270 [02:21<-1:53:38, -0.12it/s, loss=0.0171, v_num=ypmf]Epoch 194:  83% 225/270 [02:21<-1:53:21, -0.11it/s, loss=0.0171, v_num=ypmf]Epoch 194:  83% 225/270 [02:21<-1:53:21, -0.11it/s, loss=0.0171, v_num=ypmf]Epoch 194:  83% 225/270 [02:22<-1:53:21, -0.11it/s, loss=0.0171, v_num=ypmf]Epoch 194:  84% 226/270 [02:22<-1:53:03, -0.11it/s, loss=0.0171, v_num=ypmf]Epoch 194:  84% 226/270 [02:22<-1:53:03, -0.11it/s, loss=0.0171, v_num=ypmf]Epoch 194:  84% 226/270 [02:22<-1:53:02, -0.11it/s, loss=0.0171, v_num=ypmf]Epoch 194:  84% 227/270 [02:23<-1:52:41, -0.10it/s, loss=0.0171, v_num=ypmf]Epoch 194:  84% 227/270 [02:23<-1:52:41, -0.10it/s, loss=0.0171, v_num=ypmf]Epoch 194:  84% 227/270 [02:23<-1:52:41, -0.10it/s, loss=0.017, v_num=ypmf] Epoch 194:  84% 228/270 [02:23<-1:52:17, -0.09it/s, loss=0.017, v_num=ypmf]Epoch 194:  84% 228/270 [02:23<-1:52:17, -0.09it/s, loss=0.017, v_num=ypmf]Epoch 194:  84% 228/270 [02:23<-1:52:16, -0.09it/s, loss=0.0169, v_num=ypmf]Epoch 194:  85% 229/270 [02:24<-1:51:48, -0.08it/s, loss=0.0169, v_num=ypmf]Epoch 194:  85% 229/270 [02:24<-1:51:48, -0.08it/s, loss=0.0169, v_num=ypmf]Epoch 194:  85% 229/270 [02:24<-1:51:47, -0.08it/s, loss=0.0169, v_num=ypmf]Epoch 194:  85% 230/270 [02:24<-1:51:14, -0.08it/s, loss=0.0169, v_num=ypmf]Epoch 194:  85% 230/270 [02:24<-1:51:14, -0.08it/s, loss=0.0169, v_num=ypmf]Epoch 194:  85% 230/270 [02:24<-1:51:13, -0.08it/s, loss=0.0168, v_num=ypmf]Epoch 194:  86% 231/270 [02:25<-1:50:33, -0.07it/s, loss=0.0168, v_num=ypmf]Epoch 194:  86% 231/270 [02:25<-1:50:33, -0.07it/s, loss=0.0168, v_num=ypmf]Epoch 194:  86% 231/270 [02:25<-1:50:33, -0.07it/s, loss=0.0167, v_num=ypmf]Epoch 194:  86% 232/270 [02:26<-1:49:44, -0.06it/s, loss=0.0167, v_num=ypmf]Epoch 194:  86% 232/270 [02:26<-1:49:44, -0.06it/s, loss=0.0167, v_num=ypmf]Epoch 194:  86% 232/270 [02:26<-1:49:43, -0.06it/s, loss=0.0167, v_num=ypmf]Epoch 194:  86% 233/270 [02:26<-1:48:43, -0.05it/s, loss=0.0167, v_num=ypmf]Epoch 194:  86% 233/270 [02:26<-1:48:43, -0.05it/s, loss=0.0167, v_num=ypmf]Epoch 194:  86% 233/270 [02:26<-1:48:42, -0.05it/s, loss=0.0167, v_num=ypmf]Epoch 194:  87% 234/270 [02:27<-1:47:24, -0.05it/s, loss=0.0167, v_num=ypmf]Epoch 194:  87% 234/270 [02:27<-1:47:24, -0.05it/s, loss=0.0167, v_num=ypmf]Epoch 194:  87% 234/270 [02:27<-1:47:22, -0.05it/s, loss=0.0167, v_num=ypmf]Epoch 194:  87% 235/270 [02:27<-1:45:38, -0.04it/s, loss=0.0167, v_num=ypmf]Epoch 194:  87% 235/270 [02:27<-1:45:38, -0.04it/s, loss=0.0167, v_num=ypmf]Epoch 194:  87% 235/270 [02:28<-1:45:37, -0.04it/s, loss=0.0168, v_num=ypmf]Epoch 194:  87% 236/270 [02:28<-1:43:12, -0.03it/s, loss=0.0168, v_num=ypmf]Epoch 194:  87% 236/270 [02:28<-1:43:12, -0.03it/s, loss=0.0168, v_num=ypmf]Epoch 194:  87% 236/270 [02:28<-1:43:10, -0.03it/s, loss=0.0171, v_num=ypmf]Epoch 194:  88% 237/270 [02:28<-1:39:32, -0.03it/s, loss=0.0171, v_num=ypmf]Epoch 194:  88% 237/270 [02:28<-1:39:32, -0.03it/s, loss=0.0171, v_num=ypmf]Epoch 194:  88% 237/270 [02:29<-1:39:31, -0.03it/s, loss=0.0171, v_num=ypmf]Epoch 194:  88% 238/270 [02:29<-1:33:26, -0.02it/s, loss=0.0171, v_num=ypmf]Epoch 194:  88% 238/270 [02:29<-1:33:26, -0.02it/s, loss=0.0171, v_num=ypmf]Epoch 194:  88% 238/270 [02:29<-1:33:24, -0.02it/s, loss=0.0171, v_num=ypmf]Epoch 194:  89% 239/270 [02:30<-1:21:14, -0.01it/s, loss=0.0171, v_num=ypmf]Epoch 194:  89% 239/270 [02:30<-1:21:14, -0.01it/s, loss=0.0171, v_num=ypmf]Epoch 194:  89% 239/270 [02:30<-1:21:10, -0.01it/s, loss=0.0171, v_num=ypmf]Epoch 194:  89% 240/270 [02:30<-2:44:39, -0.01it/s, loss=0.0171, v_num=ypmf]Epoch 194:  89% 240/270 [02:30<-2:44:39, -0.01it/s, loss=0.0171, v_num=ypmf]Epoch 194:  89% 240/270 [02:30<-2:44:33, -0.01it/s, loss=0.0171, v_num=ypmf]Epoch 194:  89% 241/270 [02:31<?, ?it/s, loss=0.0171, v_num=ypmf]           Epoch 194:  89% 241/270 [02:31<?, ?it/s, loss=0.0171, v_num=ypmf]Epoch 194:  89% 241/270 [02:31<?, ?it/s, loss=0.017, v_num=ypmf] Epoch 194:  90% 242/270 [02:32<1:10:57, 152.04s/it, loss=0.017, v_num=ypmf]Epoch 194:  90% 242/270 [02:32<1:10:57, 152.04s/it, loss=0.017, v_num=ypmf]Epoch 194:  90% 242/270 [02:32<1:11:01, 152.20s/it, loss=0.0168, v_num=ypmf]Epoch 194:  90% 243/270 [02:32<34:18, 76.26s/it, loss=0.0168, v_num=ypmf]   Epoch 194:  90% 243/270 [02:32<34:18, 76.26s/it, loss=0.0168, v_num=ypmf]Epoch 194:  90% 243/270 [02:32<34:21, 76.34s/it, loss=0.0169, v_num=ypmf]Epoch 194:  90% 244/270 [02:33<22:06, 51.01s/it, loss=0.0169, v_num=ypmf]Epoch 194:  90% 244/270 [02:33<22:06, 51.01s/it, loss=0.0169, v_num=ypmf]Epoch 194:  90% 244/270 [02:33<22:09, 51.12s/it, loss=0.0169, v_num=ypmf]Epoch 194:  91% 245/270 [02:33<16:00, 38.44s/it, loss=0.0169, v_num=ypmf]Epoch 194:  91% 245/270 [02:33<16:00, 38.44s/it, loss=0.0169, v_num=ypmf]Epoch 194:  91% 245/270 [02:33<16:02, 38.49s/it, loss=0.0169, v_num=ypmf]Epoch 194:  91% 246/270 [02:34<12:20, 30.87s/it, loss=0.0169, v_num=ypmf]Epoch 194:  91% 246/270 [02:34<12:20, 30.87s/it, loss=0.0169, v_num=ypmf]Epoch 194:  91% 246/270 [02:34<12:21, 30.91s/it, loss=0.0169, v_num=ypmf]Epoch 194:  91% 247/270 [02:34<09:53, 25.82s/it, loss=0.0169, v_num=ypmf]Epoch 194:  91% 247/270 [02:34<09:53, 25.82s/it, loss=0.0169, v_num=ypmf]Epoch 194:  91% 247/270 [02:35<09:54, 25.85s/it, loss=0.0169, v_num=ypmf]Epoch 194:  92% 248/270 [02:35<08:08, 22.21s/it, loss=0.0169, v_num=ypmf]Epoch 194:  92% 248/270 [02:35<08:08, 22.21s/it, loss=0.0169, v_num=ypmf]Epoch 194:  92% 248/270 [02:35<08:09, 22.24s/it, loss=0.017, v_num=ypmf] Epoch 194:  92% 249/270 [02:36<06:49, 19.50s/it, loss=0.017, v_num=ypmf]Epoch 194:  92% 249/270 [02:36<06:49, 19.50s/it, loss=0.017, v_num=ypmf]Epoch 194:  92% 249/270 [02:36<06:50, 19.53s/it, loss=0.0173, v_num=ypmf]Epoch 194:  93% 250/270 [02:36<05:48, 17.40s/it, loss=0.0173, v_num=ypmf]Epoch 194:  93% 250/270 [02:36<05:48, 17.40s/it, loss=0.0173, v_num=ypmf]Epoch 194:  93% 250/270 [02:36<05:48, 17.42s/it, loss=0.0174, v_num=ypmf]
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 361213. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 318987. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 284348. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 274745. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 346634. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 289597. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 296730. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 351832. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 299346. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 288105. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 253715. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Validation: 0it [00:00, ?it/s][A
Validation:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.19it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.19it/s][AEpoch 194:  93% 251/270 [02:38<05:00, 15.83s/it, loss=0.0174, v_num=ypmf]Epoch 194:  93% 251/270 [02:38<05:00, 15.83s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  10% 2/20 [00:01<00:17,  1.01it/s][A
Validation DataLoader 0:  10% 2/20 [00:01<00:17,  1.01it/s][AEpoch 194:  93% 252/270 [02:39<04:21, 14.51s/it, loss=0.0174, v_num=ypmf]Epoch 194:  93% 252/270 [02:39<04:21, 14.51s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  15% 3/20 [00:03<00:23,  1.39s/it][A
Validation DataLoader 0:  15% 3/20 [00:03<00:23,  1.39s/it][AEpoch 194:  94% 253/270 [02:41<03:48, 13.46s/it, loss=0.0174, v_num=ypmf]Epoch 194:  94% 253/270 [02:41<03:48, 13.46s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  20% 4/20 [00:04<00:17,  1.12s/it][A
Validation DataLoader 0:  20% 4/20 [00:04<00:17,  1.12s/it][AEpoch 194:  94% 254/270 [02:42<03:19, 12.48s/it, loss=0.0174, v_num=ypmf]Epoch 194:  94% 254/270 [02:42<03:19, 12.48s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  25% 5/20 [00:05<00:18,  1.21s/it][A
Validation DataLoader 0:  25% 5/20 [00:05<00:18,  1.21s/it][AEpoch 194:  94% 255/270 [02:43<02:55, 11.68s/it, loss=0.0174, v_num=ypmf]Epoch 194:  94% 255/270 [02:43<02:55, 11.68s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  30% 6/20 [00:07<00:18,  1.32s/it][A
Validation DataLoader 0:  30% 6/20 [00:07<00:18,  1.32s/it][AEpoch 194:  95% 256/270 [02:45<02:34, 11.01s/it, loss=0.0174, v_num=ypmf]Epoch 194:  95% 256/270 [02:45<02:34, 11.01s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  35% 7/20 [00:08<00:18,  1.42s/it][A
Validation DataLoader 0:  35% 7/20 [00:08<00:18,  1.42s/it][AEpoch 194:  95% 257/270 [02:46<02:15, 10.42s/it, loss=0.0174, v_num=ypmf]Epoch 194:  95% 257/270 [02:46<02:15, 10.42s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  40% 8/20 [00:11<00:20,  1.71s/it][A
Validation DataLoader 0:  40% 8/20 [00:11<00:20,  1.71s/it][AEpoch 194:  96% 258/270 [02:49<01:59,  9.94s/it, loss=0.0174, v_num=ypmf]Epoch 194:  96% 258/270 [02:49<01:59,  9.94s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  45% 9/20 [00:11<00:15,  1.41s/it][A
Validation DataLoader 0:  45% 9/20 [00:11<00:15,  1.41s/it][AEpoch 194:  96% 259/270 [02:49<01:43,  9.43s/it, loss=0.0174, v_num=ypmf]Epoch 194:  96% 259/270 [02:49<01:43,  9.43s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  50% 10/20 [00:12<00:12,  1.23s/it][A
Validation DataLoader 0:  50% 10/20 [00:12<00:12,  1.23s/it][AEpoch 194:  96% 260/270 [02:50<01:29,  8.98s/it, loss=0.0174, v_num=ypmf]Epoch 194:  96% 260/270 [02:50<01:29,  8.98s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  55% 11/20 [00:13<00:09,  1.08s/it][A
Validation DataLoader 0:  55% 11/20 [00:13<00:09,  1.08s/it][AEpoch 194:  97% 261/270 [02:51<01:17,  8.57s/it, loss=0.0174, v_num=ypmf]Epoch 194:  97% 261/270 [02:51<01:17,  8.57s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  60% 12/20 [00:15<00:11,  1.46s/it][A
Validation DataLoader 0:  60% 12/20 [00:15<00:11,  1.46s/it][AEpoch 194:  97% 262/270 [02:53<01:06,  8.27s/it, loss=0.0174, v_num=ypmf]Epoch 194:  97% 262/270 [02:53<01:06,  8.27s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  65% 13/20 [00:16<00:08,  1.27s/it][A
Validation DataLoader 0:  65% 13/20 [00:16<00:08,  1.27s/it][AEpoch 194:  97% 263/270 [02:54<00:55,  7.93s/it, loss=0.0174, v_num=ypmf]Epoch 194:  97% 263/270 [02:54<00:55,  7.93s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  70% 14/20 [00:17<00:06,  1.10s/it][A
Validation DataLoader 0:  70% 14/20 [00:17<00:06,  1.10s/it][AEpoch 194:  98% 264/270 [02:55<00:45,  7.62s/it, loss=0.0174, v_num=ypmf]Epoch 194:  98% 264/270 [02:55<00:45,  7.62s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  75% 15/20 [00:18<00:06,  1.24s/it][A
Validation DataLoader 0:  75% 15/20 [00:18<00:06,  1.24s/it][AEpoch 194:  98% 265/270 [02:56<00:36,  7.37s/it, loss=0.0174, v_num=ypmf]Epoch 194:  98% 265/270 [02:56<00:36,  7.37s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  80% 16/20 [00:20<00:05,  1.44s/it][A
Validation DataLoader 0:  80% 16/20 [00:20<00:05,  1.44s/it][AEpoch 194:  99% 266/270 [02:58<00:28,  7.15s/it, loss=0.0174, v_num=ypmf]Epoch 194:  99% 266/270 [02:58<00:28,  7.15s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  85% 17/20 [00:21<00:03,  1.29s/it][A
Validation DataLoader 0:  85% 17/20 [00:21<00:03,  1.29s/it][AEpoch 194:  99% 267/270 [02:59<00:20,  6.91s/it, loss=0.0174, v_num=ypmf]Epoch 194:  99% 267/270 [02:59<00:20,  6.91s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  90% 18/20 [00:22<00:02,  1.14s/it][A
Validation DataLoader 0:  90% 18/20 [00:22<00:02,  1.14s/it][AEpoch 194:  99% 268/270 [03:00<00:13,  6.68s/it, loss=0.0174, v_num=ypmf]Epoch 194:  99% 268/270 [03:00<00:13,  6.68s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0:  95% 19/20 [00:24<00:01,  1.22s/it][A
Validation DataLoader 0:  95% 19/20 [00:24<00:01,  1.22s/it][AEpoch 194: 100% 269/270 [03:01<00:06,  6.49s/it, loss=0.0174, v_num=ypmf]Epoch 194: 100% 269/270 [03:01<00:06,  6.49s/it, loss=0.0174, v_num=ypmf]
Validation DataLoader 0: 100% 20/20 [00:24<00:00,  1.03s/it][A
Validation DataLoader 0: 100% 20/20 [00:24<00:00,  1.03s/it][AEpoch 194: 100% 270/270 [03:02<00:00,  6.29s/it, loss=0.0174, v_num=ypmf]Epoch 194: 100% 270/270 [03:02<00:00,  6.29s/it, loss=0.0174, v_num=ypmf]Epoch 194: 100% 270/270 [03:03<00:00,  6.32s/it, loss=0.0174, v_num=ypmf]
                                                            [AEpoch 194: 100% 270/270 [03:03<00:00,  6.32s/it, loss=0.0174, v_num=ypmf]Epoch 194:   0% 0/270 [00:00<00:00, -6923474.41it/s, loss=0.0174, v_num=ypmf]Epoch 195:   0% 0/270 [00:00<00:00, -1742805.63it/s, loss=0.0174, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 195:   0% 1/270 [00:01<-1:59:59, -181.41it/s, loss=0.0174, v_num=ypmf] Epoch 195:   0% 1/270 [00:01<-1:59:59, -181.39it/s, loss=0.0174, v_num=ypmf]Epoch 195:   0% 1/270 [00:01<-1:59:58, -128.41it/s, loss=0.0176, v_num=ypmf]Epoch 195:   1% 2/270 [00:02<-1:59:58, -105.97it/s, loss=0.0176, v_num=ypmf]Epoch 195:   1% 2/270 [00:02<-1:59:58, -105.96it/s, loss=0.0176, v_num=ypmf]Epoch 195:   1% 2/270 [00:02<-1:59:58, -100.18it/s, loss=0.0176, v_num=ypmf]Epoch 195:   1% 3/270 [00:02<-1:59:57, -88.23it/s, loss=0.0176, v_num=ypmf] Epoch 195:   1% 3/270 [00:02<-1:59:57, -88.23it/s, loss=0.0176, v_num=ypmf]Epoch 195:   1% 3/270 [00:03<-1:59:57, -77.44it/s, loss=0.0176, v_num=ypmf]Epoch 195:   1% 4/270 [00:03<-1:59:57, -70.37it/s, loss=0.0176, v_num=ypmf]Epoch 195:   1% 4/270 [00:03<-1:59:57, -70.37it/s, loss=0.0176, v_num=ypmf]Epoch 195:   1% 4/270 [00:03<-1:59:56, -65.93it/s, loss=0.0177, v_num=ypmf]Epoch 195:   2% 5/270 [00:03<-1:59:56, -59.35it/s, loss=0.0177, v_num=ypmf]Epoch 195:   2% 5/270 [00:03<-1:59:56, -59.35it/s, loss=0.0177, v_num=ypmf]Epoch 195:   2% 5/270 [00:04<-1:59:56, -56.30it/s, loss=0.0178, v_num=ypmf]Epoch 195:   2% 6/270 [00:04<-1:59:55, -51.82it/s, loss=0.0178, v_num=ypmf]Epoch 195:   2% 6/270 [00:04<-1:59:55, -51.82it/s, loss=0.0178, v_num=ypmf]Epoch 195:   2% 6/270 [00:04<-1:59:55, -49.16it/s, loss=0.0176, v_num=ypmf]Epoch 195:   3% 7/270 [00:05<-1:59:55, -45.07it/s, loss=0.0176, v_num=ypmf]Epoch 195:   3% 7/270 [00:05<-1:59:55, -45.07it/s, loss=0.0176, v_num=ypmf]Epoch 195:   3% 7/270 [00:05<-1:59:54, -43.82it/s, loss=0.0176, v_num=ypmf]Epoch 195:   3% 8/270 [00:05<-1:59:54, -41.30it/s, loss=0.0176, v_num=ypmf]Epoch 195:   3% 8/270 [00:05<-1:59:54, -41.30it/s, loss=0.0176, v_num=ypmf]Epoch 195:   3% 8/270 [00:05<-1:59:54, -38.89it/s, loss=0.0177, v_num=ypmf]Epoch 195:   3% 9/270 [00:06<-1:59:53, -36.19it/s, loss=0.0177, v_num=ypmf]Epoch 195:   3% 9/270 [00:06<-1:59:53, -36.19it/s, loss=0.0177, v_num=ypmf]Epoch 195:   3% 9/270 [00:06<-1:59:53, -35.03it/s, loss=0.0176, v_num=ypmf]Epoch 195:   4% 10/270 [00:06<-1:59:53, -33.13it/s, loss=0.0176, v_num=ypmf]Epoch 195:   4% 10/270 [00:06<-1:59:53, -33.13it/s, loss=0.0176, v_num=ypmf]Epoch 195:   4% 10/270 [00:07<-1:59:52, -31.54it/s, loss=0.0176, v_num=ypmf]Epoch 195:   4% 11/270 [00:07<-1:59:52, -29.77it/s, loss=0.0176, v_num=ypmf]Epoch 195:   4% 11/270 [00:07<-1:59:52, -29.77it/s, loss=0.0176, v_num=ypmf]Epoch 195:   4% 11/270 [00:07<-1:59:52, -28.86it/s, loss=0.0177, v_num=ypmf]Epoch 195:   4% 12/270 [00:08<-1:59:51, -27.48it/s, loss=0.0177, v_num=ypmf]Epoch 195:   4% 12/270 [00:08<-1:59:51, -27.48it/s, loss=0.0177, v_num=ypmf]Epoch 195:   4% 12/270 [00:08<-1:59:51, -26.74it/s, loss=0.0177, v_num=ypmf]Epoch 195:   5% 13/270 [00:08<-1:59:50, -25.52it/s, loss=0.0177, v_num=ypmf]Epoch 195:   5% 13/270 [00:08<-1:59:50, -25.52it/s, loss=0.0177, v_num=ypmf]Epoch 195:   5% 13/270 [00:09<-1:59:50, -24.97it/s, loss=0.0177, v_num=ypmf]Epoch 195:   5% 14/270 [00:09<-1:59:50, -23.92it/s, loss=0.0177, v_num=ypmf]Epoch 195:   5% 14/270 [00:09<-1:59:50, -23.92it/s, loss=0.0177, v_num=ypmf]Epoch 195:   5% 14/270 [00:09<-1:59:50, -23.47it/s, loss=0.0177, v_num=ypmf]Epoch 195:   6% 15/270 [00:10<-1:59:49, -22.36it/s, loss=0.0177, v_num=ypmf]Epoch 195:   6% 15/270 [00:10<-1:59:49, -22.36it/s, loss=0.0177, v_num=ypmf]Epoch 195:   6% 15/270 [00:10<-1:59:49, -22.05it/s, loss=0.0176, v_num=ypmf]Epoch 195:   6% 16/270 [00:10<-1:59:48, -21.01it/s, loss=0.0176, v_num=ypmf]Epoch 195:   6% 16/270 [00:10<-1:59:48, -21.01it/s, loss=0.0176, v_num=ypmf]Epoch 195:   6% 16/270 [00:10<-1:59:48, -20.85it/s, loss=0.0176, v_num=ypmf]Epoch 195:   6% 17/270 [00:11<-1:59:48, -20.07it/s, loss=0.0176, v_num=ypmf]Epoch 195:   6% 17/270 [00:11<-1:59:48, -20.07it/s, loss=0.0176, v_num=ypmf]Epoch 195:   6% 17/270 [00:11<-1:59:48, -19.74it/s, loss=0.0177, v_num=ypmf]Epoch 195:   7% 18/270 [00:11<-1:59:47, -19.26it/s, loss=0.0177, v_num=ypmf]Epoch 195:   7% 18/270 [00:11<-1:59:47, -19.26it/s, loss=0.0177, v_num=ypmf]Epoch 195:   7% 18/270 [00:12<-1:59:47, -18.25it/s, loss=0.0177, v_num=ypmf]Epoch 195:   7% 19/270 [00:12<-1:59:46, -17.58it/s, loss=0.0177, v_num=ypmf]Epoch 195:   7% 19/270 [00:12<-1:59:46, -17.58it/s, loss=0.0177, v_num=ypmf]Epoch 195:   7% 19/270 [00:12<-1:59:46, -17.40it/s, loss=0.0176, v_num=ypmf]Epoch 195:   7% 20/270 [00:13<-1:59:46, -16.69it/s, loss=0.0176, v_num=ypmf]Epoch 195:   7% 20/270 [00:13<-1:59:46, -16.69it/s, loss=0.0176, v_num=ypmf]Epoch 195:   7% 20/270 [00:14<-1:59:44, -14.95it/s, loss=0.0175, v_num=ypmf]Epoch 195:   8% 21/270 [00:15<-1:59:43, -14.51it/s, loss=0.0175, v_num=ypmf]Epoch 195:   8% 21/270 [00:15<-1:59:43, -14.51it/s, loss=0.0175, v_num=ypmf]Epoch 195:   8% 21/270 [00:15<-1:59:43, -14.30it/s, loss=0.0174, v_num=ypmf]Epoch 195:   8% 22/270 [00:15<-1:59:43, -13.95it/s, loss=0.0174, v_num=ypmf]Epoch 195:   8% 22/270 [00:15<-1:59:43, -13.95it/s, loss=0.0174, v_num=ypmf]Epoch 195:   8% 22/270 [00:15<-1:59:42, -13.73it/s, loss=0.0175, v_num=ypmf]Epoch 195:   9% 23/270 [00:16<-1:59:42, -13.28it/s, loss=0.0175, v_num=ypmf]Epoch 195:   9% 23/270 [00:16<-1:59:42, -13.28it/s, loss=0.0175, v_num=ypmf]Epoch 195:   9% 23/270 [00:16<-1:59:42, -13.16it/s, loss=0.0174, v_num=ypmf]Epoch 195:   9% 24/270 [00:16<-1:59:41, -12.89it/s, loss=0.0174, v_num=ypmf]Epoch 195:   9% 24/270 [00:16<-1:59:41, -12.89it/s, loss=0.0174, v_num=ypmf]Epoch 195:   9% 24/270 [00:18<-1:59:40, -11.99it/s, loss=0.0174, v_num=ypmf]Epoch 195:   9% 25/270 [00:18<-1:59:40, -11.72it/s, loss=0.0174, v_num=ypmf]Epoch 195:   9% 25/270 [00:18<-1:59:40, -11.72it/s, loss=0.0174, v_num=ypmf]Epoch 195:   9% 25/270 [00:18<-1:59:39, -11.53it/s, loss=0.0172, v_num=ypmf]Epoch 195:  10% 26/270 [00:19<-1:59:39, -11.24it/s, loss=0.0172, v_num=ypmf]Epoch 195:  10% 26/270 [00:19<-1:59:39, -11.24it/s, loss=0.0172, v_num=ypmf]Epoch 195:  10% 26/270 [00:19<-1:59:38, -11.09it/s, loss=0.0172, v_num=ypmf]Epoch 195:  10% 27/270 [00:19<-1:59:38, -10.84it/s, loss=0.0172, v_num=ypmf]Epoch 195:  10% 27/270 [00:19<-1:59:38, -10.84it/s, loss=0.0172, v_num=ypmf]Epoch 195:  10% 27/270 [00:19<-1:59:38, -10.75it/s, loss=0.0171, v_num=ypmf]Epoch 195:  10% 28/270 [00:20<-1:59:37, -10.44it/s, loss=0.0171, v_num=ypmf]Epoch 195:  10% 28/270 [00:20<-1:59:37, -10.44it/s, loss=0.0171, v_num=ypmf]Epoch 195:  10% 28/270 [00:20<-1:59:37, -10.36it/s, loss=0.0171, v_num=ypmf]Epoch 195:  11% 29/270 [00:20<-1:59:37, -10.15it/s, loss=0.0171, v_num=ypmf]Epoch 195:  11% 29/270 [00:20<-1:59:37, -10.15it/s, loss=0.0171, v_num=ypmf]Epoch 195:  11% 29/270 [00:21<-1:59:36, -10.01it/s, loss=0.0172, v_num=ypmf]Epoch 195:  11% 30/270 [00:21<-1:59:36, -9.81it/s, loss=0.0172, v_num=ypmf] Epoch 195:  11% 30/270 [00:21<-1:59:36, -9.81it/s, loss=0.0172, v_num=ypmf]Epoch 195:  11% 30/270 [00:21<-1:59:36, -9.68it/s, loss=0.0173, v_num=ypmf]Epoch 195:  11% 31/270 [00:22<-1:59:35, -9.48it/s, loss=0.0173, v_num=ypmf]Epoch 195:  11% 31/270 [00:22<-1:59:35, -9.48it/s, loss=0.0173, v_num=ypmf]Epoch 195:  11% 31/270 [00:22<-1:59:35, -9.41it/s, loss=0.0172, v_num=ypmf]Epoch 195:  12% 32/270 [00:22<-1:59:35, -9.18it/s, loss=0.0172, v_num=ypmf]Epoch 195:  12% 32/270 [00:22<-1:59:35, -9.18it/s, loss=0.0172, v_num=ypmf]Epoch 195:  12% 32/270 [00:22<-1:59:34, -9.12it/s, loss=0.0173, v_num=ypmf]Epoch 195:  12% 33/270 [00:23<-1:59:34, -8.95it/s, loss=0.0173, v_num=ypmf]Epoch 195:  12% 33/270 [00:23<-1:59:34, -8.95it/s, loss=0.0173, v_num=ypmf]Epoch 195:  12% 33/270 [00:23<-1:59:34, -8.86it/s, loss=0.0173, v_num=ypmf]Epoch 195:  13% 34/270 [00:23<-1:59:33, -8.66it/s, loss=0.0173, v_num=ypmf]Epoch 195:  13% 34/270 [00:23<-1:59:33, -8.66it/s, loss=0.0173, v_num=ypmf]Epoch 195:  13% 34/270 [00:24<-1:59:33, -8.61it/s, loss=0.0174, v_num=ypmf]Epoch 195:  13% 35/270 [00:25<-1:59:31, -8.10it/s, loss=0.0174, v_num=ypmf]Epoch 195:  13% 35/270 [00:25<-1:59:31, -8.10it/s, loss=0.0174, v_num=ypmf]Epoch 195:  13% 35/270 [00:25<-1:59:31, -8.05it/s, loss=0.0174, v_num=ypmf]Epoch 195:  13% 36/270 [00:25<-1:59:31, -7.91it/s, loss=0.0174, v_num=ypmf]Epoch 195:  13% 36/270 [00:25<-1:59:31, -7.91it/s, loss=0.0174, v_num=ypmf]Epoch 195:  13% 36/270 [00:26<-1:59:31, -7.80it/s, loss=0.0174, v_num=ypmf]Epoch 195:  14% 37/270 [00:26<-1:59:30, -7.65it/s, loss=0.0174, v_num=ypmf]Epoch 195:  14% 37/270 [00:26<-1:59:30, -7.65it/s, loss=0.0174, v_num=ypmf]Epoch 195:  14% 37/270 [00:26<-1:59:30, -7.60it/s, loss=0.0173, v_num=ypmf]Epoch 195:  14% 38/270 [00:27<-1:59:29, -7.46it/s, loss=0.0173, v_num=ypmf]Epoch 195:  14% 38/270 [00:27<-1:59:29, -7.46it/s, loss=0.0173, v_num=ypmf]Epoch 195:  14% 38/270 [00:27<-1:59:29, -7.42it/s, loss=0.0173, v_num=ypmf]Epoch 195:  14% 39/270 [00:28<-1:59:28, -7.17it/s, loss=0.0173, v_num=ypmf]Epoch 195:  14% 39/270 [00:28<-1:59:28, -7.17it/s, loss=0.0173, v_num=ypmf]Epoch 195:  14% 39/270 [00:28<-1:59:28, -7.13it/s, loss=0.0171, v_num=ypmf]Epoch 195:  15% 40/270 [00:28<-1:59:28, -6.98it/s, loss=0.0171, v_num=ypmf]Epoch 195:  15% 40/270 [00:28<-1:59:28, -6.98it/s, loss=0.0171, v_num=ypmf]Epoch 195:  15% 40/270 [00:28<-1:59:27, -6.94it/s, loss=0.0172, v_num=ypmf]Epoch 195:  15% 41/270 [00:29<-1:59:27, -6.80it/s, loss=0.0172, v_num=ypmf]Epoch 195:  15% 41/270 [00:29<-1:59:27, -6.80it/s, loss=0.0172, v_num=ypmf]Epoch 195:  15% 41/270 [00:29<-1:59:27, -6.75it/s, loss=0.0171, v_num=ypmf]Epoch 195:  16% 42/270 [00:29<-1:59:26, -6.63it/s, loss=0.0171, v_num=ypmf]Epoch 195:  16% 42/270 [00:29<-1:59:26, -6.63it/s, loss=0.0171, v_num=ypmf]Epoch 195:  16% 42/270 [00:30<-1:59:26, -6.61it/s, loss=0.0171, v_num=ypmf]Epoch 195:  16% 43/270 [00:30<-1:59:25, -6.48it/s, loss=0.0171, v_num=ypmf]Epoch 195:  16% 43/270 [00:30<-1:59:25, -6.48it/s, loss=0.0171, v_num=ypmf]Epoch 195:  16% 43/270 [00:30<-1:59:25, -6.45it/s, loss=0.0172, v_num=ypmf]Epoch 195:  16% 44/270 [00:31<-1:59:25, -6.34it/s, loss=0.0172, v_num=ypmf]Epoch 195:  16% 44/270 [00:31<-1:59:25, -6.34it/s, loss=0.0172, v_num=ypmf]Epoch 195:  16% 44/270 [00:31<-1:59:25, -6.30it/s, loss=0.017, v_num=ypmf] Epoch 195:  17% 45/270 [00:31<-1:59:24, -6.20it/s, loss=0.017, v_num=ypmf]Epoch 195:  17% 45/270 [00:31<-1:59:24, -6.20it/s, loss=0.017, v_num=ypmf]Epoch 195:  17% 45/270 [00:31<-1:59:24, -6.16it/s, loss=0.0171, v_num=ypmf]Epoch 195:  17% 46/270 [00:32<-1:59:24, -6.08it/s, loss=0.0171, v_num=ypmf]Epoch 195:  17% 46/270 [00:32<-1:59:24, -6.08it/s, loss=0.0171, v_num=ypmf]Epoch 195:  17% 46/270 [00:32<-1:59:23, -6.00it/s, loss=0.0171, v_num=ypmf]Epoch 195:  17% 47/270 [00:32<-1:59:23, -5.89it/s, loss=0.0171, v_num=ypmf]Epoch 195:  17% 47/270 [00:32<-1:59:23, -5.89it/s, loss=0.0171, v_num=ypmf]Epoch 195:  17% 47/270 [00:33<-1:59:22, -5.85it/s, loss=0.0171, v_num=ypmf]Epoch 195:  18% 48/270 [00:33<-1:59:22, -5.76it/s, loss=0.0171, v_num=ypmf]Epoch 195:  18% 48/270 [00:33<-1:59:22, -5.76it/s, loss=0.0171, v_num=ypmf]Epoch 195:  18% 48/270 [00:33<-1:59:22, -5.71it/s, loss=0.0172, v_num=ypmf]Epoch 195:  18% 49/270 [00:34<-1:59:21, -5.62it/s, loss=0.0172, v_num=ypmf]Epoch 195:  18% 49/270 [00:34<-1:59:21, -5.62it/s, loss=0.0172, v_num=ypmf]Epoch 195:  18% 49/270 [00:34<-1:59:21, -5.58it/s, loss=0.0171, v_num=ypmf]Epoch 195:  19% 50/270 [00:34<-1:59:20, -5.50it/s, loss=0.0171, v_num=ypmf]Epoch 195:  19% 50/270 [00:34<-1:59:20, -5.50it/s, loss=0.0171, v_num=ypmf]Epoch 195:  19% 50/270 [00:34<-1:59:20, -5.47it/s, loss=0.0172, v_num=ypmf]Epoch 195:  19% 51/270 [00:35<-1:59:20, -5.39it/s, loss=0.0172, v_num=ypmf]Epoch 195:  19% 51/270 [00:35<-1:59:20, -5.39it/s, loss=0.0172, v_num=ypmf]Epoch 195:  19% 51/270 [00:35<-1:59:20, -5.35it/s, loss=0.0171, v_num=ypmf]Epoch 195:  19% 52/270 [00:35<-1:59:19, -5.26it/s, loss=0.0171, v_num=ypmf]Epoch 195:  19% 52/270 [00:35<-1:59:19, -5.26it/s, loss=0.0171, v_num=ypmf]Epoch 195:  19% 52/270 [00:36<-1:59:19, -5.23it/s, loss=0.0171, v_num=ypmf]Epoch 195:  20% 53/270 [00:36<-1:59:18, -5.15it/s, loss=0.0171, v_num=ypmf]Epoch 195:  20% 53/270 [00:36<-1:59:18, -5.15it/s, loss=0.0171, v_num=ypmf]Epoch 195:  20% 53/270 [00:36<-1:59:18, -5.12it/s, loss=0.0172, v_num=ypmf]Epoch 195:  20% 54/270 [00:37<-1:59:18, -5.04it/s, loss=0.0172, v_num=ypmf]Epoch 195:  20% 54/270 [00:37<-1:59:18, -5.04it/s, loss=0.0172, v_num=ypmf]Epoch 195:  20% 54/270 [00:37<-1:59:17, -5.02it/s, loss=0.0171, v_num=ypmf]Epoch 195:  20% 55/270 [00:37<-1:59:17, -4.95it/s, loss=0.0171, v_num=ypmf]Epoch 195:  20% 55/270 [00:37<-1:59:17, -4.95it/s, loss=0.0171, v_num=ypmf]Epoch 195:  20% 55/270 [00:37<-1:59:17, -4.93it/s, loss=0.0172, v_num=ypmf]Epoch 195:  21% 56/270 [00:38<-1:59:16, -4.85it/s, loss=0.0172, v_num=ypmf]Epoch 195:  21% 56/270 [00:38<-1:59:16, -4.85it/s, loss=0.0172, v_num=ypmf]Epoch 195:  21% 56/270 [00:38<-1:59:16, -4.83it/s, loss=0.0171, v_num=ypmf]Epoch 195:  21% 57/270 [00:38<-1:59:16, -4.76it/s, loss=0.0171, v_num=ypmf]Epoch 195:  21% 57/270 [00:38<-1:59:16, -4.76it/s, loss=0.0171, v_num=ypmf]Epoch 195:  21% 57/270 [00:38<-1:59:16, -4.74it/s, loss=0.0173, v_num=ypmf]Epoch 195:  21% 58/270 [00:39<-1:59:14, -4.60it/s, loss=0.0173, v_num=ypmf]Epoch 195:  21% 58/270 [00:39<-1:59:14, -4.60it/s, loss=0.0173, v_num=ypmf]Epoch 195:  21% 58/270 [00:39<-1:59:14, -4.58it/s, loss=0.0172, v_num=ypmf]Epoch 195:  22% 59/270 [00:40<-1:59:14, -4.51it/s, loss=0.0172, v_num=ypmf]Epoch 195:  22% 59/270 [00:40<-1:59:14, -4.51it/s, loss=0.0172, v_num=ypmf]Epoch 195:  22% 59/270 [00:40<-1:59:13, -4.49it/s, loss=0.0173, v_num=ypmf]Epoch 195:  22% 60/270 [00:40<-1:59:13, -4.41it/s, loss=0.0173, v_num=ypmf]Epoch 195:  22% 60/270 [00:40<-1:59:13, -4.41it/s, loss=0.0173, v_num=ypmf]Epoch 195:  22% 60/270 [00:41<-1:59:12, -4.32it/s, loss=0.0172, v_num=ypmf]Epoch 195:  23% 61/270 [00:42<-1:59:11, -4.25it/s, loss=0.0172, v_num=ypmf]Epoch 195:  23% 61/270 [00:42<-1:59:11, -4.25it/s, loss=0.0172, v_num=ypmf]Epoch 195:  23% 61/270 [00:42<-1:59:11, -4.24it/s, loss=0.0173, v_num=ypmf]Epoch 195:  23% 62/270 [00:42<-1:59:11, -4.18it/s, loss=0.0173, v_num=ypmf]Epoch 195:  23% 62/270 [00:42<-1:59:11, -4.18it/s, loss=0.0173, v_num=ypmf]Epoch 195:  23% 62/270 [00:43<-1:59:10, -4.15it/s, loss=0.0173, v_num=ypmf]Epoch 195:  23% 63/270 [00:43<-1:59:10, -4.09it/s, loss=0.0173, v_num=ypmf]Epoch 195:  23% 63/270 [00:43<-1:59:10, -4.09it/s, loss=0.0173, v_num=ypmf]Epoch 195:  23% 63/270 [00:43<-1:59:09, -4.06it/s, loss=0.0173, v_num=ypmf]Epoch 195:  24% 64/270 [00:44<-1:59:09, -4.00it/s, loss=0.0173, v_num=ypmf]Epoch 195:  24% 64/270 [00:44<-1:59:09, -4.00it/s, loss=0.0173, v_num=ypmf]Epoch 195:  24% 64/270 [00:44<-1:59:08, -3.94it/s, loss=0.0174, v_num=ypmf]Epoch 195:  24% 65/270 [00:45<-1:59:08, -3.89it/s, loss=0.0174, v_num=ypmf]Epoch 195:  24% 65/270 [00:45<-1:59:08, -3.89it/s, loss=0.0174, v_num=ypmf]Epoch 195:  24% 65/270 [00:45<-1:59:08, -3.88it/s, loss=0.0174, v_num=ypmf]Epoch 195:  24% 66/270 [00:45<-1:59:07, -3.81it/s, loss=0.0174, v_num=ypmf]Epoch 195:  24% 66/270 [00:45<-1:59:07, -3.81it/s, loss=0.0174, v_num=ypmf]Epoch 195:  24% 66/270 [00:45<-1:59:07, -3.81it/s, loss=0.0173, v_num=ypmf]Epoch 195:  25% 67/270 [00:46<-1:59:06, -3.75it/s, loss=0.0173, v_num=ypmf]Epoch 195:  25% 67/270 [00:46<-1:59:06, -3.75it/s, loss=0.0173, v_num=ypmf]Epoch 195:  25% 67/270 [00:46<-1:59:06, -3.74it/s, loss=0.0173, v_num=ypmf]Epoch 195:  25% 68/270 [00:46<-1:59:06, -3.69it/s, loss=0.0173, v_num=ypmf]Epoch 195:  25% 68/270 [00:46<-1:59:06, -3.69it/s, loss=0.0173, v_num=ypmf]Epoch 195:  25% 68/270 [00:48<-1:59:04, -3.56it/s, loss=0.0174, v_num=ypmf]Epoch 195:  26% 69/270 [00:49<-1:59:03, -3.51it/s, loss=0.0174, v_num=ypmf]Epoch 195:  26% 69/270 [00:49<-1:59:03, -3.51it/s, loss=0.0174, v_num=ypmf]Epoch 195:  26% 69/270 [00:49<-1:59:03, -3.50it/s, loss=0.0174, v_num=ypmf]Epoch 195:  26% 70/270 [00:49<-1:59:03, -3.45it/s, loss=0.0174, v_num=ypmf]Epoch 195:  26% 70/270 [00:49<-1:59:03, -3.45it/s, loss=0.0174, v_num=ypmf]Epoch 195:  26% 70/270 [00:49<-1:59:02, -3.43it/s, loss=0.0172, v_num=ypmf]Epoch 195:  26% 71/270 [00:50<-1:59:02, -3.39it/s, loss=0.0172, v_num=ypmf]Epoch 195:  26% 71/270 [00:50<-1:59:02, -3.39it/s, loss=0.0172, v_num=ypmf]Epoch 195:  26% 71/270 [00:50<-1:59:01, -3.36it/s, loss=0.0173, v_num=ypmf]Epoch 195:  27% 72/270 [00:50<-1:59:01, -3.32it/s, loss=0.0173, v_num=ypmf]Epoch 195:  27% 72/270 [00:50<-1:59:01, -3.32it/s, loss=0.0173, v_num=ypmf]Epoch 195:  27% 72/270 [00:51<-1:59:01, -3.31it/s, loss=0.0174, v_num=ypmf]Epoch 195:  27% 73/270 [00:51<-1:59:00, -3.24it/s, loss=0.0174, v_num=ypmf]Epoch 195:  27% 73/270 [00:51<-1:59:00, -3.24it/s, loss=0.0174, v_num=ypmf]Epoch 195:  27% 73/270 [00:51<-1:59:00, -3.23it/s, loss=0.0173, v_num=ypmf]Epoch 195:  27% 74/270 [00:52<-1:58:59, -3.19it/s, loss=0.0173, v_num=ypmf]Epoch 195:  27% 74/270 [00:52<-1:58:59, -3.19it/s, loss=0.0173, v_num=ypmf]Epoch 195:  27% 74/270 [00:52<-1:58:59, -3.18it/s, loss=0.0173, v_num=ypmf]Epoch 195:  28% 75/270 [00:53<-1:58:58, -3.13it/s, loss=0.0173, v_num=ypmf]Epoch 195:  28% 75/270 [00:53<-1:58:58, -3.13it/s, loss=0.0173, v_num=ypmf]Epoch 195:  28% 75/270 [00:53<-1:58:58, -3.12it/s, loss=0.0171, v_num=ypmf]Epoch 195:  28% 76/270 [00:53<-1:58:58, -3.08it/s, loss=0.0171, v_num=ypmf]Epoch 195:  28% 76/270 [00:53<-1:58:58, -3.08it/s, loss=0.0171, v_num=ypmf]Epoch 195:  28% 76/270 [00:53<-1:58:57, -3.07it/s, loss=0.0172, v_num=ypmf]Epoch 195:  29% 77/270 [00:54<-1:58:56, -3.01it/s, loss=0.0172, v_num=ypmf]Epoch 195:  29% 77/270 [00:54<-1:58:56, -3.01it/s, loss=0.0172, v_num=ypmf]Epoch 195:  29% 77/270 [00:54<-1:58:56, -3.00it/s, loss=0.0171, v_num=ypmf]Epoch 195:  29% 78/270 [00:54<-1:58:56, -2.97it/s, loss=0.0171, v_num=ypmf]Epoch 195:  29% 78/270 [00:54<-1:58:56, -2.97it/s, loss=0.0171, v_num=ypmf]Epoch 195:  29% 78/270 [00:55<-1:58:56, -2.95it/s, loss=0.0173, v_num=ypmf]Epoch 195:  29% 79/270 [00:55<-1:58:55, -2.91it/s, loss=0.0173, v_num=ypmf]Epoch 195:  29% 79/270 [00:55<-1:58:55, -2.91it/s, loss=0.0173, v_num=ypmf]Epoch 195:  29% 79/270 [00:55<-1:58:55, -2.90it/s, loss=0.0173, v_num=ypmf]Epoch 195:  30% 80/270 [00:56<-1:58:54, -2.86it/s, loss=0.0173, v_num=ypmf]Epoch 195:  30% 80/270 [00:56<-1:58:54, -2.86it/s, loss=0.0173, v_num=ypmf]Epoch 195:  30% 80/270 [00:56<-1:58:54, -2.85it/s, loss=0.0174, v_num=ypmf]Epoch 195:  30% 81/270 [00:56<-1:58:53, -2.81it/s, loss=0.0174, v_num=ypmf]Epoch 195:  30% 81/270 [00:56<-1:58:53, -2.81it/s, loss=0.0174, v_num=ypmf]Epoch 195:  30% 81/270 [00:57<-1:58:53, -2.81it/s, loss=0.0173, v_num=ypmf]Epoch 195:  30% 82/270 [00:57<-1:58:53, -2.77it/s, loss=0.0173, v_num=ypmf]Epoch 195:  30% 82/270 [00:57<-1:58:53, -2.77it/s, loss=0.0173, v_num=ypmf]Epoch 195:  30% 82/270 [00:57<-1:58:52, -2.76it/s, loss=0.0173, v_num=ypmf]Epoch 195:  31% 83/270 [00:58<-1:58:52, -2.72it/s, loss=0.0173, v_num=ypmf]Epoch 195:  31% 83/270 [00:58<-1:58:52, -2.72it/s, loss=0.0173, v_num=ypmf]Epoch 195:  31% 83/270 [00:58<-1:58:52, -2.72it/s, loss=0.0172, v_num=ypmf]Epoch 195:  31% 84/270 [00:58<-1:58:51, -2.68it/s, loss=0.0172, v_num=ypmf]Epoch 195:  31% 84/270 [00:58<-1:58:51, -2.68it/s, loss=0.0172, v_num=ypmf]Epoch 195:  31% 84/270 [00:58<-1:58:51, -2.67it/s, loss=0.0173, v_num=ypmf]Epoch 195:  31% 85/270 [00:59<-1:58:50, -2.64it/s, loss=0.0173, v_num=ypmf]Epoch 195:  31% 85/270 [00:59<-1:58:50, -2.64it/s, loss=0.0173, v_num=ypmf]Epoch 195:  31% 85/270 [00:59<-1:58:50, -2.63it/s, loss=0.0173, v_num=ypmf]Epoch 195:  32% 86/270 [00:59<-1:58:50, -2.60it/s, loss=0.0173, v_num=ypmf]Epoch 195:  32% 86/270 [00:59<-1:58:50, -2.60it/s, loss=0.0173, v_num=ypmf]Epoch 195:  32% 86/270 [00:59<-1:58:49, -2.59it/s, loss=0.0173, v_num=ypmf]Epoch 195:  32% 87/270 [01:00<-1:58:49, -2.56it/s, loss=0.0173, v_num=ypmf]Epoch 195:  32% 87/270 [01:00<-1:58:49, -2.56it/s, loss=0.0173, v_num=ypmf]Epoch 195:  32% 87/270 [01:00<-1:58:49, -2.55it/s, loss=0.0173, v_num=ypmf]Epoch 195:  33% 88/270 [01:00<-1:58:48, -2.52it/s, loss=0.0173, v_num=ypmf]Epoch 195:  33% 88/270 [01:00<-1:58:48, -2.52it/s, loss=0.0173, v_num=ypmf]Epoch 195:  33% 88/270 [01:00<-1:58:48, -2.51it/s, loss=0.0172, v_num=ypmf]Epoch 195:  33% 89/270 [01:01<-1:58:48, -2.48it/s, loss=0.0172, v_num=ypmf]Epoch 195:  33% 89/270 [01:01<-1:58:48, -2.48it/s, loss=0.0172, v_num=ypmf]Epoch 195:  33% 89/270 [01:01<-1:58:47, -2.47it/s, loss=0.0172, v_num=ypmf]Epoch 195:  33% 90/270 [01:01<-1:58:47, -2.44it/s, loss=0.0172, v_num=ypmf]Epoch 195:  33% 90/270 [01:01<-1:58:47, -2.44it/s, loss=0.0172, v_num=ypmf]Epoch 195:  33% 90/270 [01:02<-1:58:46, -2.43it/s, loss=0.0173, v_num=ypmf]Epoch 195:  34% 91/270 [01:02<-1:58:46, -2.39it/s, loss=0.0173, v_num=ypmf]Epoch 195:  34% 91/270 [01:02<-1:58:46, -2.39it/s, loss=0.0173, v_num=ypmf]Epoch 195:  34% 91/270 [01:02<-1:58:46, -2.39it/s, loss=0.0172, v_num=ypmf]Epoch 195:  34% 92/270 [01:03<-1:58:45, -2.36it/s, loss=0.0172, v_num=ypmf]Epoch 195:  34% 92/270 [01:03<-1:58:45, -2.36it/s, loss=0.0172, v_num=ypmf]Epoch 195:  34% 92/270 [01:03<-1:58:45, -2.36it/s, loss=0.0171, v_num=ypmf]Epoch 195:  34% 93/270 [01:03<-1:58:44, -2.32it/s, loss=0.0171, v_num=ypmf]Epoch 195:  34% 93/270 [01:03<-1:58:44, -2.32it/s, loss=0.0171, v_num=ypmf]Epoch 195:  34% 93/270 [01:03<-1:58:44, -2.32it/s, loss=0.0172, v_num=ypmf]Epoch 195:  35% 94/270 [01:04<-1:58:44, -2.29it/s, loss=0.0172, v_num=ypmf]Epoch 195:  35% 94/270 [01:04<-1:58:44, -2.29it/s, loss=0.0172, v_num=ypmf]Epoch 195:  35% 94/270 [01:04<-1:58:43, -2.28it/s, loss=0.0173, v_num=ypmf]Epoch 195:  35% 95/270 [01:04<-1:58:43, -2.25it/s, loss=0.0173, v_num=ypmf]Epoch 195:  35% 95/270 [01:04<-1:58:43, -2.25it/s, loss=0.0173, v_num=ypmf]Epoch 195:  35% 95/270 [01:04<-1:58:43, -2.25it/s, loss=0.0173, v_num=ypmf]Epoch 195:  36% 96/270 [01:05<-1:58:42, -2.22it/s, loss=0.0173, v_num=ypmf]Epoch 195:  36% 96/270 [01:05<-1:58:42, -2.22it/s, loss=0.0173, v_num=ypmf]Epoch 195:  36% 96/270 [01:05<-1:58:42, -2.21it/s, loss=0.0173, v_num=ypmf]Epoch 195:  36% 97/270 [01:05<-1:58:41, -2.18it/s, loss=0.0173, v_num=ypmf]Epoch 195:  36% 97/270 [01:05<-1:58:41, -2.18it/s, loss=0.0173, v_num=ypmf]Epoch 195:  36% 97/270 [01:06<-1:58:41, -2.18it/s, loss=0.0173, v_num=ypmf]Epoch 195:  36% 98/270 [01:06<-1:58:41, -2.15it/s, loss=0.0173, v_num=ypmf]Epoch 195:  36% 98/270 [01:06<-1:58:41, -2.15it/s, loss=0.0173, v_num=ypmf]Epoch 195:  36% 98/270 [01:06<-1:58:40, -2.14it/s, loss=0.0172, v_num=ypmf]Epoch 195:  37% 99/270 [01:07<-1:58:40, -2.12it/s, loss=0.0172, v_num=ypmf]Epoch 195:  37% 99/270 [01:07<-1:58:40, -2.12it/s, loss=0.0172, v_num=ypmf]Epoch 195:  37% 99/270 [01:07<-1:58:39, -2.11it/s, loss=0.0172, v_num=ypmf]Epoch 195:  37% 100/270 [01:07<-1:58:39, -2.09it/s, loss=0.0172, v_num=ypmf]Epoch 195:  37% 100/270 [01:07<-1:58:39, -2.09it/s, loss=0.0172, v_num=ypmf]Epoch 195:  37% 100/270 [01:07<-1:58:39, -2.08it/s, loss=0.0171, v_num=ypmf]Epoch 195:  37% 101/270 [01:08<-1:58:38, -2.05it/s, loss=0.0171, v_num=ypmf]Epoch 195:  37% 101/270 [01:08<-1:58:38, -2.05it/s, loss=0.0171, v_num=ypmf]Epoch 195:  37% 101/270 [01:08<-1:58:38, -2.04it/s, loss=0.0171, v_num=ypmf]Epoch 195:  38% 102/270 [01:08<-1:58:37, -2.02it/s, loss=0.0171, v_num=ypmf]Epoch 195:  38% 102/270 [01:08<-1:58:37, -2.02it/s, loss=0.0171, v_num=ypmf]Epoch 195:  38% 102/270 [01:09<-1:58:37, -2.01it/s, loss=0.0171, v_num=ypmf]Epoch 195:  38% 103/270 [01:09<-1:58:36, -1.99it/s, loss=0.0171, v_num=ypmf]Epoch 195:  38% 103/270 [01:09<-1:58:36, -1.99it/s, loss=0.0171, v_num=ypmf]Epoch 195:  38% 103/270 [01:09<-1:58:36, -1.98it/s, loss=0.0171, v_num=ypmf]Epoch 195:  39% 104/270 [01:10<-1:58:36, -1.96it/s, loss=0.0171, v_num=ypmf]Epoch 195:  39% 104/270 [01:10<-1:58:36, -1.96it/s, loss=0.0171, v_num=ypmf]Epoch 195:  39% 104/270 [01:10<-1:58:35, -1.95it/s, loss=0.0169, v_num=ypmf]Epoch 195:  39% 105/270 [01:10<-1:58:35, -1.93it/s, loss=0.0169, v_num=ypmf]Epoch 195:  39% 105/270 [01:10<-1:58:35, -1.93it/s, loss=0.0169, v_num=ypmf]Epoch 195:  39% 105/270 [01:10<-1:58:35, -1.92it/s, loss=0.017, v_num=ypmf] Epoch 195:  39% 106/270 [01:11<-1:58:34, -1.90it/s, loss=0.017, v_num=ypmf]Epoch 195:  39% 106/270 [01:11<-1:58:34, -1.90it/s, loss=0.017, v_num=ypmf]Epoch 195:  39% 106/270 [01:11<-1:58:34, -1.89it/s, loss=0.0169, v_num=ypmf]Epoch 195:  40% 107/270 [01:11<-1:58:33, -1.87it/s, loss=0.0169, v_num=ypmf]Epoch 195:  40% 107/270 [01:11<-1:58:33, -1.87it/s, loss=0.0169, v_num=ypmf]Epoch 195:  40% 107/270 [01:11<-1:58:33, -1.86it/s, loss=0.017, v_num=ypmf] Epoch 195:  40% 108/270 [01:12<-1:58:32, -1.84it/s, loss=0.017, v_num=ypmf]Epoch 195:  40% 108/270 [01:12<-1:58:32, -1.84it/s, loss=0.017, v_num=ypmf]Epoch 195:  40% 108/270 [01:12<-1:58:32, -1.83it/s, loss=0.0169, v_num=ypmf]Epoch 195:  40% 109/270 [01:12<-1:58:32, -1.81it/s, loss=0.0169, v_num=ypmf]Epoch 195:  40% 109/270 [01:12<-1:58:32, -1.81it/s, loss=0.0169, v_num=ypmf]Epoch 195:  40% 109/270 [01:13<-1:58:31, -1.81it/s, loss=0.0169, v_num=ypmf]Epoch 195:  41% 110/270 [01:13<-1:58:31, -1.78it/s, loss=0.0169, v_num=ypmf]Epoch 195:  41% 110/270 [01:13<-1:58:31, -1.78it/s, loss=0.0169, v_num=ypmf]Epoch 195:  41% 110/270 [01:13<-1:58:31, -1.78it/s, loss=0.0167, v_num=ypmf]Epoch 195:  41% 111/270 [01:13<-1:58:30, -1.76it/s, loss=0.0167, v_num=ypmf]Epoch 195:  41% 111/270 [01:13<-1:58:30, -1.76it/s, loss=0.0167, v_num=ypmf]Epoch 195:  41% 111/270 [01:14<-1:58:30, -1.75it/s, loss=0.0169, v_num=ypmf]Epoch 195:  41% 112/270 [01:14<-1:58:29, -1.73it/s, loss=0.0169, v_num=ypmf]Epoch 195:  41% 112/270 [01:14<-1:58:29, -1.73it/s, loss=0.0169, v_num=ypmf]Epoch 195:  41% 112/270 [01:14<-1:58:29, -1.72it/s, loss=0.0169, v_num=ypmf]Epoch 195:  42% 113/270 [01:15<-1:58:28, -1.70it/s, loss=0.0169, v_num=ypmf]Epoch 195:  42% 113/270 [01:15<-1:58:28, -1.70it/s, loss=0.0169, v_num=ypmf]Epoch 195:  42% 113/270 [01:15<-1:58:28, -1.70it/s, loss=0.0168, v_num=ypmf]Epoch 195:  42% 114/270 [01:15<-1:58:27, -1.68it/s, loss=0.0168, v_num=ypmf]Epoch 195:  42% 114/270 [01:15<-1:58:27, -1.68it/s, loss=0.0168, v_num=ypmf]Epoch 195:  42% 114/270 [01:15<-1:58:27, -1.67it/s, loss=0.0167, v_num=ypmf]Epoch 195:  43% 115/270 [01:16<-1:58:27, -1.65it/s, loss=0.0167, v_num=ypmf]Epoch 195:  43% 115/270 [01:16<-1:58:27, -1.65it/s, loss=0.0167, v_num=ypmf]Epoch 195:  43% 115/270 [01:16<-1:58:26, -1.65it/s, loss=0.0166, v_num=ypmf]Epoch 195:  43% 116/270 [01:16<-1:58:26, -1.62it/s, loss=0.0166, v_num=ypmf]Epoch 195:  43% 116/270 [01:16<-1:58:26, -1.62it/s, loss=0.0166, v_num=ypmf]Epoch 195:  43% 116/270 [01:17<-1:58:26, -1.62it/s, loss=0.0167, v_num=ypmf]Epoch 195:  43% 117/270 [01:17<-1:58:25, -1.60it/s, loss=0.0167, v_num=ypmf]Epoch 195:  43% 117/270 [01:17<-1:58:25, -1.60it/s, loss=0.0167, v_num=ypmf]Epoch 195:  43% 117/270 [01:17<-1:58:25, -1.60it/s, loss=0.0168, v_num=ypmf]Epoch 195:  44% 118/270 [01:18<-1:58:24, -1.58it/s, loss=0.0168, v_num=ypmf]Epoch 195:  44% 118/270 [01:18<-1:58:24, -1.58it/s, loss=0.0168, v_num=ypmf]Epoch 195:  44% 118/270 [01:18<-1:58:24, -1.57it/s, loss=0.0167, v_num=ypmf]Epoch 195:  44% 119/270 [01:18<-1:58:23, -1.55it/s, loss=0.0167, v_num=ypmf]Epoch 195:  44% 119/270 [01:18<-1:58:23, -1.55it/s, loss=0.0167, v_num=ypmf]Epoch 195:  44% 119/270 [01:18<-1:58:23, -1.55it/s, loss=0.0168, v_num=ypmf]Epoch 195:  44% 120/270 [01:19<-1:58:22, -1.53it/s, loss=0.0168, v_num=ypmf]Epoch 195:  44% 120/270 [01:19<-1:58:22, -1.53it/s, loss=0.0168, v_num=ypmf]Epoch 195:  44% 120/270 [01:19<-1:58:22, -1.53it/s, loss=0.017, v_num=ypmf] Epoch 195:  45% 121/270 [01:19<-1:58:22, -1.51it/s, loss=0.017, v_num=ypmf]Epoch 195:  45% 121/270 [01:19<-1:58:22, -1.51it/s, loss=0.017, v_num=ypmf]Epoch 195:  45% 121/270 [01:19<-1:58:21, -1.50it/s, loss=0.0169, v_num=ypmf]Epoch 195:  45% 122/270 [01:20<-1:58:21, -1.48it/s, loss=0.0169, v_num=ypmf]Epoch 195:  45% 122/270 [01:20<-1:58:21, -1.48it/s, loss=0.0169, v_num=ypmf]Epoch 195:  45% 122/270 [01:20<-1:58:20, -1.48it/s, loss=0.017, v_num=ypmf] Epoch 195:  46% 123/270 [01:20<-1:58:20, -1.46it/s, loss=0.017, v_num=ypmf]Epoch 195:  46% 123/270 [01:20<-1:58:20, -1.46it/s, loss=0.017, v_num=ypmf]Epoch 195:  46% 123/270 [01:20<-1:58:20, -1.46it/s, loss=0.0171, v_num=ypmf]Epoch 195:  46% 124/270 [01:21<-1:58:19, -1.44it/s, loss=0.0171, v_num=ypmf]Epoch 195:  46% 124/270 [01:21<-1:58:19, -1.44it/s, loss=0.0171, v_num=ypmf]Epoch 195:  46% 124/270 [01:21<-1:58:19, -1.43it/s, loss=0.0171, v_num=ypmf]Epoch 195:  46% 125/270 [01:21<-1:58:18, -1.42it/s, loss=0.0171, v_num=ypmf]Epoch 195:  46% 125/270 [01:21<-1:58:18, -1.42it/s, loss=0.0171, v_num=ypmf]Epoch 195:  46% 125/270 [01:22<-1:58:18, -1.41it/s, loss=0.0171, v_num=ypmf]Epoch 195:  47% 126/270 [01:22<-1:58:17, -1.40it/s, loss=0.0171, v_num=ypmf]Epoch 195:  47% 126/270 [01:22<-1:58:17, -1.40it/s, loss=0.0171, v_num=ypmf]Epoch 195:  47% 126/270 [01:22<-1:58:17, -1.39it/s, loss=0.0172, v_num=ypmf]Epoch 195:  47% 127/270 [01:22<-1:58:16, -1.37it/s, loss=0.0172, v_num=ypmf]Epoch 195:  47% 127/270 [01:22<-1:58:16, -1.37it/s, loss=0.0172, v_num=ypmf]Epoch 195:  47% 127/270 [01:23<-1:58:16, -1.37it/s, loss=0.0171, v_num=ypmf]Epoch 195:  47% 128/270 [01:23<-1:58:16, -1.35it/s, loss=0.0171, v_num=ypmf]Epoch 195:  47% 128/270 [01:23<-1:58:16, -1.35it/s, loss=0.0171, v_num=ypmf]Epoch 195:  47% 128/270 [01:23<-1:58:15, -1.35it/s, loss=0.0174, v_num=ypmf]Epoch 195:  48% 129/270 [01:24<-1:58:15, -1.33it/s, loss=0.0174, v_num=ypmf]Epoch 195:  48% 129/270 [01:24<-1:58:15, -1.33it/s, loss=0.0174, v_num=ypmf]Epoch 195:  48% 129/270 [01:24<-1:58:14, -1.32it/s, loss=0.0173, v_num=ypmf]Epoch 195:  48% 130/270 [01:25<-1:58:13, -1.30it/s, loss=0.0173, v_num=ypmf]Epoch 195:  48% 130/270 [01:25<-1:58:13, -1.30it/s, loss=0.0173, v_num=ypmf]Epoch 195:  48% 130/270 [01:25<-1:58:13, -1.30it/s, loss=0.0174, v_num=ypmf]Epoch 195:  49% 131/270 [01:25<-1:58:12, -1.28it/s, loss=0.0174, v_num=ypmf]Epoch 195:  49% 131/270 [01:25<-1:58:12, -1.28it/s, loss=0.0174, v_num=ypmf]Epoch 195:  49% 131/270 [01:26<-1:58:12, -1.28it/s, loss=0.0173, v_num=ypmf]Epoch 195:  49% 132/270 [01:26<-1:58:11, -1.26it/s, loss=0.0173, v_num=ypmf]Epoch 195:  49% 132/270 [01:26<-1:58:11, -1.26it/s, loss=0.0173, v_num=ypmf]Epoch 195:  49% 132/270 [01:26<-1:58:11, -1.26it/s, loss=0.0173, v_num=ypmf]Epoch 195:  49% 133/270 [01:26<-1:58:10, -1.24it/s, loss=0.0173, v_num=ypmf]Epoch 195:  49% 133/270 [01:26<-1:58:10, -1.24it/s, loss=0.0173, v_num=ypmf]Epoch 195:  49% 133/270 [01:27<-1:58:10, -1.24it/s, loss=0.0174, v_num=ypmf]Epoch 195:  50% 134/270 [01:27<-1:58:09, -1.22it/s, loss=0.0174, v_num=ypmf]Epoch 195:  50% 134/270 [01:27<-1:58:09, -1.22it/s, loss=0.0174, v_num=ypmf]Epoch 195:  50% 134/270 [01:27<-1:58:09, -1.22it/s, loss=0.0174, v_num=ypmf]Epoch 195:  50% 135/270 [01:28<-1:58:08, -1.20it/s, loss=0.0174, v_num=ypmf]Epoch 195:  50% 135/270 [01:28<-1:58:08, -1.20it/s, loss=0.0174, v_num=ypmf]Epoch 195:  50% 135/270 [01:28<-1:58:08, -1.20it/s, loss=0.0174, v_num=ypmf]Epoch 195:  50% 136/270 [01:28<-1:58:07, -1.18it/s, loss=0.0174, v_num=ypmf]Epoch 195:  50% 136/270 [01:28<-1:58:07, -1.18it/s, loss=0.0174, v_num=ypmf]Epoch 195:  50% 136/270 [01:29<-1:58:07, -1.18it/s, loss=0.0175, v_num=ypmf]Epoch 195:  51% 137/270 [01:29<-1:58:06, -1.16it/s, loss=0.0175, v_num=ypmf]Epoch 195:  51% 137/270 [01:29<-1:58:06, -1.16it/s, loss=0.0175, v_num=ypmf]Epoch 195:  51% 137/270 [01:29<-1:58:06, -1.16it/s, loss=0.0174, v_num=ypmf]Epoch 195:  51% 138/270 [01:30<-1:58:05, -1.14it/s, loss=0.0174, v_num=ypmf]Epoch 195:  51% 138/270 [01:30<-1:58:05, -1.14it/s, loss=0.0174, v_num=ypmf]Epoch 195:  51% 138/270 [01:30<-1:58:05, -1.14it/s, loss=0.0176, v_num=ypmf]Epoch 195:  51% 139/270 [01:30<-1:58:04, -1.12it/s, loss=0.0176, v_num=ypmf]Epoch 195:  51% 139/270 [01:30<-1:58:04, -1.12it/s, loss=0.0176, v_num=ypmf]Epoch 195:  51% 139/270 [01:30<-1:58:04, -1.12it/s, loss=0.0175, v_num=ypmf]Epoch 195:  52% 140/270 [01:31<-1:58:03, -1.10it/s, loss=0.0175, v_num=ypmf]Epoch 195:  52% 140/270 [01:31<-1:58:03, -1.10it/s, loss=0.0175, v_num=ypmf]Epoch 195:  52% 140/270 [01:31<-1:58:03, -1.10it/s, loss=0.0174, v_num=ypmf]Epoch 195:  52% 141/270 [01:32<-1:58:02, -1.09it/s, loss=0.0174, v_num=ypmf]Epoch 195:  52% 141/270 [01:32<-1:58:02, -1.09it/s, loss=0.0174, v_num=ypmf]Epoch 195:  52% 141/270 [01:32<-1:58:02, -1.09it/s, loss=0.0175, v_num=ypmf]Epoch 195:  53% 142/270 [01:32<-1:58:01, -1.07it/s, loss=0.0175, v_num=ypmf]Epoch 195:  53% 142/270 [01:32<-1:58:01, -1.07it/s, loss=0.0175, v_num=ypmf]Epoch 195:  53% 142/270 [01:32<-1:58:01, -1.07it/s, loss=0.0175, v_num=ypmf]Epoch 195:  53% 143/270 [01:33<-1:58:00, -1.05it/s, loss=0.0175, v_num=ypmf]Epoch 195:  53% 143/270 [01:33<-1:58:00, -1.05it/s, loss=0.0175, v_num=ypmf]Epoch 195:  53% 143/270 [01:33<-1:57:59, -1.05it/s, loss=0.0173, v_num=ypmf]Epoch 195:  53% 144/270 [01:33<-1:57:59, -1.04it/s, loss=0.0173, v_num=ypmf]Epoch 195:  53% 144/270 [01:33<-1:57:59, -1.04it/s, loss=0.0173, v_num=ypmf]Epoch 195:  53% 144/270 [01:33<-1:57:58, -1.03it/s, loss=0.0174, v_num=ypmf]Epoch 195:  54% 145/270 [01:34<-1:57:58, -1.02it/s, loss=0.0174, v_num=ypmf]Epoch 195:  54% 145/270 [01:34<-1:57:58, -1.02it/s, loss=0.0174, v_num=ypmf]Epoch 195:  54% 145/270 [01:34<-1:57:57, -1.02it/s, loss=0.0174, v_num=ypmf]Epoch 195:  54% 146/270 [01:34<-1:57:57, -1.00it/s, loss=0.0174, v_num=ypmf]Epoch 195:  54% 146/270 [01:34<-1:57:57, -1.00it/s, loss=0.0174, v_num=ypmf]Epoch 195:  54% 146/270 [01:35<-1:57:56, -1.00it/s, loss=0.0174, v_num=ypmf]Epoch 195:  54% 147/270 [01:35<-1:57:56, -0.98it/s, loss=0.0174, v_num=ypmf]Epoch 195:  54% 147/270 [01:35<-1:57:56, -0.98it/s, loss=0.0174, v_num=ypmf]Epoch 195:  54% 147/270 [01:36<-1:57:54, -0.98it/s, loss=0.0173, v_num=ypmf]Epoch 195:  55% 148/270 [01:36<-1:57:53, -0.96it/s, loss=0.0173, v_num=ypmf]Epoch 195:  55% 148/270 [01:36<-1:57:53, -0.96it/s, loss=0.0173, v_num=ypmf]Epoch 195:  55% 148/270 [01:37<-1:57:53, -0.96it/s, loss=0.0171, v_num=ypmf]Epoch 195:  55% 149/270 [01:37<-1:57:52, -0.94it/s, loss=0.0171, v_num=ypmf]Epoch 195:  55% 149/270 [01:37<-1:57:52, -0.94it/s, loss=0.0171, v_num=ypmf]Epoch 195:  55% 149/270 [01:37<-1:57:52, -0.94it/s, loss=0.0172, v_num=ypmf]Epoch 195:  56% 150/270 [01:38<-1:57:51, -0.93it/s, loss=0.0172, v_num=ypmf]Epoch 195:  56% 150/270 [01:38<-1:57:51, -0.93it/s, loss=0.0172, v_num=ypmf]Epoch 195:  56% 150/270 [01:38<-1:57:51, -0.93it/s, loss=0.0172, v_num=ypmf]Epoch 195:  56% 151/270 [01:38<-1:57:50, -0.91it/s, loss=0.0172, v_num=ypmf]Epoch 195:  56% 151/270 [01:38<-1:57:50, -0.91it/s, loss=0.0172, v_num=ypmf]Epoch 195:  56% 151/270 [01:38<-1:57:50, -0.91it/s, loss=0.0173, v_num=ypmf]Epoch 195:  56% 152/270 [01:39<-1:57:49, -0.90it/s, loss=0.0173, v_num=ypmf]Epoch 195:  56% 152/270 [01:39<-1:57:49, -0.90it/s, loss=0.0173, v_num=ypmf]Epoch 195:  56% 152/270 [01:39<-1:57:48, -0.89it/s, loss=0.0173, v_num=ypmf]Epoch 195:  57% 153/270 [01:39<-1:57:48, -0.88it/s, loss=0.0173, v_num=ypmf]Epoch 195:  57% 153/270 [01:39<-1:57:48, -0.88it/s, loss=0.0173, v_num=ypmf]Epoch 195:  57% 153/270 [01:40<-1:57:47, -0.88it/s, loss=0.0172, v_num=ypmf]Epoch 195:  57% 154/270 [01:40<-1:57:47, -0.87it/s, loss=0.0172, v_num=ypmf]Epoch 195:  57% 154/270 [01:40<-1:57:47, -0.87it/s, loss=0.0172, v_num=ypmf]Epoch 195:  57% 154/270 [01:40<-1:57:46, -0.86it/s, loss=0.0172, v_num=ypmf]Epoch 195:  57% 155/270 [01:41<-1:57:45, -0.85it/s, loss=0.0172, v_num=ypmf]Epoch 195:  57% 155/270 [01:41<-1:57:45, -0.85it/s, loss=0.0172, v_num=ypmf]Epoch 195:  57% 155/270 [01:41<-1:57:45, -0.85it/s, loss=0.0173, v_num=ypmf]Epoch 195:  58% 156/270 [01:41<-1:57:44, -0.84it/s, loss=0.0173, v_num=ypmf]Epoch 195:  58% 156/270 [01:41<-1:57:44, -0.84it/s, loss=0.0173, v_num=ypmf]Epoch 195:  58% 156/270 [01:42<-1:57:43, -0.83it/s, loss=0.0172, v_num=ypmf]Epoch 195:  58% 157/270 [01:43<-1:57:42, -0.81it/s, loss=0.0172, v_num=ypmf]Epoch 195:  58% 157/270 [01:43<-1:57:42, -0.81it/s, loss=0.0172, v_num=ypmf]Epoch 195:  58% 157/270 [01:43<-1:57:42, -0.81it/s, loss=0.0172, v_num=ypmf]Epoch 195:  59% 158/270 [01:43<-1:57:41, -0.80it/s, loss=0.0172, v_num=ypmf]Epoch 195:  59% 158/270 [01:43<-1:57:41, -0.80it/s, loss=0.0172, v_num=ypmf]Epoch 195:  59% 158/270 [01:43<-1:57:40, -0.80it/s, loss=0.0171, v_num=ypmf]Epoch 195:  59% 159/270 [01:44<-1:57:39, -0.79it/s, loss=0.0171, v_num=ypmf]Epoch 195:  59% 159/270 [01:44<-1:57:39, -0.79it/s, loss=0.0171, v_num=ypmf]Epoch 195:  59% 159/270 [01:44<-1:57:39, -0.79it/s, loss=0.0171, v_num=ypmf]Epoch 195:  59% 160/270 [01:44<-1:57:38, -0.77it/s, loss=0.0171, v_num=ypmf]Epoch 195:  59% 160/270 [01:44<-1:57:38, -0.77it/s, loss=0.0171, v_num=ypmf]Epoch 195:  59% 160/270 [01:44<-1:57:38, -0.77it/s, loss=0.0171, v_num=ypmf]Epoch 195:  60% 161/270 [01:45<-1:57:37, -0.76it/s, loss=0.0171, v_num=ypmf]Epoch 195:  60% 161/270 [01:45<-1:57:37, -0.76it/s, loss=0.0171, v_num=ypmf]Epoch 195:  60% 161/270 [01:45<-1:57:37, -0.76it/s, loss=0.0171, v_num=ypmf]Epoch 195:  60% 162/270 [01:45<-1:57:36, -0.75it/s, loss=0.0171, v_num=ypmf]Epoch 195:  60% 162/270 [01:45<-1:57:36, -0.75it/s, loss=0.0171, v_num=ypmf]Epoch 195:  60% 162/270 [01:46<-1:57:35, -0.74it/s, loss=0.0171, v_num=ypmf]Epoch 195:  60% 163/270 [01:46<-1:57:35, -0.73it/s, loss=0.0171, v_num=ypmf]Epoch 195:  60% 163/270 [01:46<-1:57:35, -0.73it/s, loss=0.0171, v_num=ypmf]Epoch 195:  60% 163/270 [01:46<-1:57:34, -0.73it/s, loss=0.0172, v_num=ypmf]Epoch 195:  61% 164/270 [01:46<-1:57:33, -0.72it/s, loss=0.0172, v_num=ypmf]Epoch 195:  61% 164/270 [01:46<-1:57:33, -0.72it/s, loss=0.0172, v_num=ypmf]Epoch 195:  61% 164/270 [01:47<-1:57:33, -0.72it/s, loss=0.0172, v_num=ypmf]Epoch 195:  61% 165/270 [01:47<-1:57:32, -0.71it/s, loss=0.0172, v_num=ypmf]Epoch 195:  61% 165/270 [01:47<-1:57:32, -0.71it/s, loss=0.0172, v_num=ypmf]Epoch 195:  61% 165/270 [01:47<-1:57:32, -0.71it/s, loss=0.0172, v_num=ypmf]Epoch 195:  61% 166/270 [01:48<-1:57:30, -0.69it/s, loss=0.0172, v_num=ypmf]Epoch 195:  61% 166/270 [01:48<-1:57:30, -0.69it/s, loss=0.0172, v_num=ypmf]Epoch 195:  61% 166/270 [01:48<-1:57:30, -0.69it/s, loss=0.0172, v_num=ypmf]Epoch 195:  62% 167/270 [01:48<-1:57:30, -0.68it/s, loss=0.0172, v_num=ypmf]Epoch 195:  62% 167/270 [01:48<-1:57:30, -0.68it/s, loss=0.0172, v_num=ypmf]Epoch 195:  62% 167/270 [01:48<-1:57:29, -0.68it/s, loss=0.0173, v_num=ypmf]Epoch 195:  62% 168/270 [01:49<-1:57:28, -0.67it/s, loss=0.0173, v_num=ypmf]Epoch 195:  62% 168/270 [01:49<-1:57:28, -0.67it/s, loss=0.0173, v_num=ypmf]Epoch 195:  62% 168/270 [01:49<-1:57:28, -0.67it/s, loss=0.0174, v_num=ypmf]Epoch 195:  63% 169/270 [01:49<-1:57:27, -0.66it/s, loss=0.0174, v_num=ypmf]Epoch 195:  63% 169/270 [01:49<-1:57:27, -0.66it/s, loss=0.0174, v_num=ypmf]Epoch 195:  63% 169/270 [01:49<-1:57:26, -0.66it/s, loss=0.0174, v_num=ypmf]Epoch 195:  63% 170/270 [01:50<-1:57:25, -0.64it/s, loss=0.0174, v_num=ypmf]Epoch 195:  63% 170/270 [01:50<-1:57:25, -0.64it/s, loss=0.0174, v_num=ypmf]Epoch 195:  63% 170/270 [01:50<-1:57:25, -0.64it/s, loss=0.0172, v_num=ypmf]Epoch 195:  63% 171/270 [01:51<-1:57:23, -0.63it/s, loss=0.0172, v_num=ypmf]Epoch 195:  63% 171/270 [01:51<-1:57:23, -0.63it/s, loss=0.0172, v_num=ypmf]Epoch 195:  63% 171/270 [01:51<-1:57:23, -0.63it/s, loss=0.0172, v_num=ypmf]Epoch 195:  64% 172/270 [01:51<-1:57:22, -0.62it/s, loss=0.0172, v_num=ypmf]Epoch 195:  64% 172/270 [01:51<-1:57:22, -0.62it/s, loss=0.0172, v_num=ypmf]Epoch 195:  64% 172/270 [01:51<-1:57:21, -0.62it/s, loss=0.0172, v_num=ypmf]Epoch 195:  64% 173/270 [01:52<-1:57:20, -0.61it/s, loss=0.0172, v_num=ypmf]Epoch 195:  64% 173/270 [01:52<-1:57:20, -0.61it/s, loss=0.0172, v_num=ypmf]Epoch 195:  64% 173/270 [01:52<-1:57:20, -0.60it/s, loss=0.0172, v_num=ypmf]Epoch 195:  64% 174/270 [01:52<-1:57:19, -0.59it/s, loss=0.0172, v_num=ypmf]Epoch 195:  64% 174/270 [01:52<-1:57:19, -0.59it/s, loss=0.0172, v_num=ypmf]Epoch 195:  64% 174/270 [01:53<-1:57:19, -0.59it/s, loss=0.0171, v_num=ypmf]Epoch 195:  65% 175/270 [01:53<-1:57:17, -0.58it/s, loss=0.0171, v_num=ypmf]Epoch 195:  65% 175/270 [01:53<-1:57:17, -0.58it/s, loss=0.0171, v_num=ypmf]Epoch 195:  65% 175/270 [01:53<-1:57:17, -0.58it/s, loss=0.0171, v_num=ypmf]Epoch 195:  65% 176/270 [01:54<-1:57:16, -0.57it/s, loss=0.0171, v_num=ypmf]Epoch 195:  65% 176/270 [01:54<-1:57:16, -0.57it/s, loss=0.0171, v_num=ypmf]Epoch 195:  65% 176/270 [01:54<-1:57:15, -0.57it/s, loss=0.0169, v_num=ypmf]Epoch 195:  66% 177/270 [01:54<-1:57:14, -0.56it/s, loss=0.0169, v_num=ypmf]Epoch 195:  66% 177/270 [01:54<-1:57:14, -0.56it/s, loss=0.0169, v_num=ypmf]Epoch 195:  66% 177/270 [01:54<-1:57:14, -0.56it/s, loss=0.017, v_num=ypmf] Epoch 195:  66% 178/270 [01:55<-1:57:12, -0.55it/s, loss=0.017, v_num=ypmf]Epoch 195:  66% 178/270 [01:55<-1:57:12, -0.55it/s, loss=0.017, v_num=ypmf]Epoch 195:  66% 178/270 [01:55<-1:57:12, -0.55it/s, loss=0.017, v_num=ypmf]Epoch 195:  66% 179/270 [01:55<-1:57:11, -0.54it/s, loss=0.017, v_num=ypmf]Epoch 195:  66% 179/270 [01:55<-1:57:11, -0.54it/s, loss=0.017, v_num=ypmf]Epoch 195:  66% 179/270 [01:55<-1:57:10, -0.54it/s, loss=0.017, v_num=ypmf]Epoch 195:  67% 180/270 [01:56<-1:57:08, -0.52it/s, loss=0.017, v_num=ypmf]Epoch 195:  67% 180/270 [01:56<-1:57:08, -0.52it/s, loss=0.017, v_num=ypmf]Epoch 195:  67% 180/270 [01:56<-1:57:08, -0.52it/s, loss=0.017, v_num=ypmf]Epoch 195:  67% 181/270 [01:57<-1:57:06, -0.51it/s, loss=0.017, v_num=ypmf]Epoch 195:  67% 181/270 [01:57<-1:57:06, -0.51it/s, loss=0.017, v_num=ypmf]Epoch 195:  67% 181/270 [01:57<-1:57:06, -0.51it/s, loss=0.0169, v_num=ypmf]Epoch 195:  67% 182/270 [01:57<-1:57:05, -0.50it/s, loss=0.0169, v_num=ypmf]Epoch 195:  67% 182/270 [01:57<-1:57:05, -0.50it/s, loss=0.0169, v_num=ypmf]Epoch 195:  67% 182/270 [01:58<-1:57:04, -0.50it/s, loss=0.0168, v_num=ypmf]Epoch 195:  68% 183/270 [01:58<-1:57:03, -0.49it/s, loss=0.0168, v_num=ypmf]Epoch 195:  68% 183/270 [01:58<-1:57:03, -0.49it/s, loss=0.0168, v_num=ypmf]Epoch 195:  68% 183/270 [01:58<-1:57:03, -0.49it/s, loss=0.0169, v_num=ypmf]Epoch 195:  68% 184/270 [01:58<-1:57:01, -0.48it/s, loss=0.0169, v_num=ypmf]Epoch 195:  68% 184/270 [01:58<-1:57:01, -0.48it/s, loss=0.0169, v_num=ypmf]Epoch 195:  68% 184/270 [01:59<-1:57:01, -0.48it/s, loss=0.0167, v_num=ypmf]Epoch 195:  69% 185/270 [01:59<-1:56:59, -0.47it/s, loss=0.0167, v_num=ypmf]Epoch 195:  69% 185/270 [01:59<-1:56:59, -0.47it/s, loss=0.0167, v_num=ypmf]Epoch 195:  69% 185/270 [01:59<-1:56:59, -0.47it/s, loss=0.0168, v_num=ypmf]Epoch 195:  69% 186/270 [01:59<-1:56:57, -0.46it/s, loss=0.0168, v_num=ypmf]Epoch 195:  69% 186/270 [01:59<-1:56:57, -0.46it/s, loss=0.0168, v_num=ypmf]Epoch 195:  69% 186/270 [02:00<-1:56:57, -0.46it/s, loss=0.0167, v_num=ypmf]Epoch 195:  69% 187/270 [02:00<-1:56:55, -0.45it/s, loss=0.0167, v_num=ypmf]Epoch 195:  69% 187/270 [02:00<-1:56:55, -0.45it/s, loss=0.0167, v_num=ypmf]Epoch 195:  69% 187/270 [02:00<-1:56:55, -0.45it/s, loss=0.0167, v_num=ypmf]Epoch 195:  70% 188/270 [02:01<-1:56:53, -0.44it/s, loss=0.0167, v_num=ypmf]Epoch 195:  70% 188/270 [02:01<-1:56:53, -0.44it/s, loss=0.0167, v_num=ypmf]Epoch 195:  70% 188/270 [02:01<-1:56:52, -0.44it/s, loss=0.0166, v_num=ypmf]Epoch 195:  70% 189/270 [02:02<-1:56:50, -0.43it/s, loss=0.0166, v_num=ypmf]Epoch 195:  70% 189/270 [02:02<-1:56:50, -0.43it/s, loss=0.0166, v_num=ypmf]Epoch 195:  70% 189/270 [02:02<-1:56:50, -0.43it/s, loss=0.0166, v_num=ypmf]Epoch 195:  70% 190/270 [02:02<-1:56:48, -0.42it/s, loss=0.0166, v_num=ypmf]Epoch 195:  70% 190/270 [02:02<-1:56:48, -0.42it/s, loss=0.0166, v_num=ypmf]Epoch 195:  70% 190/270 [02:02<-1:56:48, -0.42it/s, loss=0.0167, v_num=ypmf]Epoch 195:  71% 191/270 [02:03<-1:56:46, -0.41it/s, loss=0.0167, v_num=ypmf]Epoch 195:  71% 191/270 [02:03<-1:56:46, -0.41it/s, loss=0.0167, v_num=ypmf]Epoch 195:  71% 191/270 [02:03<-1:56:46, -0.41it/s, loss=0.0166, v_num=ypmf]Epoch 195:  71% 192/270 [02:03<-1:56:44, -0.40it/s, loss=0.0166, v_num=ypmf]Epoch 195:  71% 192/270 [02:03<-1:56:44, -0.40it/s, loss=0.0166, v_num=ypmf]Epoch 195:  71% 192/270 [02:03<-1:56:43, -0.40it/s, loss=0.0166, v_num=ypmf]Epoch 195:  71% 193/270 [02:04<-1:56:41, -0.39it/s, loss=0.0166, v_num=ypmf]Epoch 195:  71% 193/270 [02:04<-1:56:41, -0.39it/s, loss=0.0166, v_num=ypmf]Epoch 195:  71% 193/270 [02:04<-1:56:41, -0.39it/s, loss=0.0167, v_num=ypmf]Epoch 195:  72% 194/270 [02:04<-1:56:38, -0.38it/s, loss=0.0167, v_num=ypmf]Epoch 195:  72% 194/270 [02:04<-1:56:38, -0.38it/s, loss=0.0167, v_num=ypmf]Epoch 195:  72% 194/270 [02:05<-1:56:38, -0.38it/s, loss=0.0167, v_num=ypmf]Epoch 195:  72% 195/270 [02:05<-1:56:36, -0.37it/s, loss=0.0167, v_num=ypmf]Epoch 195:  72% 195/270 [02:05<-1:56:36, -0.37it/s, loss=0.0167, v_num=ypmf]Epoch 195:  72% 195/270 [02:06<-1:56:34, -0.36it/s, loss=0.0166, v_num=ypmf]Epoch 195:  73% 196/270 [02:07<-1:56:32, -0.35it/s, loss=0.0166, v_num=ypmf]Epoch 195:  73% 196/270 [02:07<-1:56:32, -0.35it/s, loss=0.0166, v_num=ypmf]Epoch 195:  73% 196/270 [02:07<-1:56:31, -0.35it/s, loss=0.0166, v_num=ypmf]Epoch 195:  73% 197/270 [02:07<-1:56:29, -0.34it/s, loss=0.0166, v_num=ypmf]Epoch 195:  73% 197/270 [02:07<-1:56:29, -0.34it/s, loss=0.0166, v_num=ypmf]Epoch 195:  73% 197/270 [02:07<-1:56:29, -0.34it/s, loss=0.0166, v_num=ypmf]Epoch 195:  73% 198/270 [02:08<-1:56:26, -0.34it/s, loss=0.0166, v_num=ypmf]Epoch 195:  73% 198/270 [02:08<-1:56:26, -0.34it/s, loss=0.0166, v_num=ypmf]Epoch 195:  73% 198/270 [02:08<-1:56:25, -0.33it/s, loss=0.0165, v_num=ypmf]Epoch 195:  74% 199/270 [02:08<-1:56:23, -0.33it/s, loss=0.0165, v_num=ypmf]Epoch 195:  74% 199/270 [02:08<-1:56:23, -0.33it/s, loss=0.0165, v_num=ypmf]Epoch 195:  74% 199/270 [02:09<-1:56:21, -0.32it/s, loss=0.0165, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 294787. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 223545. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 318293. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 275611. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 296736. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 313349. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 317400. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 296011. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 321405. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 335438. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 309165. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 324655. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 289400. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 245949. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 270427. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 328945. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 239946. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 315293. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 263096. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 246974. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 310767. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 317045. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 407658. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 326259. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 286163. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 195:  74% 200/270 [02:10<-1:56:18, -0.32it/s, loss=0.0165, v_num=ypmf]Epoch 195:  74% 200/270 [02:10<-1:56:18, -0.32it/s, loss=0.0165, v_num=ypmf]Epoch 195:  74% 200/270 [02:10<-1:56:18, -0.31it/s, loss=0.0166, v_num=ypmf]Epoch 195:  74% 201/270 [02:10<-1:56:15, -0.31it/s, loss=0.0166, v_num=ypmf]Epoch 195:  74% 201/270 [02:10<-1:56:15, -0.31it/s, loss=0.0166, v_num=ypmf]Epoch 195:  74% 201/270 [02:10<-1:56:15, -0.31it/s, loss=0.0167, v_num=ypmf]Epoch 195:  75% 202/270 [02:11<-1:56:12, -0.30it/s, loss=0.0167, v_num=ypmf]Epoch 195:  75% 202/270 [02:11<-1:56:12, -0.30it/s, loss=0.0167, v_num=ypmf]Epoch 195:  75% 202/270 [02:11<-1:56:11, -0.30it/s, loss=0.0167, v_num=ypmf]Epoch 195:  75% 203/270 [02:11<-1:56:08, -0.29it/s, loss=0.0167, v_num=ypmf]Epoch 195:  75% 203/270 [02:11<-1:56:08, -0.29it/s, loss=0.0167, v_num=ypmf]Epoch 195:  75% 203/270 [02:12<-1:56:08, -0.29it/s, loss=0.0166, v_num=ypmf]Epoch 195:  76% 204/270 [02:12<-1:56:04, -0.28it/s, loss=0.0166, v_num=ypmf]Epoch 195:  76% 204/270 [02:12<-1:56:04, -0.28it/s, loss=0.0166, v_num=ypmf]Epoch 195:  76% 204/270 [02:12<-1:56:04, -0.28it/s, loss=0.0167, v_num=ypmf]Epoch 195:  76% 205/270 [02:13<-1:56:00, -0.27it/s, loss=0.0167, v_num=ypmf]Epoch 195:  76% 205/270 [02:13<-1:56:00, -0.27it/s, loss=0.0167, v_num=ypmf]Epoch 195:  76% 205/270 [02:13<-1:56:00, -0.27it/s, loss=0.0167, v_num=ypmf]Epoch 195:  76% 206/270 [02:13<-1:55:56, -0.26it/s, loss=0.0167, v_num=ypmf]Epoch 195:  76% 206/270 [02:13<-1:55:56, -0.26it/s, loss=0.0167, v_num=ypmf]Epoch 195:  76% 206/270 [02:13<-1:55:56, -0.26it/s, loss=0.0167, v_num=ypmf]Epoch 195:  77% 207/270 [02:14<-1:55:52, -0.25it/s, loss=0.0167, v_num=ypmf]Epoch 195:  77% 207/270 [02:14<-1:55:52, -0.25it/s, loss=0.0167, v_num=ypmf]Epoch 195:  77% 207/270 [02:14<-1:55:51, -0.25it/s, loss=0.0167, v_num=ypmf]Epoch 195:  77% 208/270 [02:14<-1:55:47, -0.24it/s, loss=0.0167, v_num=ypmf]Epoch 195:  77% 208/270 [02:14<-1:55:47, -0.24it/s, loss=0.0167, v_num=ypmf]Epoch 195:  77% 208/270 [02:15<-1:55:47, -0.24it/s, loss=0.0167, v_num=ypmf]Epoch 195:  77% 209/270 [02:15<-1:55:43, -0.24it/s, loss=0.0167, v_num=ypmf]Epoch 195:  77% 209/270 [02:15<-1:55:43, -0.24it/s, loss=0.0167, v_num=ypmf]Epoch 195:  77% 209/270 [02:16<-1:55:41, -0.23it/s, loss=0.0168, v_num=ypmf]Epoch 195:  78% 210/270 [02:16<-1:55:36, -0.23it/s, loss=0.0168, v_num=ypmf]Epoch 195:  78% 210/270 [02:16<-1:55:36, -0.23it/s, loss=0.0168, v_num=ypmf]Epoch 195:  78% 210/270 [02:16<-1:55:36, -0.23it/s, loss=0.0167, v_num=ypmf]Epoch 195:  78% 211/270 [02:17<-1:55:31, -0.22it/s, loss=0.0167, v_num=ypmf]Epoch 195:  78% 211/270 [02:17<-1:55:31, -0.22it/s, loss=0.0167, v_num=ypmf]Epoch 195:  78% 211/270 [02:17<-1:55:30, -0.22it/s, loss=0.0168, v_num=ypmf]Epoch 195:  79% 212/270 [02:17<-1:55:25, -0.21it/s, loss=0.0168, v_num=ypmf]Epoch 195:  79% 212/270 [02:17<-1:55:25, -0.21it/s, loss=0.0168, v_num=ypmf]Epoch 195:  79% 212/270 [02:18<-1:55:24, -0.21it/s, loss=0.0169, v_num=ypmf]Epoch 195:  79% 213/270 [02:18<-1:55:19, -0.20it/s, loss=0.0169, v_num=ypmf]Epoch 195:  79% 213/270 [02:18<-1:55:19, -0.20it/s, loss=0.0169, v_num=ypmf]Epoch 195:  79% 213/270 [02:18<-1:55:18, -0.20it/s, loss=0.0168, v_num=ypmf]Epoch 195:  79% 214/270 [02:18<-1:55:12, -0.19it/s, loss=0.0168, v_num=ypmf]Epoch 195:  79% 214/270 [02:18<-1:55:12, -0.19it/s, loss=0.0168, v_num=ypmf]Epoch 195:  79% 214/270 [02:19<-1:55:10, -0.19it/s, loss=0.0169, v_num=ypmf]Epoch 195:  80% 215/270 [02:20<-1:55:04, -0.19it/s, loss=0.0169, v_num=ypmf]Epoch 195:  80% 215/270 [02:20<-1:55:04, -0.19it/s, loss=0.0169, v_num=ypmf]Epoch 195:  80% 215/270 [02:20<-1:55:03, -0.19it/s, loss=0.0169, v_num=ypmf]Epoch 195:  80% 216/270 [02:21<-1:54:56, -0.18it/s, loss=0.0169, v_num=ypmf]Epoch 195:  80% 216/270 [02:21<-1:54:56, -0.18it/s, loss=0.0169, v_num=ypmf]Epoch 195:  80% 216/270 [02:21<-1:54:56, -0.18it/s, loss=0.0169, v_num=ypmf]Epoch 195:  80% 217/270 [02:21<-1:54:48, -0.17it/s, loss=0.0169, v_num=ypmf]Epoch 195:  80% 217/270 [02:21<-1:54:48, -0.17it/s, loss=0.0169, v_num=ypmf]Epoch 195:  80% 217/270 [02:21<-1:54:48, -0.17it/s, loss=0.017, v_num=ypmf] Epoch 195:  81% 218/270 [02:21<-1:54:40, -0.16it/s, loss=0.017, v_num=ypmf]Epoch 195:  81% 218/270 [02:21<-1:54:40, -0.16it/s, loss=0.017, v_num=ypmf]Epoch 195:  81% 218/270 [02:22<-1:54:39, -0.16it/s, loss=0.0172, v_num=ypmf]Epoch 195:  81% 219/270 [02:22<-1:54:30, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 195:  81% 219/270 [02:22<-1:54:30, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 195:  81% 219/270 [02:22<-1:54:30, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 195:  81% 220/270 [02:23<-1:54:20, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 195:  81% 220/270 [02:23<-1:54:20, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 195:  81% 220/270 [02:23<-1:54:19, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 195:  82% 221/270 [02:23<-1:54:08, -0.14it/s, loss=0.0172, v_num=ypmf]Epoch 195:  82% 221/270 [02:23<-1:54:08, -0.14it/s, loss=0.0172, v_num=ypmf]Epoch 195:  82% 221/270 [02:23<-1:54:08, -0.14it/s, loss=0.0172, v_num=ypmf]Epoch 195:  82% 222/270 [02:24<-1:53:56, -0.13it/s, loss=0.0172, v_num=ypmf]Epoch 195:  82% 222/270 [02:24<-1:53:56, -0.13it/s, loss=0.0172, v_num=ypmf]Epoch 195:  82% 222/270 [02:24<-1:53:55, -0.13it/s, loss=0.0172, v_num=ypmf]Epoch 195:  83% 223/270 [02:24<-1:53:42, -0.12it/s, loss=0.0172, v_num=ypmf]Epoch 195:  83% 223/270 [02:24<-1:53:42, -0.12it/s, loss=0.0172, v_num=ypmf]Epoch 195:  83% 223/270 [02:25<-1:53:41, -0.12it/s, loss=0.0173, v_num=ypmf]Epoch 195:  83% 224/270 [02:25<-1:53:26, -0.12it/s, loss=0.0173, v_num=ypmf]Epoch 195:  83% 224/270 [02:25<-1:53:26, -0.12it/s, loss=0.0173, v_num=ypmf]Epoch 195:  83% 224/270 [02:25<-1:53:26, -0.12it/s, loss=0.0173, v_num=ypmf]Epoch 195:  83% 225/270 [02:26<-1:53:10, -0.11it/s, loss=0.0173, v_num=ypmf]Epoch 195:  83% 225/270 [02:26<-1:53:10, -0.11it/s, loss=0.0173, v_num=ypmf]Epoch 195:  83% 225/270 [02:26<-1:53:09, -0.11it/s, loss=0.0174, v_num=ypmf]Epoch 195:  84% 226/270 [02:26<-1:52:50, -0.10it/s, loss=0.0174, v_num=ypmf]Epoch 195:  84% 226/270 [02:26<-1:52:50, -0.10it/s, loss=0.0174, v_num=ypmf]Epoch 195:  84% 226/270 [02:26<-1:52:50, -0.10it/s, loss=0.0172, v_num=ypmf]Epoch 195:  84% 227/270 [02:27<-1:52:28, -0.10it/s, loss=0.0172, v_num=ypmf]Epoch 195:  84% 227/270 [02:27<-1:52:28, -0.10it/s, loss=0.0172, v_num=ypmf]Epoch 195:  84% 227/270 [02:27<-1:52:28, -0.09it/s, loss=0.0173, v_num=ypmf]Epoch 195:  84% 228/270 [02:27<-1:52:03, -0.09it/s, loss=0.0173, v_num=ypmf]Epoch 195:  84% 228/270 [02:27<-1:52:03, -0.09it/s, loss=0.0173, v_num=ypmf]Epoch 195:  84% 228/270 [02:28<-1:52:02, -0.09it/s, loss=0.0172, v_num=ypmf]Epoch 195:  85% 229/270 [02:28<-1:51:33, -0.08it/s, loss=0.0172, v_num=ypmf]Epoch 195:  85% 229/270 [02:28<-1:51:33, -0.08it/s, loss=0.0172, v_num=ypmf]Epoch 195:  85% 229/270 [02:28<-1:51:32, -0.08it/s, loss=0.0171, v_num=ypmf]Epoch 195:  85% 230/270 [02:29<-1:50:59, -0.07it/s, loss=0.0171, v_num=ypmf]Epoch 195:  85% 230/270 [02:29<-1:50:59, -0.07it/s, loss=0.0171, v_num=ypmf]Epoch 195:  85% 230/270 [02:29<-1:50:58, -0.07it/s, loss=0.0171, v_num=ypmf]Epoch 195:  86% 231/270 [02:29<-1:50:17, -0.07it/s, loss=0.0171, v_num=ypmf]Epoch 195:  86% 231/270 [02:29<-1:50:17, -0.07it/s, loss=0.0171, v_num=ypmf]Epoch 195:  86% 231/270 [02:29<-1:50:17, -0.07it/s, loss=0.0171, v_num=ypmf]Epoch 195:  86% 232/270 [02:30<-1:49:27, -0.06it/s, loss=0.0171, v_num=ypmf]Epoch 195:  86% 232/270 [02:30<-1:49:27, -0.06it/s, loss=0.0171, v_num=ypmf]Epoch 195:  86% 232/270 [02:30<-1:49:26, -0.06it/s, loss=0.0171, v_num=ypmf]Epoch 195:  86% 233/270 [02:30<-1:48:24, -0.05it/s, loss=0.0171, v_num=ypmf]Epoch 195:  86% 233/270 [02:30<-1:48:24, -0.05it/s, loss=0.0171, v_num=ypmf]Epoch 195:  86% 233/270 [02:30<-1:48:23, -0.05it/s, loss=0.0171, v_num=ypmf]Epoch 195:  87% 234/270 [02:31<-1:47:03, -0.05it/s, loss=0.0171, v_num=ypmf]Epoch 195:  87% 234/270 [02:31<-1:47:03, -0.05it/s, loss=0.0171, v_num=ypmf]Epoch 195:  87% 234/270 [02:31<-1:47:02, -0.05it/s, loss=0.0171, v_num=ypmf]Epoch 195:  87% 235/270 [02:31<-1:45:15, -0.04it/s, loss=0.0171, v_num=ypmf]Epoch 195:  87% 235/270 [02:31<-1:45:15, -0.04it/s, loss=0.0171, v_num=ypmf]Epoch 195:  87% 235/270 [02:32<-1:45:14, -0.04it/s, loss=0.0171, v_num=ypmf]Epoch 195:  87% 236/270 [02:32<-1:42:44, -0.03it/s, loss=0.0171, v_num=ypmf]Epoch 195:  87% 236/270 [02:32<-1:42:44, -0.03it/s, loss=0.0171, v_num=ypmf]Epoch 195:  87% 236/270 [02:32<-1:42:43, -0.03it/s, loss=0.0172, v_num=ypmf]Epoch 195:  88% 237/270 [02:33<-1:38:58, -0.03it/s, loss=0.0172, v_num=ypmf]Epoch 195:  88% 237/270 [02:33<-1:38:58, -0.03it/s, loss=0.0172, v_num=ypmf]Epoch 195:  88% 237/270 [02:33<-1:38:57, -0.03it/s, loss=0.0171, v_num=ypmf]Epoch 195:  88% 238/270 [02:33<-1:32:43, -0.02it/s, loss=0.0171, v_num=ypmf]Epoch 195:  88% 238/270 [02:33<-1:32:43, -0.02it/s, loss=0.0171, v_num=ypmf]Epoch 195:  88% 238/270 [02:33<-1:32:39, -0.02it/s, loss=0.0169, v_num=ypmf]Epoch 195:  89% 239/270 [02:34<-1:20:09, -0.01it/s, loss=0.0169, v_num=ypmf]Epoch 195:  89% 239/270 [02:34<-1:20:09, -0.01it/s, loss=0.0169, v_num=ypmf]Epoch 195:  89% 239/270 [02:34<-1:20:00, -0.01it/s, loss=0.0169, v_num=ypmf]Epoch 195:  89% 240/270 [02:35<-2:42:22, -0.01it/s, loss=0.0169, v_num=ypmf]Epoch 195:  89% 240/270 [02:35<-2:42:22, -0.01it/s, loss=0.0169, v_num=ypmf]Epoch 195:  89% 240/270 [02:35<-2:42:15, -0.01it/s, loss=0.0168, v_num=ypmf]Epoch 195:  89% 241/270 [02:36<?, ?it/s, loss=0.0168, v_num=ypmf]           Epoch 195:  89% 241/270 [02:36<?, ?it/s, loss=0.0168, v_num=ypmf]Epoch 195:  89% 241/270 [02:36<?, ?it/s, loss=0.0168, v_num=ypmf]Epoch 195:  90% 242/270 [02:36<1:13:02, 156.52s/it, loss=0.0168, v_num=ypmf]Epoch 195:  90% 242/270 [02:36<1:13:02, 156.52s/it, loss=0.0168, v_num=ypmf]Epoch 195:  90% 242/270 [02:36<1:13:06, 156.66s/it, loss=0.0168, v_num=ypmf]Epoch 195:  90% 243/270 [02:36<35:19, 78.49s/it, loss=0.0168, v_num=ypmf]   Epoch 195:  90% 243/270 [02:36<35:19, 78.49s/it, loss=0.0168, v_num=ypmf]Epoch 195:  90% 243/270 [02:37<35:22, 78.61s/it, loss=0.0168, v_num=ypmf]Epoch 195:  90% 244/270 [02:37<22:46, 52.55s/it, loss=0.0168, v_num=ypmf]Epoch 195:  90% 244/270 [02:37<22:46, 52.55s/it, loss=0.0168, v_num=ypmf]Epoch 195:  90% 244/270 [02:37<22:47, 52.61s/it, loss=0.0166, v_num=ypmf]Epoch 195:  91% 245/270 [02:38<16:28, 39.55s/it, loss=0.0166, v_num=ypmf]Epoch 195:  91% 245/270 [02:38<16:28, 39.55s/it, loss=0.0166, v_num=ypmf]Epoch 195:  91% 245/270 [02:38<16:30, 39.62s/it, loss=0.0166, v_num=ypmf]Epoch 195:  91% 246/270 [02:38<12:42, 31.77s/it, loss=0.0166, v_num=ypmf]Epoch 195:  91% 246/270 [02:38<12:42, 31.77s/it, loss=0.0166, v_num=ypmf]Epoch 195:  91% 246/270 [02:39<12:43, 31.82s/it, loss=0.0166, v_num=ypmf]Epoch 195:  91% 247/270 [02:39<10:10, 26.56s/it, loss=0.0166, v_num=ypmf]Epoch 195:  91% 247/270 [02:39<10:10, 26.56s/it, loss=0.0166, v_num=ypmf]Epoch 195:  91% 247/270 [02:39<10:12, 26.64s/it, loss=0.0167, v_num=ypmf]Epoch 195:  92% 248/270 [02:40<08:23, 22.89s/it, loss=0.0167, v_num=ypmf]Epoch 195:  92% 248/270 [02:40<08:23, 22.89s/it, loss=0.0167, v_num=ypmf]Epoch 195:  92% 248/270 [02:40<08:23, 22.91s/it, loss=0.0167, v_num=ypmf]Epoch 195:  92% 249/270 [02:40<07:01, 20.09s/it, loss=0.0167, v_num=ypmf]Epoch 195:  92% 249/270 [02:40<07:01, 20.09s/it, loss=0.0167, v_num=ypmf]Epoch 195:  92% 249/270 [02:40<07:02, 20.12s/it, loss=0.0168, v_num=ypmf]Epoch 195:  93% 250/270 [02:41<05:58, 17.91s/it, loss=0.0168, v_num=ypmf]Epoch 195:  93% 250/270 [02:41<05:58, 17.91s/it, loss=0.0168, v_num=ypmf]Epoch 195:  93% 250/270 [02:41<05:58, 17.94s/it, loss=0.0168, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 312999. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 261717. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 295845. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 240492. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(

Validation: 0it [00:00, ?it/s][A
Validation:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.26it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.26it/s][AEpoch 195:  93% 251/270 [02:42<05:09, 16.28s/it, loss=0.0168, v_num=ypmf]Epoch 195:  93% 251/270 [02:42<05:09, 16.28s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  10% 2/20 [00:02<00:20,  1.14s/it][A
Validation DataLoader 0:  10% 2/20 [00:02<00:20,  1.14s/it][AEpoch 195:  93% 252/270 [02:44<04:29, 14.95s/it, loss=0.0168, v_num=ypmf]Epoch 195:  93% 252/270 [02:44<04:29, 14.95s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  15% 3/20 [00:04<00:26,  1.58s/it][A
Validation DataLoader 0:  15% 3/20 [00:04<00:26,  1.58s/it][AEpoch 195:  94% 253/270 [02:46<03:55, 13.87s/it, loss=0.0168, v_num=ypmf]Epoch 195:  94% 253/270 [02:46<03:55, 13.87s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  20% 4/20 [00:04<00:19,  1.23s/it][A
Validation DataLoader 0:  20% 4/20 [00:04<00:19,  1.23s/it][AEpoch 195:  94% 254/270 [02:47<03:25, 12.86s/it, loss=0.0168, v_num=ypmf]Epoch 195:  94% 254/270 [02:47<03:25, 12.86s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  25% 5/20 [00:06<00:19,  1.28s/it][A
Validation DataLoader 0:  25% 5/20 [00:06<00:19,  1.28s/it][AEpoch 195:  94% 255/270 [02:48<03:00, 12.04s/it, loss=0.0168, v_num=ypmf]Epoch 195:  94% 255/270 [02:48<03:00, 12.04s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  30% 6/20 [00:07<00:16,  1.21s/it][A
Validation DataLoader 0:  30% 6/20 [00:07<00:16,  1.21s/it][AEpoch 195:  95% 256/270 [02:49<02:38, 11.31s/it, loss=0.0168, v_num=ypmf]Epoch 195:  95% 256/270 [02:49<02:38, 11.31s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  35% 7/20 [00:08<00:14,  1.14s/it][A
Validation DataLoader 0:  35% 7/20 [00:08<00:14,  1.14s/it][AEpoch 195:  95% 257/270 [02:50<02:18, 10.66s/it, loss=0.0168, v_num=ypmf]Epoch 195:  95% 257/270 [02:50<02:18, 10.66s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  40% 8/20 [00:09<00:14,  1.22s/it][A
Validation DataLoader 0:  40% 8/20 [00:09<00:14,  1.22s/it][AEpoch 195:  96% 258/270 [02:52<02:01, 10.12s/it, loss=0.0168, v_num=ypmf]Epoch 195:  96% 258/270 [02:52<02:01, 10.12s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  45% 9/20 [00:10<00:11,  1.06s/it][A
Validation DataLoader 0:  45% 9/20 [00:10<00:11,  1.06s/it][AEpoch 195:  96% 259/270 [02:52<01:45,  9.60s/it, loss=0.0168, v_num=ypmf]Epoch 195:  96% 259/270 [02:52<01:45,  9.60s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  50% 10/20 [00:11<00:10,  1.01s/it][A
Validation DataLoader 0:  50% 10/20 [00:11<00:10,  1.01s/it][AEpoch 195:  96% 260/270 [02:53<01:31,  9.14s/it, loss=0.0168, v_num=ypmf]Epoch 195:  96% 260/270 [02:53<01:31,  9.14s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  55% 11/20 [00:12<00:08,  1.08it/s][A
Validation DataLoader 0:  55% 11/20 [00:12<00:08,  1.08it/s][AEpoch 195:  97% 261/270 [02:54<01:18,  8.72s/it, loss=0.0168, v_num=ypmf]Epoch 195:  97% 261/270 [02:54<01:18,  8.72s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  60% 12/20 [00:13<00:08,  1.02s/it][A
Validation DataLoader 0:  60% 12/20 [00:13<00:08,  1.02s/it][AEpoch 195:  97% 262/270 [02:55<01:06,  8.36s/it, loss=0.0168, v_num=ypmf]Epoch 195:  97% 262/270 [02:55<01:06,  8.36s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  65% 13/20 [00:14<00:06,  1.03it/s][A
Validation DataLoader 0:  65% 13/20 [00:14<00:06,  1.03it/s][AEpoch 195:  97% 263/270 [02:56<00:56,  8.02s/it, loss=0.0168, v_num=ypmf]Epoch 195:  97% 263/270 [02:56<00:56,  8.02s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  70% 14/20 [00:15<00:06,  1.17s/it][A
Validation DataLoader 0:  70% 14/20 [00:15<00:06,  1.17s/it][AEpoch 195:  98% 264/270 [02:58<00:46,  7.74s/it, loss=0.0168, v_num=ypmf]Epoch 195:  98% 264/270 [02:58<00:46,  7.74s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  75% 15/20 [00:18<00:07,  1.59s/it][A
Validation DataLoader 0:  75% 15/20 [00:18<00:07,  1.59s/it][AEpoch 195:  98% 265/270 [03:00<00:37,  7.53s/it, loss=0.0168, v_num=ypmf]Epoch 195:  98% 265/270 [03:00<00:37,  7.53s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  80% 16/20 [00:20<00:06,  1.63s/it][A
Validation DataLoader 0:  80% 16/20 [00:20<00:06,  1.63s/it][AEpoch 195:  99% 266/270 [03:02<00:29,  7.29s/it, loss=0.0168, v_num=ypmf]Epoch 195:  99% 266/270 [03:02<00:29,  7.29s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  85% 17/20 [00:21<00:04,  1.45s/it][A
Validation DataLoader 0:  85% 17/20 [00:21<00:04,  1.45s/it][AEpoch 195:  99% 267/270 [03:03<00:21,  7.05s/it, loss=0.0168, v_num=ypmf]Epoch 195:  99% 267/270 [03:03<00:21,  7.05s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  90% 18/20 [00:21<00:02,  1.21s/it][A
Validation DataLoader 0:  90% 18/20 [00:21<00:02,  1.21s/it][AEpoch 195:  99% 268/270 [03:04<00:13,  6.82s/it, loss=0.0168, v_num=ypmf]Epoch 195:  99% 268/270 [03:04<00:13,  6.82s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  95% 19/20 [00:23<00:01,  1.37s/it][A
Validation DataLoader 0:  95% 19/20 [00:23<00:01,  1.37s/it][AEpoch 195: 100% 269/270 [03:05<00:06,  6.64s/it, loss=0.0168, v_num=ypmf]Epoch 195: 100% 269/270 [03:05<00:06,  6.64s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0: 100% 20/20 [00:24<00:00,  1.12s/it][A
Validation DataLoader 0: 100% 20/20 [00:24<00:00,  1.12s/it][AEpoch 195: 100% 270/270 [03:06<00:00,  6.43s/it, loss=0.0168, v_num=ypmf]Epoch 195: 100% 270/270 [03:06<00:00,  6.43s/it, loss=0.0168, v_num=ypmf]Epoch 195: 100% 270/270 [03:08<00:00,  6.51s/it, loss=0.0168, v_num=ypmf]
                                                            [AEpoch 195: 100% 270/270 [03:08<00:00,  6.51s/it, loss=0.0168, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 195:   0% 0/270 [00:00<00:00, -4701522.16it/s, loss=0.0168, v_num=ypmf]Epoch 196:   0% 0/270 [00:00<00:00, -1324806.37it/s, loss=0.0168, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 196:   0% 1/270 [00:01<-1:59:58, -132.85it/s, loss=0.0168, v_num=ypmf] Epoch 196:   0% 1/270 [00:01<-1:59:58, -132.84it/s, loss=0.0168, v_num=ypmf]Epoch 196:   0% 1/270 [00:01<-1:59:58, -124.94it/s, loss=0.0169, v_num=ypmf]Epoch 196:   1% 2/270 [00:02<-1:59:58, -105.12it/s, loss=0.0169, v_num=ypmf]Epoch 196:   1% 2/270 [00:02<-1:59:58, -105.12it/s, loss=0.0169, v_num=ypmf]Epoch 196:   1% 2/270 [00:02<-1:59:58, -95.76it/s, loss=0.0169, v_num=ypmf] Epoch 196:   1% 3/270 [00:03<-1:59:57, -77.55it/s, loss=0.0169, v_num=ypmf]Epoch 196:   1% 3/270 [00:03<-1:59:57, -77.55it/s, loss=0.0169, v_num=ypmf]Epoch 196:   1% 3/270 [00:03<-1:59:57, -74.52it/s, loss=0.0169, v_num=ypmf]Epoch 196:   1% 4/270 [00:03<-1:59:57, -67.66it/s, loss=0.0169, v_num=ypmf]Epoch 196:   1% 4/270 [00:03<-1:59:57, -67.65it/s, loss=0.0169, v_num=ypmf]Epoch 196:   1% 4/270 [00:03<-1:59:56, -64.24it/s, loss=0.017, v_num=ypmf] Epoch 196:   2% 5/270 [00:04<-1:59:56, -57.55it/s, loss=0.017, v_num=ypmf]Epoch 196:   2% 5/270 [00:04<-1:59:56, -57.55it/s, loss=0.017, v_num=ypmf]Epoch 196:   2% 5/270 [00:04<-1:59:56, -54.63it/s, loss=0.0171, v_num=ypmf]Epoch 196:   2% 6/270 [00:04<-1:59:55, -50.79it/s, loss=0.0171, v_num=ypmf]Epoch 196:   2% 6/270 [00:04<-1:59:55, -50.79it/s, loss=0.0171, v_num=ypmf]Epoch 196:   2% 6/270 [00:04<-1:59:55, -48.86it/s, loss=0.0171, v_num=ypmf]Epoch 196:   3% 7/270 [00:05<-1:59:55, -45.21it/s, loss=0.0171, v_num=ypmf]Epoch 196:   3% 7/270 [00:05<-1:59:55, -45.21it/s, loss=0.0171, v_num=ypmf]Epoch 196:   3% 7/270 [00:05<-1:59:55, -44.22it/s, loss=0.0172, v_num=ypmf]Epoch 196:   3% 8/270 [00:05<-1:59:54, -41.68it/s, loss=0.0172, v_num=ypmf]Epoch 196:   3% 8/270 [00:05<-1:59:54, -41.68it/s, loss=0.0172, v_num=ypmf]Epoch 196:   3% 8/270 [00:05<-1:59:54, -39.67it/s, loss=0.0171, v_num=ypmf]Epoch 196:   3% 9/270 [00:06<-1:59:54, -37.60it/s, loss=0.0171, v_num=ypmf]Epoch 196:   3% 9/270 [00:06<-1:59:54, -37.60it/s, loss=0.0171, v_num=ypmf]Epoch 196:   3% 9/270 [00:06<-1:59:53, -35.92it/s, loss=0.0173, v_num=ypmf]Epoch 196:   4% 10/270 [00:06<-1:59:53, -34.08it/s, loss=0.0173, v_num=ypmf]Epoch 196:   4% 10/270 [00:06<-1:59:53, -34.08it/s, loss=0.0173, v_num=ypmf]Epoch 196:   4% 10/270 [00:07<-1:59:53, -32.91it/s, loss=0.0174, v_num=ypmf]Epoch 196:   4% 11/270 [00:07<-1:59:52, -29.69it/s, loss=0.0174, v_num=ypmf]Epoch 196:   4% 11/270 [00:07<-1:59:52, -29.69it/s, loss=0.0174, v_num=ypmf]Epoch 196:   4% 11/270 [00:07<-1:59:52, -29.04it/s, loss=0.0173, v_num=ypmf]Epoch 196:   4% 12/270 [00:08<-1:59:51, -27.44it/s, loss=0.0173, v_num=ypmf]Epoch 196:   4% 12/270 [00:08<-1:59:51, -27.44it/s, loss=0.0173, v_num=ypmf]Epoch 196:   4% 12/270 [00:08<-1:59:51, -26.99it/s, loss=0.0172, v_num=ypmf]Epoch 196:   5% 13/270 [00:08<-1:59:51, -25.71it/s, loss=0.0172, v_num=ypmf]Epoch 196:   5% 13/270 [00:08<-1:59:51, -25.71it/s, loss=0.0172, v_num=ypmf]Epoch 196:   5% 13/270 [00:09<-1:59:50, -25.15it/s, loss=0.0171, v_num=ypmf]Epoch 196:   5% 14/270 [00:09<-1:59:50, -23.95it/s, loss=0.0171, v_num=ypmf]Epoch 196:   5% 14/270 [00:09<-1:59:50, -23.95it/s, loss=0.0171, v_num=ypmf]Epoch 196:   5% 14/270 [00:09<-1:59:50, -23.59it/s, loss=0.0173, v_num=ypmf]Epoch 196:   6% 15/270 [00:10<-1:59:49, -22.55it/s, loss=0.0173, v_num=ypmf]Epoch 196:   6% 15/270 [00:10<-1:59:49, -22.55it/s, loss=0.0173, v_num=ypmf]Epoch 196:   6% 15/270 [00:10<-1:59:49, -22.26it/s, loss=0.0173, v_num=ypmf]Epoch 196:   6% 16/270 [00:10<-1:59:48, -20.88it/s, loss=0.0173, v_num=ypmf]Epoch 196:   6% 16/270 [00:10<-1:59:48, -20.88it/s, loss=0.0173, v_num=ypmf]Epoch 196:   6% 16/270 [00:11<-1:59:47, -18.78it/s, loss=0.0173, v_num=ypmf]Epoch 196:   6% 17/270 [00:12<-1:59:47, -18.20it/s, loss=0.0173, v_num=ypmf]Epoch 196:   6% 17/270 [00:12<-1:59:47, -18.20it/s, loss=0.0173, v_num=ypmf]Epoch 196:   6% 17/270 [00:12<-1:59:46, -17.84it/s, loss=0.0173, v_num=ypmf]Epoch 196:   7% 18/270 [00:12<-1:59:46, -17.25it/s, loss=0.0173, v_num=ypmf]Epoch 196:   7% 18/270 [00:12<-1:59:46, -17.25it/s, loss=0.0173, v_num=ypmf]Epoch 196:   7% 18/270 [00:13<-1:59:46, -17.09it/s, loss=0.0175, v_num=ypmf]Epoch 196:   7% 19/270 [00:13<-1:59:45, -16.42it/s, loss=0.0175, v_num=ypmf]Epoch 196:   7% 19/270 [00:13<-1:59:45, -16.42it/s, loss=0.0175, v_num=ypmf]Epoch 196:   7% 19/270 [00:14<-1:59:44, -15.49it/s, loss=0.0174, v_num=ypmf]Epoch 196:   7% 20/270 [00:14<-1:59:44, -15.04it/s, loss=0.0174, v_num=ypmf]Epoch 196:   7% 20/270 [00:14<-1:59:44, -15.04it/s, loss=0.0174, v_num=ypmf]Epoch 196:   7% 20/270 [00:14<-1:59:44, -14.91it/s, loss=0.0174, v_num=ypmf]Epoch 196:   8% 21/270 [00:15<-1:59:43, -14.52it/s, loss=0.0174, v_num=ypmf]Epoch 196:   8% 21/270 [00:15<-1:59:43, -14.52it/s, loss=0.0174, v_num=ypmf]Epoch 196:   8% 21/270 [00:15<-1:59:43, -14.32it/s, loss=0.0173, v_num=ypmf]Epoch 196:   8% 22/270 [00:15<-1:59:43, -13.92it/s, loss=0.0173, v_num=ypmf]Epoch 196:   8% 22/270 [00:15<-1:59:43, -13.92it/s, loss=0.0173, v_num=ypmf]Epoch 196:   8% 22/270 [00:15<-1:59:43, -13.81it/s, loss=0.0173, v_num=ypmf]Epoch 196:   9% 23/270 [00:16<-1:59:42, -13.38it/s, loss=0.0173, v_num=ypmf]Epoch 196:   9% 23/270 [00:16<-1:59:42, -13.38it/s, loss=0.0173, v_num=ypmf]Epoch 196:   9% 23/270 [00:16<-1:59:42, -13.27it/s, loss=0.0174, v_num=ypmf]Epoch 196:   9% 24/270 [00:16<-1:59:41, -12.80it/s, loss=0.0174, v_num=ypmf]Epoch 196:   9% 24/270 [00:16<-1:59:41, -12.80it/s, loss=0.0174, v_num=ypmf]Epoch 196:   9% 24/270 [00:17<-1:59:41, -12.67it/s, loss=0.0172, v_num=ypmf]Epoch 196:   9% 25/270 [00:17<-1:59:41, -12.30it/s, loss=0.0172, v_num=ypmf]Epoch 196:   9% 25/270 [00:17<-1:59:41, -12.29it/s, loss=0.0172, v_num=ypmf]Epoch 196:   9% 25/270 [00:17<-1:59:40, -12.20it/s, loss=0.0171, v_num=ypmf]Epoch 196:  10% 26/270 [00:18<-1:59:40, -11.86it/s, loss=0.0171, v_num=ypmf]Epoch 196:  10% 26/270 [00:18<-1:59:40, -11.86it/s, loss=0.0171, v_num=ypmf]Epoch 196:  10% 26/270 [00:18<-1:59:40, -11.77it/s, loss=0.0171, v_num=ypmf]Epoch 196:  10% 27/270 [00:18<-1:59:39, -11.41it/s, loss=0.0171, v_num=ypmf]Epoch 196:  10% 27/270 [00:18<-1:59:39, -11.41it/s, loss=0.0171, v_num=ypmf]Epoch 196:  10% 27/270 [00:18<-1:59:39, -11.32it/s, loss=0.0171, v_num=ypmf]Epoch 196:  10% 28/270 [00:19<-1:59:39, -11.14it/s, loss=0.0171, v_num=ypmf]Epoch 196:  10% 28/270 [00:19<-1:59:39, -11.14it/s, loss=0.0171, v_num=ypmf]Epoch 196:  10% 28/270 [00:19<-1:59:38, -10.93it/s, loss=0.0172, v_num=ypmf]Epoch 196:  11% 29/270 [00:19<-1:59:38, -10.65it/s, loss=0.0172, v_num=ypmf]Epoch 196:  11% 29/270 [00:19<-1:59:38, -10.65it/s, loss=0.0172, v_num=ypmf]Epoch 196:  11% 29/270 [00:20<-1:59:38, -10.56it/s, loss=0.017, v_num=ypmf] Epoch 196:  11% 30/270 [00:20<-1:59:37, -10.34it/s, loss=0.017, v_num=ypmf]Epoch 196:  11% 30/270 [00:20<-1:59:37, -10.34it/s, loss=0.017, v_num=ypmf]Epoch 196:  11% 30/270 [00:20<-1:59:37, -10.23it/s, loss=0.0171, v_num=ypmf]Epoch 196:  11% 31/270 [00:20<-1:59:37, -10.02it/s, loss=0.0171, v_num=ypmf]Epoch 196:  11% 31/270 [00:20<-1:59:37, -10.02it/s, loss=0.0171, v_num=ypmf]Epoch 196:  11% 31/270 [00:21<-1:59:36, -9.91it/s, loss=0.0173, v_num=ypmf] Epoch 196:  12% 32/270 [00:21<-1:59:36, -9.69it/s, loss=0.0173, v_num=ypmf]Epoch 196:  12% 32/270 [00:21<-1:59:36, -9.69it/s, loss=0.0173, v_num=ypmf]Epoch 196:  12% 32/270 [00:21<-1:59:36, -9.60it/s, loss=0.0173, v_num=ypmf]Epoch 196:  12% 33/270 [00:22<-1:59:35, -9.37it/s, loss=0.0173, v_num=ypmf]Epoch 196:  12% 33/270 [00:22<-1:59:35, -9.37it/s, loss=0.0173, v_num=ypmf]Epoch 196:  12% 33/270 [00:22<-1:59:35, -9.31it/s, loss=0.0174, v_num=ypmf]Epoch 196:  13% 34/270 [00:22<-1:59:35, -9.12it/s, loss=0.0174, v_num=ypmf]Epoch 196:  13% 34/270 [00:22<-1:59:35, -9.12it/s, loss=0.0174, v_num=ypmf]Epoch 196:  13% 34/270 [00:22<-1:59:34, -9.01it/s, loss=0.0172, v_num=ypmf]Epoch 196:  13% 35/270 [00:23<-1:59:34, -8.83it/s, loss=0.0172, v_num=ypmf]Epoch 196:  13% 35/270 [00:23<-1:59:34, -8.83it/s, loss=0.0172, v_num=ypmf]Epoch 196:  13% 35/270 [00:23<-1:59:34, -8.76it/s, loss=0.0172, v_num=ypmf]Epoch 196:  13% 36/270 [00:23<-1:59:33, -8.60it/s, loss=0.0172, v_num=ypmf]Epoch 196:  13% 36/270 [00:23<-1:59:33, -8.60it/s, loss=0.0172, v_num=ypmf]Epoch 196:  13% 36/270 [00:24<-1:59:33, -8.54it/s, loss=0.0173, v_num=ypmf]Epoch 196:  14% 37/270 [00:24<-1:59:33, -8.36it/s, loss=0.0173, v_num=ypmf]Epoch 196:  14% 37/270 [00:24<-1:59:33, -8.36it/s, loss=0.0173, v_num=ypmf]Epoch 196:  14% 37/270 [00:24<-1:59:32, -8.29it/s, loss=0.0172, v_num=ypmf]Epoch 196:  14% 38/270 [00:25<-1:59:32, -8.10it/s, loss=0.0172, v_num=ypmf]Epoch 196:  14% 38/270 [00:25<-1:59:32, -8.10it/s, loss=0.0172, v_num=ypmf]Epoch 196:  14% 38/270 [00:25<-1:59:32, -8.06it/s, loss=0.0171, v_num=ypmf]Epoch 196:  14% 39/270 [00:25<-1:59:31, -7.90it/s, loss=0.0171, v_num=ypmf]Epoch 196:  14% 39/270 [00:25<-1:59:31, -7.90it/s, loss=0.0171, v_num=ypmf]Epoch 196:  14% 39/270 [00:25<-1:59:31, -7.85it/s, loss=0.0172, v_num=ypmf]Epoch 196:  15% 40/270 [00:26<-1:59:31, -7.72it/s, loss=0.0172, v_num=ypmf]Epoch 196:  15% 40/270 [00:26<-1:59:31, -7.72it/s, loss=0.0172, v_num=ypmf]Epoch 196:  15% 40/270 [00:26<-1:59:30, -7.66it/s, loss=0.0171, v_num=ypmf]Epoch 196:  15% 41/270 [00:27<-1:59:29, -7.38it/s, loss=0.0171, v_num=ypmf]Epoch 196:  15% 41/270 [00:27<-1:59:29, -7.38it/s, loss=0.0171, v_num=ypmf]Epoch 196:  15% 41/270 [00:27<-1:59:29, -7.38it/s, loss=0.0171, v_num=ypmf]Epoch 196:  16% 42/270 [00:27<-1:59:29, -7.24it/s, loss=0.0171, v_num=ypmf]Epoch 196:  16% 42/270 [00:27<-1:59:29, -7.24it/s, loss=0.0171, v_num=ypmf]Epoch 196:  16% 42/270 [00:27<-1:59:29, -7.20it/s, loss=0.017, v_num=ypmf] Epoch 196:  16% 43/270 [00:28<-1:59:28, -7.05it/s, loss=0.017, v_num=ypmf]Epoch 196:  16% 43/270 [00:28<-1:59:28, -7.05it/s, loss=0.017, v_num=ypmf]Epoch 196:  16% 43/270 [00:28<-1:59:28, -7.02it/s, loss=0.0169, v_num=ypmf]Epoch 196:  16% 44/270 [00:28<-1:59:28, -6.86it/s, loss=0.0169, v_num=ypmf]Epoch 196:  16% 44/270 [00:28<-1:59:28, -6.86it/s, loss=0.0169, v_num=ypmf]Epoch 196:  16% 44/270 [00:28<-1:59:27, -6.82it/s, loss=0.017, v_num=ypmf] Epoch 196:  17% 45/270 [00:29<-1:59:27, -6.70it/s, loss=0.017, v_num=ypmf]Epoch 196:  17% 45/270 [00:29<-1:59:27, -6.70it/s, loss=0.017, v_num=ypmf]Epoch 196:  17% 45/270 [00:29<-1:59:27, -6.67it/s, loss=0.017, v_num=ypmf]Epoch 196:  17% 46/270 [00:30<-1:59:26, -6.50it/s, loss=0.017, v_num=ypmf]Epoch 196:  17% 46/270 [00:30<-1:59:26, -6.50it/s, loss=0.017, v_num=ypmf]Epoch 196:  17% 46/270 [00:30<-1:59:26, -6.47it/s, loss=0.0168, v_num=ypmf]Epoch 196:  17% 47/270 [00:30<-1:59:25, -6.34it/s, loss=0.0168, v_num=ypmf]Epoch 196:  17% 47/270 [00:30<-1:59:25, -6.34it/s, loss=0.0168, v_num=ypmf]Epoch 196:  17% 47/270 [00:30<-1:59:25, -6.31it/s, loss=0.0169, v_num=ypmf]Epoch 196:  18% 48/270 [00:31<-1:59:25, -6.20it/s, loss=0.0169, v_num=ypmf]Epoch 196:  18% 48/270 [00:31<-1:59:25, -6.20it/s, loss=0.0169, v_num=ypmf]Epoch 196:  18% 48/270 [00:31<-1:59:25, -6.18it/s, loss=0.0168, v_num=ypmf]Epoch 196:  18% 49/270 [00:33<-1:59:22, -5.70it/s, loss=0.0168, v_num=ypmf]Epoch 196:  18% 49/270 [00:33<-1:59:22, -5.70it/s, loss=0.0168, v_num=ypmf]Epoch 196:  18% 49/270 [00:33<-1:59:22, -5.68it/s, loss=0.0168, v_num=ypmf]Epoch 196:  19% 50/270 [00:34<-1:59:21, -5.59it/s, loss=0.0168, v_num=ypmf]Epoch 196:  19% 50/270 [00:34<-1:59:21, -5.59it/s, loss=0.0168, v_num=ypmf]Epoch 196:  19% 50/270 [00:34<-1:59:21, -5.57it/s, loss=0.0167, v_num=ypmf]Epoch 196:  19% 51/270 [00:34<-1:59:20, -5.46it/s, loss=0.0167, v_num=ypmf]Epoch 196:  19% 51/270 [00:34<-1:59:20, -5.46it/s, loss=0.0167, v_num=ypmf]Epoch 196:  19% 51/270 [00:34<-1:59:20, -5.45it/s, loss=0.0168, v_num=ypmf]Epoch 196:  19% 52/270 [00:35<-1:59:20, -5.36it/s, loss=0.0168, v_num=ypmf]Epoch 196:  19% 52/270 [00:35<-1:59:20, -5.36it/s, loss=0.0168, v_num=ypmf]Epoch 196:  19% 52/270 [00:35<-1:59:20, -5.32it/s, loss=0.0168, v_num=ypmf]Epoch 196:  20% 53/270 [00:35<-1:59:19, -5.24it/s, loss=0.0168, v_num=ypmf]Epoch 196:  20% 53/270 [00:35<-1:59:19, -5.24it/s, loss=0.0168, v_num=ypmf]Epoch 196:  20% 53/270 [00:36<-1:59:19, -5.22it/s, loss=0.0168, v_num=ypmf]Epoch 196:  20% 54/270 [00:36<-1:59:18, -5.14it/s, loss=0.0168, v_num=ypmf]Epoch 196:  20% 54/270 [00:36<-1:59:18, -5.14it/s, loss=0.0168, v_num=ypmf]Epoch 196:  20% 54/270 [00:36<-1:59:18, -5.12it/s, loss=0.017, v_num=ypmf] Epoch 196:  20% 55/270 [00:36<-1:59:18, -5.04it/s, loss=0.017, v_num=ypmf]Epoch 196:  20% 55/270 [00:36<-1:59:18, -5.03it/s, loss=0.017, v_num=ypmf]Epoch 196:  20% 55/270 [00:37<-1:59:18, -5.02it/s, loss=0.0171, v_num=ypmf]Epoch 196:  21% 56/270 [00:37<-1:59:17, -4.94it/s, loss=0.0171, v_num=ypmf]Epoch 196:  21% 56/270 [00:37<-1:59:17, -4.94it/s, loss=0.0171, v_num=ypmf]Epoch 196:  21% 56/270 [00:37<-1:59:17, -4.92it/s, loss=0.017, v_num=ypmf] Epoch 196:  21% 57/270 [00:37<-1:59:17, -4.85it/s, loss=0.017, v_num=ypmf]Epoch 196:  21% 57/270 [00:37<-1:59:17, -4.85it/s, loss=0.017, v_num=ypmf]Epoch 196:  21% 57/270 [00:38<-1:59:16, -4.83it/s, loss=0.017, v_num=ypmf]Epoch 196:  21% 58/270 [00:38<-1:59:16, -4.76it/s, loss=0.017, v_num=ypmf]Epoch 196:  21% 58/270 [00:38<-1:59:16, -4.76it/s, loss=0.017, v_num=ypmf]Epoch 196:  21% 58/270 [00:38<-1:59:16, -4.72it/s, loss=0.0169, v_num=ypmf]Epoch 196:  22% 59/270 [00:39<-1:59:15, -4.65it/s, loss=0.0169, v_num=ypmf]Epoch 196:  22% 59/270 [00:39<-1:59:15, -4.65it/s, loss=0.0169, v_num=ypmf]Epoch 196:  22% 59/270 [00:39<-1:59:15, -4.63it/s, loss=0.0169, v_num=ypmf]Epoch 196:  22% 60/270 [00:39<-1:59:14, -4.55it/s, loss=0.0169, v_num=ypmf]Epoch 196:  22% 60/270 [00:39<-1:59:14, -4.55it/s, loss=0.0169, v_num=ypmf]Epoch 196:  22% 60/270 [00:39<-1:59:14, -4.54it/s, loss=0.017, v_num=ypmf] Epoch 196:  23% 61/270 [00:40<-1:59:14, -4.47it/s, loss=0.017, v_num=ypmf]Epoch 196:  23% 61/270 [00:40<-1:59:14, -4.47it/s, loss=0.017, v_num=ypmf]Epoch 196:  23% 61/270 [00:40<-1:59:14, -4.45it/s, loss=0.017, v_num=ypmf]Epoch 196:  23% 62/270 [00:40<-1:59:13, -4.39it/s, loss=0.017, v_num=ypmf]Epoch 196:  23% 62/270 [00:40<-1:59:13, -4.39it/s, loss=0.017, v_num=ypmf]Epoch 196:  23% 62/270 [00:40<-1:59:13, -4.37it/s, loss=0.0169, v_num=ypmf]Epoch 196:  23% 63/270 [00:41<-1:59:12, -4.29it/s, loss=0.0169, v_num=ypmf]Epoch 196:  23% 63/270 [00:41<-1:59:12, -4.29it/s, loss=0.0169, v_num=ypmf]Epoch 196:  23% 63/270 [00:41<-1:59:12, -4.27it/s, loss=0.0168, v_num=ypmf]Epoch 196:  24% 64/270 [00:42<-1:59:11, -4.20it/s, loss=0.0168, v_num=ypmf]Epoch 196:  24% 64/270 [00:42<-1:59:11, -4.20it/s, loss=0.0168, v_num=ypmf]Epoch 196:  24% 64/270 [00:42<-1:59:11, -4.19it/s, loss=0.0168, v_num=ypmf]Epoch 196:  24% 65/270 [00:42<-1:59:11, -4.13it/s, loss=0.0168, v_num=ypmf]Epoch 196:  24% 65/270 [00:42<-1:59:11, -4.13it/s, loss=0.0168, v_num=ypmf]Epoch 196:  24% 65/270 [00:42<-1:59:11, -4.12it/s, loss=0.0168, v_num=ypmf]Epoch 196:  24% 66/270 [00:43<-1:59:10, -4.05it/s, loss=0.0168, v_num=ypmf]Epoch 196:  24% 66/270 [00:43<-1:59:10, -4.05it/s, loss=0.0168, v_num=ypmf]Epoch 196:  24% 66/270 [00:43<-1:59:10, -4.05it/s, loss=0.0169, v_num=ypmf]Epoch 196:  25% 67/270 [00:43<-1:59:09, -3.98it/s, loss=0.0169, v_num=ypmf]Epoch 196:  25% 67/270 [00:43<-1:59:09, -3.98it/s, loss=0.0169, v_num=ypmf]Epoch 196:  25% 67/270 [00:43<-1:59:09, -3.96it/s, loss=0.0168, v_num=ypmf]Epoch 196:  25% 68/270 [00:44<-1:59:09, -3.91it/s, loss=0.0168, v_num=ypmf]Epoch 196:  25% 68/270 [00:44<-1:59:09, -3.91it/s, loss=0.0168, v_num=ypmf]Epoch 196:  25% 68/270 [00:44<-1:59:09, -3.89it/s, loss=0.017, v_num=ypmf] Epoch 196:  26% 69/270 [00:44<-1:59:08, -3.84it/s, loss=0.017, v_num=ypmf]Epoch 196:  26% 69/270 [00:44<-1:59:08, -3.84it/s, loss=0.017, v_num=ypmf]Epoch 196:  26% 69/270 [00:45<-1:59:08, -3.82it/s, loss=0.0171, v_num=ypmf]Epoch 196:  26% 70/270 [00:45<-1:59:07, -3.77it/s, loss=0.0171, v_num=ypmf]Epoch 196:  26% 70/270 [00:45<-1:59:07, -3.77it/s, loss=0.0171, v_num=ypmf]Epoch 196:  26% 70/270 [00:45<-1:59:07, -3.75it/s, loss=0.0171, v_num=ypmf]Epoch 196:  26% 71/270 [00:46<-1:59:07, -3.69it/s, loss=0.0171, v_num=ypmf]Epoch 196:  26% 71/270 [00:46<-1:59:07, -3.69it/s, loss=0.0171, v_num=ypmf]Epoch 196:  26% 71/270 [00:46<-1:59:06, -3.67it/s, loss=0.017, v_num=ypmf] Epoch 196:  27% 72/270 [00:46<-1:59:06, -3.61it/s, loss=0.017, v_num=ypmf]Epoch 196:  27% 72/270 [00:46<-1:59:06, -3.61it/s, loss=0.017, v_num=ypmf]Epoch 196:  27% 72/270 [00:46<-1:59:06, -3.60it/s, loss=0.017, v_num=ypmf]Epoch 196:  27% 73/270 [00:47<-1:59:05, -3.56it/s, loss=0.017, v_num=ypmf]Epoch 196:  27% 73/270 [00:47<-1:59:05, -3.56it/s, loss=0.017, v_num=ypmf]Epoch 196:  27% 73/270 [00:47<-1:59:05, -3.55it/s, loss=0.017, v_num=ypmf]Epoch 196:  27% 74/270 [00:47<-1:59:05, -3.51it/s, loss=0.017, v_num=ypmf]Epoch 196:  27% 74/270 [00:47<-1:59:05, -3.51it/s, loss=0.017, v_num=ypmf]Epoch 196:  27% 74/270 [00:47<-1:59:04, -3.49it/s, loss=0.0169, v_num=ypmf]Epoch 196:  28% 75/270 [00:48<-1:59:04, -3.44it/s, loss=0.0169, v_num=ypmf]Epoch 196:  28% 75/270 [00:48<-1:59:04, -3.44it/s, loss=0.0169, v_num=ypmf]Epoch 196:  28% 75/270 [00:48<-1:59:04, -3.42it/s, loss=0.0169, v_num=ypmf]Epoch 196:  28% 76/270 [00:48<-1:59:03, -3.37it/s, loss=0.0169, v_num=ypmf]Epoch 196:  28% 76/270 [00:48<-1:59:03, -3.37it/s, loss=0.0169, v_num=ypmf]Epoch 196:  28% 76/270 [00:49<-1:59:03, -3.36it/s, loss=0.0168, v_num=ypmf]Epoch 196:  29% 77/270 [00:49<-1:59:02, -3.31it/s, loss=0.0168, v_num=ypmf]Epoch 196:  29% 77/270 [00:49<-1:59:02, -3.31it/s, loss=0.0168, v_num=ypmf]Epoch 196:  29% 77/270 [00:49<-1:59:02, -3.30it/s, loss=0.0169, v_num=ypmf]Epoch 196:  29% 78/270 [00:50<-1:59:02, -3.26it/s, loss=0.0169, v_num=ypmf]Epoch 196:  29% 78/270 [00:50<-1:59:02, -3.26it/s, loss=0.0169, v_num=ypmf]Epoch 196:  29% 78/270 [00:50<-1:59:01, -3.24it/s, loss=0.0168, v_num=ypmf]Epoch 196:  29% 79/270 [00:50<-1:59:01, -3.19it/s, loss=0.0168, v_num=ypmf]Epoch 196:  29% 79/270 [00:50<-1:59:01, -3.19it/s, loss=0.0168, v_num=ypmf]Epoch 196:  29% 79/270 [00:51<-1:59:00, -3.18it/s, loss=0.0168, v_num=ypmf]Epoch 196:  30% 80/270 [00:51<-1:59:00, -3.13it/s, loss=0.0168, v_num=ypmf]Epoch 196:  30% 80/270 [00:51<-1:59:00, -3.13it/s, loss=0.0168, v_num=ypmf]Epoch 196:  30% 80/270 [00:51<-1:59:00, -3.12it/s, loss=0.0168, v_num=ypmf]Epoch 196:  30% 81/270 [00:52<-1:58:59, -3.08it/s, loss=0.0168, v_num=ypmf]Epoch 196:  30% 81/270 [00:52<-1:58:59, -3.08it/s, loss=0.0168, v_num=ypmf]Epoch 196:  30% 81/270 [00:52<-1:58:59, -3.07it/s, loss=0.0168, v_num=ypmf]Epoch 196:  30% 82/270 [00:52<-1:58:58, -3.03it/s, loss=0.0168, v_num=ypmf]Epoch 196:  30% 82/270 [00:52<-1:58:58, -3.03it/s, loss=0.0168, v_num=ypmf]Epoch 196:  30% 82/270 [00:52<-1:58:58, -3.02it/s, loss=0.0169, v_num=ypmf]Epoch 196:  31% 83/270 [00:53<-1:58:58, -2.97it/s, loss=0.0169, v_num=ypmf]Epoch 196:  31% 83/270 [00:53<-1:58:58, -2.97it/s, loss=0.0169, v_num=ypmf]Epoch 196:  31% 83/270 [00:53<-1:58:57, -2.96it/s, loss=0.0171, v_num=ypmf]Epoch 196:  31% 84/270 [00:53<-1:58:57, -2.93it/s, loss=0.0171, v_num=ypmf]Epoch 196:  31% 84/270 [00:53<-1:58:57, -2.93it/s, loss=0.0171, v_num=ypmf]Epoch 196:  31% 84/270 [00:53<-1:58:57, -2.91it/s, loss=0.017, v_num=ypmf] Epoch 196:  31% 85/270 [00:54<-1:58:56, -2.87it/s, loss=0.017, v_num=ypmf]Epoch 196:  31% 85/270 [00:54<-1:58:56, -2.87it/s, loss=0.017, v_num=ypmf]Epoch 196:  31% 85/270 [00:54<-1:58:56, -2.86it/s, loss=0.017, v_num=ypmf]Epoch 196:  32% 86/270 [00:54<-1:58:55, -2.83it/s, loss=0.017, v_num=ypmf]Epoch 196:  32% 86/270 [00:54<-1:58:55, -2.83it/s, loss=0.017, v_num=ypmf]Epoch 196:  32% 86/270 [00:54<-1:58:55, -2.82it/s, loss=0.0171, v_num=ypmf]Epoch 196:  32% 87/270 [00:55<-1:58:55, -2.78it/s, loss=0.0171, v_num=ypmf]Epoch 196:  32% 87/270 [00:55<-1:58:55, -2.78it/s, loss=0.0171, v_num=ypmf]Epoch 196:  32% 87/270 [00:55<-1:58:54, -2.77it/s, loss=0.0171, v_num=ypmf]Epoch 196:  33% 88/270 [00:55<-1:58:54, -2.73it/s, loss=0.0171, v_num=ypmf]Epoch 196:  33% 88/270 [00:55<-1:58:54, -2.73it/s, loss=0.0171, v_num=ypmf]Epoch 196:  33% 88/270 [00:56<-1:58:54, -2.73it/s, loss=0.0169, v_num=ypmf]Epoch 196:  33% 89/270 [00:56<-1:58:53, -2.69it/s, loss=0.0169, v_num=ypmf]Epoch 196:  33% 89/270 [00:56<-1:58:53, -2.69it/s, loss=0.0169, v_num=ypmf]Epoch 196:  33% 89/270 [00:56<-1:58:53, -2.68it/s, loss=0.017, v_num=ypmf] Epoch 196:  33% 90/270 [00:57<-1:58:53, -2.65it/s, loss=0.017, v_num=ypmf]Epoch 196:  33% 90/270 [00:57<-1:58:53, -2.65it/s, loss=0.017, v_num=ypmf]Epoch 196:  33% 90/270 [00:57<-1:58:52, -2.64it/s, loss=0.0169, v_num=ypmf]Epoch 196:  34% 91/270 [00:57<-1:58:52, -2.60it/s, loss=0.0169, v_num=ypmf]Epoch 196:  34% 91/270 [00:57<-1:58:52, -2.60it/s, loss=0.0169, v_num=ypmf]Epoch 196:  34% 91/270 [00:57<-1:58:51, -2.59it/s, loss=0.0169, v_num=ypmf]Epoch 196:  34% 92/270 [00:58<-1:58:51, -2.55it/s, loss=0.0169, v_num=ypmf]Epoch 196:  34% 92/270 [00:58<-1:58:51, -2.55it/s, loss=0.0169, v_num=ypmf]Epoch 196:  34% 92/270 [00:58<-1:58:51, -2.55it/s, loss=0.017, v_num=ypmf] Epoch 196:  34% 93/270 [00:58<-1:58:50, -2.51it/s, loss=0.017, v_num=ypmf]Epoch 196:  34% 93/270 [00:58<-1:58:50, -2.51it/s, loss=0.017, v_num=ypmf]Epoch 196:  34% 93/270 [00:59<-1:58:50, -2.51it/s, loss=0.0169, v_num=ypmf]Epoch 196:  35% 94/270 [00:59<-1:58:49, -2.47it/s, loss=0.0169, v_num=ypmf]Epoch 196:  35% 94/270 [00:59<-1:58:49, -2.47it/s, loss=0.0169, v_num=ypmf]Epoch 196:  35% 94/270 [00:59<-1:58:49, -2.47it/s, loss=0.0167, v_num=ypmf]Epoch 196:  35% 95/270 [01:00<-1:58:49, -2.43it/s, loss=0.0167, v_num=ypmf]Epoch 196:  35% 95/270 [01:00<-1:58:49, -2.43it/s, loss=0.0167, v_num=ypmf]Epoch 196:  35% 95/270 [01:00<-1:58:48, -2.43it/s, loss=0.0166, v_num=ypmf]Epoch 196:  36% 96/270 [01:00<-1:58:48, -2.39it/s, loss=0.0166, v_num=ypmf]Epoch 196:  36% 96/270 [01:00<-1:58:48, -2.39it/s, loss=0.0166, v_num=ypmf]Epoch 196:  36% 96/270 [01:00<-1:58:48, -2.38it/s, loss=0.0166, v_num=ypmf]Epoch 196:  36% 97/270 [01:01<-1:58:47, -2.35it/s, loss=0.0166, v_num=ypmf]Epoch 196:  36% 97/270 [01:01<-1:58:47, -2.35it/s, loss=0.0166, v_num=ypmf]Epoch 196:  36% 97/270 [01:05<-1:58:42, -2.21it/s, loss=0.0167, v_num=ypmf]Epoch 196:  36% 98/270 [01:05<-1:58:42, -2.18it/s, loss=0.0167, v_num=ypmf]Epoch 196:  36% 98/270 [01:05<-1:58:42, -2.18it/s, loss=0.0167, v_num=ypmf]Epoch 196:  36% 98/270 [01:05<-1:58:41, -2.17it/s, loss=0.0167, v_num=ypmf]Epoch 196:  37% 99/270 [01:06<-1:58:41, -2.14it/s, loss=0.0167, v_num=ypmf]Epoch 196:  37% 99/270 [01:06<-1:58:41, -2.14it/s, loss=0.0167, v_num=ypmf]Epoch 196:  37% 99/270 [01:06<-1:58:40, -2.14it/s, loss=0.0167, v_num=ypmf]Epoch 196:  37% 100/270 [01:06<-1:58:40, -2.11it/s, loss=0.0167, v_num=ypmf]Epoch 196:  37% 100/270 [01:06<-1:58:40, -2.11it/s, loss=0.0167, v_num=ypmf]Epoch 196:  37% 100/270 [01:07<-1:58:40, -2.10it/s, loss=0.0166, v_num=ypmf]Epoch 196:  37% 101/270 [01:07<-1:58:39, -2.07it/s, loss=0.0166, v_num=ypmf]Epoch 196:  37% 101/270 [01:07<-1:58:39, -2.07it/s, loss=0.0166, v_num=ypmf]Epoch 196:  37% 101/270 [01:07<-1:58:39, -2.07it/s, loss=0.0168, v_num=ypmf]Epoch 196:  38% 102/270 [01:08<-1:58:38, -2.04it/s, loss=0.0168, v_num=ypmf]Epoch 196:  38% 102/270 [01:08<-1:58:38, -2.04it/s, loss=0.0168, v_num=ypmf]Epoch 196:  38% 102/270 [01:08<-1:58:38, -2.04it/s, loss=0.0167, v_num=ypmf]Epoch 196:  38% 103/270 [01:08<-1:58:38, -2.01it/s, loss=0.0167, v_num=ypmf]Epoch 196:  38% 103/270 [01:08<-1:58:38, -2.01it/s, loss=0.0167, v_num=ypmf]Epoch 196:  38% 103/270 [01:08<-1:58:37, -2.01it/s, loss=0.0167, v_num=ypmf]Epoch 196:  39% 104/270 [01:09<-1:58:37, -1.98it/s, loss=0.0167, v_num=ypmf]Epoch 196:  39% 104/270 [01:09<-1:58:37, -1.98it/s, loss=0.0167, v_num=ypmf]Epoch 196:  39% 104/270 [01:09<-1:58:37, -1.98it/s, loss=0.0168, v_num=ypmf]Epoch 196:  39% 105/270 [01:09<-1:58:36, -1.95it/s, loss=0.0168, v_num=ypmf]Epoch 196:  39% 105/270 [01:09<-1:58:36, -1.95it/s, loss=0.0168, v_num=ypmf]Epoch 196:  39% 105/270 [01:10<-1:58:36, -1.94it/s, loss=0.0169, v_num=ypmf]Epoch 196:  39% 106/270 [01:10<-1:58:35, -1.92it/s, loss=0.0169, v_num=ypmf]Epoch 196:  39% 106/270 [01:10<-1:58:35, -1.92it/s, loss=0.0169, v_num=ypmf]Epoch 196:  39% 106/270 [01:10<-1:58:35, -1.91it/s, loss=0.0169, v_num=ypmf]Epoch 196:  40% 107/270 [01:10<-1:58:34, -1.89it/s, loss=0.0169, v_num=ypmf]Epoch 196:  40% 107/270 [01:10<-1:58:34, -1.89it/s, loss=0.0169, v_num=ypmf]Epoch 196:  40% 107/270 [01:11<-1:58:34, -1.88it/s, loss=0.0169, v_num=ypmf]Epoch 196:  40% 108/270 [01:11<-1:58:33, -1.85it/s, loss=0.0169, v_num=ypmf]Epoch 196:  40% 108/270 [01:11<-1:58:33, -1.85it/s, loss=0.0169, v_num=ypmf]Epoch 196:  40% 108/270 [01:11<-1:58:33, -1.85it/s, loss=0.0168, v_num=ypmf]Epoch 196:  40% 109/270 [01:12<-1:58:32, -1.83it/s, loss=0.0168, v_num=ypmf]Epoch 196:  40% 109/270 [01:12<-1:58:32, -1.83it/s, loss=0.0168, v_num=ypmf]Epoch 196:  40% 109/270 [01:12<-1:58:32, -1.82it/s, loss=0.0167, v_num=ypmf]Epoch 196:  41% 110/270 [01:12<-1:58:31, -1.80it/s, loss=0.0167, v_num=ypmf]Epoch 196:  41% 110/270 [01:12<-1:58:31, -1.80it/s, loss=0.0167, v_num=ypmf]Epoch 196:  41% 110/270 [01:13<-1:58:31, -1.79it/s, loss=0.0167, v_num=ypmf]Epoch 196:  41% 111/270 [01:13<-1:58:31, -1.77it/s, loss=0.0167, v_num=ypmf]Epoch 196:  41% 111/270 [01:13<-1:58:31, -1.77it/s, loss=0.0167, v_num=ypmf]Epoch 196:  41% 111/270 [01:13<-1:58:30, -1.76it/s, loss=0.0168, v_num=ypmf]Epoch 196:  41% 112/270 [01:14<-1:58:30, -1.74it/s, loss=0.0168, v_num=ypmf]Epoch 196:  41% 112/270 [01:14<-1:58:30, -1.74it/s, loss=0.0168, v_num=ypmf]Epoch 196:  41% 112/270 [01:15<-1:58:28, -1.71it/s, loss=0.0167, v_num=ypmf]Epoch 196:  42% 113/270 [01:15<-1:58:28, -1.69it/s, loss=0.0167, v_num=ypmf]Epoch 196:  42% 113/270 [01:15<-1:58:28, -1.69it/s, loss=0.0167, v_num=ypmf]Epoch 196:  42% 113/270 [01:15<-1:58:28, -1.69it/s, loss=0.0167, v_num=ypmf]Epoch 196:  42% 114/270 [01:16<-1:58:27, -1.67it/s, loss=0.0167, v_num=ypmf]Epoch 196:  42% 114/270 [01:16<-1:58:27, -1.67it/s, loss=0.0167, v_num=ypmf]Epoch 196:  42% 114/270 [01:16<-1:58:26, -1.65it/s, loss=0.0168, v_num=ypmf]Epoch 196:  43% 115/270 [01:17<-1:58:26, -1.63it/s, loss=0.0168, v_num=ypmf]Epoch 196:  43% 115/270 [01:17<-1:58:26, -1.63it/s, loss=0.0168, v_num=ypmf]Epoch 196:  43% 115/270 [01:17<-1:58:25, -1.63it/s, loss=0.0169, v_num=ypmf]Epoch 196:  43% 116/270 [01:17<-1:58:25, -1.61it/s, loss=0.0169, v_num=ypmf]Epoch 196:  43% 116/270 [01:17<-1:58:25, -1.61it/s, loss=0.0169, v_num=ypmf]Epoch 196:  43% 116/270 [01:17<-1:58:24, -1.60it/s, loss=0.017, v_num=ypmf] Epoch 196:  43% 117/270 [01:18<-1:58:24, -1.58it/s, loss=0.017, v_num=ypmf]Epoch 196:  43% 117/270 [01:18<-1:58:24, -1.58it/s, loss=0.017, v_num=ypmf]Epoch 196:  43% 117/270 [01:18<-1:58:24, -1.58it/s, loss=0.017, v_num=ypmf]Epoch 196:  44% 118/270 [01:19<-1:58:23, -1.56it/s, loss=0.017, v_num=ypmf]Epoch 196:  44% 118/270 [01:19<-1:58:23, -1.56it/s, loss=0.017, v_num=ypmf]Epoch 196:  44% 118/270 [01:19<-1:58:23, -1.55it/s, loss=0.017, v_num=ypmf]Epoch 196:  44% 119/270 [01:19<-1:58:22, -1.53it/s, loss=0.017, v_num=ypmf]Epoch 196:  44% 119/270 [01:19<-1:58:22, -1.53it/s, loss=0.017, v_num=ypmf]Epoch 196:  44% 119/270 [01:19<-1:58:22, -1.53it/s, loss=0.017, v_num=ypmf]Epoch 196:  44% 120/270 [01:20<-1:58:21, -1.51it/s, loss=0.017, v_num=ypmf]Epoch 196:  44% 120/270 [01:20<-1:58:21, -1.51it/s, loss=0.017, v_num=ypmf]Epoch 196:  44% 120/270 [01:20<-1:58:20, -1.50it/s, loss=0.017, v_num=ypmf]Epoch 196:  45% 121/270 [01:21<-1:58:20, -1.48it/s, loss=0.017, v_num=ypmf]Epoch 196:  45% 121/270 [01:21<-1:58:20, -1.48it/s, loss=0.017, v_num=ypmf]Epoch 196:  45% 121/270 [01:21<-1:58:20, -1.48it/s, loss=0.0169, v_num=ypmf]Epoch 196:  45% 122/270 [01:21<-1:58:19, -1.46it/s, loss=0.0169, v_num=ypmf]Epoch 196:  45% 122/270 [01:21<-1:58:19, -1.46it/s, loss=0.0169, v_num=ypmf]Epoch 196:  45% 122/270 [01:21<-1:58:19, -1.45it/s, loss=0.0169, v_num=ypmf]Epoch 196:  46% 123/270 [01:22<-1:58:18, -1.44it/s, loss=0.0169, v_num=ypmf]Epoch 196:  46% 123/270 [01:22<-1:58:18, -1.44it/s, loss=0.0169, v_num=ypmf]Epoch 196:  46% 123/270 [01:22<-1:58:18, -1.43it/s, loss=0.0169, v_num=ypmf]Epoch 196:  46% 124/270 [01:22<-1:58:17, -1.41it/s, loss=0.0169, v_num=ypmf]Epoch 196:  46% 124/270 [01:22<-1:58:17, -1.41it/s, loss=0.0169, v_num=ypmf]Epoch 196:  46% 124/270 [01:22<-1:58:17, -1.41it/s, loss=0.0169, v_num=ypmf]Epoch 196:  46% 125/270 [01:23<-1:58:16, -1.39it/s, loss=0.0169, v_num=ypmf]Epoch 196:  46% 125/270 [01:23<-1:58:16, -1.39it/s, loss=0.0169, v_num=ypmf]Epoch 196:  46% 125/270 [01:23<-1:58:16, -1.39it/s, loss=0.0169, v_num=ypmf]Epoch 196:  47% 126/270 [01:23<-1:58:15, -1.37it/s, loss=0.0169, v_num=ypmf]Epoch 196:  47% 126/270 [01:23<-1:58:15, -1.37it/s, loss=0.0169, v_num=ypmf]Epoch 196:  47% 126/270 [01:24<-1:58:15, -1.36it/s, loss=0.0169, v_num=ypmf]Epoch 196:  47% 127/270 [01:24<-1:58:14, -1.34it/s, loss=0.0169, v_num=ypmf]Epoch 196:  47% 127/270 [01:24<-1:58:14, -1.34it/s, loss=0.0169, v_num=ypmf]Epoch 196:  47% 127/270 [01:25<-1:58:14, -1.34it/s, loss=0.017, v_num=ypmf] Epoch 196:  47% 128/270 [01:25<-1:58:13, -1.32it/s, loss=0.017, v_num=ypmf]Epoch 196:  47% 128/270 [01:25<-1:58:13, -1.32it/s, loss=0.017, v_num=ypmf]Epoch 196:  47% 128/270 [01:25<-1:58:13, -1.32it/s, loss=0.0171, v_num=ypmf]Epoch 196:  48% 129/270 [01:26<-1:58:12, -1.30it/s, loss=0.0171, v_num=ypmf]Epoch 196:  48% 129/270 [01:26<-1:58:12, -1.30it/s, loss=0.0171, v_num=ypmf]Epoch 196:  48% 129/270 [01:26<-1:58:12, -1.30it/s, loss=0.017, v_num=ypmf] Epoch 196:  48% 130/270 [01:26<-1:58:11, -1.28it/s, loss=0.017, v_num=ypmf]Epoch 196:  48% 130/270 [01:26<-1:58:11, -1.28it/s, loss=0.017, v_num=ypmf]Epoch 196:  48% 130/270 [01:26<-1:58:11, -1.28it/s, loss=0.017, v_num=ypmf]Epoch 196:  49% 131/270 [01:27<-1:58:10, -1.26it/s, loss=0.017, v_num=ypmf]Epoch 196:  49% 131/270 [01:27<-1:58:10, -1.26it/s, loss=0.017, v_num=ypmf]Epoch 196:  49% 131/270 [01:27<-1:58:10, -1.26it/s, loss=0.017, v_num=ypmf]Epoch 196:  49% 132/270 [01:28<-1:58:09, -1.24it/s, loss=0.017, v_num=ypmf]Epoch 196:  49% 132/270 [01:28<-1:58:09, -1.24it/s, loss=0.017, v_num=ypmf]Epoch 196:  49% 132/270 [01:28<-1:58:09, -1.24it/s, loss=0.0169, v_num=ypmf]Epoch 196:  49% 133/270 [01:28<-1:58:08, -1.22it/s, loss=0.0169, v_num=ypmf]Epoch 196:  49% 133/270 [01:28<-1:58:08, -1.22it/s, loss=0.0169, v_num=ypmf]Epoch 196:  49% 133/270 [01:28<-1:58:08, -1.22it/s, loss=0.017, v_num=ypmf] Epoch 196:  50% 134/270 [01:29<-1:58:07, -1.20it/s, loss=0.017, v_num=ypmf]Epoch 196:  50% 134/270 [01:29<-1:58:07, -1.20it/s, loss=0.017, v_num=ypmf]Epoch 196:  50% 134/270 [01:29<-1:58:07, -1.20it/s, loss=0.017, v_num=ypmf]Epoch 196:  50% 135/270 [01:29<-1:58:06, -1.18it/s, loss=0.017, v_num=ypmf]Epoch 196:  50% 135/270 [01:29<-1:58:06, -1.18it/s, loss=0.017, v_num=ypmf]Epoch 196:  50% 135/270 [01:30<-1:58:06, -1.18it/s, loss=0.0171, v_num=ypmf]Epoch 196:  50% 136/270 [01:30<-1:58:05, -1.16it/s, loss=0.0171, v_num=ypmf]Epoch 196:  50% 136/270 [01:30<-1:58:05, -1.16it/s, loss=0.0171, v_num=ypmf]Epoch 196:  50% 136/270 [01:30<-1:58:05, -1.16it/s, loss=0.017, v_num=ypmf] Epoch 196:  51% 137/270 [01:31<-1:58:04, -1.14it/s, loss=0.017, v_num=ypmf]Epoch 196:  51% 137/270 [01:31<-1:58:04, -1.14it/s, loss=0.017, v_num=ypmf]Epoch 196:  51% 137/270 [01:31<-1:58:04, -1.14it/s, loss=0.017, v_num=ypmf]Epoch 196:  51% 138/270 [01:31<-1:58:03, -1.12it/s, loss=0.017, v_num=ypmf]Epoch 196:  51% 138/270 [01:31<-1:58:03, -1.12it/s, loss=0.017, v_num=ypmf]Epoch 196:  51% 138/270 [01:32<-1:58:03, -1.12it/s, loss=0.0169, v_num=ypmf]Epoch 196:  51% 139/270 [01:32<-1:58:02, -1.10it/s, loss=0.0169, v_num=ypmf]Epoch 196:  51% 139/270 [01:32<-1:58:02, -1.10it/s, loss=0.0169, v_num=ypmf]Epoch 196:  51% 139/270 [01:32<-1:58:02, -1.10it/s, loss=0.0169, v_num=ypmf]Epoch 196:  52% 140/270 [01:33<-1:58:01, -1.09it/s, loss=0.0169, v_num=ypmf]Epoch 196:  52% 140/270 [01:33<-1:58:01, -1.09it/s, loss=0.0169, v_num=ypmf]Epoch 196:  52% 140/270 [01:33<-1:58:00, -1.08it/s, loss=0.0169, v_num=ypmf]Epoch 196:  52% 141/270 [01:33<-1:58:00, -1.07it/s, loss=0.0169, v_num=ypmf]Epoch 196:  52% 141/270 [01:33<-1:58:00, -1.07it/s, loss=0.0169, v_num=ypmf]Epoch 196:  52% 141/270 [01:33<-1:57:59, -1.06it/s, loss=0.0169, v_num=ypmf]Epoch 196:  53% 142/270 [01:34<-1:57:59, -1.05it/s, loss=0.0169, v_num=ypmf]Epoch 196:  53% 142/270 [01:34<-1:57:59, -1.05it/s, loss=0.0169, v_num=ypmf]Epoch 196:  53% 142/270 [01:34<-1:57:58, -1.05it/s, loss=0.017, v_num=ypmf] Epoch 196:  53% 143/270 [01:34<-1:57:58, -1.03it/s, loss=0.017, v_num=ypmf]Epoch 196:  53% 143/270 [01:34<-1:57:58, -1.03it/s, loss=0.017, v_num=ypmf]Epoch 196:  53% 143/270 [01:34<-1:57:57, -1.03it/s, loss=0.017, v_num=ypmf]Epoch 196:  53% 144/270 [01:35<-1:57:57, -1.02it/s, loss=0.017, v_num=ypmf]Epoch 196:  53% 144/270 [01:35<-1:57:57, -1.02it/s, loss=0.017, v_num=ypmf]Epoch 196:  53% 144/270 [01:35<-1:57:56, -1.01it/s, loss=0.0169, v_num=ypmf]Epoch 196:  54% 145/270 [01:36<-1:57:55, -1.00it/s, loss=0.0169, v_num=ypmf]Epoch 196:  54% 145/270 [01:36<-1:57:55, -1.00it/s, loss=0.0169, v_num=ypmf]Epoch 196:  54% 145/270 [01:36<-1:57:55, -1.00it/s, loss=0.0169, v_num=ypmf]Epoch 196:  54% 146/270 [01:36<-1:57:55, -0.98it/s, loss=0.0169, v_num=ypmf]Epoch 196:  54% 146/270 [01:36<-1:57:55, -0.98it/s, loss=0.0169, v_num=ypmf]Epoch 196:  54% 146/270 [01:36<-1:57:54, -0.98it/s, loss=0.0168, v_num=ypmf]Epoch 196:  54% 147/270 [01:36<-1:57:54, -0.97it/s, loss=0.0168, v_num=ypmf]Epoch 196:  54% 147/270 [01:36<-1:57:54, -0.97it/s, loss=0.0168, v_num=ypmf]Epoch 196:  54% 147/270 [01:37<-1:57:53, -0.97it/s, loss=0.0167, v_num=ypmf]Epoch 196:  55% 148/270 [01:38<-1:57:52, -0.95it/s, loss=0.0167, v_num=ypmf]Epoch 196:  55% 148/270 [01:38<-1:57:52, -0.95it/s, loss=0.0167, v_num=ypmf]Epoch 196:  55% 148/270 [01:38<-1:57:51, -0.94it/s, loss=0.0166, v_num=ypmf]Epoch 196:  55% 149/270 [01:38<-1:57:51, -0.93it/s, loss=0.0166, v_num=ypmf]Epoch 196:  55% 149/270 [01:38<-1:57:51, -0.93it/s, loss=0.0166, v_num=ypmf]Epoch 196:  55% 149/270 [01:39<-1:57:50, -0.93it/s, loss=0.0167, v_num=ypmf]Epoch 196:  56% 150/270 [01:39<-1:57:49, -0.91it/s, loss=0.0167, v_num=ypmf]Epoch 196:  56% 150/270 [01:39<-1:57:49, -0.91it/s, loss=0.0167, v_num=ypmf]Epoch 196:  56% 150/270 [01:39<-1:57:49, -0.91it/s, loss=0.0168, v_num=ypmf]Epoch 196:  56% 151/270 [01:40<-1:57:48, -0.90it/s, loss=0.0168, v_num=ypmf]Epoch 196:  56% 151/270 [01:40<-1:57:48, -0.90it/s, loss=0.0168, v_num=ypmf]Epoch 196:  56% 151/270 [01:40<-1:57:48, -0.90it/s, loss=0.0167, v_num=ypmf]Epoch 196:  56% 152/270 [01:40<-1:57:47, -0.88it/s, loss=0.0167, v_num=ypmf]Epoch 196:  56% 152/270 [01:40<-1:57:47, -0.88it/s, loss=0.0167, v_num=ypmf]Epoch 196:  56% 152/270 [01:40<-1:57:47, -0.88it/s, loss=0.0169, v_num=ypmf]Epoch 196:  57% 153/270 [01:41<-1:57:46, -0.87it/s, loss=0.0169, v_num=ypmf]Epoch 196:  57% 153/270 [01:41<-1:57:46, -0.87it/s, loss=0.0169, v_num=ypmf]Epoch 196:  57% 153/270 [01:41<-1:57:46, -0.87it/s, loss=0.0168, v_num=ypmf]Epoch 196:  57% 154/270 [01:41<-1:57:45, -0.85it/s, loss=0.0168, v_num=ypmf]Epoch 196:  57% 154/270 [01:41<-1:57:45, -0.85it/s, loss=0.0168, v_num=ypmf]Epoch 196:  57% 154/270 [01:42<-1:57:44, -0.85it/s, loss=0.0168, v_num=ypmf]Epoch 196:  57% 155/270 [01:42<-1:57:44, -0.84it/s, loss=0.0168, v_num=ypmf]Epoch 196:  57% 155/270 [01:42<-1:57:44, -0.84it/s, loss=0.0168, v_num=ypmf]Epoch 196:  57% 155/270 [01:42<-1:57:43, -0.84it/s, loss=0.0168, v_num=ypmf]Epoch 196:  58% 156/270 [01:42<-1:57:42, -0.83it/s, loss=0.0168, v_num=ypmf]Epoch 196:  58% 156/270 [01:42<-1:57:42, -0.83it/s, loss=0.0168, v_num=ypmf]Epoch 196:  58% 156/270 [01:43<-1:57:42, -0.82it/s, loss=0.0167, v_num=ypmf]Epoch 196:  58% 157/270 [01:43<-1:57:41, -0.81it/s, loss=0.0167, v_num=ypmf]Epoch 196:  58% 157/270 [01:43<-1:57:41, -0.81it/s, loss=0.0167, v_num=ypmf]Epoch 196:  58% 157/270 [01:43<-1:57:41, -0.81it/s, loss=0.0166, v_num=ypmf]Epoch 196:  59% 158/270 [01:44<-1:57:40, -0.80it/s, loss=0.0166, v_num=ypmf]Epoch 196:  59% 158/270 [01:44<-1:57:40, -0.80it/s, loss=0.0166, v_num=ypmf]Epoch 196:  59% 158/270 [01:44<-1:57:40, -0.80it/s, loss=0.0166, v_num=ypmf]Epoch 196:  59% 159/270 [01:44<-1:57:39, -0.78it/s, loss=0.0166, v_num=ypmf]Epoch 196:  59% 159/270 [01:44<-1:57:39, -0.78it/s, loss=0.0166, v_num=ypmf]Epoch 196:  59% 159/270 [01:45<-1:57:38, -0.78it/s, loss=0.0166, v_num=ypmf]Epoch 196:  59% 160/270 [01:45<-1:57:37, -0.77it/s, loss=0.0166, v_num=ypmf]Epoch 196:  59% 160/270 [01:45<-1:57:37, -0.77it/s, loss=0.0166, v_num=ypmf]Epoch 196:  59% 160/270 [01:45<-1:57:37, -0.77it/s, loss=0.0167, v_num=ypmf]Epoch 196:  60% 161/270 [01:45<-1:57:36, -0.75it/s, loss=0.0167, v_num=ypmf]Epoch 196:  60% 161/270 [01:45<-1:57:36, -0.75it/s, loss=0.0167, v_num=ypmf]Epoch 196:  60% 161/270 [01:46<-1:57:36, -0.75it/s, loss=0.0167, v_num=ypmf]Epoch 196:  60% 162/270 [01:46<-1:57:35, -0.74it/s, loss=0.0167, v_num=ypmf]Epoch 196:  60% 162/270 [01:46<-1:57:35, -0.74it/s, loss=0.0167, v_num=ypmf]Epoch 196:  60% 162/270 [01:46<-1:57:35, -0.74it/s, loss=0.0167, v_num=ypmf]Epoch 196:  60% 163/270 [01:47<-1:57:34, -0.73it/s, loss=0.0167, v_num=ypmf]Epoch 196:  60% 163/270 [01:47<-1:57:34, -0.73it/s, loss=0.0167, v_num=ypmf]Epoch 196:  60% 163/270 [01:47<-1:57:33, -0.73it/s, loss=0.0167, v_num=ypmf]Epoch 196:  61% 164/270 [01:48<-1:57:32, -0.71it/s, loss=0.0167, v_num=ypmf]Epoch 196:  61% 164/270 [01:48<-1:57:32, -0.71it/s, loss=0.0167, v_num=ypmf]Epoch 196:  61% 164/270 [01:48<-1:57:31, -0.71it/s, loss=0.0167, v_num=ypmf]Epoch 196:  61% 165/270 [01:48<-1:57:30, -0.70it/s, loss=0.0167, v_num=ypmf]Epoch 196:  61% 165/270 [01:48<-1:57:30, -0.70it/s, loss=0.0167, v_num=ypmf]Epoch 196:  61% 165/270 [01:48<-1:57:30, -0.70it/s, loss=0.0167, v_num=ypmf]Epoch 196:  61% 166/270 [01:49<-1:57:28, -0.68it/s, loss=0.0167, v_num=ypmf]Epoch 196:  61% 166/270 [01:49<-1:57:28, -0.68it/s, loss=0.0167, v_num=ypmf]Epoch 196:  61% 166/270 [01:49<-1:57:28, -0.68it/s, loss=0.0167, v_num=ypmf]Epoch 196:  62% 167/270 [01:50<-1:57:27, -0.67it/s, loss=0.0167, v_num=ypmf]Epoch 196:  62% 167/270 [01:50<-1:57:27, -0.67it/s, loss=0.0167, v_num=ypmf]Epoch 196:  62% 167/270 [01:50<-1:57:27, -0.67it/s, loss=0.0167, v_num=ypmf]Epoch 196:  62% 168/270 [01:50<-1:57:25, -0.66it/s, loss=0.0167, v_num=ypmf]Epoch 196:  62% 168/270 [01:50<-1:57:25, -0.66it/s, loss=0.0167, v_num=ypmf]Epoch 196:  62% 168/270 [01:51<-1:57:25, -0.66it/s, loss=0.0167, v_num=ypmf]Epoch 196:  63% 169/270 [01:51<-1:57:24, -0.65it/s, loss=0.0167, v_num=ypmf]Epoch 196:  63% 169/270 [01:51<-1:57:24, -0.65it/s, loss=0.0167, v_num=ypmf]Epoch 196:  63% 169/270 [01:51<-1:57:24, -0.65it/s, loss=0.0165, v_num=ypmf]Epoch 196:  63% 170/270 [01:53<-1:57:21, -0.63it/s, loss=0.0165, v_num=ypmf]Epoch 196:  63% 170/270 [01:53<-1:57:21, -0.63it/s, loss=0.0165, v_num=ypmf]Epoch 196:  63% 170/270 [01:53<-1:57:21, -0.63it/s, loss=0.0166, v_num=ypmf]Epoch 196:  63% 171/270 [01:53<-1:57:20, -0.62it/s, loss=0.0166, v_num=ypmf]Epoch 196:  63% 171/270 [01:53<-1:57:20, -0.62it/s, loss=0.0166, v_num=ypmf]Epoch 196:  63% 171/270 [01:53<-1:57:20, -0.62it/s, loss=0.0166, v_num=ypmf]Epoch 196:  64% 172/270 [01:54<-1:57:18, -0.60it/s, loss=0.0166, v_num=ypmf]Epoch 196:  64% 172/270 [01:54<-1:57:18, -0.60it/s, loss=0.0166, v_num=ypmf]Epoch 196:  64% 172/270 [01:54<-1:57:18, -0.60it/s, loss=0.0165, v_num=ypmf]Epoch 196:  64% 173/270 [01:54<-1:57:17, -0.59it/s, loss=0.0165, v_num=ypmf]Epoch 196:  64% 173/270 [01:54<-1:57:17, -0.59it/s, loss=0.0165, v_num=ypmf]Epoch 196:  64% 173/270 [01:54<-1:57:17, -0.59it/s, loss=0.0166, v_num=ypmf]Epoch 196:  64% 174/270 [01:55<-1:57:15, -0.58it/s, loss=0.0166, v_num=ypmf]Epoch 196:  64% 174/270 [01:55<-1:57:15, -0.58it/s, loss=0.0166, v_num=ypmf]Epoch 196:  64% 174/270 [01:55<-1:57:15, -0.58it/s, loss=0.0166, v_num=ypmf]Epoch 196:  65% 175/270 [01:55<-1:57:14, -0.57it/s, loss=0.0166, v_num=ypmf]Epoch 196:  65% 175/270 [01:55<-1:57:14, -0.57it/s, loss=0.0166, v_num=ypmf]Epoch 196:  65% 175/270 [01:55<-1:57:14, -0.57it/s, loss=0.0165, v_num=ypmf]Epoch 196:  65% 176/270 [01:56<-1:57:12, -0.56it/s, loss=0.0165, v_num=ypmf]Epoch 196:  65% 176/270 [01:56<-1:57:12, -0.56it/s, loss=0.0165, v_num=ypmf]Epoch 196:  65% 176/270 [01:56<-1:57:12, -0.56it/s, loss=0.0167, v_num=ypmf]Epoch 196:  66% 177/270 [01:56<-1:57:11, -0.55it/s, loss=0.0167, v_num=ypmf]Epoch 196:  66% 177/270 [01:56<-1:57:11, -0.55it/s, loss=0.0167, v_num=ypmf]Epoch 196:  66% 177/270 [01:57<-1:57:10, -0.55it/s, loss=0.0168, v_num=ypmf]Epoch 196:  66% 178/270 [01:57<-1:57:09, -0.54it/s, loss=0.0168, v_num=ypmf]Epoch 196:  66% 178/270 [01:57<-1:57:09, -0.54it/s, loss=0.0168, v_num=ypmf]Epoch 196:  66% 178/270 [01:57<-1:57:08, -0.53it/s, loss=0.0168, v_num=ypmf]Epoch 196:  66% 179/270 [01:58<-1:57:07, -0.52it/s, loss=0.0168, v_num=ypmf]Epoch 196:  66% 179/270 [01:58<-1:57:07, -0.52it/s, loss=0.0168, v_num=ypmf]Epoch 196:  66% 179/270 [01:58<-1:57:07, -0.52it/s, loss=0.0169, v_num=ypmf]Epoch 196:  67% 180/270 [01:58<-1:57:05, -0.51it/s, loss=0.0169, v_num=ypmf]Epoch 196:  67% 180/270 [01:58<-1:57:05, -0.51it/s, loss=0.0169, v_num=ypmf]Epoch 196:  67% 180/270 [01:58<-1:57:05, -0.51it/s, loss=0.0168, v_num=ypmf]Epoch 196:  67% 181/270 [01:59<-1:57:03, -0.50it/s, loss=0.0168, v_num=ypmf]Epoch 196:  67% 181/270 [01:59<-1:57:03, -0.50it/s, loss=0.0168, v_num=ypmf]Epoch 196:  67% 181/270 [01:59<-1:57:03, -0.50it/s, loss=0.0168, v_num=ypmf]Epoch 196:  67% 182/270 [01:59<-1:57:02, -0.49it/s, loss=0.0168, v_num=ypmf]Epoch 196:  67% 182/270 [01:59<-1:57:02, -0.49it/s, loss=0.0168, v_num=ypmf]Epoch 196:  67% 182/270 [02:00<-1:57:01, -0.49it/s, loss=0.0168, v_num=ypmf]Epoch 196:  68% 183/270 [02:00<-1:57:00, -0.48it/s, loss=0.0168, v_num=ypmf]Epoch 196:  68% 183/270 [02:00<-1:57:00, -0.48it/s, loss=0.0168, v_num=ypmf]Epoch 196:  68% 183/270 [02:00<-1:56:59, -0.48it/s, loss=0.0168, v_num=ypmf]Epoch 196:  68% 184/270 [02:01<-1:56:58, -0.47it/s, loss=0.0168, v_num=ypmf]Epoch 196:  68% 184/270 [02:01<-1:56:58, -0.47it/s, loss=0.0168, v_num=ypmf]Epoch 196:  68% 184/270 [02:01<-1:56:58, -0.47it/s, loss=0.0168, v_num=ypmf]Epoch 196:  69% 185/270 [02:01<-1:56:56, -0.46it/s, loss=0.0168, v_num=ypmf]Epoch 196:  69% 185/270 [02:01<-1:56:56, -0.46it/s, loss=0.0168, v_num=ypmf]Epoch 196:  69% 185/270 [02:01<-1:56:56, -0.46it/s, loss=0.0169, v_num=ypmf]Epoch 196:  69% 186/270 [02:02<-1:56:54, -0.45it/s, loss=0.0169, v_num=ypmf]Epoch 196:  69% 186/270 [02:02<-1:56:54, -0.45it/s, loss=0.0169, v_num=ypmf]Epoch 196:  69% 186/270 [02:02<-1:56:53, -0.45it/s, loss=0.0169, v_num=ypmf]Epoch 196:  69% 187/270 [02:02<-1:56:52, -0.44it/s, loss=0.0169, v_num=ypmf]Epoch 196:  69% 187/270 [02:02<-1:56:52, -0.44it/s, loss=0.0169, v_num=ypmf]Epoch 196:  69% 187/270 [02:03<-1:56:51, -0.44it/s, loss=0.0169, v_num=ypmf]Epoch 196:  70% 188/270 [02:03<-1:56:49, -0.43it/s, loss=0.0169, v_num=ypmf]Epoch 196:  70% 188/270 [02:03<-1:56:49, -0.43it/s, loss=0.0169, v_num=ypmf]Epoch 196:  70% 188/270 [02:03<-1:56:49, -0.43it/s, loss=0.017, v_num=ypmf] Epoch 196:  70% 189/270 [02:03<-1:56:47, -0.42it/s, loss=0.017, v_num=ypmf]Epoch 196:  70% 189/270 [02:03<-1:56:47, -0.42it/s, loss=0.017, v_num=ypmf]Epoch 196:  70% 189/270 [02:04<-1:56:47, -0.42it/s, loss=0.0171, v_num=ypmf]Epoch 196:  70% 190/270 [02:04<-1:56:45, -0.41it/s, loss=0.0171, v_num=ypmf]Epoch 196:  70% 190/270 [02:04<-1:56:45, -0.41it/s, loss=0.0171, v_num=ypmf]Epoch 196:  70% 190/270 [02:06<-1:56:42, -0.40it/s, loss=0.0171, v_num=ypmf]Epoch 196:  71% 191/270 [02:06<-1:56:40, -0.39it/s, loss=0.0171, v_num=ypmf]Epoch 196:  71% 191/270 [02:06<-1:56:40, -0.39it/s, loss=0.0171, v_num=ypmf]Epoch 196:  71% 191/270 [02:06<-1:56:40, -0.39it/s, loss=0.0172, v_num=ypmf]Epoch 196:  71% 192/270 [02:07<-1:56:38, -0.38it/s, loss=0.0172, v_num=ypmf]Epoch 196:  71% 192/270 [02:07<-1:56:38, -0.38it/s, loss=0.0172, v_num=ypmf]Epoch 196:  71% 192/270 [02:07<-1:56:38, -0.38it/s, loss=0.0173, v_num=ypmf]Epoch 196:  71% 193/270 [02:07<-1:56:36, -0.38it/s, loss=0.0173, v_num=ypmf]Epoch 196:  71% 193/270 [02:07<-1:56:36, -0.38it/s, loss=0.0173, v_num=ypmf]Epoch 196:  71% 193/270 [02:08<-1:56:35, -0.37it/s, loss=0.0173, v_num=ypmf]Epoch 196:  72% 194/270 [02:08<-1:56:33, -0.37it/s, loss=0.0173, v_num=ypmf]Epoch 196:  72% 194/270 [02:08<-1:56:33, -0.37it/s, loss=0.0173, v_num=ypmf]Epoch 196:  72% 194/270 [02:08<-1:56:33, -0.37it/s, loss=0.0172, v_num=ypmf]Epoch 196:  72% 195/270 [02:08<-1:56:30, -0.36it/s, loss=0.0172, v_num=ypmf]Epoch 196:  72% 195/270 [02:08<-1:56:30, -0.36it/s, loss=0.0172, v_num=ypmf]Epoch 196:  72% 195/270 [02:09<-1:56:30, -0.36it/s, loss=0.0172, v_num=ypmf]Epoch 196:  73% 196/270 [02:09<-1:56:28, -0.35it/s, loss=0.0172, v_num=ypmf]Epoch 196:  73% 196/270 [02:09<-1:56:28, -0.35it/s, loss=0.0172, v_num=ypmf]Epoch 196:  73% 196/270 [02:09<-1:56:27, -0.35it/s, loss=0.0172, v_num=ypmf]Epoch 196:  73% 197/270 [02:10<-1:56:25, -0.34it/s, loss=0.0172, v_num=ypmf]Epoch 196:  73% 197/270 [02:10<-1:56:25, -0.34it/s, loss=0.0172, v_num=ypmf]Epoch 196:  73% 197/270 [02:10<-1:56:25, -0.34it/s, loss=0.0173, v_num=ypmf]Epoch 196:  73% 198/270 [02:10<-1:56:22, -0.33it/s, loss=0.0173, v_num=ypmf]Epoch 196:  73% 198/270 [02:10<-1:56:22, -0.33it/s, loss=0.0173, v_num=ypmf]Epoch 196:  73% 198/270 [02:10<-1:56:22, -0.33it/s, loss=0.0173, v_num=ypmf]Epoch 196:  74% 199/270 [02:11<-1:56:18, -0.32it/s, loss=0.0173, v_num=ypmf]Epoch 196:  74% 199/270 [02:11<-1:56:18, -0.32it/s, loss=0.0173, v_num=ypmf]Epoch 196:  74% 199/270 [02:11<-1:56:18, -0.32it/s, loss=0.0172, v_num=ypmf]Epoch 196:  74% 200/270 [02:11<-1:56:15, -0.31it/s, loss=0.0172, v_num=ypmf]Epoch 196:  74% 200/270 [02:11<-1:56:15, -0.31it/s, loss=0.0172, v_num=ypmf]Epoch 196:  74% 200/270 [02:12<-1:56:15, -0.31it/s, loss=0.0172, v_num=ypmf]Epoch 196:  74% 201/270 [02:12<-1:56:12, -0.30it/s, loss=0.0172, v_num=ypmf]Epoch 196:  74% 201/270 [02:12<-1:56:12, -0.30it/s, loss=0.0172, v_num=ypmf]Epoch 196:  74% 201/270 [02:12<-1:56:11, -0.30it/s, loss=0.0172, v_num=ypmf]Epoch 196:  75% 202/270 [02:13<-1:56:08, -0.29it/s, loss=0.0172, v_num=ypmf]Epoch 196:  75% 202/270 [02:13<-1:56:08, -0.29it/s, loss=0.0172, v_num=ypmf]Epoch 196:  75% 202/270 [02:13<-1:56:08, -0.29it/s, loss=0.0172, v_num=ypmf]Epoch 196:  75% 203/270 [02:13<-1:56:05, -0.28it/s, loss=0.0172, v_num=ypmf]Epoch 196:  75% 203/270 [02:13<-1:56:05, -0.28it/s, loss=0.0172, v_num=ypmf]Epoch 196:  75% 203/270 [02:13<-1:56:04, -0.28it/s, loss=0.0171, v_num=ypmf]Epoch 196:  76% 204/270 [02:14<-1:56:01, -0.28it/s, loss=0.0171, v_num=ypmf]Epoch 196:  76% 204/270 [02:14<-1:56:01, -0.28it/s, loss=0.0171, v_num=ypmf]Epoch 196:  76% 204/270 [02:14<-1:56:00, -0.27it/s, loss=0.0171, v_num=ypmf]Epoch 196:  76% 205/270 [02:15<-1:55:57, -0.27it/s, loss=0.0171, v_num=ypmf]Epoch 196:  76% 205/270 [02:15<-1:55:57, -0.27it/s, loss=0.0171, v_num=ypmf]Epoch 196:  76% 205/270 [02:15<-1:55:56, -0.27it/s, loss=0.0171, v_num=ypmf]Epoch 196:  76% 206/270 [02:15<-1:55:52, -0.26it/s, loss=0.0171, v_num=ypmf]Epoch 196:  76% 206/270 [02:15<-1:55:52, -0.26it/s, loss=0.0171, v_num=ypmf]Epoch 196:  76% 206/270 [02:16<-1:55:52, -0.26it/s, loss=0.0172, v_num=ypmf]Epoch 196:  77% 207/270 [02:16<-1:55:48, -0.25it/s, loss=0.0172, v_num=ypmf]Epoch 196:  77% 207/270 [02:16<-1:55:48, -0.25it/s, loss=0.0172, v_num=ypmf]Epoch 196:  77% 207/270 [02:16<-1:55:47, -0.25it/s, loss=0.0175, v_num=ypmf]Epoch 196:  77% 208/270 [02:16<-1:55:43, -0.24it/s, loss=0.0175, v_num=ypmf]Epoch 196:  77% 208/270 [02:16<-1:55:43, -0.24it/s, loss=0.0175, v_num=ypmf]Epoch 196:  77% 208/270 [02:17<-1:55:43, -0.24it/s, loss=0.0174, v_num=ypmf]Epoch 196:  77% 209/270 [02:17<-1:55:38, -0.23it/s, loss=0.0174, v_num=ypmf]Epoch 196:  77% 209/270 [02:17<-1:55:38, -0.23it/s, loss=0.0174, v_num=ypmf]Epoch 196:  77% 209/270 [02:17<-1:55:38, -0.23it/s, loss=0.0173, v_num=ypmf]Epoch 196:  78% 210/270 [02:18<-1:55:33, -0.22it/s, loss=0.0173, v_num=ypmf]Epoch 196:  78% 210/270 [02:18<-1:55:33, -0.22it/s, loss=0.0173, v_num=ypmf]Epoch 196:  78% 210/270 [02:18<-1:55:33, -0.22it/s, loss=0.0172, v_num=ypmf]Epoch 196:  78% 211/270 [02:18<-1:55:27, -0.22it/s, loss=0.0172, v_num=ypmf]Epoch 196:  78% 211/270 [02:18<-1:55:27, -0.22it/s, loss=0.0172, v_num=ypmf]Epoch 196:  78% 211/270 [02:19<-1:55:27, -0.22it/s, loss=0.0172, v_num=ypmf]Epoch 196:  79% 212/270 [02:19<-1:55:22, -0.21it/s, loss=0.0172, v_num=ypmf]Epoch 196:  79% 212/270 [02:19<-1:55:22, -0.21it/s, loss=0.0172, v_num=ypmf]Epoch 196:  79% 212/270 [02:19<-1:55:21, -0.21it/s, loss=0.017, v_num=ypmf] Epoch 196:  79% 213/270 [02:19<-1:55:16, -0.20it/s, loss=0.017, v_num=ypmf]Epoch 196:  79% 213/270 [02:19<-1:55:16, -0.20it/s, loss=0.017, v_num=ypmf]Epoch 196:  79% 213/270 [02:20<-1:55:15, -0.20it/s, loss=0.017, v_num=ypmf]Epoch 196:  79% 214/270 [02:20<-1:55:09, -0.19it/s, loss=0.017, v_num=ypmf]Epoch 196:  79% 214/270 [02:20<-1:55:09, -0.19it/s, loss=0.017, v_num=ypmf]Epoch 196:  79% 214/270 [02:20<-1:55:09, -0.19it/s, loss=0.0171, v_num=ypmf]Epoch 196:  80% 215/270 [02:21<-1:55:02, -0.18it/s, loss=0.0171, v_num=ypmf]Epoch 196:  80% 215/270 [02:21<-1:55:02, -0.18it/s, loss=0.0171, v_num=ypmf]Epoch 196:  80% 215/270 [02:21<-1:55:02, -0.18it/s, loss=0.0172, v_num=ypmf]Epoch 196:  80% 216/270 [02:21<-1:54:54, -0.18it/s, loss=0.0172, v_num=ypmf]Epoch 196:  80% 216/270 [02:21<-1:54:54, -0.18it/s, loss=0.0172, v_num=ypmf]Epoch 196:  80% 216/270 [02:21<-1:54:54, -0.18it/s, loss=0.0173, v_num=ypmf]Epoch 196:  80% 217/270 [02:22<-1:54:46, -0.17it/s, loss=0.0173, v_num=ypmf]Epoch 196:  80% 217/270 [02:22<-1:54:46, -0.17it/s, loss=0.0173, v_num=ypmf]Epoch 196:  80% 217/270 [02:22<-1:54:46, -0.17it/s, loss=0.0173, v_num=ypmf]Epoch 196:  81% 218/270 [02:22<-1:54:38, -0.16it/s, loss=0.0173, v_num=ypmf]Epoch 196:  81% 218/270 [02:22<-1:54:38, -0.16it/s, loss=0.0173, v_num=ypmf]Epoch 196:  81% 218/270 [02:22<-1:54:37, -0.16it/s, loss=0.0173, v_num=ypmf]Epoch 196:  81% 219/270 [02:23<-1:54:28, -0.15it/s, loss=0.0173, v_num=ypmf]Epoch 196:  81% 219/270 [02:23<-1:54:28, -0.15it/s, loss=0.0173, v_num=ypmf]Epoch 196:  81% 219/270 [02:23<-1:54:28, -0.15it/s, loss=0.0173, v_num=ypmf]Epoch 196:  81% 220/270 [02:23<-1:54:18, -0.15it/s, loss=0.0173, v_num=ypmf]Epoch 196:  81% 220/270 [02:23<-1:54:18, -0.15it/s, loss=0.0173, v_num=ypmf]Epoch 196:  81% 220/270 [02:24<-1:54:17, -0.15it/s, loss=0.0173, v_num=ypmf]Epoch 196:  82% 221/270 [02:24<-1:54:07, -0.14it/s, loss=0.0173, v_num=ypmf]Epoch 196:  82% 221/270 [02:24<-1:54:07, -0.14it/s, loss=0.0173, v_num=ypmf]Epoch 196:  82% 221/270 [02:24<-1:54:05, -0.14it/s, loss=0.0174, v_num=ypmf]Epoch 196:  82% 222/270 [02:25<-1:53:54, -0.13it/s, loss=0.0174, v_num=ypmf]Epoch 196:  82% 222/270 [02:25<-1:53:54, -0.13it/s, loss=0.0174, v_num=ypmf]Epoch 196:  82% 222/270 [02:25<-1:53:53, -0.13it/s, loss=0.0173, v_num=ypmf]Epoch 196:  83% 223/270 [02:25<-1:53:39, -0.12it/s, loss=0.0173, v_num=ypmf]Epoch 196:  83% 223/270 [02:25<-1:53:39, -0.12it/s, loss=0.0173, v_num=ypmf]Epoch 196:  83% 223/270 [02:26<-1:53:39, -0.12it/s, loss=0.0173, v_num=ypmf]Epoch 196:  83% 224/270 [02:26<-1:53:24, -0.12it/s, loss=0.0173, v_num=ypmf]Epoch 196:  83% 224/270 [02:26<-1:53:24, -0.12it/s, loss=0.0173, v_num=ypmf]Epoch 196:  83% 224/270 [02:26<-1:53:23, -0.12it/s, loss=0.0174, v_num=ypmf]Epoch 196:  83% 225/270 [02:27<-1:53:07, -0.11it/s, loss=0.0174, v_num=ypmf]Epoch 196:  83% 225/270 [02:27<-1:53:07, -0.11it/s, loss=0.0174, v_num=ypmf]Epoch 196:  83% 225/270 [02:27<-1:53:06, -0.11it/s, loss=0.0173, v_num=ypmf]Epoch 196:  84% 226/270 [02:30<-1:52:39, -0.10it/s, loss=0.0173, v_num=ypmf]Epoch 196:  84% 226/270 [02:30<-1:52:39, -0.10it/s, loss=0.0173, v_num=ypmf]Epoch 196:  84% 226/270 [02:30<-1:52:38, -0.10it/s, loss=0.0172, v_num=ypmf]Epoch 196:  84% 227/270 [02:31<-1:52:17, -0.09it/s, loss=0.0172, v_num=ypmf]Epoch 196:  84% 227/270 [02:31<-1:52:17, -0.09it/s, loss=0.0172, v_num=ypmf]Epoch 196:  84% 227/270 [02:31<-1:52:15, -0.09it/s, loss=0.017, v_num=ypmf] Epoch 196:  84% 228/270 [02:31<-1:51:50, -0.09it/s, loss=0.017, v_num=ypmf]Epoch 196:  84% 228/270 [02:31<-1:51:50, -0.09it/s, loss=0.017, v_num=ypmf]Epoch 196:  84% 228/270 [02:32<-1:51:49, -0.09it/s, loss=0.017, v_num=ypmf]Epoch 196:  85% 229/270 [02:32<-1:51:20, -0.08it/s, loss=0.017, v_num=ypmf]Epoch 196:  85% 229/270 [02:32<-1:51:20, -0.08it/s, loss=0.017, v_num=ypmf]Epoch 196:  85% 229/270 [02:32<-1:51:19, -0.08it/s, loss=0.0171, v_num=ypmf]Epoch 196:  85% 230/270 [02:33<-1:50:41, -0.07it/s, loss=0.0171, v_num=ypmf]Epoch 196:  85% 230/270 [02:33<-1:50:41, -0.07it/s, loss=0.0171, v_num=ypmf]Epoch 196:  85% 230/270 [02:34<-1:50:40, -0.07it/s, loss=0.0171, v_num=ypmf]Epoch 196:  86% 231/270 [02:34<-1:49:58, -0.06it/s, loss=0.0171, v_num=ypmf]Epoch 196:  86% 231/270 [02:34<-1:49:58, -0.06it/s, loss=0.0171, v_num=ypmf]Epoch 196:  86% 231/270 [02:34<-1:49:58, -0.06it/s, loss=0.0171, v_num=ypmf]Epoch 196:  86% 232/270 [02:34<-1:49:06, -0.06it/s, loss=0.0171, v_num=ypmf]Epoch 196:  86% 232/270 [02:34<-1:49:06, -0.06it/s, loss=0.0171, v_num=ypmf]Epoch 196:  86% 232/270 [02:35<-1:49:06, -0.06it/s, loss=0.0171, v_num=ypmf]Epoch 196:  86% 233/270 [02:35<-1:48:02, -0.05it/s, loss=0.0171, v_num=ypmf]Epoch 196:  86% 233/270 [02:35<-1:48:02, -0.05it/s, loss=0.0171, v_num=ypmf]Epoch 196:  86% 233/270 [02:35<-1:48:01, -0.05it/s, loss=0.0171, v_num=ypmf]Epoch 196:  87% 234/270 [02:35<-1:46:38, -0.04it/s, loss=0.0171, v_num=ypmf]Epoch 196:  87% 234/270 [02:35<-1:46:38, -0.04it/s, loss=0.0171, v_num=ypmf]Epoch 196:  87% 234/270 [02:36<-1:46:37, -0.04it/s, loss=0.0172, v_num=ypmf]Epoch 196:  87% 235/270 [02:36<-1:44:47, -0.04it/s, loss=0.0172, v_num=ypmf]Epoch 196:  87% 235/270 [02:36<-1:44:47, -0.04it/s, loss=0.0172, v_num=ypmf]Epoch 196:  87% 235/270 [02:36<-1:44:46, -0.04it/s, loss=0.0171, v_num=ypmf]Epoch 196:  87% 236/270 [02:37<-1:42:12, -0.03it/s, loss=0.0171, v_num=ypmf]Epoch 196:  87% 236/270 [02:37<-1:42:12, -0.03it/s, loss=0.0171, v_num=ypmf]Epoch 196:  87% 236/270 [02:37<-1:42:09, -0.03it/s, loss=0.0169, v_num=ypmf]Epoch 196:  88% 237/270 [02:37<-1:38:18, -0.03it/s, loss=0.0169, v_num=ypmf]Epoch 196:  88% 237/270 [02:37<-1:38:18, -0.03it/s, loss=0.0169, v_num=ypmf]Epoch 196:  88% 237/270 [02:38<-1:38:17, -0.03it/s, loss=0.017, v_num=ypmf] Epoch 196:  88% 238/270 [02:38<-1:31:51, -0.02it/s, loss=0.017, v_num=ypmf]Epoch 196:  88% 238/270 [02:38<-1:31:51, -0.02it/s, loss=0.017, v_num=ypmf]Epoch 196:  88% 238/270 [02:38<-1:31:50, -0.02it/s, loss=0.017, v_num=ypmf]Epoch 196:  89% 239/270 [02:38<-1:18:57, -0.01it/s, loss=0.017, v_num=ypmf]Epoch 196:  89% 239/270 [02:38<-1:18:57, -0.01it/s, loss=0.017, v_num=ypmf]Epoch 196:  89% 239/270 [02:39<-1:18:55, -0.01it/s, loss=0.017, v_num=ypmf]Epoch 196:  89% 240/270 [02:39<-2:40:17, -0.01it/s, loss=0.017, v_num=ypmf]Epoch 196:  89% 240/270 [02:39<-2:40:17, -0.01it/s, loss=0.017, v_num=ypmf]Epoch 196:  89% 240/270 [02:41<-2:39:14, -0.01it/s, loss=0.0171, v_num=ypmf]Epoch 196:  89% 241/270 [02:41<?, ?it/s, loss=0.0171, v_num=ypmf]           Epoch 196:  89% 241/270 [02:41<?, ?it/s, loss=0.0171, v_num=ypmf]Epoch 196:  89% 241/270 [02:42<?, ?it/s, loss=0.017, v_num=ypmf] Epoch 196:  90% 242/270 [02:42<1:15:45, 162.33s/it, loss=0.017, v_num=ypmf]Epoch 196:  90% 242/270 [02:42<1:15:45, 162.33s/it, loss=0.017, v_num=ypmf]Epoch 196:  90% 242/270 [02:42<1:15:56, 162.72s/it, loss=0.0172, v_num=ypmf]Epoch 196:  90% 243/270 [02:43<36:41, 81.53s/it, loss=0.0172, v_num=ypmf]   Epoch 196:  90% 243/270 [02:43<36:41, 81.53s/it, loss=0.0172, v_num=ypmf]Epoch 196:  90% 243/270 [02:43<36:44, 81.64s/it, loss=0.0172, v_num=ypmf]Epoch 196:  90% 244/270 [02:43<23:39, 54.58s/it, loss=0.0172, v_num=ypmf]Epoch 196:  90% 244/270 [02:43<23:39, 54.58s/it, loss=0.0172, v_num=ypmf]Epoch 196:  90% 244/270 [02:43<23:40, 54.63s/it, loss=0.017, v_num=ypmf] Epoch 196:  91% 245/270 [02:44<17:09, 41.16s/it, loss=0.017, v_num=ypmf]Epoch 196:  91% 245/270 [02:44<17:09, 41.16s/it, loss=0.017, v_num=ypmf]Epoch 196:  91% 245/270 [02:44<17:09, 41.20s/it, loss=0.017, v_num=ypmf]Epoch 196:  91% 246/270 [02:45<13:12, 33.02s/it, loss=0.017, v_num=ypmf]Epoch 196:  91% 246/270 [02:45<13:12, 33.02s/it, loss=0.017, v_num=ypmf]Epoch 196:  91% 246/270 [02:45<13:13, 33.07s/it, loss=0.0172, v_num=ypmf]Epoch 196:  91% 247/270 [02:45<10:35, 27.63s/it, loss=0.0172, v_num=ypmf]Epoch 196:  91% 247/270 [02:45<10:35, 27.63s/it, loss=0.0172, v_num=ypmf]Epoch 196:  91% 247/270 [02:45<10:36, 27.66s/it, loss=0.0171, v_num=ypmf]Epoch 196:  92% 248/270 [02:46<08:42, 23.77s/it, loss=0.0171, v_num=ypmf]Epoch 196:  92% 248/270 [02:46<08:42, 23.77s/it, loss=0.0171, v_num=ypmf]Epoch 196:  92% 248/270 [02:46<08:43, 23.79s/it, loss=0.017, v_num=ypmf] Epoch 196:  92% 249/270 [02:47<07:18, 20.90s/it, loss=0.017, v_num=ypmf]Epoch 196:  92% 249/270 [02:47<07:18, 20.90s/it, loss=0.017, v_num=ypmf]Epoch 196:  92% 249/270 [02:47<07:19, 20.92s/it, loss=0.0169, v_num=ypmf]Epoch 196:  93% 250/270 [02:47<06:12, 18.63s/it, loss=0.0169, v_num=ypmf]Epoch 196:  93% 250/270 [02:47<06:12, 18.63s/it, loss=0.0169, v_num=ypmf]Epoch 196:  93% 250/270 [02:47<06:13, 18.65s/it, loss=0.0168, v_num=ypmf]
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 279080. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 349567. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 341470. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 332165. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 293029. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 318627. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 364778. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 323645. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 297714. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 271657. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 312534. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 278336. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batchValidation: 0it [00:00, ?it/s][A_size` from an ambiguous collection. The batch size we found is 350211. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 271869. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 309684. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 309015. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 303935. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 274434. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 276912. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 329510. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 312160. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 332239. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 266938. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 273785. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(

Validation:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.26it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.26it/s][AEpoch 196:  93% 251/270 [02:49<05:21, 16.91s/it, loss=0.0168, v_num=ypmf]Epoch 196:  93% 251/270 [02:49<05:21, 16.91s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  10% 2/20 [00:02<00:30,  1.68s/it][A
Validation DataLoader 0:  10% 2/20 [00:02<00:30,  1.68s/it][AEpoch 196:  93% 252/270 [02:51<04:40, 15.61s/it, loss=0.0168, v_num=ypmf]Epoch 196:  93% 252/270 [02:51<04:40, 15.61s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  15% 3/20 [00:04<00:25,  1.53s/it][A
Validation DataLoader 0:  15% 3/20 [00:04<00:25,  1.53s/it][AEpoch 196:  94% 253/270 [02:53<04:05, 14.42s/it, loss=0.0168, v_num=ypmf]Epoch 196:  94% 253/270 [02:53<04:05, 14.42s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  20% 4/20 [00:05<00:19,  1.20s/it][A
Validation DataLoader 0:  20% 4/20 [00:05<00:19,  1.20s/it][AEpoch 196:  94% 254/270 [02:53<03:33, 13.36s/it, loss=0.0168, v_num=ypmf]Epoch 196:  94% 254/270 [02:53<03:33, 13.36s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  25% 5/20 [00:05<00:16,  1.10s/it][A
Validation DataLoader 0:  25% 5/20 [00:05<00:16,  1.10s/it][AEpoch 196:  94% 255/270 [02:54<03:07, 12.47s/it, loss=0.0168, v_num=ypmf]Epoch 196:  94% 255/270 [02:54<03:07, 12.47s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  30% 6/20 [00:07<00:15,  1.12s/it][A
Validation DataLoader 0:  30% 6/20 [00:07<00:15,  1.12s/it][AEpoch 196:  95% 256/270 [02:55<02:44, 11.72s/it, loss=0.0168, v_num=ypmf]Epoch 196:  95% 256/270 [02:55<02:44, 11.72s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  35% 7/20 [00:09<00:18,  1.41s/it][A
Validation DataLoader 0:  35% 7/20 [00:09<00:18,  1.41s/it][AEpoch 196:  95% 257/270 [02:57<02:24, 11.11s/it, loss=0.0168, v_num=ypmf]Epoch 196:  95% 257/270 [02:57<02:24, 11.11s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  40% 8/20 [00:10<00:17,  1.43s/it][A
Validation DataLoader 0:  40% 8/20 [00:10<00:17,  1.43s/it][AEpoch 196:  96% 258/270 [02:59<02:06, 10.55s/it, loss=0.0168, v_num=ypmf]Epoch 196:  96% 258/270 [02:59<02:06, 10.55s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  45% 9/20 [00:11<00:13,  1.21s/it][A
Validation DataLoader 0:  45% 9/20 [00:11<00:13,  1.21s/it][AEpoch 196:  96% 259/270 [03:00<01:50, 10.00s/it, loss=0.0168, v_num=ypmf]Epoch 196:  96% 259/270 [03:00<01:50, 10.00s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  50% 10/20 [00:12<00:12,  1.22s/it][A
Validation DataLoader 0:  50% 10/20 [00:12<00:12,  1.22s/it][AEpoch 196:  96% 260/270 [03:01<01:35,  9.54s/it, loss=0.0168, v_num=ypmf]Epoch 196:  96% 260/270 [03:01<01:35,  9.54s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  55% 11/20 [00:13<00:09,  1.07s/it][A
Validation DataLoader 0:  55% 11/20 [00:13<00:09,  1.07s/it][AEpoch 196:  97% 261/270 [03:01<01:21,  9.10s/it, loss=0.0168, v_num=ypmf]Epoch 196:  97% 261/270 [03:01<01:21,  9.10s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  60% 12/20 [00:14<00:09,  1.22s/it][A
Validation DataLoader 0:  60% 12/20 [00:14<00:09,  1.22s/it][AEpoch 196:  97% 262/270 [03:03<01:09,  8.74s/it, loss=0.0168, v_num=ypmf]Epoch 196:  97% 262/270 [03:03<01:09,  8.74s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  65% 13/20 [00:15<00:07,  1.11s/it][A
Validation DataLoader 0:  65% 13/20 [00:15<00:07,  1.11s/it][AEpoch 196:  97% 263/270 [03:04<00:58,  8.38s/it, loss=0.0168, v_num=ypmf]Epoch 196:  97% 263/270 [03:04<00:58,  8.38s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  70% 14/20 [00:16<00:05,  1.02it/s][A
Validation DataLoader 0:  70% 14/20 [00:16<00:05,  1.02it/s][AEpoch 196:  98% 264/270 [03:05<00:48,  8.05s/it, loss=0.0168, v_num=ypmf]Epoch 196:  98% 264/270 [03:05<00:48,  8.05s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  75% 15/20 [00:18<00:06,  1.24s/it][A
Validation DataLoader 0:  75% 15/20 [00:18<00:06,  1.24s/it][AEpoch 196:  98% 265/270 [03:06<00:38,  7.79s/it, loss=0.0168, v_num=ypmf]Epoch 196:  98% 265/270 [03:06<00:38,  7.79s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  80% 16/20 [00:19<00:05,  1.33s/it][A
Validation DataLoader 0:  80% 16/20 [00:19<00:05,  1.33s/it][AEpoch 196:  99% 266/270 [03:08<00:30,  7.54s/it, loss=0.0168, v_num=ypmf]Epoch 196:  99% 266/270 [03:08<00:30,  7.54s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  85% 17/20 [00:21<00:04,  1.34s/it][A
Validation DataLoader 0:  85% 17/20 [00:21<00:04,  1.34s/it][AEpoch 196:  99% 267/270 [03:09<00:21,  7.30s/it, loss=0.0168, v_num=ypmf]Epoch 196:  99% 267/270 [03:09<00:21,  7.30s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  90% 18/20 [00:21<00:02,  1.14s/it][A
Validation DataLoader 0:  90% 18/20 [00:21<00:02,  1.14s/it][AEpoch 196:  99% 268/270 [03:10<00:14,  7.06s/it, loss=0.0168, v_num=ypmf]Epoch 196:  99% 268/270 [03:10<00:14,  7.06s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0:  95% 19/20 [00:23<00:01,  1.33s/it][A
Validation DataLoader 0:  95% 19/20 [00:23<00:01,  1.33s/it][AEpoch 196: 100% 269/270 [03:12<00:06,  6.87s/it, loss=0.0168, v_num=ypmf]Epoch 196: 100% 269/270 [03:12<00:06,  6.87s/it, loss=0.0168, v_num=ypmf]
Validation DataLoader 0: 100% 20/20 [00:24<00:00,  1.15s/it][A
Validation DataLoader 0: 100% 20/20 [00:24<00:00,  1.15s/it][AEpoch 196: 100% 270/270 [03:13<00:00,  6.66s/it, loss=0.0168, v_num=ypmf]Epoch 196: 100% 270/270 [03:13<00:00,  6.66s/it, loss=0.0168, v_num=ypmf]Epoch 196: 100% 270/270 [03:13<00:00,  6.67s/it, loss=0.0168, v_num=ypmf]
                                                            [AEpoch 196: 100% 270/270 [03:13<00:00,  6.67s/it, loss=0.0168, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 196:   0% 0/270 [00:00<00:00, -6479661.95it/s, loss=0.0168, v_num=ypmf]Epoch 197:   0% 0/270 [00:00<00:00, -1609597.55it/s, loss=0.0168, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 197:   0% 1/270 [00:03<-1:59:56, -66.92it/s, loss=0.0168, v_num=ypmf]  Epoch 197:   0% 1/270 [00:03<-1:59:56, -66.91it/s, loss=0.0168, v_num=ypmf]Epoch 197:   0% 1/270 [00:03<-1:59:56, -64.51it/s, loss=0.0167, v_num=ypmf]Epoch 197:   1% 2/270 [00:04<-1:59:56, -57.91it/s, loss=0.0167, v_num=ypmf]Epoch 197:   1% 2/270 [00:04<-1:59:56, -57.91it/s, loss=0.0167, v_num=ypmf]Epoch 197:   1% 2/270 [00:04<-1:59:56, -54.38it/s, loss=0.0168, v_num=ypmf]Epoch 197:   1% 3/270 [00:04<-1:59:55, -49.93it/s, loss=0.0168, v_num=ypmf]Epoch 197:   1% 3/270 [00:04<-1:59:55, -49.92it/s, loss=0.0168, v_num=ypmf]Epoch 197:   1% 3/270 [00:04<-1:59:55, -47.89it/s, loss=0.0168, v_num=ypmf]Epoch 197:   1% 4/270 [00:05<-1:59:55, -44.36it/s, loss=0.0168, v_num=ypmf]Epoch 197:   1% 4/270 [00:05<-1:59:55, -44.36it/s, loss=0.0168, v_num=ypmf]Epoch 197:   1% 4/270 [00:05<-1:59:54, -42.07it/s, loss=0.0167, v_num=ypmf]Epoch 197:   2% 5/270 [00:06<-1:59:54, -39.04it/s, loss=0.0167, v_num=ypmf]Epoch 197:   2% 5/270 [00:06<-1:59:54, -39.03it/s, loss=0.0167, v_num=ypmf]Epoch 197:   2% 5/270 [00:06<-1:59:54, -38.04it/s, loss=0.0166, v_num=ypmf]Epoch 197:   2% 6/270 [00:06<-1:59:53, -35.86it/s, loss=0.0166, v_num=ypmf]Epoch 197:   2% 6/270 [00:06<-1:59:53, -35.86it/s, loss=0.0166, v_num=ypmf]Epoch 197:   2% 6/270 [00:06<-1:59:53, -34.53it/s, loss=0.0166, v_num=ypmf]Epoch 197:   3% 7/270 [00:07<-1:59:52, -32.78it/s, loss=0.0166, v_num=ypmf]Epoch 197:   3% 7/270 [00:07<-1:59:52, -32.77it/s, loss=0.0166, v_num=ypmf]Epoch 197:   3% 7/270 [00:07<-1:59:52, -31.91it/s, loss=0.0166, v_num=ypmf]Epoch 197:   3% 8/270 [00:07<-1:59:52, -30.11it/s, loss=0.0166, v_num=ypmf]Epoch 197:   3% 8/270 [00:07<-1:59:52, -30.11it/s, loss=0.0166, v_num=ypmf]Epoch 197:   3% 8/270 [00:07<-1:59:52, -29.61it/s, loss=0.0165, v_num=ypmf]Epoch 197:   3% 9/270 [00:08<-1:59:51, -27.84it/s, loss=0.0165, v_num=ypmf]Epoch 197:   3% 9/270 [00:08<-1:59:51, -27.84it/s, loss=0.0165, v_num=ypmf]Epoch 197:   3% 9/270 [00:08<-1:59:51, -27.35it/s, loss=0.0166, v_num=ypmf]Epoch 197:   4% 10/270 [00:08<-1:59:50, -25.99it/s, loss=0.0166, v_num=ypmf]Epoch 197:   4% 10/270 [00:08<-1:59:50, -25.99it/s, loss=0.0166, v_num=ypmf]Epoch 197:   4% 10/270 [00:09<-1:59:50, -25.62it/s, loss=0.0165, v_num=ypmf]Epoch 197:   4% 11/270 [00:09<-1:59:50, -24.56it/s, loss=0.0165, v_num=ypmf]Epoch 197:   4% 11/270 [00:09<-1:59:50, -24.56it/s, loss=0.0165, v_num=ypmf]Epoch 197:   4% 11/270 [00:09<-1:59:50, -23.65it/s, loss=0.0165, v_num=ypmf]Epoch 197:   4% 12/270 [00:10<-1:59:49, -22.69it/s, loss=0.0165, v_num=ypmf]Epoch 197:   4% 12/270 [00:10<-1:59:49, -22.69it/s, loss=0.0165, v_num=ypmf]Epoch 197:   4% 12/270 [00:10<-1:59:49, -22.41it/s, loss=0.0165, v_num=ypmf]Epoch 197:   5% 13/270 [00:10<-1:59:49, -21.60it/s, loss=0.0165, v_num=ypmf]Epoch 197:   5% 13/270 [00:10<-1:59:49, -21.60it/s, loss=0.0165, v_num=ypmf]Epoch 197:   5% 13/270 [00:10<-1:59:48, -21.11it/s, loss=0.0166, v_num=ypmf]Epoch 197:   5% 14/270 [00:11<-1:59:48, -20.36it/s, loss=0.0166, v_num=ypmf]Epoch 197:   5% 14/270 [00:11<-1:59:48, -20.36it/s, loss=0.0166, v_num=ypmf]Epoch 197:   5% 14/270 [00:11<-1:59:48, -19.75it/s, loss=0.0166, v_num=ypmf]Epoch 197:   6% 15/270 [00:11<-1:59:47, -19.04it/s, loss=0.0166, v_num=ypmf]Epoch 197:   6% 15/270 [00:11<-1:59:47, -19.04it/s, loss=0.0166, v_num=ypmf]Epoch 197:   6% 15/270 [00:11<-1:59:47, -18.84it/s, loss=0.0166, v_num=ypmf]Epoch 197:   6% 16/270 [00:12<-1:59:46, -18.01it/s, loss=0.0166, v_num=ypmf]Epoch 197:   6% 16/270 [00:12<-1:59:46, -18.01it/s, loss=0.0166, v_num=ypmf]Epoch 197:   6% 16/270 [00:12<-1:59:46, -17.77it/s, loss=0.0165, v_num=ypmf]Epoch 197:   6% 17/270 [00:12<-1:59:46, -17.26it/s, loss=0.0165, v_num=ypmf]Epoch 197:   6% 17/270 [00:12<-1:59:46, -17.26it/s, loss=0.0165, v_num=ypmf]Epoch 197:   6% 17/270 [00:13<-1:59:46, -17.00it/s, loss=0.0167, v_num=ypmf]Epoch 197:   7% 18/270 [00:14<-1:59:45, -15.80it/s, loss=0.0167, v_num=ypmf]Epoch 197:   7% 18/270 [00:14<-1:59:45, -15.80it/s, loss=0.0167, v_num=ypmf]Epoch 197:   7% 18/270 [00:14<-1:59:44, -15.68it/s, loss=0.0167, v_num=ypmf]Epoch 197:   7% 19/270 [00:14<-1:59:44, -15.21it/s, loss=0.0167, v_num=ypmf]Epoch 197:   7% 19/270 [00:14<-1:59:44, -15.21it/s, loss=0.0167, v_num=ypmf]Epoch 197:   7% 19/270 [00:14<-1:59:44, -15.03it/s, loss=0.0168, v_num=ypmf]Epoch 197:   7% 20/270 [00:16<-1:59:42, -13.77it/s, loss=0.0168, v_num=ypmf]Epoch 197:   7% 20/270 [00:16<-1:59:42, -13.77it/s, loss=0.0168, v_num=ypmf]Epoch 197:   7% 20/270 [00:16<-1:59:42, -13.67it/s, loss=0.0169, v_num=ypmf]Epoch 197:   8% 21/270 [00:16<-1:59:42, -13.31it/s, loss=0.0169, v_num=ypmf]Epoch 197:   8% 21/270 [00:16<-1:59:42, -13.31it/s, loss=0.0169, v_num=ypmf]Epoch 197:   8% 21/270 [00:16<-1:59:42, -13.17it/s, loss=0.0168, v_num=ypmf]Epoch 197:   8% 22/270 [00:17<-1:59:41, -12.77it/s, loss=0.0168, v_num=ypmf]Epoch 197:   8% 22/270 [00:17<-1:59:41, -12.77it/s, loss=0.0168, v_num=ypmf]Epoch 197:   8% 22/270 [00:17<-1:59:41, -12.63it/s, loss=0.0168, v_num=ypmf]Epoch 197:   9% 23/270 [00:17<-1:59:40, -12.32it/s, loss=0.0168, v_num=ypmf]Epoch 197:   9% 23/270 [00:17<-1:59:40, -12.32it/s, loss=0.0168, v_num=ypmf]Epoch 197:   9% 23/270 [00:17<-1:59:40, -12.12it/s, loss=0.0168, v_num=ypmf]Epoch 197:   9% 24/270 [00:18<-1:59:40, -11.84it/s, loss=0.0168, v_num=ypmf]Epoch 197:   9% 24/270 [00:18<-1:59:40, -11.84it/s, loss=0.0168, v_num=ypmf]Epoch 197:   9% 24/270 [00:18<-1:59:39, -11.69it/s, loss=0.0169, v_num=ypmf]Epoch 197:   9% 25/270 [00:19<-1:59:39, -11.35it/s, loss=0.0169, v_num=ypmf]Epoch 197:   9% 25/270 [00:19<-1:59:39, -11.35it/s, loss=0.0169, v_num=ypmf]Epoch 197:   9% 25/270 [00:19<-1:59:39, -11.26it/s, loss=0.017, v_num=ypmf] Epoch 197:  10% 26/270 [00:19<-1:59:38, -11.00it/s, loss=0.017, v_num=ypmf]Epoch 197:  10% 26/270 [00:19<-1:59:38, -11.00it/s, loss=0.017, v_num=ypmf]Epoch 197:  10% 26/270 [00:19<-1:59:38, -10.93it/s, loss=0.0171, v_num=ypmf]Epoch 197:  10% 27/270 [00:20<-1:59:38, -10.63it/s, loss=0.0171, v_num=ypmf]Epoch 197:  10% 27/270 [00:20<-1:59:38, -10.63it/s, loss=0.0171, v_num=ypmf]Epoch 197:  10% 27/270 [00:20<-1:59:37, -10.56it/s, loss=0.0171, v_num=ypmf]Epoch 197:  10% 28/270 [00:20<-1:59:37, -10.33it/s, loss=0.0171, v_num=ypmf]Epoch 197:  10% 28/270 [00:20<-1:59:37, -10.33it/s, loss=0.0171, v_num=ypmf]Epoch 197:  10% 28/270 [00:20<-1:59:37, -10.25it/s, loss=0.0171, v_num=ypmf]Epoch 197:  11% 29/270 [00:21<-1:59:36, -10.02it/s, loss=0.0171, v_num=ypmf]Epoch 197:  11% 29/270 [00:21<-1:59:36, -10.02it/s, loss=0.0171, v_num=ypmf]Epoch 197:  11% 29/270 [00:21<-1:59:36, -9.91it/s, loss=0.017, v_num=ypmf]  Epoch 197:  11% 30/270 [00:21<-1:59:36, -9.71it/s, loss=0.017, v_num=ypmf]Epoch 197:  11% 30/270 [00:21<-1:59:36, -9.71it/s, loss=0.017, v_num=ypmf]Epoch 197:  11% 30/270 [00:21<-1:59:36, -9.62it/s, loss=0.017, v_num=ypmf]Epoch 197:  11% 31/270 [00:22<-1:59:35, -9.40it/s, loss=0.017, v_num=ypmf]Epoch 197:  11% 31/270 [00:22<-1:59:35, -9.40it/s, loss=0.017, v_num=ypmf]Epoch 197:  11% 31/270 [00:22<-1:59:35, -9.34it/s, loss=0.017, v_num=ypmf]Epoch 197:  12% 32/270 [00:22<-1:59:34, -9.15it/s, loss=0.017, v_num=ypmf]Epoch 197:  12% 32/270 [00:22<-1:59:34, -9.15it/s, loss=0.017, v_num=ypmf]Epoch 197:  12% 32/270 [00:23<-1:59:34, -9.08it/s, loss=0.0169, v_num=ypmf]Epoch 197:  12% 33/270 [00:23<-1:59:34, -8.86it/s, loss=0.0169, v_num=ypmf]Epoch 197:  12% 33/270 [00:23<-1:59:34, -8.86it/s, loss=0.0169, v_num=ypmf]Epoch 197:  12% 33/270 [00:23<-1:59:34, -8.81it/s, loss=0.0168, v_num=ypmf]Epoch 197:  13% 34/270 [00:23<-1:59:33, -8.64it/s, loss=0.0168, v_num=ypmf]Epoch 197:  13% 34/270 [00:23<-1:59:33, -8.64it/s, loss=0.0168, v_num=ypmf]Epoch 197:  13% 34/270 [00:24<-1:59:33, -8.60it/s, loss=0.0169, v_num=ypmf]Epoch 197:  13% 35/270 [00:24<-1:59:33, -8.47it/s, loss=0.0169, v_num=ypmf]Epoch 197:  13% 35/270 [00:24<-1:59:33, -8.47it/s, loss=0.0169, v_num=ypmf]Epoch 197:  13% 35/270 [00:24<-1:59:32, -8.38it/s, loss=0.0171, v_num=ypmf]Epoch 197:  13% 36/270 [00:25<-1:59:32, -8.08it/s, loss=0.0171, v_num=ypmf]Epoch 197:  13% 36/270 [00:25<-1:59:32, -8.08it/s, loss=0.0171, v_num=ypmf]Epoch 197:  13% 36/270 [00:25<-1:59:31, -8.03it/s, loss=0.017, v_num=ypmf] Epoch 197:  14% 37/270 [00:25<-1:59:31, -7.88it/s, loss=0.017, v_num=ypmf]Epoch 197:  14% 37/270 [00:25<-1:59:31, -7.88it/s, loss=0.017, v_num=ypmf]Epoch 197:  14% 37/270 [00:26<-1:59:31, -7.81it/s, loss=0.017, v_num=ypmf]Epoch 197:  14% 38/270 [00:26<-1:59:30, -7.66it/s, loss=0.017, v_num=ypmf]Epoch 197:  14% 38/270 [00:26<-1:59:30, -7.66it/s, loss=0.017, v_num=ypmf]Epoch 197:  14% 38/270 [00:26<-1:59:30, -7.60it/s, loss=0.0171, v_num=ypmf]Epoch 197:  14% 39/270 [00:27<-1:59:29, -7.44it/s, loss=0.0171, v_num=ypmf]Epoch 197:  14% 39/270 [00:27<-1:59:29, -7.44it/s, loss=0.0171, v_num=ypmf]Epoch 197:  14% 39/270 [00:27<-1:59:29, -7.39it/s, loss=0.0171, v_num=ypmf]Epoch 197:  15% 40/270 [00:27<-1:59:29, -7.28it/s, loss=0.0171, v_num=ypmf]Epoch 197:  15% 40/270 [00:27<-1:59:29, -7.28it/s, loss=0.0171, v_num=ypmf]Epoch 197:  15% 40/270 [00:27<-1:59:29, -7.23it/s, loss=0.0172, v_num=ypmf]Epoch 197:  15% 41/270 [00:28<-1:59:28, -7.10it/s, loss=0.0172, v_num=ypmf]Epoch 197:  15% 41/270 [00:28<-1:59:28, -7.10it/s, loss=0.0172, v_num=ypmf]Epoch 197:  15% 41/270 [00:28<-1:59:28, -7.01it/s, loss=0.0174, v_num=ypmf]Epoch 197:  16% 42/270 [00:28<-1:59:27, -6.91it/s, loss=0.0174, v_num=ypmf]Epoch 197:  16% 42/270 [00:28<-1:59:27, -6.91it/s, loss=0.0174, v_num=ypmf]Epoch 197:  16% 42/270 [00:29<-1:59:27, -6.80it/s, loss=0.0176, v_num=ypmf]Epoch 197:  16% 43/270 [00:29<-1:59:26, -6.66it/s, loss=0.0176, v_num=ypmf]Epoch 197:  16% 43/270 [00:29<-1:59:26, -6.66it/s, loss=0.0176, v_num=ypmf]Epoch 197:  16% 43/270 [00:29<-1:59:26, -6.62it/s, loss=0.0175, v_num=ypmf]Epoch 197:  16% 44/270 [00:30<-1:59:26, -6.50it/s, loss=0.0175, v_num=ypmf]Epoch 197:  16% 44/270 [00:30<-1:59:26, -6.50it/s, loss=0.0175, v_num=ypmf]Epoch 197:  16% 44/270 [00:30<-1:59:25, -6.46it/s, loss=0.0174, v_num=ypmf]Epoch 197:  17% 45/270 [00:30<-1:59:25, -6.37it/s, loss=0.0174, v_num=ypmf]Epoch 197:  17% 45/270 [00:30<-1:59:25, -6.37it/s, loss=0.0174, v_num=ypmf]Epoch 197:  17% 45/270 [00:31<-1:59:25, -6.32it/s, loss=0.0175, v_num=ypmf]Epoch 197:  17% 46/270 [00:31<-1:59:24, -6.22it/s, loss=0.0175, v_num=ypmf]Epoch 197:  17% 46/270 [00:31<-1:59:24, -6.22it/s, loss=0.0175, v_num=ypmf]Epoch 197:  17% 46/270 [00:31<-1:59:24, -6.18it/s, loss=0.0175, v_num=ypmf]Epoch 197:  17% 47/270 [00:31<-1:59:24, -6.08it/s, loss=0.0175, v_num=ypmf]Epoch 197:  17% 47/270 [00:31<-1:59:24, -6.08it/s, loss=0.0175, v_num=ypmf]Epoch 197:  17% 47/270 [00:32<-1:59:23, -6.02it/s, loss=0.0176, v_num=ypmf]Epoch 197:  18% 48/270 [00:32<-1:59:23, -5.92it/s, loss=0.0176, v_num=ypmf]Epoch 197:  18% 48/270 [00:32<-1:59:23, -5.92it/s, loss=0.0176, v_num=ypmf]Epoch 197:  18% 48/270 [00:32<-1:59:23, -5.89it/s, loss=0.0176, v_num=ypmf]Epoch 197:  18% 49/270 [00:33<-1:59:22, -5.79it/s, loss=0.0176, v_num=ypmf]Epoch 197:  18% 49/270 [00:33<-1:59:22, -5.79it/s, loss=0.0176, v_num=ypmf]Epoch 197:  18% 49/270 [00:33<-1:59:22, -5.77it/s, loss=0.0176, v_num=ypmf]Epoch 197:  19% 50/270 [00:33<-1:59:22, -5.68it/s, loss=0.0176, v_num=ypmf]Epoch 197:  19% 50/270 [00:33<-1:59:22, -5.68it/s, loss=0.0176, v_num=ypmf]Epoch 197:  19% 50/270 [00:33<-1:59:22, -5.65it/s, loss=0.0177, v_num=ypmf]Epoch 197:  19% 51/270 [00:34<-1:59:21, -5.56it/s, loss=0.0177, v_num=ypmf]Epoch 197:  19% 51/270 [00:34<-1:59:21, -5.56it/s, loss=0.0177, v_num=ypmf]Epoch 197:  19% 51/270 [00:34<-1:59:21, -5.53it/s, loss=0.0177, v_num=ypmf]Epoch 197:  19% 52/270 [00:34<-1:59:20, -5.44it/s, loss=0.0177, v_num=ypmf]Epoch 197:  19% 52/270 [00:34<-1:59:20, -5.44it/s, loss=0.0177, v_num=ypmf]Epoch 197:  19% 52/270 [00:34<-1:59:20, -5.42it/s, loss=0.0177, v_num=ypmf]Epoch 197:  20% 53/270 [00:35<-1:59:19, -5.29it/s, loss=0.0177, v_num=ypmf]Epoch 197:  20% 53/270 [00:35<-1:59:19, -5.29it/s, loss=0.0177, v_num=ypmf]Epoch 197:  20% 53/270 [00:35<-1:59:19, -5.27it/s, loss=0.0177, v_num=ypmf]Epoch 197:  20% 54/270 [00:36<-1:59:19, -5.19it/s, loss=0.0177, v_num=ypmf]Epoch 197:  20% 54/270 [00:36<-1:59:19, -5.19it/s, loss=0.0177, v_num=ypmf]Epoch 197:  20% 54/270 [00:36<-1:59:19, -5.17it/s, loss=0.0176, v_num=ypmf]Epoch 197:  20% 55/270 [00:37<-1:59:17, -4.94it/s, loss=0.0176, v_num=ypmf]Epoch 197:  20% 55/270 [00:37<-1:59:17, -4.94it/s, loss=0.0176, v_num=ypmf]Epoch 197:  20% 55/270 [00:37<-1:59:17, -4.92it/s, loss=0.0175, v_num=ypmf]Epoch 197:  21% 56/270 [00:38<-1:59:16, -4.84it/s, loss=0.0175, v_num=ypmf]Epoch 197:  21% 56/270 [00:38<-1:59:16, -4.84it/s, loss=0.0175, v_num=ypmf]Epoch 197:  21% 56/270 [00:38<-1:59:16, -4.82it/s, loss=0.0176, v_num=ypmf]Epoch 197:  21% 57/270 [00:38<-1:59:16, -4.75it/s, loss=0.0176, v_num=ypmf]Epoch 197:  21% 57/270 [00:38<-1:59:16, -4.75it/s, loss=0.0176, v_num=ypmf]Epoch 197:  21% 57/270 [00:38<-1:59:15, -4.72it/s, loss=0.0175, v_num=ypmf]Epoch 197:  21% 58/270 [00:39<-1:59:15, -4.65it/s, loss=0.0175, v_num=ypmf]Epoch 197:  21% 58/270 [00:39<-1:59:15, -4.65it/s, loss=0.0175, v_num=ypmf]Epoch 197:  21% 58/270 [00:39<-1:59:15, -4.63it/s, loss=0.0175, v_num=ypmf]Epoch 197:  22% 59/270 [00:39<-1:59:14, -4.56it/s, loss=0.0175, v_num=ypmf]Epoch 197:  22% 59/270 [00:39<-1:59:14, -4.56it/s, loss=0.0175, v_num=ypmf]Epoch 197:  22% 59/270 [00:40<-1:59:14, -4.55it/s, loss=0.0175, v_num=ypmf]Epoch 197:  22% 60/270 [00:40<-1:59:14, -4.48it/s, loss=0.0175, v_num=ypmf]Epoch 197:  22% 60/270 [00:40<-1:59:14, -4.48it/s, loss=0.0175, v_num=ypmf]Epoch 197:  22% 60/270 [00:40<-1:59:13, -4.46it/s, loss=0.0174, v_num=ypmf]Epoch 197:  23% 61/270 [00:40<-1:59:13, -4.40it/s, loss=0.0174, v_num=ypmf]Epoch 197:  23% 61/270 [00:40<-1:59:13, -4.40it/s, loss=0.0174, v_num=ypmf]Epoch 197:  23% 61/270 [00:41<-1:59:13, -4.37it/s, loss=0.0173, v_num=ypmf]Epoch 197:  23% 62/270 [00:41<-1:59:12, -4.31it/s, loss=0.0173, v_num=ypmf]Epoch 197:  23% 62/270 [00:41<-1:59:12, -4.31it/s, loss=0.0173, v_num=ypmf]Epoch 197:  23% 62/270 [00:41<-1:59:12, -4.28it/s, loss=0.0172, v_num=ypmf]Epoch 197:  23% 63/270 [00:42<-1:59:11, -4.22it/s, loss=0.0172, v_num=ypmf]Epoch 197:  23% 63/270 [00:42<-1:59:11, -4.22it/s, loss=0.0172, v_num=ypmf]Epoch 197:  23% 63/270 [00:42<-1:59:11, -4.21it/s, loss=0.0173, v_num=ypmf]Epoch 197:  24% 64/270 [00:42<-1:59:11, -4.14it/s, loss=0.0173, v_num=ypmf]Epoch 197:  24% 64/270 [00:42<-1:59:11, -4.14it/s, loss=0.0173, v_num=ypmf]Epoch 197:  24% 64/270 [00:42<-1:59:11, -4.13it/s, loss=0.0174, v_num=ypmf]Epoch 197:  24% 65/270 [00:43<-1:59:10, -4.07it/s, loss=0.0174, v_num=ypmf]Epoch 197:  24% 65/270 [00:43<-1:59:10, -4.07it/s, loss=0.0174, v_num=ypmf]Epoch 197:  24% 65/270 [00:43<-1:59:10, -4.05it/s, loss=0.0172, v_num=ypmf]Epoch 197:  24% 66/270 [00:43<-1:59:09, -3.98it/s, loss=0.0172, v_num=ypmf]Epoch 197:  24% 66/270 [00:43<-1:59:09, -3.98it/s, loss=0.0172, v_num=ypmf]Epoch 197:  24% 66/270 [00:43<-1:59:09, -3.98it/s, loss=0.017, v_num=ypmf] Epoch 197:  25% 67/270 [00:44<-1:59:09, -3.92it/s, loss=0.017, v_num=ypmf]Epoch 197:  25% 67/270 [00:44<-1:59:09, -3.92it/s, loss=0.017, v_num=ypmf]Epoch 197:  25% 67/270 [00:44<-1:59:08, -3.90it/s, loss=0.017, v_num=ypmf]Epoch 197:  25% 68/270 [00:44<-1:59:08, -3.85it/s, loss=0.017, v_num=ypmf]Epoch 197:  25% 68/270 [00:44<-1:59:08, -3.85it/s, loss=0.017, v_num=ypmf]Epoch 197:  25% 68/270 [00:45<-1:59:08, -3.82it/s, loss=0.017, v_num=ypmf]Epoch 197:  26% 69/270 [00:45<-1:59:07, -3.78it/s, loss=0.017, v_num=ypmf]Epoch 197:  26% 69/270 [00:45<-1:59:07, -3.78it/s, loss=0.017, v_num=ypmf]Epoch 197:  26% 69/270 [00:45<-1:59:07, -3.74it/s, loss=0.0172, v_num=ypmf]Epoch 197:  26% 70/270 [00:46<-1:59:06, -3.69it/s, loss=0.0172, v_num=ypmf]Epoch 197:  26% 70/270 [00:46<-1:59:06, -3.69it/s, loss=0.0172, v_num=ypmf]Epoch 197:  26% 70/270 [00:48<-1:59:04, -3.54it/s, loss=0.0171, v_num=ypmf]Epoch 197:  26% 71/270 [00:48<-1:59:03, -3.49it/s, loss=0.0171, v_num=ypmf]Epoch 197:  26% 71/270 [00:48<-1:59:03, -3.49it/s, loss=0.0171, v_num=ypmf]Epoch 197:  26% 71/270 [00:48<-1:59:03, -3.48it/s, loss=0.0171, v_num=ypmf]Epoch 197:  27% 72/270 [00:49<-1:59:03, -3.43it/s, loss=0.0171, v_num=ypmf]Epoch 197:  27% 72/270 [00:49<-1:59:03, -3.43it/s, loss=0.0171, v_num=ypmf]Epoch 197:  27% 72/270 [00:49<-1:59:03, -3.42it/s, loss=0.0172, v_num=ypmf]Epoch 197:  27% 73/270 [00:49<-1:59:02, -3.38it/s, loss=0.0172, v_num=ypmf]Epoch 197:  27% 73/270 [00:49<-1:59:02, -3.38it/s, loss=0.0172, v_num=ypmf]Epoch 197:  27% 73/270 [00:50<-1:59:02, -3.36it/s, loss=0.0173, v_num=ypmf]Epoch 197:  27% 74/270 [00:50<-1:59:01, -3.31it/s, loss=0.0173, v_num=ypmf]Epoch 197:  27% 74/270 [00:50<-1:59:01, -3.31it/s, loss=0.0173, v_num=ypmf]Epoch 197:  27% 74/270 [00:50<-1:59:01, -3.30it/s, loss=0.0173, v_num=ypmf]Epoch 197:  28% 75/270 [00:51<-1:59:01, -3.25it/s, loss=0.0173, v_num=ypmf]Epoch 197:  28% 75/270 [00:51<-1:59:01, -3.25it/s, loss=0.0173, v_num=ypmf]Epoch 197:  28% 75/270 [00:51<-1:59:00, -3.24it/s, loss=0.0172, v_num=ypmf]Epoch 197:  28% 76/270 [00:51<-1:59:00, -3.19it/s, loss=0.0172, v_num=ypmf]Epoch 197:  28% 76/270 [00:51<-1:59:00, -3.19it/s, loss=0.0172, v_num=ypmf]Epoch 197:  28% 76/270 [00:51<-1:59:00, -3.18it/s, loss=0.0171, v_num=ypmf]Epoch 197:  29% 77/270 [00:52<-1:58:59, -3.14it/s, loss=0.0171, v_num=ypmf]Epoch 197:  29% 77/270 [00:52<-1:58:59, -3.14it/s, loss=0.0171, v_num=ypmf]Epoch 197:  29% 77/270 [00:52<-1:58:59, -3.13it/s, loss=0.0172, v_num=ypmf]Epoch 197:  29% 78/270 [00:52<-1:58:58, -3.08it/s, loss=0.0172, v_num=ypmf]Epoch 197:  29% 78/270 [00:52<-1:58:58, -3.08it/s, loss=0.0172, v_num=ypmf]Epoch 197:  29% 78/270 [00:53<-1:58:58, -3.07it/s, loss=0.0172, v_num=ypmf]Epoch 197:  29% 79/270 [00:53<-1:58:58, -3.03it/s, loss=0.0172, v_num=ypmf]Epoch 197:  29% 79/270 [00:53<-1:58:58, -3.03it/s, loss=0.0172, v_num=ypmf]Epoch 197:  29% 79/270 [00:53<-1:58:57, -3.02it/s, loss=0.0171, v_num=ypmf]Epoch 197:  30% 80/270 [00:54<-1:58:57, -2.98it/s, loss=0.0171, v_num=ypmf]Epoch 197:  30% 80/270 [00:54<-1:58:57, -2.98it/s, loss=0.0171, v_num=ypmf]Epoch 197:  30% 80/270 [00:55<-1:58:55, -2.89it/s, loss=0.0171, v_num=ypmf]Epoch 197:  30% 81/270 [00:56<-1:58:54, -2.85it/s, loss=0.0171, v_num=ypmf]Epoch 197:  30% 81/270 [00:56<-1:58:54, -2.85it/s, loss=0.0171, v_num=ypmf]Epoch 197:  30% 81/270 [00:56<-1:58:54, -2.84it/s, loss=0.0171, v_num=ypmf]Epoch 197:  30% 82/270 [00:56<-1:58:54, -2.81it/s, loss=0.0171, v_num=ypmf]Epoch 197:  30% 82/270 [00:56<-1:58:54, -2.81it/s, loss=0.0171, v_num=ypmf]Epoch 197:  30% 82/270 [00:56<-1:58:53, -2.80it/s, loss=0.0169, v_num=ypmf]Epoch 197:  31% 83/270 [00:57<-1:58:53, -2.76it/s, loss=0.0169, v_num=ypmf]Epoch 197:  31% 83/270 [00:57<-1:58:53, -2.76it/s, loss=0.0169, v_num=ypmf]Epoch 197:  31% 83/270 [00:57<-1:58:52, -2.75it/s, loss=0.0168, v_num=ypmf]Epoch 197:  31% 84/270 [00:57<-1:58:52, -2.71it/s, loss=0.0168, v_num=ypmf]Epoch 197:  31% 84/270 [00:57<-1:58:52, -2.71it/s, loss=0.0168, v_num=ypmf]Epoch 197:  31% 84/270 [00:58<-1:58:52, -2.70it/s, loss=0.0169, v_num=ypmf]Epoch 197:  31% 85/270 [00:58<-1:58:51, -2.67it/s, loss=0.0169, v_num=ypmf]Epoch 197:  31% 85/270 [00:58<-1:58:51, -2.67it/s, loss=0.0169, v_num=ypmf]Epoch 197:  31% 85/270 [00:58<-1:58:51, -2.65it/s, loss=0.017, v_num=ypmf] Epoch 197:  32% 86/270 [00:59<-1:58:50, -2.61it/s, loss=0.017, v_num=ypmf]Epoch 197:  32% 86/270 [00:59<-1:58:50, -2.61it/s, loss=0.017, v_num=ypmf]Epoch 197:  32% 86/270 [00:59<-1:58:50, -2.60it/s, loss=0.0169, v_num=ypmf]Epoch 197:  32% 87/270 [01:00<-1:58:49, -2.56it/s, loss=0.0169, v_num=ypmf]Epoch 197:  32% 87/270 [01:00<-1:58:49, -2.56it/s, loss=0.0169, v_num=ypmf]Epoch 197:  32% 87/270 [01:00<-1:58:49, -2.56it/s, loss=0.0168, v_num=ypmf]Epoch 197:  33% 88/270 [01:00<-1:58:48, -2.52it/s, loss=0.0168, v_num=ypmf]Epoch 197:  33% 88/270 [01:00<-1:58:48, -2.52it/s, loss=0.0168, v_num=ypmf]Epoch 197:  33% 88/270 [01:00<-1:58:48, -2.52it/s, loss=0.0168, v_num=ypmf]Epoch 197:  33% 89/270 [01:01<-1:58:48, -2.49it/s, loss=0.0168, v_num=ypmf]Epoch 197:  33% 89/270 [01:01<-1:58:48, -2.49it/s, loss=0.0168, v_num=ypmf]Epoch 197:  33% 89/270 [01:01<-1:58:48, -2.48it/s, loss=0.0167, v_num=ypmf]Epoch 197:  33% 90/270 [01:01<-1:58:47, -2.45it/s, loss=0.0167, v_num=ypmf]Epoch 197:  33% 90/270 [01:01<-1:58:47, -2.45it/s, loss=0.0167, v_num=ypmf]Epoch 197:  33% 90/270 [01:01<-1:58:47, -2.44it/s, loss=0.0166, v_num=ypmf]Epoch 197:  34% 91/270 [01:02<-1:58:46, -2.40it/s, loss=0.0166, v_num=ypmf]Epoch 197:  34% 91/270 [01:02<-1:58:46, -2.40it/s, loss=0.0166, v_num=ypmf]Epoch 197:  34% 91/270 [01:02<-1:58:46, -2.40it/s, loss=0.0167, v_num=ypmf]Epoch 197:  34% 92/270 [01:02<-1:58:45, -2.37it/s, loss=0.0167, v_num=ypmf]Epoch 197:  34% 92/270 [01:02<-1:58:45, -2.37it/s, loss=0.0167, v_num=ypmf]Epoch 197:  34% 92/270 [01:03<-1:58:45, -2.36it/s, loss=0.0166, v_num=ypmf]Epoch 197:  34% 93/270 [01:03<-1:58:45, -2.33it/s, loss=0.0166, v_num=ypmf]Epoch 197:  34% 93/270 [01:03<-1:58:45, -2.33it/s, loss=0.0166, v_num=ypmf]Epoch 197:  34% 93/270 [01:03<-1:58:44, -2.32it/s, loss=0.0166, v_num=ypmf]Epoch 197:  35% 94/270 [01:04<-1:58:44, -2.29it/s, loss=0.0166, v_num=ypmf]Epoch 197:  35% 94/270 [01:04<-1:58:44, -2.29it/s, loss=0.0166, v_num=ypmf]Epoch 197:  35% 94/270 [01:04<-1:58:43, -2.28it/s, loss=0.0167, v_num=ypmf]Epoch 197:  35% 95/270 [01:04<-1:58:43, -2.26it/s, loss=0.0167, v_num=ypmf]Epoch 197:  35% 95/270 [01:04<-1:58:43, -2.26it/s, loss=0.0167, v_num=ypmf]Epoch 197:  35% 95/270 [01:04<-1:58:43, -2.25it/s, loss=0.0168, v_num=ypmf]Epoch 197:  36% 96/270 [01:05<-1:58:42, -2.22it/s, loss=0.0168, v_num=ypmf]Epoch 197:  36% 96/270 [01:05<-1:58:42, -2.22it/s, loss=0.0168, v_num=ypmf]Epoch 197:  36% 96/270 [01:05<-1:58:42, -2.21it/s, loss=0.0169, v_num=ypmf]Epoch 197:  36% 97/270 [01:05<-1:58:41, -2.18it/s, loss=0.0169, v_num=ypmf]Epoch 197:  36% 97/270 [01:05<-1:58:41, -2.18it/s, loss=0.0169, v_num=ypmf]Epoch 197:  36% 97/270 [01:06<-1:58:41, -2.17it/s, loss=0.0167, v_num=ypmf]Epoch 197:  36% 98/270 [01:06<-1:58:40, -2.14it/s, loss=0.0167, v_num=ypmf]Epoch 197:  36% 98/270 [01:06<-1:58:40, -2.14it/s, loss=0.0167, v_num=ypmf]Epoch 197:  36% 98/270 [01:06<-1:58:40, -2.14it/s, loss=0.0167, v_num=ypmf]Epoch 197:  37% 99/270 [01:07<-1:58:40, -2.11it/s, loss=0.0167, v_num=ypmf]Epoch 197:  37% 99/270 [01:07<-1:58:40, -2.11it/s, loss=0.0167, v_num=ypmf]Epoch 197:  37% 99/270 [01:08<-1:58:38, -2.08it/s, loss=0.0168, v_num=ypmf]Epoch 197:  37% 100/270 [01:08<-1:58:38, -2.05it/s, loss=0.0168, v_num=ypmf]Epoch 197:  37% 100/270 [01:08<-1:58:38, -2.05it/s, loss=0.0168, v_num=ypmf]Epoch 197:  37% 100/270 [01:08<-1:58:37, -2.04it/s, loss=0.0168, v_num=ypmf]Epoch 197:  37% 101/270 [01:09<-1:58:37, -2.02it/s, loss=0.0168, v_num=ypmf]Epoch 197:  37% 101/270 [01:09<-1:58:37, -2.02it/s, loss=0.0168, v_num=ypmf]Epoch 197:  37% 101/270 [01:09<-1:58:37, -2.01it/s, loss=0.0169, v_num=ypmf]Epoch 197:  38% 102/270 [01:09<-1:58:36, -1.99it/s, loss=0.0169, v_num=ypmf]Epoch 197:  38% 102/270 [01:09<-1:58:36, -1.99it/s, loss=0.0169, v_num=ypmf]Epoch 197:  38% 102/270 [01:10<-1:58:36, -1.98it/s, loss=0.0169, v_num=ypmf]Epoch 197:  38% 103/270 [01:10<-1:58:35, -1.96it/s, loss=0.0169, v_num=ypmf]Epoch 197:  38% 103/270 [01:10<-1:58:35, -1.96it/s, loss=0.0169, v_num=ypmf]Epoch 197:  38% 103/270 [01:10<-1:58:35, -1.95it/s, loss=0.017, v_num=ypmf] Epoch 197:  39% 104/270 [01:11<-1:58:34, -1.93it/s, loss=0.017, v_num=ypmf]Epoch 197:  39% 104/270 [01:11<-1:58:34, -1.93it/s, loss=0.017, v_num=ypmf]Epoch 197:  39% 104/270 [01:11<-1:58:34, -1.92it/s, loss=0.0169, v_num=ypmf]Epoch 197:  39% 105/270 [01:11<-1:58:34, -1.90it/s, loss=0.0169, v_num=ypmf]Epoch 197:  39% 105/270 [01:11<-1:58:34, -1.90it/s, loss=0.0169, v_num=ypmf]Epoch 197:  39% 105/270 [01:11<-1:58:33, -1.89it/s, loss=0.0169, v_num=ypmf]Epoch 197:  39% 106/270 [01:12<-1:58:33, -1.87it/s, loss=0.0169, v_num=ypmf]Epoch 197:  39% 106/270 [01:12<-1:58:33, -1.87it/s, loss=0.0169, v_num=ypmf]Epoch 197:  39% 106/270 [01:12<-1:58:32, -1.86it/s, loss=0.017, v_num=ypmf] Epoch 197:  40% 107/270 [01:12<-1:58:32, -1.84it/s, loss=0.017, v_num=ypmf]Epoch 197:  40% 107/270 [01:12<-1:58:32, -1.84it/s, loss=0.017, v_num=ypmf]Epoch 197:  40% 107/270 [01:13<-1:58:32, -1.83it/s, loss=0.017, v_num=ypmf]Epoch 197:  40% 108/270 [01:13<-1:58:31, -1.81it/s, loss=0.017, v_num=ypmf]Epoch 197:  40% 108/270 [01:13<-1:58:31, -1.81it/s, loss=0.017, v_num=ypmf]Epoch 197:  40% 108/270 [01:13<-1:58:31, -1.81it/s, loss=0.017, v_num=ypmf]Epoch 197:  40% 109/270 [01:13<-1:58:30, -1.79it/s, loss=0.017, v_num=ypmf]Epoch 197:  40% 109/270 [01:13<-1:58:30, -1.79it/s, loss=0.017, v_num=ypmf]Epoch 197:  40% 109/270 [01:14<-1:58:30, -1.78it/s, loss=0.0171, v_num=ypmf]Epoch 197:  41% 110/270 [01:14<-1:58:29, -1.75it/s, loss=0.0171, v_num=ypmf]Epoch 197:  41% 110/270 [01:14<-1:58:29, -1.75it/s, loss=0.0171, v_num=ypmf]Epoch 197:  41% 110/270 [01:14<-1:58:29, -1.75it/s, loss=0.017, v_num=ypmf] Epoch 197:  41% 111/270 [01:15<-1:58:29, -1.73it/s, loss=0.017, v_num=ypmf]Epoch 197:  41% 111/270 [01:15<-1:58:29, -1.73it/s, loss=0.017, v_num=ypmf]Epoch 197:  41% 111/270 [01:15<-1:58:28, -1.72it/s, loss=0.017, v_num=ypmf]Epoch 197:  41% 112/270 [01:15<-1:58:28, -1.70it/s, loss=0.017, v_num=ypmf]Epoch 197:  41% 112/270 [01:15<-1:58:28, -1.70it/s, loss=0.017, v_num=ypmf]Epoch 197:  41% 112/270 [01:16<-1:58:27, -1.70it/s, loss=0.0171, v_num=ypmf]Epoch 197:  42% 113/270 [01:16<-1:58:27, -1.68it/s, loss=0.0171, v_num=ypmf]Epoch 197:  42% 113/270 [01:16<-1:58:27, -1.68it/s, loss=0.0171, v_num=ypmf]Epoch 197:  42% 113/270 [01:16<-1:58:27, -1.67it/s, loss=0.0171, v_num=ypmf]Epoch 197:  42% 114/270 [01:16<-1:58:26, -1.65it/s, loss=0.0171, v_num=ypmf]Epoch 197:  42% 114/270 [01:16<-1:58:26, -1.65it/s, loss=0.0171, v_num=ypmf]Epoch 197:  42% 114/270 [01:17<-1:58:26, -1.65it/s, loss=0.0171, v_num=ypmf]Epoch 197:  43% 115/270 [01:17<-1:58:25, -1.63it/s, loss=0.0171, v_num=ypmf]Epoch 197:  43% 115/270 [01:17<-1:58:25, -1.63it/s, loss=0.0171, v_num=ypmf]Epoch 197:  43% 115/270 [01:17<-1:58:25, -1.62it/s, loss=0.017, v_num=ypmf] Epoch 197:  43% 116/270 [01:18<-1:58:24, -1.60it/s, loss=0.017, v_num=ypmf]Epoch 197:  43% 116/270 [01:18<-1:58:24, -1.60it/s, loss=0.017, v_num=ypmf]Epoch 197:  43% 116/270 [01:18<-1:58:24, -1.60it/s, loss=0.0169, v_num=ypmf]Epoch 197:  43% 117/270 [01:18<-1:58:23, -1.57it/s, loss=0.0169, v_num=ypmf]Epoch 197:  43% 117/270 [01:18<-1:58:23, -1.57it/s, loss=0.0169, v_num=ypmf]Epoch 197:  43% 117/270 [01:19<-1:58:23, -1.57it/s, loss=0.0169, v_num=ypmf]Epoch 197:  44% 118/270 [01:19<-1:58:22, -1.55it/s, loss=0.0169, v_num=ypmf]Epoch 197:  44% 118/270 [01:19<-1:58:22, -1.55it/s, loss=0.0169, v_num=ypmf]Epoch 197:  44% 118/270 [01:19<-1:58:22, -1.54it/s, loss=0.0171, v_num=ypmf]Epoch 197:  44% 119/270 [01:20<-1:58:21, -1.52it/s, loss=0.0171, v_num=ypmf]Epoch 197:  44% 119/270 [01:20<-1:58:21, -1.52it/s, loss=0.0171, v_num=ypmf]Epoch 197:  44% 119/270 [01:20<-1:58:21, -1.52it/s, loss=0.017, v_num=ypmf] Epoch 197:  44% 120/270 [01:20<-1:58:21, -1.50it/s, loss=0.017, v_num=ypmf]Epoch 197:  44% 120/270 [01:20<-1:58:21, -1.50it/s, loss=0.017, v_num=ypmf]Epoch 197:  44% 120/270 [01:20<-1:58:20, -1.50it/s, loss=0.017, v_num=ypmf]Epoch 197:  45% 121/270 [01:21<-1:58:20, -1.48it/s, loss=0.017, v_num=ypmf]Epoch 197:  45% 121/270 [01:21<-1:58:20, -1.48it/s, loss=0.017, v_num=ypmf]Epoch 197:  45% 121/270 [01:21<-1:58:19, -1.47it/s, loss=0.0169, v_num=ypmf]Epoch 197:  45% 122/270 [01:21<-1:58:19, -1.46it/s, loss=0.0169, v_num=ypmf]Epoch 197:  45% 122/270 [01:21<-1:58:19, -1.46it/s, loss=0.0169, v_num=ypmf]Epoch 197:  45% 122/270 [01:21<-1:58:19, -1.45it/s, loss=0.0169, v_num=ypmf]Epoch 197:  46% 123/270 [01:22<-1:58:18, -1.43it/s, loss=0.0169, v_num=ypmf]Epoch 197:  46% 123/270 [01:22<-1:58:18, -1.43it/s, loss=0.0169, v_num=ypmf]Epoch 197:  46% 123/270 [01:22<-1:58:18, -1.43it/s, loss=0.0168, v_num=ypmf]Epoch 197:  46% 124/270 [01:22<-1:58:17, -1.41it/s, loss=0.0168, v_num=ypmf]Epoch 197:  46% 124/270 [01:22<-1:58:17, -1.41it/s, loss=0.0168, v_num=ypmf]Epoch 197:  46% 124/270 [01:23<-1:58:17, -1.41it/s, loss=0.0168, v_num=ypmf]Epoch 197:  46% 125/270 [01:23<-1:58:16, -1.39it/s, loss=0.0168, v_num=ypmf]Epoch 197:  46% 125/270 [01:23<-1:58:16, -1.39it/s, loss=0.0168, v_num=ypmf]Epoch 197:  46% 125/270 [01:23<-1:58:16, -1.39it/s, loss=0.0167, v_num=ypmf]Epoch 197:  47% 126/270 [01:24<-1:58:15, -1.37it/s, loss=0.0167, v_num=ypmf]Epoch 197:  47% 126/270 [01:24<-1:58:15, -1.37it/s, loss=0.0167, v_num=ypmf]Epoch 197:  47% 126/270 [01:24<-1:58:15, -1.36it/s, loss=0.0168, v_num=ypmf]Epoch 197:  47% 127/270 [01:24<-1:58:14, -1.35it/s, loss=0.0168, v_num=ypmf]Epoch 197:  47% 127/270 [01:24<-1:58:14, -1.35it/s, loss=0.0168, v_num=ypmf]Epoch 197:  47% 127/270 [01:24<-1:58:14, -1.34it/s, loss=0.0168, v_num=ypmf]Epoch 197:  47% 128/270 [01:25<-1:58:13, -1.32it/s, loss=0.0168, v_num=ypmf]Epoch 197:  47% 128/270 [01:25<-1:58:13, -1.32it/s, loss=0.0168, v_num=ypmf]Epoch 197:  47% 128/270 [01:25<-1:58:13, -1.32it/s, loss=0.0167, v_num=ypmf]Epoch 197:  48% 129/270 [01:26<-1:58:12, -1.30it/s, loss=0.0167, v_num=ypmf]Epoch 197:  48% 129/270 [01:26<-1:58:12, -1.30it/s, loss=0.0167, v_num=ypmf]Epoch 197:  48% 129/270 [01:26<-1:58:12, -1.30it/s, loss=0.0167, v_num=ypmf]Epoch 197:  48% 130/270 [01:26<-1:58:11, -1.28it/s, loss=0.0167, v_num=ypmf]Epoch 197:  48% 130/270 [01:26<-1:58:11, -1.28it/s, loss=0.0167, v_num=ypmf]Epoch 197:  48% 130/270 [01:26<-1:58:11, -1.28it/s, loss=0.0168, v_num=ypmf]Epoch 197:  49% 131/270 [01:27<-1:58:10, -1.26it/s, loss=0.0168, v_num=ypmf]Epoch 197:  49% 131/270 [01:27<-1:58:10, -1.26it/s, loss=0.0168, v_num=ypmf]Epoch 197:  49% 131/270 [01:27<-1:58:10, -1.26it/s, loss=0.0168, v_num=ypmf]Epoch 197:  49% 132/270 [01:27<-1:58:09, -1.24it/s, loss=0.0168, v_num=ypmf]Epoch 197:  49% 132/270 [01:27<-1:58:09, -1.24it/s, loss=0.0168, v_num=ypmf]Epoch 197:  49% 132/270 [01:28<-1:58:08, -1.23it/s, loss=0.0167, v_num=ypmf]Epoch 197:  49% 133/270 [01:29<-1:58:08, -1.21it/s, loss=0.0167, v_num=ypmf]Epoch 197:  49% 133/270 [01:29<-1:58:08, -1.21it/s, loss=0.0167, v_num=ypmf]Epoch 197:  49% 133/270 [01:29<-1:58:07, -1.21it/s, loss=0.0167, v_num=ypmf]Epoch 197:  50% 134/270 [01:29<-1:58:07, -1.20it/s, loss=0.0167, v_num=ypmf]Epoch 197:  50% 134/270 [01:29<-1:58:07, -1.20it/s, loss=0.0167, v_num=ypmf]Epoch 197:  50% 134/270 [01:29<-1:58:06, -1.19it/s, loss=0.0166, v_num=ypmf]Epoch 197:  50% 135/270 [01:30<-1:58:05, -1.17it/s, loss=0.0166, v_num=ypmf]Epoch 197:  50% 135/270 [01:30<-1:58:05, -1.17it/s, loss=0.0166, v_num=ypmf]Epoch 197:  50% 135/270 [01:30<-1:58:05, -1.17it/s, loss=0.0165, v_num=ypmf]Epoch 197:  50% 136/270 [01:31<-1:58:04, -1.15it/s, loss=0.0165, v_num=ypmf]Epoch 197:  50% 136/270 [01:31<-1:58:04, -1.15it/s, loss=0.0165, v_num=ypmf]Epoch 197:  50% 136/270 [01:31<-1:58:04, -1.15it/s, loss=0.0165, v_num=ypmf]Epoch 197:  51% 137/270 [01:31<-1:58:03, -1.13it/s, loss=0.0165, v_num=ypmf]Epoch 197:  51% 137/270 [01:31<-1:58:03, -1.13it/s, loss=0.0165, v_num=ypmf]Epoch 197:  51% 137/270 [01:31<-1:58:03, -1.13it/s, loss=0.0166, v_num=ypmf]Epoch 197:  51% 138/270 [01:32<-1:58:02, -1.12it/s, loss=0.0166, v_num=ypmf]Epoch 197:  51% 138/270 [01:32<-1:58:02, -1.12it/s, loss=0.0166, v_num=ypmf]Epoch 197:  51% 138/270 [01:32<-1:58:02, -1.11it/s, loss=0.0166, v_num=ypmf]Epoch 197:  51% 139/270 [01:32<-1:58:01, -1.10it/s, loss=0.0166, v_num=ypmf]Epoch 197:  51% 139/270 [01:32<-1:58:01, -1.10it/s, loss=0.0166, v_num=ypmf]Epoch 197:  51% 139/270 [01:33<-1:58:01, -1.10it/s, loss=0.0165, v_num=ypmf]Epoch 197:  52% 140/270 [01:33<-1:58:00, -1.08it/s, loss=0.0165, v_num=ypmf]Epoch 197:  52% 140/270 [01:33<-1:58:00, -1.08it/s, loss=0.0165, v_num=ypmf]Epoch 197:  52% 140/270 [01:33<-1:58:00, -1.08it/s, loss=0.0166, v_num=ypmf]Epoch 197:  52% 141/270 [01:34<-1:57:59, -1.06it/s, loss=0.0166, v_num=ypmf]Epoch 197:  52% 141/270 [01:34<-1:57:59, -1.06it/s, loss=0.0166, v_num=ypmf]Epoch 197:  52% 141/270 [01:34<-1:57:59, -1.06it/s, loss=0.0166, v_num=ypmf]Epoch 197:  53% 142/270 [01:34<-1:57:58, -1.04it/s, loss=0.0166, v_num=ypmf]Epoch 197:  53% 142/270 [01:34<-1:57:58, -1.04it/s, loss=0.0166, v_num=ypmf]Epoch 197:  53% 142/270 [01:34<-1:57:58, -1.04it/s, loss=0.0165, v_num=ypmf]Epoch 197:  53% 143/270 [01:35<-1:57:57, -1.03it/s, loss=0.0165, v_num=ypmf]Epoch 197:  53% 143/270 [01:35<-1:57:57, -1.03it/s, loss=0.0165, v_num=ypmf]Epoch 197:  53% 143/270 [01:35<-1:57:57, -1.03it/s, loss=0.0166, v_num=ypmf]Epoch 197:  53% 144/270 [01:35<-1:57:56, -1.01it/s, loss=0.0166, v_num=ypmf]Epoch 197:  53% 144/270 [01:35<-1:57:56, -1.01it/s, loss=0.0166, v_num=ypmf]Epoch 197:  53% 144/270 [01:36<-1:57:56, -1.01it/s, loss=0.0165, v_num=ypmf]Epoch 197:  54% 145/270 [01:38<-1:57:53, -0.98it/s, loss=0.0165, v_num=ypmf]Epoch 197:  54% 145/270 [01:38<-1:57:53, -0.98it/s, loss=0.0165, v_num=ypmf]Epoch 197:  54% 145/270 [01:38<-1:57:53, -0.98it/s, loss=0.0166, v_num=ypmf]Epoch 197:  54% 146/270 [01:38<-1:57:52, -0.96it/s, loss=0.0166, v_num=ypmf]Epoch 197:  54% 146/270 [01:38<-1:57:52, -0.96it/s, loss=0.0166, v_num=ypmf]Epoch 197:  54% 146/270 [01:38<-1:57:52, -0.96it/s, loss=0.0167, v_num=ypmf]Epoch 197:  54% 147/270 [01:39<-1:57:51, -0.95it/s, loss=0.0167, v_num=ypmf]Epoch 197:  54% 147/270 [01:39<-1:57:51, -0.95it/s, loss=0.0167, v_num=ypmf]Epoch 197:  54% 147/270 [01:39<-1:57:51, -0.95it/s, loss=0.0168, v_num=ypmf]Epoch 197:  55% 148/270 [01:39<-1:57:50, -0.93it/s, loss=0.0168, v_num=ypmf]Epoch 197:  55% 148/270 [01:39<-1:57:50, -0.93it/s, loss=0.0168, v_num=ypmf]Epoch 197:  55% 148/270 [01:39<-1:57:50, -0.93it/s, loss=0.0169, v_num=ypmf]Epoch 197:  55% 149/270 [01:40<-1:57:49, -0.92it/s, loss=0.0169, v_num=ypmf]Epoch 197:  55% 149/270 [01:40<-1:57:49, -0.92it/s, loss=0.0169, v_num=ypmf]Epoch 197:  55% 149/270 [01:40<-1:57:48, -0.92it/s, loss=0.0168, v_num=ypmf]Epoch 197:  56% 150/270 [01:40<-1:57:48, -0.90it/s, loss=0.0168, v_num=ypmf]Epoch 197:  56% 150/270 [01:40<-1:57:48, -0.90it/s, loss=0.0168, v_num=ypmf]Epoch 197:  56% 150/270 [01:41<-1:57:47, -0.90it/s, loss=0.0167, v_num=ypmf]Epoch 197:  56% 151/270 [01:41<-1:57:46, -0.89it/s, loss=0.0167, v_num=ypmf]Epoch 197:  56% 151/270 [01:41<-1:57:46, -0.89it/s, loss=0.0167, v_num=ypmf]Epoch 197:  56% 151/270 [01:41<-1:57:46, -0.89it/s, loss=0.0168, v_num=ypmf]Epoch 197:  56% 152/270 [01:41<-1:57:45, -0.87it/s, loss=0.0168, v_num=ypmf]Epoch 197:  56% 152/270 [01:41<-1:57:45, -0.87it/s, loss=0.0168, v_num=ypmf]Epoch 197:  56% 152/270 [01:42<-1:57:45, -0.87it/s, loss=0.0167, v_num=ypmf]Epoch 197:  57% 153/270 [01:42<-1:57:44, -0.86it/s, loss=0.0167, v_num=ypmf]Epoch 197:  57% 153/270 [01:42<-1:57:44, -0.86it/s, loss=0.0167, v_num=ypmf]Epoch 197:  57% 153/270 [01:42<-1:57:44, -0.86it/s, loss=0.0168, v_num=ypmf]Epoch 197:  57% 154/270 [01:42<-1:57:43, -0.84it/s, loss=0.0168, v_num=ypmf]Epoch 197:  57% 154/270 [01:42<-1:57:43, -0.84it/s, loss=0.0168, v_num=ypmf]Epoch 197:  57% 154/270 [01:43<-1:57:43, -0.84it/s, loss=0.0169, v_num=ypmf]Epoch 197:  57% 155/270 [01:43<-1:57:42, -0.83it/s, loss=0.0169, v_num=ypmf]Epoch 197:  57% 155/270 [01:43<-1:57:42, -0.83it/s, loss=0.0169, v_num=ypmf]Epoch 197:  57% 155/270 [01:43<-1:57:42, -0.83it/s, loss=0.017, v_num=ypmf] Epoch 197:  58% 156/270 [01:44<-1:57:41, -0.82it/s, loss=0.017, v_num=ypmf]Epoch 197:  58% 156/270 [01:44<-1:57:41, -0.82it/s, loss=0.017, v_num=ypmf]Epoch 197:  58% 156/270 [01:45<-1:57:39, -0.81it/s, loss=0.0172, v_num=ypmf]Epoch 197:  58% 157/270 [01:45<-1:57:38, -0.79it/s, loss=0.0172, v_num=ypmf]Epoch 197:  58% 157/270 [01:45<-1:57:38, -0.79it/s, loss=0.0172, v_num=ypmf]Epoch 197:  58% 157/270 [01:46<-1:57:38, -0.79it/s, loss=0.0173, v_num=ypmf]Epoch 197:  59% 158/270 [01:46<-1:57:37, -0.78it/s, loss=0.0173, v_num=ypmf]Epoch 197:  59% 158/270 [01:46<-1:57:37, -0.78it/s, loss=0.0173, v_num=ypmf]Epoch 197:  59% 158/270 [01:46<-1:57:37, -0.78it/s, loss=0.0171, v_num=ypmf]Epoch 197:  59% 159/270 [01:47<-1:57:36, -0.77it/s, loss=0.0171, v_num=ypmf]Epoch 197:  59% 159/270 [01:47<-1:57:36, -0.77it/s, loss=0.0171, v_num=ypmf]Epoch 197:  59% 159/270 [01:47<-1:57:35, -0.76it/s, loss=0.0172, v_num=ypmf]Epoch 197:  59% 160/270 [01:47<-1:57:34, -0.75it/s, loss=0.0172, v_num=ypmf]Epoch 197:  59% 160/270 [01:47<-1:57:34, -0.75it/s, loss=0.0172, v_num=ypmf]Epoch 197:  59% 160/270 [01:49<-1:57:32, -0.74it/s, loss=0.0172, v_num=ypmf]Epoch 197:  60% 161/270 [01:49<-1:57:32, -0.73it/s, loss=0.0172, v_num=ypmf]Epoch 197:  60% 161/270 [01:49<-1:57:32, -0.73it/s, loss=0.0172, v_num=ypmf]Epoch 197:  60% 161/270 [01:49<-1:57:31, -0.73it/s, loss=0.0172, v_num=ypmf]Epoch 197:  60% 162/270 [01:49<-1:57:30, -0.72it/s, loss=0.0172, v_num=ypmf]Epoch 197:  60% 162/270 [01:49<-1:57:30, -0.72it/s, loss=0.0172, v_num=ypmf]Epoch 197:  60% 162/270 [01:50<-1:57:30, -0.72it/s, loss=0.0173, v_num=ypmf]Epoch 197:  60% 163/270 [01:50<-1:57:29, -0.70it/s, loss=0.0173, v_num=ypmf]Epoch 197:  60% 163/270 [01:50<-1:57:29, -0.70it/s, loss=0.0173, v_num=ypmf]Epoch 197:  60% 163/270 [01:51<-1:57:28, -0.70it/s, loss=0.0173, v_num=ypmf]Epoch 197:  61% 164/270 [01:51<-1:57:27, -0.69it/s, loss=0.0173, v_num=ypmf]Epoch 197:  61% 164/270 [01:51<-1:57:27, -0.69it/s, loss=0.0173, v_num=ypmf]Epoch 197:  61% 164/270 [01:51<-1:57:27, -0.69it/s, loss=0.0174, v_num=ypmf]Epoch 197:  61% 165/270 [01:52<-1:57:26, -0.68it/s, loss=0.0174, v_num=ypmf]Epoch 197:  61% 165/270 [01:52<-1:57:26, -0.68it/s, loss=0.0174, v_num=ypmf]Epoch 197:  61% 165/270 [01:52<-1:57:25, -0.68it/s, loss=0.0174, v_num=ypmf]Epoch 197:  61% 166/270 [01:52<-1:57:24, -0.67it/s, loss=0.0174, v_num=ypmf]Epoch 197:  61% 166/270 [01:52<-1:57:24, -0.67it/s, loss=0.0174, v_num=ypmf]Epoch 197:  61% 166/270 [01:52<-1:57:24, -0.66it/s, loss=0.0174, v_num=ypmf]Epoch 197:  62% 167/270 [01:53<-1:57:23, -0.65it/s, loss=0.0174, v_num=ypmf]Epoch 197:  62% 167/270 [01:53<-1:57:23, -0.65it/s, loss=0.0174, v_num=ypmf]Epoch 197:  62% 167/270 [01:53<-1:57:23, -0.65it/s, loss=0.0173, v_num=ypmf]Epoch 197:  62% 168/270 [01:53<-1:57:22, -0.64it/s, loss=0.0173, v_num=ypmf]Epoch 197:  62% 168/270 [01:53<-1:57:22, -0.64it/s, loss=0.0173, v_num=ypmf]Epoch 197:  62% 168/270 [01:53<-1:57:21, -0.64it/s, loss=0.0174, v_num=ypmf]Epoch 197:  63% 169/270 [01:54<-1:57:20, -0.63it/s, loss=0.0174, v_num=ypmf]Epoch 197:  63% 169/270 [01:54<-1:57:20, -0.63it/s, loss=0.0174, v_num=ypmf]Epoch 197:  63% 169/270 [01:54<-1:57:20, -0.63it/s, loss=0.0174, v_num=ypmf]Epoch 197:  63% 170/270 [01:54<-1:57:19, -0.62it/s, loss=0.0174, v_num=ypmf]Epoch 197:  63% 170/270 [01:54<-1:57:19, -0.62it/s, loss=0.0174, v_num=ypmf]Epoch 197:  63% 170/270 [01:55<-1:57:18, -0.62it/s, loss=0.0174, v_num=ypmf]Epoch 197:  63% 171/270 [01:55<-1:57:17, -0.61it/s, loss=0.0174, v_num=ypmf]Epoch 197:  63% 171/270 [01:55<-1:57:17, -0.61it/s, loss=0.0174, v_num=ypmf]Epoch 197:  63% 171/270 [01:55<-1:57:17, -0.60it/s, loss=0.0174, v_num=ypmf]Epoch 197:  64% 172/270 [01:56<-1:57:15, -0.59it/s, loss=0.0174, v_num=ypmf]Epoch 197:  64% 172/270 [01:56<-1:57:15, -0.59it/s, loss=0.0174, v_num=ypmf]Epoch 197:  64% 172/270 [01:56<-1:57:15, -0.59it/s, loss=0.0174, v_num=ypmf]Epoch 197:  64% 173/270 [01:56<-1:57:14, -0.58it/s, loss=0.0174, v_num=ypmf]Epoch 197:  64% 173/270 [01:56<-1:57:14, -0.58it/s, loss=0.0174, v_num=ypmf]Epoch 197:  64% 173/270 [01:57<-1:57:13, -0.58it/s, loss=0.0172, v_num=ypmf]Epoch 197:  64% 174/270 [01:57<-1:57:12, -0.57it/s, loss=0.0172, v_num=ypmf]Epoch 197:  64% 174/270 [01:57<-1:57:12, -0.57it/s, loss=0.0172, v_num=ypmf]Epoch 197:  64% 174/270 [01:57<-1:57:12, -0.57it/s, loss=0.0173, v_num=ypmf]Epoch 197:  65% 175/270 [01:58<-1:57:11, -0.56it/s, loss=0.0173, v_num=ypmf]Epoch 197:  65% 175/270 [01:58<-1:57:11, -0.56it/s, loss=0.0173, v_num=ypmf]Epoch 197:  65% 175/270 [01:58<-1:57:10, -0.56it/s, loss=0.0171, v_num=ypmf]Epoch 197:  65% 176/270 [01:58<-1:57:09, -0.55it/s, loss=0.0171, v_num=ypmf]Epoch 197:  65% 176/270 [01:58<-1:57:09, -0.55it/s, loss=0.0171, v_num=ypmf]Epoch 197:  65% 176/270 [01:58<-1:57:08, -0.55it/s, loss=0.017, v_num=ypmf] Epoch 197:  66% 177/270 [01:59<-1:57:07, -0.54it/s, loss=0.017, v_num=ypmf]Epoch 197:  66% 177/270 [01:59<-1:57:07, -0.54it/s, loss=0.017, v_num=ypmf]Epoch 197:  66% 177/270 [01:59<-1:57:07, -0.54it/s, loss=0.017, v_num=ypmf]Epoch 197:  66% 178/270 [01:59<-1:57:05, -0.53it/s, loss=0.017, v_num=ypmf]Epoch 197:  66% 178/270 [01:59<-1:57:05, -0.53it/s, loss=0.017, v_num=ypmf]Epoch 197:  66% 178/270 [02:00<-1:57:05, -0.52it/s, loss=0.017, v_num=ypmf]Epoch 197:  66% 179/270 [02:00<-1:57:04, -0.51it/s, loss=0.017, v_num=ypmf]Epoch 197:  66% 179/270 [02:00<-1:57:04, -0.51it/s, loss=0.017, v_num=ypmf]Epoch 197:  66% 179/270 [02:00<-1:57:03, -0.51it/s, loss=0.017, v_num=ypmf]Epoch 197:  67% 180/270 [02:01<-1:57:02, -0.50it/s, loss=0.017, v_num=ypmf]Epoch 197:  67% 180/270 [02:01<-1:57:02, -0.50it/s, loss=0.017, v_num=ypmf]Epoch 197:  67% 180/270 [02:01<-1:57:02, -0.50it/s, loss=0.0169, v_num=ypmf]Epoch 197:  67% 181/270 [02:01<-1:57:00, -0.49it/s, loss=0.0169, v_num=ypmf]Epoch 197:  67% 181/270 [02:01<-1:57:00, -0.49it/s, loss=0.0169, v_num=ypmf]Epoch 197:  67% 181/270 [02:01<-1:57:00, -0.49it/s, loss=0.0169, v_num=ypmf]Epoch 197:  67% 182/270 [02:02<-1:56:58, -0.48it/s, loss=0.0169, v_num=ypmf]Epoch 197:  67% 182/270 [02:02<-1:56:58, -0.48it/s, loss=0.0169, v_num=ypmf]Epoch 197:  67% 182/270 [02:02<-1:56:58, -0.48it/s, loss=0.0168, v_num=ypmf]Epoch 197:  68% 183/270 [02:02<-1:56:56, -0.47it/s, loss=0.0168, v_num=ypmf]Epoch 197:  68% 183/270 [02:02<-1:56:56, -0.47it/s, loss=0.0168, v_num=ypmf]Epoch 197:  68% 183/270 [02:03<-1:56:56, -0.47it/s, loss=0.0169, v_num=ypmf]Epoch 197:  68% 184/270 [02:03<-1:56:54, -0.46it/s, loss=0.0169, v_num=ypmf]Epoch 197:  68% 184/270 [02:03<-1:56:54, -0.46it/s, loss=0.0169, v_num=ypmf]Epoch 197:  68% 184/270 [02:03<-1:56:54, -0.46it/s, loss=0.0168, v_num=ypmf]Epoch 197:  69% 185/270 [02:04<-1:56:52, -0.45it/s, loss=0.0168, v_num=ypmf]Epoch 197:  69% 185/270 [02:04<-1:56:52, -0.45it/s, loss=0.0168, v_num=ypmf]Epoch 197:  69% 185/270 [02:04<-1:56:52, -0.45it/s, loss=0.0167, v_num=ypmf]Epoch 197:  69% 186/270 [02:04<-1:56:50, -0.44it/s, loss=0.0167, v_num=ypmf]Epoch 197:  69% 186/270 [02:04<-1:56:50, -0.44it/s, loss=0.0167, v_num=ypmf]Epoch 197:  69% 186/270 [02:04<-1:56:50, -0.44it/s, loss=0.0167, v_num=ypmf]Epoch 197:  69% 187/270 [02:05<-1:56:48, -0.43it/s, loss=0.0167, v_num=ypmf]Epoch 197:  69% 187/270 [02:05<-1:56:48, -0.43it/s, loss=0.0167, v_num=ypmf]Epoch 197:  69% 187/270 [02:05<-1:56:48, -0.43it/s, loss=0.0167, v_num=ypmf]Epoch 197:  70% 188/270 [02:05<-1:56:46, -0.42it/s, loss=0.0167, v_num=ypmf]Epoch 197:  70% 188/270 [02:05<-1:56:46, -0.42it/s, loss=0.0167, v_num=ypmf]Epoch 197:  70% 188/270 [02:05<-1:56:46, -0.42it/s, loss=0.0167, v_num=ypmf]Epoch 197:  70% 189/270 [02:06<-1:56:44, -0.41it/s, loss=0.0167, v_num=ypmf]Epoch 197:  70% 189/270 [02:06<-1:56:44, -0.41it/s, loss=0.0167, v_num=ypmf]Epoch 197:  70% 189/270 [02:06<-1:56:44, -0.41it/s, loss=0.0166, v_num=ypmf]Epoch 197:  70% 190/270 [02:06<-1:56:42, -0.40it/s, loss=0.0166, v_num=ypmf]Epoch 197:  70% 190/270 [02:06<-1:56:42, -0.40it/s, loss=0.0166, v_num=ypmf]Epoch 197:  70% 190/270 [02:06<-1:56:41, -0.40it/s, loss=0.0166, v_num=ypmf]Epoch 197:  71% 191/270 [02:07<-1:56:39, -0.39it/s, loss=0.0166, v_num=ypmf]Epoch 197:  71% 191/270 [02:07<-1:56:39, -0.39it/s, loss=0.0166, v_num=ypmf]Epoch 197:  71% 191/270 [02:07<-1:56:39, -0.39it/s, loss=0.0167, v_num=ypmf]Epoch 197:  71% 192/270 [02:07<-1:56:37, -0.38it/s, loss=0.0167, v_num=ypmf]Epoch 197:  71% 192/270 [02:07<-1:56:37, -0.38it/s, loss=0.0167, v_num=ypmf]Epoch 197:  71% 192/270 [02:08<-1:56:37, -0.38it/s, loss=0.0166, v_num=ypmf]Epoch 197:  71% 193/270 [02:08<-1:56:34, -0.37it/s, loss=0.0166, v_num=ypmf]Epoch 197:  71% 193/270 [02:08<-1:56:34, -0.37it/s, loss=0.0166, v_num=ypmf]Epoch 197:  71% 193/270 [02:08<-1:56:34, -0.37it/s, loss=0.0167, v_num=ypmf]Epoch 197:  72% 194/270 [02:09<-1:56:32, -0.36it/s, loss=0.0167, v_num=ypmf]Epoch 197:  72% 194/270 [02:09<-1:56:32, -0.36it/s, loss=0.0167, v_num=ypmf]Epoch 197:  72% 194/270 [02:09<-1:56:31, -0.36it/s, loss=0.0165, v_num=ypmf]Epoch 197:  72% 195/270 [02:09<-1:56:29, -0.35it/s, loss=0.0165, v_num=ypmf]Epoch 197:  72% 195/270 [02:09<-1:56:29, -0.35it/s, loss=0.0165, v_num=ypmf]Epoch 197:  72% 195/270 [02:10<-1:56:28, -0.35it/s, loss=0.0166, v_num=ypmf]Epoch 197:  73% 196/270 [02:10<-1:56:26, -0.34it/s, loss=0.0166, v_num=ypmf]Epoch 197:  73% 196/270 [02:10<-1:56:26, -0.34it/s, loss=0.0166, v_num=ypmf]Epoch 197:  73% 196/270 [02:10<-1:56:25, -0.34it/s, loss=0.0165, v_num=ypmf]Epoch 197:  73% 197/270 [02:11<-1:56:23, -0.33it/s, loss=0.0165, v_num=ypmf]Epoch 197:  73% 197/270 [02:11<-1:56:23, -0.33it/s, loss=0.0165, v_num=ypmf]Epoch 197:  73% 197/270 [02:12<-1:56:21, -0.33it/s, loss=0.0165, v_num=ypmf]Epoch 197:  73% 198/270 [02:12<-1:56:19, -0.32it/s, loss=0.0165, v_num=ypmf]Epoch 197:  73% 198/270 [02:12<-1:56:19, -0.32it/s, loss=0.0165, v_num=ypmf]Epoch 197:  73% 198/270 [02:12<-1:56:18, -0.32it/s, loss=0.0165, v_num=ypmf]Epoch 197:  74% 199/270 [02:13<-1:56:15, -0.32it/s, loss=0.0165, v_num=ypmf]Epoch 197:  74% 199/270 [02:13<-1:56:15, -0.32it/s, loss=0.0165, v_num=ypmf]Epoch 197:  74% 199/270 [02:13<-1:56:15, -0.31it/s, loss=0.0166, v_num=ypmf]Epoch 197:  74% 200/270 [02:13<-1:56:12, -0.31it/s, loss=0.0166, v_num=ypmf]Epoch 197:  74% 200/270 [02:13<-1:56:12, -0.31it/s, loss=0.0166, v_num=ypmf]Epoch 197:  74% 200/270 [02:13<-1:56:12, -0.31it/s, loss=0.0167, v_num=ypmf]Epoch 197:  74% 201/270 [02:14<-1:56:09, -0.30it/s, loss=0.0167, v_num=ypmf]Epoch 197:  74% 201/270 [02:14<-1:56:09, -0.30it/s, loss=0.0167, v_num=ypmf]Epoch 197:  74% 201/270 [02:14<-1:56:09, -0.30it/s, loss=0.0167, v_num=ypmf]Epoch 197:  75% 202/270 [02:14<-1:56:06, -0.29it/s, loss=0.0167, v_num=ypmf]Epoch 197:  75% 202/270 [02:14<-1:56:06, -0.29it/s, loss=0.0167, v_num=ypmf]Epoch 197:  75% 202/270 [02:14<-1:56:05, -0.29it/s, loss=0.0168, v_num=ypmf]Epoch 197:  75% 203/270 [02:15<-1:56:02, -0.28it/s, loss=0.0168, v_num=ypmf]Epoch 197:  75% 203/270 [02:15<-1:56:02, -0.28it/s, loss=0.0168, v_num=ypmf]Epoch 197:  75% 203/270 [02:15<-1:56:02, -0.28it/s, loss=0.0167, v_num=ypmf]Epoch 197:  76% 204/270 [02:16<-1:55:58, -0.27it/s, loss=0.0167, v_num=ypmf]Epoch 197:  76% 204/270 [02:16<-1:55:58, -0.27it/s, loss=0.0167, v_num=ypmf]Epoch 197:  76% 204/270 [02:16<-1:55:58, -0.27it/s, loss=0.0167, v_num=ypmf]Epoch 197:  76% 205/270 [02:16<-1:55:54, -0.26it/s, loss=0.0167, v_num=ypmf]Epoch 197:  76% 205/270 [02:16<-1:55:54, -0.26it/s, loss=0.0167, v_num=ypmf]Epoch 197:  76% 205/270 [02:16<-1:55:53, -0.26it/s, loss=0.0168, v_num=ypmf]Epoch 197:  76% 206/270 [02:17<-1:55:50, -0.26it/s, loss=0.0168, v_num=ypmf]Epoch 197:  76% 206/270 [02:17<-1:55:50, -0.26it/s, loss=0.0168, v_num=ypmf]Epoch 197:  76% 206/270 [02:17<-1:55:49, -0.25it/s, loss=0.0168, v_num=ypmf]Epoch 197:  77% 207/270 [02:17<-1:55:45, -0.25it/s, loss=0.0168, v_num=ypmf]Epoch 197:  77% 207/270 [02:17<-1:55:45, -0.25it/s, loss=0.0168, v_num=ypmf]Epoch 197:  77% 207/270 [02:18<-1:55:45, -0.25it/s, loss=0.0169, v_num=ypmf]Epoch 197:  77% 208/270 [02:18<-1:55:40, -0.24it/s, loss=0.0169, v_num=ypmf]Epoch 197:  77% 208/270 [02:18<-1:55:40, -0.24it/s, loss=0.0169, v_num=ypmf]Epoch 197:  77% 208/270 [02:18<-1:55:40, -0.24it/s, loss=0.0169, v_num=ypmf]Epoch 197:  77% 209/270 [02:19<-1:55:35, -0.23it/s, loss=0.0169, v_num=ypmf]Epoch 197:  77% 209/270 [02:19<-1:55:35, -0.23it/s, loss=0.0169, v_num=ypmf]Epoch 197:  77% 209/270 [02:19<-1:55:35, -0.23it/s, loss=0.0169, v_num=ypmf]Epoch 197:  78% 210/270 [02:19<-1:55:30, -0.22it/s, loss=0.0169, v_num=ypmf]Epoch 197:  78% 210/270 [02:19<-1:55:30, -0.22it/s, loss=0.0169, v_num=ypmf]Epoch 197:  78% 210/270 [02:19<-1:55:30, -0.22it/s, loss=0.0169, v_num=ypmf]Epoch 197:  78% 211/270 [02:20<-1:55:25, -0.21it/s, loss=0.0169, v_num=ypmf]Epoch 197:  78% 211/270 [02:20<-1:55:25, -0.21it/s, loss=0.0169, v_num=ypmf]Epoch 197:  78% 211/270 [02:20<-1:55:24, -0.21it/s, loss=0.017, v_num=ypmf] Epoch 197:  79% 212/270 [02:20<-1:55:19, -0.21it/s, loss=0.017, v_num=ypmf]Epoch 197:  79% 212/270 [02:20<-1:55:19, -0.21it/s, loss=0.017, v_num=ypmf]Epoch 197:  79% 212/270 [02:20<-1:55:19, -0.21it/s, loss=0.0171, v_num=ypmf]Epoch 197:  79% 213/270 [02:21<-1:55:13, -0.20it/s, loss=0.0171, v_num=ypmf]Epoch 197:  79% 213/270 [02:21<-1:55:13, -0.20it/s, loss=0.0171, v_num=ypmf]Epoch 197:  79% 213/270 [02:21<-1:55:12, -0.20it/s, loss=0.0171, v_num=ypmf]Epoch 197:  79% 214/270 [02:21<-1:55:06, -0.19it/s, loss=0.0171, v_num=ypmf]Epoch 197:  79% 214/270 [02:21<-1:55:06, -0.19it/s, loss=0.0171, v_num=ypmf]Epoch 197:  79% 214/270 [02:22<-1:55:06, -0.19it/s, loss=0.0171, v_num=ypmf]Epoch 197:  80% 215/270 [02:22<-1:54:59, -0.18it/s, loss=0.0171, v_num=ypmf]Epoch 197:  80% 215/270 [02:22<-1:54:59, -0.18it/s, loss=0.0171, v_num=ypmf]Epoch 197:  80% 215/270 [02:22<-1:54:59, -0.18it/s, loss=0.0172, v_num=ypmf]Epoch 197:  80% 216/270 [02:23<-1:54:51, -0.17it/s, loss=0.0172, v_num=ypmf]Epoch 197:  80% 216/270 [02:23<-1:54:51, -0.17it/s, loss=0.0172, v_num=ypmf]Epoch 197:  80% 216/270 [02:23<-1:54:51, -0.17it/s, loss=0.0172, v_num=ypmf]Epoch 197:  80% 217/270 [02:23<-1:54:43, -0.17it/s, loss=0.0172, v_num=ypmf]Epoch 197:  80% 217/270 [02:23<-1:54:43, -0.17it/s, loss=0.0172, v_num=ypmf]Epoch 197:  80% 217/270 [02:23<-1:54:43, -0.17it/s, loss=0.0171, v_num=ypmf]Epoch 197:  81% 218/270 [02:24<-1:54:34, -0.16it/s, loss=0.0171, v_num=ypmf]Epoch 197:  81% 218/270 [02:24<-1:54:34, -0.16it/s, loss=0.0171, v_num=ypmf]Epoch 197:  81% 218/270 [02:24<-1:54:34, -0.16it/s, loss=0.0172, v_num=ypmf]Epoch 197:  81% 219/270 [02:24<-1:54:25, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 197:  81% 219/270 [02:24<-1:54:25, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 197:  81% 219/270 [02:24<-1:54:24, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 197:  81% 220/270 [02:25<-1:54:14, -0.14it/s, loss=0.0172, v_num=ypmf]Epoch 197:  81% 220/270 [02:25<-1:54:14, -0.14it/s, loss=0.0172, v_num=ypmf]Epoch 197:  81% 220/270 [02:26<-1:54:13, -0.14it/s, loss=0.0171, v_num=ypmf]Epoch 197:  82% 221/270 [02:26<-1:54:02, -0.14it/s, loss=0.0171, v_num=ypmf]Epoch 197:  82% 221/270 [02:26<-1:54:02, -0.14it/s, loss=0.0171, v_num=ypmf]Epoch 197:  82% 221/270 [02:26<-1:54:01, -0.14it/s, loss=0.0172, v_num=ypmf]Epoch 197:  82% 222/270 [02:27<-1:53:49, -0.13it/s, loss=0.0172, v_num=ypmf]Epoch 197:  82% 222/270 [02:27<-1:53:49, -0.13it/s, loss=0.0172, v_num=ypmf]Epoch 197:  82% 222/270 [02:28<-1:53:45, -0.13it/s, loss=0.0171, v_num=ypmf]Epoch 197:  83% 223/270 [02:28<-1:53:32, -0.12it/s, loss=0.0171, v_num=ypmf]Epoch 197:  83% 223/270 [02:28<-1:53:32, -0.12it/s, loss=0.0171, v_num=ypmf]Epoch 197:  83% 223/270 [02:29<-1:53:31, -0.12it/s, loss=0.0171, v_num=ypmf]Epoch 197:  83% 224/270 [02:29<-1:53:16, -0.11it/s, loss=0.0171, v_num=ypmf]Epoch 197:  83% 224/270 [02:29<-1:53:16, -0.11it/s, loss=0.0171, v_num=ypmf]Epoch 197:  83% 224/270 [02:29<-1:53:16, -0.11it/s, loss=0.0172, v_num=ypmf]Epoch 197:  83% 225/270 [02:29<-1:52:59, -0.11it/s, loss=0.0172, v_num=ypmf]Epoch 197:  83% 225/270 [02:29<-1:52:59, -0.11it/s, loss=0.0172, v_num=ypmf]Epoch 197:  83% 225/270 [02:30<-1:52:58, -0.11it/s, loss=0.0173, v_num=ypmf]Epoch 197:  84% 226/270 [02:30<-1:52:39, -0.10it/s, loss=0.0173, v_num=ypmf]Epoch 197:  84% 226/270 [02:30<-1:52:39, -0.10it/s, loss=0.0173, v_num=ypmf]Epoch 197:  84% 226/270 [02:32<-1:52:33, -0.10it/s, loss=0.0172, v_num=ypmf]Epoch 197:  84% 227/270 [02:32<-1:52:11, -0.09it/s, loss=0.0172, v_num=ypmf]Epoch 197:  84% 227/270 [02:32<-1:52:11, -0.09it/s, loss=0.0172, v_num=ypmf]Epoch 197:  84% 227/270 [02:32<-1:52:11, -0.09it/s, loss=0.017, v_num=ypmf] Epoch 197:  84% 228/270 [02:33<-1:51:45, -0.08it/s, loss=0.017, v_num=ypmf]Epoch 197:  84% 228/270 [02:33<-1:51:45, -0.08it/s, loss=0.017, v_num=ypmf]Epoch 197:  84% 228/270 [02:33<-1:51:44, -0.08it/s, loss=0.017, v_num=ypmf]Epoch 197:  85% 229/270 [02:34<-1:51:14, -0.08it/s, loss=0.017, v_num=ypmf]Epoch 197:  85% 229/270 [02:34<-1:51:14, -0.08it/s, loss=0.017, v_num=ypmf]Epoch 197:  85% 229/270 [02:34<-1:51:14, -0.08it/s, loss=0.017, v_num=ypmf]Epoch 197:  85% 230/270 [02:34<-1:50:38, -0.07it/s, loss=0.017, v_num=ypmf]Epoch 197:  85% 230/270 [02:34<-1:50:38, -0.07it/s, loss=0.017, v_num=ypmf]Epoch 197:  85% 230/270 [02:34<-1:50:38, -0.07it/s, loss=0.0169, v_num=ypmf]Epoch 197:  86% 231/270 [02:35<-1:49:55, -0.06it/s, loss=0.0169, v_num=ypmf]Epoch 197:  86% 231/270 [02:35<-1:49:55, -0.06it/s, loss=0.0169, v_num=ypmf]Epoch 197:  86% 231/270 [02:35<-1:49:55, -0.06it/s, loss=0.017, v_num=ypmf] Epoch 197:  86% 232/270 [02:35<-1:49:02, -0.06it/s, loss=0.017, v_num=ypmf]Epoch 197:  86% 232/270 [02:35<-1:49:02, -0.06it/s, loss=0.017, v_num=ypmf]Epoch 197:  86% 232/270 [02:36<-1:49:02, -0.06it/s, loss=0.0169, v_num=ypmf]Epoch 197:  86% 233/270 [02:36<-1:47:57, -0.05it/s, loss=0.0169, v_num=ypmf]Epoch 197:  86% 233/270 [02:36<-1:47:57, -0.05it/s, loss=0.0169, v_num=ypmf]Epoch 197:  86% 233/270 [02:36<-1:47:56, -0.05it/s, loss=0.0169, v_num=ypmf]Epoch 197:  87% 234/270 [02:37<-1:46:33, -0.04it/s, loss=0.0169, v_num=ypmf]Epoch 197:  87% 234/270 [02:37<-1:46:33, -0.04it/s, loss=0.0169, v_num=ypmf]Epoch 197:  87% 234/270 [02:37<-1:46:32, -0.04it/s, loss=0.0171, v_num=ypmf]Epoch 197:  87% 235/270 [02:37<-1:44:41, -0.04it/s, loss=0.0171, v_num=ypmf]Epoch 197:  87% 235/270 [02:37<-1:44:41, -0.04it/s, loss=0.0171, v_num=ypmf]Epoch 197:  87% 235/270 [02:37<-1:44:40, -0.04it/s, loss=0.017, v_num=ypmf] Epoch 197:  87% 236/270 [02:39<-1:41:56, -0.03it/s, loss=0.017, v_num=ypmf]Epoch 197:  87% 236/270 [02:39<-1:41:56, -0.03it/s, loss=0.017, v_num=ypmf]Epoch 197:  87% 236/270 [02:39<-1:41:55, -0.03it/s, loss=0.017, v_num=ypmf]Epoch 197:  88% 237/270 [02:39<-1:38:01, -0.03it/s, loss=0.017, v_num=ypmf]Epoch 197:  88% 237/270 [02:39<-1:38:01, -0.03it/s, loss=0.017, v_num=ypmf]Epoch 197:  88% 237/270 [02:40<-1:37:59, -0.02it/s, loss=0.0171, v_num=ypmf]Epoch 197:  88% 238/270 [02:40<-1:31:27, -0.02it/s, loss=0.0171, v_num=ypmf]Epoch 197:  88% 238/270 [02:40<-1:31:27, -0.02it/s, loss=0.0171, v_num=ypmf]Epoch 197:  88% 238/270 [02:40<-1:31:26, -0.02it/s, loss=0.0168, v_num=ypmf]Epoch 197:  89% 239/270 [02:41<-1:18:23, -0.01it/s, loss=0.0168, v_num=ypmf]Epoch 197:  89% 239/270 [02:41<-1:18:23, -0.01it/s, loss=0.0168, v_num=ypmf]Epoch 197:  89% 239/270 [02:41<-1:18:19, -0.01it/s, loss=0.0168, v_num=ypmf]Epoch 197:  89% 240/270 [02:42<-2:38:48, -0.01it/s, loss=0.0168, v_num=ypmf]Epoch 197:  89% 240/270 [02:42<-2:38:48, -0.01it/s, loss=0.0168, v_num=ypmf]Epoch 197:  89% 240/270 [02:42<-2:38:44, -0.01it/s, loss=0.0168, v_num=ypmf]Epoch 197:  89% 241/270 [02:43<?, ?it/s, loss=0.0168, v_num=ypmf]           Epoch 197:  89% 241/270 [02:43<?, ?it/s, loss=0.0168, v_num=ypmf]Epoch 197:  89% 241/270 [02:43<?, ?it/s, loss=0.0168, v_num=ypmf]Epoch 197:  90% 242/270 [02:44<1:16:33, 164.06s/it, loss=0.0168, v_num=ypmf]Epoch 197:  90% 242/270 [02:44<1:16:33, 164.06s/it, loss=0.0168, v_num=ypmf]Epoch 197:  90% 242/270 [02:44<1:16:37, 164.21s/it, loss=0.0168, v_num=ypmf]Epoch 197:  90% 243/270 [02:44<37:01, 82.28s/it, loss=0.0168, v_num=ypmf]   Epoch 197:  90% 243/270 [02:44<37:01, 82.28s/it, loss=0.0168, v_num=ypmf]Epoch 197:  90% 243/270 [02:44<37:03, 82.36s/it, loss=0.0168, v_num=ypmf]Epoch 197:  90% 244/270 [02:45<23:50, 55.02s/it, loss=0.0168, v_num=ypmf]Epoch 197:  90% 244/270 [02:45<23:50, 55.02s/it, loss=0.0168, v_num=ypmf]Epoch 197:  90% 244/270 [02:45<23:53, 55.13s/it, loss=0.0167, v_num=ypmf]Epoch 197:  91% 245/270 [02:45<17:16, 41.45s/it, loss=0.0167, v_num=ypmf]Epoch 197:  91% 245/270 [02:45<17:16, 41.45s/it, loss=0.0167, v_num=ypmf]Epoch 197:  91% 245/270 [02:45<17:17, 41.48s/it, loss=0.0166, v_num=ypmf]Epoch 197:  91% 246/270 [02:46<13:18, 33.25s/it, loss=0.0166, v_num=ypmf]Epoch 197:  91% 246/270 [02:46<13:18, 33.25s/it, loss=0.0166, v_num=ypmf]Epoch 197:  91% 246/270 [02:46<13:18, 33.29s/it, loss=0.0168, v_num=ypmf]Epoch 197:  91% 247/270 [02:46<10:39, 27.82s/it, loss=0.0168, v_num=ypmf]Epoch 197:  91% 247/270 [02:46<10:39, 27.82s/it, loss=0.0168, v_num=ypmf]Epoch 197:  91% 247/270 [02:47<10:40, 27.85s/it, loss=0.0168, v_num=ypmf]Epoch 197:  92% 248/270 [02:47<08:45, 23.91s/it, loss=0.0168, v_num=ypmf]Epoch 197:  92% 248/270 [02:47<08:45, 23.91s/it, loss=0.0168, v_num=ypmf]Epoch 197:  92% 248/270 [02:47<08:46, 23.95s/it, loss=0.017, v_num=ypmf] Epoch 197:  92% 249/270 [02:47<07:20, 21.00s/it, loss=0.017, v_num=ypmf]Epoch 197:  92% 249/270 [02:47<07:20, 21.00s/it, loss=0.017, v_num=ypmf]Epoch 197:  92% 249/270 [02:48<07:21, 21.04s/it, loss=0.017, v_num=ypmf]Epoch 197:  93% 250/270 [02:48<06:14, 18.74s/it, loss=0.017, v_num=ypmf]Epoch 197:  93% 250/270 [02:48<06:14, 18.74s/it, loss=0.017, v_num=ypmf]Epoch 197:  93% 250/270 [02:48<06:15, 18.76s/it, loss=0.0171, v_num=ypmf]
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 321891. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 272486. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 276881. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 238803. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 335146. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 284751. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 339696. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 390429. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 263378. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 287612. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 301039. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 315825. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batchValidation: 0it [00:00, ?it/s]_size` from an ambiguous collection. The batch size we found is 367043. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 353991. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 288172. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 290509. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 273866. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 299894. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 304642. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 302967. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308155. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 303408. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
[A
Validation:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.26it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.26it/s][AEpoch 197:  93% 251/270 [02:49<05:22, 16.99s/it, loss=0.0171, v_num=ypmf]Epoch 197:  93% 251/270 [02:49<05:22, 16.99s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  10% 2/20 [00:02<00:25,  1.39s/it][A
Validation DataLoader 0:  10% 2/20 [00:02<00:25,  1.39s/it][AEpoch 197:  93% 252/270 [02:51<04:41, 15.63s/it, loss=0.0171, v_num=ypmf]Epoch 197:  93% 252/270 [02:51<04:41, 15.63s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  15% 3/20 [00:04<00:26,  1.54s/it][A
Validation DataLoader 0:  15% 3/20 [00:04<00:26,  1.54s/it][AEpoch 197:  94% 253/270 [02:53<04:06, 14.47s/it, loss=0.0171, v_num=ypmf]Epoch 197:  94% 253/270 [02:53<04:06, 14.47s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  20% 4/20 [00:04<00:19,  1.20s/it][A
Validation DataLoader 0:  20% 4/20 [00:04<00:19,  1.20s/it][AEpoch 197:  94% 254/270 [02:54<03:34, 13.41s/it, loss=0.0171, v_num=ypmf]Epoch 197:  94% 254/270 [02:54<03:34, 13.41s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  25% 5/20 [00:06<00:19,  1.28s/it][A
Validation DataLoader 0:  25% 5/20 [00:06<00:19,  1.28s/it][AEpoch 197:  94% 255/270 [02:55<03:08, 12.56s/it, loss=0.0171, v_num=ypmf]Epoch 197:  94% 255/270 [02:55<03:08, 12.56s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  30% 6/20 [00:07<00:17,  1.23s/it][A
Validation DataLoader 0:  30% 6/20 [00:07<00:17,  1.23s/it][AEpoch 197:  95% 256/270 [02:56<02:45, 11.79s/it, loss=0.0171, v_num=ypmf]Epoch 197:  95% 256/270 [02:56<02:45, 11.79s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  35% 7/20 [00:09<00:17,  1.35s/it][A
Validation DataLoader 0:  35% 7/20 [00:09<00:17,  1.35s/it][AEpoch 197:  95% 257/270 [02:58<02:25, 11.16s/it, loss=0.0171, v_num=ypmf]Epoch 197:  95% 257/270 [02:58<02:25, 11.16s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  40% 8/20 [00:10<00:16,  1.35s/it][A
Validation DataLoader 0:  40% 8/20 [00:10<00:16,  1.35s/it][AEpoch 197:  96% 258/270 [02:59<02:06, 10.58s/it, loss=0.0171, v_num=ypmf]Epoch 197:  96% 258/270 [02:59<02:06, 10.58s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  45% 9/20 [00:11<00:12,  1.15s/it][A
Validation DataLoader 0:  45% 9/20 [00:11<00:12,  1.15s/it][AEpoch 197:  96% 259/270 [03:00<01:50, 10.03s/it, loss=0.0171, v_num=ypmf]Epoch 197:  96% 259/270 [03:00<01:50, 10.03s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  50% 10/20 [00:12<00:11,  1.13s/it][A
Validation DataLoader 0:  50% 10/20 [00:12<00:11,  1.13s/it][AEpoch 197:  96% 260/270 [03:01<01:35,  9.56s/it, loss=0.0171, v_num=ypmf]Epoch 197:  96% 260/270 [03:01<01:35,  9.56s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  55% 11/20 [00:12<00:09,  1.01s/it][A
Validation DataLoader 0:  55% 11/20 [00:12<00:09,  1.01s/it][AEpoch 197:  97% 261/270 [03:02<01:22,  9.12s/it, loss=0.0171, v_num=ypmf]Epoch 197:  97% 261/270 [03:02<01:22,  9.12s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  60% 12/20 [00:14<00:09,  1.17s/it][A
Validation DataLoader 0:  60% 12/20 [00:14<00:09,  1.17s/it][AEpoch 197:  97% 262/270 [03:03<01:10,  8.76s/it, loss=0.0171, v_num=ypmf]Epoch 197:  97% 262/270 [03:03<01:10,  8.76s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  65% 13/20 [00:15<00:07,  1.07s/it][A
Validation DataLoader 0:  65% 13/20 [00:15<00:07,  1.07s/it][AEpoch 197:  97% 263/270 [03:04<00:58,  8.40s/it, loss=0.0171, v_num=ypmf]Epoch 197:  97% 263/270 [03:04<00:58,  8.40s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  70% 14/20 [00:16<00:05,  1.04it/s][A
Validation DataLoader 0:  70% 14/20 [00:16<00:05,  1.04it/s][AEpoch 197:  98% 264/270 [03:05<00:48,  8.06s/it, loss=0.0171, v_num=ypmf]Epoch 197:  98% 264/270 [03:05<00:48,  8.06s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  75% 15/20 [00:17<00:04,  1.01it/s][A
Validation DataLoader 0:  75% 15/20 [00:17<00:04,  1.01it/s][AEpoch 197:  98% 265/270 [03:06<00:38,  7.77s/it, loss=0.0171, v_num=ypmf]Epoch 197:  98% 265/270 [03:06<00:38,  7.77s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  80% 16/20 [00:18<00:04,  1.05s/it][A
Validation DataLoader 0:  80% 16/20 [00:18<00:04,  1.05s/it][AEpoch 197:  99% 266/270 [03:07<00:30,  7.51s/it, loss=0.0171, v_num=ypmf]Epoch 197:  99% 266/270 [03:07<00:30,  7.51s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  85% 17/20 [00:19<00:02,  1.00it/s][A
Validation DataLoader 0:  85% 17/20 [00:19<00:02,  1.00it/s][AEpoch 197:  99% 267/270 [03:08<00:21,  7.25s/it, loss=0.0171, v_num=ypmf]Epoch 197:  99% 267/270 [03:08<00:21,  7.25s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  90% 18/20 [00:19<00:01,  1.12it/s][A
Validation DataLoader 0:  90% 18/20 [00:19<00:01,  1.12it/s][AEpoch 197:  99% 268/270 [03:09<00:14,  7.01s/it, loss=0.0171, v_num=ypmf]Epoch 197:  99% 268/270 [03:09<00:14,  7.01s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0:  95% 19/20 [00:22<00:01,  1.30s/it][A
Validation DataLoader 0:  95% 19/20 [00:22<00:01,  1.30s/it][AEpoch 197: 100% 269/270 [03:11<00:06,  6.84s/it, loss=0.0171, v_num=ypmf]Epoch 197: 100% 269/270 [03:11<00:06,  6.84s/it, loss=0.0171, v_num=ypmf]
Validation DataLoader 0: 100% 20/20 [00:22<00:00,  1.09s/it][A
Validation DataLoader 0: 100% 20/20 [00:22<00:00,  1.09s/it][AEpoch 197: 100% 270/270 [03:12<00:00,  6.62s/it, loss=0.0171, v_num=ypmf]Epoch 197: 100% 270/270 [03:12<00:00,  6.62s/it, loss=0.0171, v_num=ypmf]Epoch 197: 100% 270/270 [03:14<00:00,  6.71s/it, loss=0.0171, v_num=ypmf]
                                                            [AEpoch 197: 100% 270/270 [03:14<00:00,  6.71s/it, loss=0.0171, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 197:   0% 0/270 [00:00<00:00, -6126225.84it/s, loss=0.0171, v_num=ypmf]Epoch 198:   0% 0/270 [00:00<00:00, -1591853.96it/s, loss=0.0171, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 198:   0% 1/270 [00:01<-1:59:59, -191.23it/s, loss=0.0171, v_num=ypmf] Epoch 198:   0% 1/270 [00:01<-1:59:59, -191.20it/s, loss=0.0171, v_num=ypmf]Epoch 198:   0% 1/270 [00:01<-1:59:59, -169.08it/s, loss=0.0171, v_num=ypmf]Epoch 198:   1% 2/270 [00:01<-1:59:59, -134.83it/s, loss=0.0171, v_num=ypmf]Epoch 198:   1% 2/270 [00:01<-1:59:59, -134.82it/s, loss=0.0171, v_num=ypmf]Epoch 198:   1% 2/270 [00:01<-1:59:58, -124.56it/s, loss=0.0172, v_num=ypmf]Epoch 198:   1% 3/270 [00:02<-1:59:58, -103.92it/s, loss=0.0172, v_num=ypmf]Epoch 198:   1% 3/270 [00:02<-1:59:58, -103.91it/s, loss=0.0172, v_num=ypmf]Epoch 198:   1% 3/270 [00:02<-1:59:58, -90.26it/s, loss=0.0173, v_num=ypmf] Epoch 198:   1% 4/270 [00:03<-1:59:56, -65.50it/s, loss=0.0173, v_num=ypmf]Epoch 198:   1% 4/270 [00:03<-1:59:56, -65.50it/s, loss=0.0173, v_num=ypmf]Epoch 198:   1% 4/270 [00:03<-1:59:56, -62.64it/s, loss=0.0171, v_num=ypmf]Epoch 198:   2% 5/270 [00:04<-1:59:56, -57.48it/s, loss=0.0171, v_num=ypmf]Epoch 198:   2% 5/270 [00:04<-1:59:56, -57.47it/s, loss=0.0171, v_num=ypmf]Epoch 198:   2% 5/270 [00:04<-1:59:56, -54.95it/s, loss=0.0172, v_num=ypmf]Epoch 198:   2% 6/270 [00:04<-1:59:55, -49.44it/s, loss=0.0172, v_num=ypmf]Epoch 198:   2% 6/270 [00:04<-1:59:55, -49.44it/s, loss=0.0172, v_num=ypmf]Epoch 198:   2% 6/270 [00:04<-1:59:55, -47.98it/s, loss=0.0172, v_num=ypmf]Epoch 198:   3% 7/270 [00:05<-1:59:54, -43.46it/s, loss=0.0172, v_num=ypmf]Epoch 198:   3% 7/270 [00:05<-1:59:54, -43.46it/s, loss=0.0172, v_num=ypmf]Epoch 198:   3% 7/270 [00:05<-1:59:54, -42.21it/s, loss=0.0172, v_num=ypmf]Epoch 198:   3% 8/270 [00:05<-1:59:54, -40.07it/s, loss=0.0172, v_num=ypmf]Epoch 198:   3% 8/270 [00:05<-1:59:54, -40.07it/s, loss=0.0172, v_num=ypmf]Epoch 198:   3% 8/270 [00:06<-1:59:54, -38.21it/s, loss=0.0174, v_num=ypmf]Epoch 198:   3% 9/270 [00:06<-1:59:53, -36.30it/s, loss=0.0174, v_num=ypmf]Epoch 198:   3% 9/270 [00:06<-1:59:53, -36.29it/s, loss=0.0174, v_num=ypmf]Epoch 198:   3% 9/270 [00:06<-1:59:53, -34.96it/s, loss=0.0173, v_num=ypmf]Epoch 198:   4% 10/270 [00:07<-1:59:53, -32.92it/s, loss=0.0173, v_num=ypmf]Epoch 198:   4% 10/270 [00:07<-1:59:53, -32.92it/s, loss=0.0173, v_num=ypmf]Epoch 198:   4% 10/270 [00:07<-1:59:52, -32.18it/s, loss=0.0174, v_num=ypmf]Epoch 198:   4% 11/270 [00:07<-1:59:52, -30.36it/s, loss=0.0174, v_num=ypmf]Epoch 198:   4% 11/270 [00:07<-1:59:52, -30.36it/s, loss=0.0174, v_num=ypmf]Epoch 198:   4% 11/270 [00:07<-1:59:52, -29.86it/s, loss=0.0173, v_num=ypmf]Epoch 198:   4% 12/270 [00:08<-1:59:51, -27.92it/s, loss=0.0173, v_num=ypmf]Epoch 198:   4% 12/270 [00:08<-1:59:51, -27.92it/s, loss=0.0173, v_num=ypmf]Epoch 198:   4% 12/270 [00:08<-1:59:51, -27.38it/s, loss=0.0174, v_num=ypmf]Epoch 198:   5% 13/270 [00:08<-1:59:51, -25.94it/s, loss=0.0174, v_num=ypmf]Epoch 198:   5% 13/270 [00:08<-1:59:51, -25.94it/s, loss=0.0174, v_num=ypmf]Epoch 198:   5% 13/270 [00:08<-1:59:50, -25.35it/s, loss=0.0174, v_num=ypmf]Epoch 198:   5% 14/270 [00:09<-1:59:50, -24.28it/s, loss=0.0174, v_num=ypmf]Epoch 198:   5% 14/270 [00:09<-1:59:50, -24.28it/s, loss=0.0174, v_num=ypmf]Epoch 198:   5% 14/270 [00:09<-1:59:50, -23.81it/s, loss=0.0176, v_num=ypmf]Epoch 198:   6% 15/270 [00:09<-1:59:49, -22.91it/s, loss=0.0176, v_num=ypmf]Epoch 198:   6% 15/270 [00:09<-1:59:49, -22.91it/s, loss=0.0176, v_num=ypmf]Epoch 198:   6% 15/270 [00:10<-1:59:49, -22.35it/s, loss=0.0177, v_num=ypmf]Epoch 198:   6% 16/270 [00:10<-1:59:48, -21.15it/s, loss=0.0177, v_num=ypmf]Epoch 198:   6% 16/270 [00:10<-1:59:48, -21.15it/s, loss=0.0177, v_num=ypmf]Epoch 198:   6% 16/270 [00:10<-1:59:48, -21.05it/s, loss=0.0175, v_num=ypmf]Epoch 198:   6% 17/270 [00:10<-1:59:48, -20.38it/s, loss=0.0175, v_num=ypmf]Epoch 198:   6% 17/270 [00:10<-1:59:48, -20.38it/s, loss=0.0175, v_num=ypmf]Epoch 198:   6% 17/270 [00:11<-1:59:48, -19.73it/s, loss=0.0176, v_num=ypmf]Epoch 198:   7% 18/270 [00:11<-1:59:47, -18.96it/s, loss=0.0176, v_num=ypmf]Epoch 198:   7% 18/270 [00:11<-1:59:47, -18.96it/s, loss=0.0176, v_num=ypmf]Epoch 198:   7% 18/270 [00:11<-1:59:47, -18.66it/s, loss=0.0174, v_num=ypmf]Epoch 198:   7% 19/270 [00:12<-1:59:46, -17.91it/s, loss=0.0174, v_num=ypmf]Epoch 198:   7% 19/270 [00:12<-1:59:46, -17.91it/s, loss=0.0174, v_num=ypmf]Epoch 198:   7% 19/270 [00:12<-1:59:46, -17.70it/s, loss=0.0174, v_num=ypmf]Epoch 198:   7% 20/270 [00:12<-1:59:46, -17.20it/s, loss=0.0174, v_num=ypmf]Epoch 198:   7% 20/270 [00:12<-1:59:46, -17.20it/s, loss=0.0174, v_num=ypmf]Epoch 198:   7% 20/270 [00:13<-1:59:46, -16.81it/s, loss=0.0174, v_num=ypmf]Epoch 198:   8% 21/270 [00:13<-1:59:45, -16.23it/s, loss=0.0174, v_num=ypmf]Epoch 198:   8% 21/270 [00:13<-1:59:45, -16.23it/s, loss=0.0174, v_num=ypmf]Epoch 198:   8% 21/270 [00:13<-1:59:45, -16.07it/s, loss=0.0174, v_num=ypmf]Epoch 198:   8% 22/270 [00:14<-1:59:45, -15.60it/s, loss=0.0174, v_num=ypmf]Epoch 198:   8% 22/270 [00:14<-1:59:45, -15.60it/s, loss=0.0174, v_num=ypmf]Epoch 198:   8% 22/270 [00:14<-1:59:44, -15.03it/s, loss=0.0173, v_num=ypmf]Epoch 198:   9% 23/270 [00:14<-1:59:44, -14.55it/s, loss=0.0173, v_num=ypmf]Epoch 198:   9% 23/270 [00:14<-1:59:44, -14.55it/s, loss=0.0173, v_num=ypmf]Epoch 198:   9% 23/270 [00:15<-1:59:43, -14.42it/s, loss=0.0172, v_num=ypmf]Epoch 198:   9% 24/270 [00:15<-1:59:43, -13.97it/s, loss=0.0172, v_num=ypmf]Epoch 198:   9% 24/270 [00:15<-1:59:43, -13.97it/s, loss=0.0172, v_num=ypmf]Epoch 198:   9% 24/270 [00:15<-1:59:42, -13.61it/s, loss=0.0171, v_num=ypmf]Epoch 198:   9% 25/270 [00:16<-1:59:42, -13.21it/s, loss=0.0171, v_num=ypmf]Epoch 198:   9% 25/270 [00:16<-1:59:42, -13.21it/s, loss=0.0171, v_num=ypmf]Epoch 198:   9% 25/270 [00:16<-1:59:42, -13.11it/s, loss=0.0171, v_num=ypmf]Epoch 198:  10% 26/270 [00:16<-1:59:41, -12.77it/s, loss=0.0171, v_num=ypmf]Epoch 198:  10% 26/270 [00:16<-1:59:41, -12.77it/s, loss=0.0171, v_num=ypmf]Epoch 198:  10% 26/270 [00:17<-1:59:41, -12.63it/s, loss=0.0172, v_num=ypmf]Epoch 198:  10% 27/270 [00:17<-1:59:41, -12.36it/s, loss=0.0172, v_num=ypmf]Epoch 198:  10% 27/270 [00:17<-1:59:41, -12.36it/s, loss=0.0172, v_num=ypmf]Epoch 198:  10% 27/270 [00:17<-1:59:41, -12.17it/s, loss=0.0173, v_num=ypmf]Epoch 198:  10% 28/270 [00:17<-1:59:40, -11.85it/s, loss=0.0173, v_num=ypmf]Epoch 198:  10% 28/270 [00:17<-1:59:40, -11.85it/s, loss=0.0173, v_num=ypmf]Epoch 198:  10% 28/270 [00:18<-1:59:40, -11.77it/s, loss=0.0171, v_num=ypmf]Epoch 198:  11% 29/270 [00:18<-1:59:39, -11.41it/s, loss=0.0171, v_num=ypmf]Epoch 198:  11% 29/270 [00:18<-1:59:39, -11.41it/s, loss=0.0171, v_num=ypmf]Epoch 198:  11% 29/270 [00:18<-1:59:39, -11.31it/s, loss=0.0171, v_num=ypmf]Epoch 198:  11% 30/270 [00:19<-1:59:39, -10.97it/s, loss=0.0171, v_num=ypmf]Epoch 198:  11% 30/270 [00:19<-1:59:39, -10.97it/s, loss=0.0171, v_num=ypmf]Epoch 198:  11% 30/270 [00:19<-1:59:38, -10.88it/s, loss=0.0171, v_num=ypmf]Epoch 198:  11% 31/270 [00:19<-1:59:38, -10.55it/s, loss=0.0171, v_num=ypmf]Epoch 198:  11% 31/270 [00:19<-1:59:38, -10.55it/s, loss=0.0171, v_num=ypmf]Epoch 198:  11% 31/270 [00:20<-1:59:38, -10.46it/s, loss=0.0172, v_num=ypmf]Epoch 198:  12% 32/270 [00:20<-1:59:37, -10.26it/s, loss=0.0172, v_num=ypmf]Epoch 198:  12% 32/270 [00:20<-1:59:37, -10.26it/s, loss=0.0172, v_num=ypmf]Epoch 198:  12% 32/270 [00:20<-1:59:37, -10.15it/s, loss=0.0173, v_num=ypmf]Epoch 198:  12% 33/270 [00:21<-1:59:36, -9.86it/s, loss=0.0173, v_num=ypmf] Epoch 198:  12% 33/270 [00:21<-1:59:36, -9.86it/s, loss=0.0173, v_num=ypmf]Epoch 198:  12% 33/270 [00:21<-1:59:36, -9.79it/s, loss=0.0173, v_num=ypmf]Epoch 198:  13% 34/270 [00:21<-1:59:36, -9.56it/s, loss=0.0173, v_num=ypmf]Epoch 198:  13% 34/270 [00:21<-1:59:36, -9.56it/s, loss=0.0173, v_num=ypmf]Epoch 198:  13% 34/270 [00:21<-1:59:36, -9.49it/s, loss=0.0171, v_num=ypmf]Epoch 198:  13% 35/270 [00:22<-1:59:35, -9.25it/s, loss=0.0171, v_num=ypmf]Epoch 198:  13% 35/270 [00:22<-1:59:35, -9.25it/s, loss=0.0171, v_num=ypmf]Epoch 198:  13% 35/270 [00:22<-1:59:35, -9.18it/s, loss=0.017, v_num=ypmf] Epoch 198:  13% 36/270 [00:22<-1:59:35, -9.02it/s, loss=0.017, v_num=ypmf]Epoch 198:  13% 36/270 [00:22<-1:59:35, -9.02it/s, loss=0.017, v_num=ypmf]Epoch 198:  13% 36/270 [00:23<-1:59:34, -8.90it/s, loss=0.0171, v_num=ypmf]Epoch 198:  14% 37/270 [00:23<-1:59:34, -8.70it/s, loss=0.0171, v_num=ypmf]Epoch 198:  14% 37/270 [00:23<-1:59:34, -8.70it/s, loss=0.0171, v_num=ypmf]Epoch 198:  14% 37/270 [00:23<-1:59:34, -8.65it/s, loss=0.017, v_num=ypmf] Epoch 198:  14% 38/270 [00:24<-1:59:33, -8.46it/s, loss=0.017, v_num=ypmf]Epoch 198:  14% 38/270 [00:24<-1:59:33, -8.46it/s, loss=0.017, v_num=ypmf]Epoch 198:  14% 38/270 [00:24<-1:59:33, -8.41it/s, loss=0.017, v_num=ypmf]Epoch 198:  14% 39/270 [00:24<-1:59:32, -8.23it/s, loss=0.017, v_num=ypmf]Epoch 198:  14% 39/270 [00:24<-1:59:32, -8.23it/s, loss=0.017, v_num=ypmf]Epoch 198:  14% 39/270 [00:24<-1:59:32, -8.18it/s, loss=0.017, v_num=ypmf]Epoch 198:  15% 40/270 [00:25<-1:59:32, -8.02it/s, loss=0.017, v_num=ypmf]Epoch 198:  15% 40/270 [00:25<-1:59:32, -8.02it/s, loss=0.017, v_num=ypmf]Epoch 198:  15% 40/270 [00:25<-1:59:32, -7.96it/s, loss=0.017, v_num=ypmf]Epoch 198:  15% 41/270 [00:25<-1:59:31, -7.75it/s, loss=0.017, v_num=ypmf]Epoch 198:  15% 41/270 [00:25<-1:59:31, -7.75it/s, loss=0.017, v_num=ypmf]Epoch 198:  15% 41/270 [00:25<-1:59:31, -7.75it/s, loss=0.017, v_num=ypmf]Epoch 198:  16% 42/270 [00:26<-1:59:30, -7.59it/s, loss=0.017, v_num=ypmf]Epoch 198:  16% 42/270 [00:26<-1:59:30, -7.59it/s, loss=0.017, v_num=ypmf]Epoch 198:  16% 42/270 [00:26<-1:59:30, -7.46it/s, loss=0.0169, v_num=ypmf]Epoch 198:  16% 43/270 [00:27<-1:59:29, -7.30it/s, loss=0.0169, v_num=ypmf]Epoch 198:  16% 43/270 [00:27<-1:59:29, -7.30it/s, loss=0.0169, v_num=ypmf]Epoch 198:  16% 43/270 [00:27<-1:59:29, -7.27it/s, loss=0.0169, v_num=ypmf]Epoch 198:  16% 44/270 [00:27<-1:59:29, -7.14it/s, loss=0.0169, v_num=ypmf]Epoch 198:  16% 44/270 [00:27<-1:59:29, -7.14it/s, loss=0.0169, v_num=ypmf]Epoch 198:  16% 44/270 [00:29<-1:59:27, -6.72it/s, loss=0.017, v_num=ypmf] Epoch 198:  17% 45/270 [00:29<-1:59:26, -6.59it/s, loss=0.017, v_num=ypmf]Epoch 198:  17% 45/270 [00:29<-1:59:26, -6.59it/s, loss=0.017, v_num=ypmf]Epoch 198:  17% 45/270 [00:29<-1:59:26, -6.56it/s, loss=0.0169, v_num=ypmf]Epoch 198:  17% 46/270 [00:30<-1:59:26, -6.44it/s, loss=0.0169, v_num=ypmf]Epoch 198:  17% 46/270 [00:30<-1:59:26, -6.44it/s, loss=0.0169, v_num=ypmf]Epoch 198:  17% 46/270 [00:30<-1:59:25, -6.32it/s, loss=0.017, v_num=ypmf] Epoch 198:  17% 47/270 [00:31<-1:59:25, -6.21it/s, loss=0.017, v_num=ypmf]Epoch 198:  17% 47/270 [00:31<-1:59:25, -6.21it/s, loss=0.017, v_num=ypmf]Epoch 198:  17% 47/270 [00:31<-1:59:24, -6.18it/s, loss=0.0169, v_num=ypmf]Epoch 198:  18% 48/270 [00:31<-1:59:24, -6.08it/s, loss=0.0169, v_num=ypmf]Epoch 198:  18% 48/270 [00:31<-1:59:24, -6.08it/s, loss=0.0169, v_num=ypmf]Epoch 198:  18% 48/270 [00:32<-1:59:24, -6.03it/s, loss=0.017, v_num=ypmf] Epoch 198:  18% 49/270 [00:32<-1:59:23, -5.92it/s, loss=0.017, v_num=ypmf]Epoch 198:  18% 49/270 [00:32<-1:59:23, -5.92it/s, loss=0.017, v_num=ypmf]Epoch 198:  18% 49/270 [00:32<-1:59:23, -5.89it/s, loss=0.017, v_num=ypmf]Epoch 198:  19% 50/270 [00:33<-1:59:22, -5.78it/s, loss=0.017, v_num=ypmf]Epoch 198:  19% 50/270 [00:33<-1:59:22, -5.78it/s, loss=0.017, v_num=ypmf]Epoch 198:  19% 50/270 [00:33<-1:59:22, -5.75it/s, loss=0.017, v_num=ypmf]Epoch 198:  19% 51/270 [00:33<-1:59:22, -5.66it/s, loss=0.017, v_num=ypmf]Epoch 198:  19% 51/270 [00:33<-1:59:22, -5.66it/s, loss=0.017, v_num=ypmf]Epoch 198:  19% 51/270 [00:33<-1:59:22, -5.63it/s, loss=0.017, v_num=ypmf]Epoch 198:  19% 52/270 [00:34<-1:59:21, -5.54it/s, loss=0.017, v_num=ypmf]Epoch 198:  19% 52/270 [00:34<-1:59:21, -5.54it/s, loss=0.017, v_num=ypmf]Epoch 198:  19% 52/270 [00:35<-1:59:19, -5.27it/s, loss=0.0169, v_num=ypmf]Epoch 198:  20% 53/270 [00:36<-1:59:19, -5.20it/s, loss=0.0169, v_num=ypmf]Epoch 198:  20% 53/270 [00:36<-1:59:19, -5.20it/s, loss=0.0169, v_num=ypmf]Epoch 198:  20% 53/270 [00:36<-1:59:19, -5.18it/s, loss=0.0169, v_num=ypmf]Epoch 198:  20% 54/270 [00:36<-1:59:18, -5.11it/s, loss=0.0169, v_num=ypmf]Epoch 198:  20% 54/270 [00:36<-1:59:18, -5.11it/s, loss=0.0169, v_num=ypmf]Epoch 198:  20% 54/270 [00:37<-1:59:17, -5.00it/s, loss=0.0169, v_num=ypmf]Epoch 198:  20% 55/270 [00:37<-1:59:17, -4.93it/s, loss=0.0169, v_num=ypmf]Epoch 198:  20% 55/270 [00:37<-1:59:17, -4.93it/s, loss=0.0169, v_num=ypmf]Epoch 198:  20% 55/270 [00:37<-1:59:17, -4.91it/s, loss=0.017, v_num=ypmf] Epoch 198:  21% 56/270 [00:38<-1:59:16, -4.84it/s, loss=0.017, v_num=ypmf]Epoch 198:  21% 56/270 [00:38<-1:59:16, -4.84it/s, loss=0.017, v_num=ypmf]Epoch 198:  21% 56/270 [00:38<-1:59:16, -4.81it/s, loss=0.017, v_num=ypmf]Epoch 198:  21% 57/270 [00:38<-1:59:16, -4.74it/s, loss=0.017, v_num=ypmf]Epoch 198:  21% 57/270 [00:38<-1:59:16, -4.74it/s, loss=0.017, v_num=ypmf]Epoch 198:  21% 57/270 [00:39<-1:59:15, -4.65it/s, loss=0.017, v_num=ypmf]Epoch 198:  21% 58/270 [00:39<-1:59:14, -4.59it/s, loss=0.017, v_num=ypmf]Epoch 198:  21% 58/270 [00:39<-1:59:14, -4.59it/s, loss=0.017, v_num=ypmf]Epoch 198:  21% 58/270 [00:40<-1:59:14, -4.55it/s, loss=0.0171, v_num=ypmf]Epoch 198:  22% 59/270 [00:40<-1:59:13, -4.49it/s, loss=0.0171, v_num=ypmf]Epoch 198:  22% 59/270 [00:40<-1:59:13, -4.49it/s, loss=0.0171, v_num=ypmf]Epoch 198:  22% 59/270 [00:41<-1:59:12, -4.37it/s, loss=0.017, v_num=ypmf] Epoch 198:  22% 60/270 [00:42<-1:59:12, -4.31it/s, loss=0.017, v_num=ypmf]Epoch 198:  22% 60/270 [00:42<-1:59:12, -4.31it/s, loss=0.017, v_num=ypmf]Epoch 198:  22% 60/270 [00:42<-1:59:12, -4.29it/s, loss=0.0169, v_num=ypmf]Epoch 198:  23% 61/270 [00:42<-1:59:11, -4.23it/s, loss=0.0169, v_num=ypmf]Epoch 198:  23% 61/270 [00:42<-1:59:11, -4.23it/s, loss=0.0169, v_num=ypmf]Epoch 198:  23% 61/270 [00:42<-1:59:11, -4.22it/s, loss=0.0169, v_num=ypmf]Epoch 198:  23% 62/270 [00:43<-1:59:10, -4.16it/s, loss=0.0169, v_num=ypmf]Epoch 198:  23% 62/270 [00:43<-1:59:10, -4.16it/s, loss=0.0169, v_num=ypmf]Epoch 198:  23% 62/270 [00:43<-1:59:10, -4.14it/s, loss=0.0169, v_num=ypmf]Epoch 198:  23% 63/270 [00:43<-1:59:10, -4.09it/s, loss=0.0169, v_num=ypmf]Epoch 198:  23% 63/270 [00:43<-1:59:10, -4.09it/s, loss=0.0169, v_num=ypmf]Epoch 198:  23% 63/270 [00:43<-1:59:10, -4.07it/s, loss=0.017, v_num=ypmf] Epoch 198:  24% 64/270 [00:43<-1:59:09, -4.02it/s, loss=0.017, v_num=ypmf]Epoch 198:  24% 64/270 [00:43<-1:59:09, -4.02it/s, loss=0.017, v_num=ypmf]Epoch 198:  24% 64/270 [00:44<-1:59:09, -3.99it/s, loss=0.0171, v_num=ypmf]Epoch 198:  24% 65/270 [00:44<-1:59:09, -3.94it/s, loss=0.0171, v_num=ypmf]Epoch 198:  24% 65/270 [00:44<-1:59:09, -3.94it/s, loss=0.0171, v_num=ypmf]Epoch 198:  24% 65/270 [00:44<-1:59:08, -3.92it/s, loss=0.0171, v_num=ypmf]Epoch 198:  24% 66/270 [00:45<-1:59:08, -3.85it/s, loss=0.0171, v_num=ypmf]Epoch 198:  24% 66/270 [00:45<-1:59:08, -3.85it/s, loss=0.0171, v_num=ypmf]Epoch 198:  24% 66/270 [00:45<-1:59:07, -3.84it/s, loss=0.0171, v_num=ypmf]Epoch 198:  25% 67/270 [00:46<-1:59:07, -3.78it/s, loss=0.0171, v_num=ypmf]Epoch 198:  25% 67/270 [00:46<-1:59:07, -3.78it/s, loss=0.0171, v_num=ypmf]Epoch 198:  25% 67/270 [00:46<-1:59:07, -3.77it/s, loss=0.0171, v_num=ypmf]Epoch 198:  25% 68/270 [00:46<-1:59:06, -3.70it/s, loss=0.0171, v_num=ypmf]Epoch 198:  25% 68/270 [00:46<-1:59:06, -3.70it/s, loss=0.0171, v_num=ypmf]Epoch 198:  25% 68/270 [00:46<-1:59:06, -3.69it/s, loss=0.0169, v_num=ypmf]Epoch 198:  26% 69/270 [00:47<-1:59:05, -3.64it/s, loss=0.0169, v_num=ypmf]Epoch 198:  26% 69/270 [00:47<-1:59:05, -3.64it/s, loss=0.0169, v_num=ypmf]Epoch 198:  26% 69/270 [00:47<-1:59:05, -3.63it/s, loss=0.0171, v_num=ypmf]Epoch 198:  26% 70/270 [00:47<-1:59:05, -3.58it/s, loss=0.0171, v_num=ypmf]Epoch 198:  26% 70/270 [00:47<-1:59:05, -3.58it/s, loss=0.0171, v_num=ypmf]Epoch 198:  26% 70/270 [00:48<-1:59:04, -3.52it/s, loss=0.0171, v_num=ypmf]Epoch 198:  26% 71/270 [00:48<-1:59:03, -3.48it/s, loss=0.0171, v_num=ypmf]Epoch 198:  26% 71/270 [00:48<-1:59:03, -3.48it/s, loss=0.0171, v_num=ypmf]Epoch 198:  26% 71/270 [00:49<-1:59:03, -3.46it/s, loss=0.0171, v_num=ypmf]Epoch 198:  27% 72/270 [00:49<-1:59:02, -3.41it/s, loss=0.0171, v_num=ypmf]Epoch 198:  27% 72/270 [00:49<-1:59:02, -3.41it/s, loss=0.0171, v_num=ypmf]Epoch 198:  27% 72/270 [00:50<-1:59:02, -3.36it/s, loss=0.0172, v_num=ypmf]Epoch 198:  27% 73/270 [00:50<-1:59:01, -3.31it/s, loss=0.0172, v_num=ypmf]Epoch 198:  27% 73/270 [00:50<-1:59:01, -3.31it/s, loss=0.0172, v_num=ypmf]Epoch 198:  27% 73/270 [00:50<-1:59:01, -3.30it/s, loss=0.0171, v_num=ypmf]Epoch 198:  27% 74/270 [00:51<-1:59:00, -3.25it/s, loss=0.0171, v_num=ypmf]Epoch 198:  27% 74/270 [00:51<-1:59:00, -3.25it/s, loss=0.0171, v_num=ypmf]Epoch 198:  27% 74/270 [00:51<-1:59:00, -3.24it/s, loss=0.0171, v_num=ypmf]Epoch 198:  28% 75/270 [00:51<-1:59:00, -3.20it/s, loss=0.0171, v_num=ypmf]Epoch 198:  28% 75/270 [00:51<-1:59:00, -3.20it/s, loss=0.0171, v_num=ypmf]Epoch 198:  28% 75/270 [00:52<-1:58:59, -3.19it/s, loss=0.0171, v_num=ypmf]Epoch 198:  28% 76/270 [00:52<-1:58:59, -3.14it/s, loss=0.0171, v_num=ypmf]Epoch 198:  28% 76/270 [00:52<-1:58:59, -3.14it/s, loss=0.0171, v_num=ypmf]Epoch 198:  28% 76/270 [00:52<-1:58:58, -3.12it/s, loss=0.0169, v_num=ypmf]Epoch 198:  29% 77/270 [00:53<-1:58:58, -3.08it/s, loss=0.0169, v_num=ypmf]Epoch 198:  29% 77/270 [00:53<-1:58:58, -3.08it/s, loss=0.0169, v_num=ypmf]Epoch 198:  29% 77/270 [00:53<-1:58:58, -3.08it/s, loss=0.0169, v_num=ypmf]Epoch 198:  29% 78/270 [00:53<-1:58:57, -3.04it/s, loss=0.0169, v_num=ypmf]Epoch 198:  29% 78/270 [00:53<-1:58:57, -3.04it/s, loss=0.0169, v_num=ypmf]Epoch 198:  29% 78/270 [00:53<-1:58:57, -3.02it/s, loss=0.0169, v_num=ypmf]Epoch 198:  29% 79/270 [00:54<-1:58:56, -2.98it/s, loss=0.0169, v_num=ypmf]Epoch 198:  29% 79/270 [00:54<-1:58:56, -2.98it/s, loss=0.0169, v_num=ypmf]Epoch 198:  29% 79/270 [00:54<-1:58:56, -2.98it/s, loss=0.0169, v_num=ypmf]Epoch 198:  30% 80/270 [00:54<-1:58:56, -2.93it/s, loss=0.0169, v_num=ypmf]Epoch 198:  30% 80/270 [00:54<-1:58:56, -2.93it/s, loss=0.0169, v_num=ypmf]Epoch 198:  30% 80/270 [00:55<-1:58:56, -2.93it/s, loss=0.017, v_num=ypmf] Epoch 198:  30% 81/270 [00:55<-1:58:55, -2.89it/s, loss=0.017, v_num=ypmf]Epoch 198:  30% 81/270 [00:55<-1:58:55, -2.89it/s, loss=0.017, v_num=ypmf]Epoch 198:  30% 81/270 [00:55<-1:58:55, -2.88it/s, loss=0.0171, v_num=ypmf]Epoch 198:  30% 82/270 [00:56<-1:58:54, -2.84it/s, loss=0.0171, v_num=ypmf]Epoch 198:  30% 82/270 [00:56<-1:58:54, -2.84it/s, loss=0.0171, v_num=ypmf]Epoch 198:  30% 82/270 [00:56<-1:58:54, -2.83it/s, loss=0.0172, v_num=ypmf]Epoch 198:  31% 83/270 [00:56<-1:58:54, -2.80it/s, loss=0.0172, v_num=ypmf]Epoch 198:  31% 83/270 [00:56<-1:58:54, -2.80it/s, loss=0.0172, v_num=ypmf]Epoch 198:  31% 83/270 [00:56<-1:58:53, -2.78it/s, loss=0.0172, v_num=ypmf]Epoch 198:  31% 84/270 [00:57<-1:58:52, -2.73it/s, loss=0.0172, v_num=ypmf]Epoch 198:  31% 84/270 [00:57<-1:58:52, -2.73it/s, loss=0.0172, v_num=ypmf]Epoch 198:  31% 84/270 [00:57<-1:58:52, -2.72it/s, loss=0.0171, v_num=ypmf]Epoch 198:  31% 85/270 [00:58<-1:58:52, -2.68it/s, loss=0.0171, v_num=ypmf]Epoch 198:  31% 85/270 [00:58<-1:58:52, -2.68it/s, loss=0.0171, v_num=ypmf]Epoch 198:  31% 85/270 [00:58<-1:58:51, -2.68it/s, loss=0.0171, v_num=ypmf]Epoch 198:  32% 86/270 [00:58<-1:58:51, -2.65it/s, loss=0.0171, v_num=ypmf]Epoch 198:  32% 86/270 [00:58<-1:58:51, -2.65it/s, loss=0.0171, v_num=ypmf]Epoch 198:  32% 86/270 [00:58<-1:58:51, -2.63it/s, loss=0.0171, v_num=ypmf]Epoch 198:  32% 87/270 [00:59<-1:58:50, -2.59it/s, loss=0.0171, v_num=ypmf]Epoch 198:  32% 87/270 [00:59<-1:58:50, -2.59it/s, loss=0.0171, v_num=ypmf]Epoch 198:  32% 87/270 [00:59<-1:58:50, -2.59it/s, loss=0.0171, v_num=ypmf]Epoch 198:  33% 88/270 [00:59<-1:58:49, -2.56it/s, loss=0.0171, v_num=ypmf]Epoch 198:  33% 88/270 [00:59<-1:58:49, -2.56it/s, loss=0.0171, v_num=ypmf]Epoch 198:  33% 88/270 [01:00<-1:58:49, -2.55it/s, loss=0.0172, v_num=ypmf]Epoch 198:  33% 89/270 [01:00<-1:58:49, -2.52it/s, loss=0.0172, v_num=ypmf]Epoch 198:  33% 89/270 [01:00<-1:58:49, -2.52it/s, loss=0.0172, v_num=ypmf]Epoch 198:  33% 89/270 [01:00<-1:58:48, -2.51it/s, loss=0.0172, v_num=ypmf]Epoch 198:  33% 90/270 [01:00<-1:58:48, -2.48it/s, loss=0.0172, v_num=ypmf]Epoch 198:  33% 90/270 [01:00<-1:58:48, -2.48it/s, loss=0.0172, v_num=ypmf]Epoch 198:  33% 90/270 [01:01<-1:58:48, -2.47it/s, loss=0.0171, v_num=ypmf]Epoch 198:  34% 91/270 [01:01<-1:58:47, -2.43it/s, loss=0.0171, v_num=ypmf]Epoch 198:  34% 91/270 [01:01<-1:58:47, -2.43it/s, loss=0.0171, v_num=ypmf]Epoch 198:  34% 91/270 [01:01<-1:58:47, -2.43it/s, loss=0.0172, v_num=ypmf]Epoch 198:  34% 92/270 [01:02<-1:58:46, -2.40it/s, loss=0.0172, v_num=ypmf]Epoch 198:  34% 92/270 [01:02<-1:58:46, -2.40it/s, loss=0.0172, v_num=ypmf]Epoch 198:  34% 92/270 [01:02<-1:58:46, -2.39it/s, loss=0.0172, v_num=ypmf]Epoch 198:  34% 93/270 [01:02<-1:58:45, -2.35it/s, loss=0.0172, v_num=ypmf]Epoch 198:  34% 93/270 [01:02<-1:58:45, -2.35it/s, loss=0.0172, v_num=ypmf]Epoch 198:  34% 93/270 [01:03<-1:58:45, -2.34it/s, loss=0.0173, v_num=ypmf]Epoch 198:  35% 94/270 [01:03<-1:58:44, -2.31it/s, loss=0.0173, v_num=ypmf]Epoch 198:  35% 94/270 [01:03<-1:58:44, -2.31it/s, loss=0.0173, v_num=ypmf]Epoch 198:  35% 94/270 [01:03<-1:58:44, -2.30it/s, loss=0.0172, v_num=ypmf]Epoch 198:  35% 95/270 [01:09<-1:58:38, -2.11it/s, loss=0.0172, v_num=ypmf]Epoch 198:  35% 95/270 [01:09<-1:58:38, -2.11it/s, loss=0.0172, v_num=ypmf]Epoch 198:  35% 95/270 [01:09<-1:58:37, -2.10it/s, loss=0.0171, v_num=ypmf]Epoch 198:  36% 96/270 [01:09<-1:58:37, -2.08it/s, loss=0.0171, v_num=ypmf]Epoch 198:  36% 96/270 [01:09<-1:58:37, -2.08it/s, loss=0.0171, v_num=ypmf]Epoch 198:  36% 96/270 [01:09<-1:58:37, -2.07it/s, loss=0.0172, v_num=ypmf]Epoch 198:  36% 97/270 [01:10<-1:58:36, -2.05it/s, loss=0.0172, v_num=ypmf]Epoch 198:  36% 97/270 [01:10<-1:58:36, -2.05it/s, loss=0.0172, v_num=ypmf]Epoch 198:  36% 97/270 [01:10<-1:58:36, -2.04it/s, loss=0.0173, v_num=ypmf]Epoch 198:  36% 98/270 [01:10<-1:58:35, -2.02it/s, loss=0.0173, v_num=ypmf]Epoch 198:  36% 98/270 [01:10<-1:58:35, -2.02it/s, loss=0.0173, v_num=ypmf]Epoch 198:  36% 98/270 [01:11<-1:58:35, -2.01it/s, loss=0.0172, v_num=ypmf]Epoch 198:  37% 99/270 [01:11<-1:58:34, -1.98it/s, loss=0.0172, v_num=ypmf]Epoch 198:  37% 99/270 [01:11<-1:58:34, -1.98it/s, loss=0.0172, v_num=ypmf]Epoch 198:  37% 99/270 [01:11<-1:58:34, -1.98it/s, loss=0.0172, v_num=ypmf]Epoch 198:  37% 100/270 [01:12<-1:58:34, -1.96it/s, loss=0.0172, v_num=ypmf]Epoch 198:  37% 100/270 [01:12<-1:58:34, -1.96it/s, loss=0.0172, v_num=ypmf]Epoch 198:  37% 100/270 [01:12<-1:58:33, -1.95it/s, loss=0.0172, v_num=ypmf]Epoch 198:  37% 101/270 [01:12<-1:58:33, -1.92it/s, loss=0.0172, v_num=ypmf]Epoch 198:  37% 101/270 [01:12<-1:58:33, -1.92it/s, loss=0.0172, v_num=ypmf]Epoch 198:  37% 101/270 [01:13<-1:58:32, -1.92it/s, loss=0.0172, v_num=ypmf]Epoch 198:  38% 102/270 [01:13<-1:58:32, -1.89it/s, loss=0.0172, v_num=ypmf]Epoch 198:  38% 102/270 [01:13<-1:58:32, -1.89it/s, loss=0.0172, v_num=ypmf]Epoch 198:  38% 102/270 [01:13<-1:58:31, -1.89it/s, loss=0.0172, v_num=ypmf]Epoch 198:  38% 103/270 [01:14<-1:58:31, -1.86it/s, loss=0.0172, v_num=ypmf]Epoch 198:  38% 103/270 [01:14<-1:58:31, -1.86it/s, loss=0.0172, v_num=ypmf]Epoch 198:  38% 103/270 [01:14<-1:58:30, -1.85it/s, loss=0.0171, v_num=ypmf]Epoch 198:  39% 104/270 [01:14<-1:58:30, -1.83it/s, loss=0.0171, v_num=ypmf]Epoch 198:  39% 104/270 [01:14<-1:58:30, -1.83it/s, loss=0.0171, v_num=ypmf]Epoch 198:  39% 104/270 [01:14<-1:58:30, -1.83it/s, loss=0.0172, v_num=ypmf]Epoch 198:  39% 105/270 [01:15<-1:58:29, -1.81it/s, loss=0.0172, v_num=ypmf]Epoch 198:  39% 105/270 [01:15<-1:58:29, -1.81it/s, loss=0.0172, v_num=ypmf]Epoch 198:  39% 105/270 [01:15<-1:58:29, -1.80it/s, loss=0.0172, v_num=ypmf]Epoch 198:  39% 106/270 [01:15<-1:58:28, -1.78it/s, loss=0.0172, v_num=ypmf]Epoch 198:  39% 106/270 [01:15<-1:58:28, -1.78it/s, loss=0.0172, v_num=ypmf]Epoch 198:  39% 106/270 [01:16<-1:58:28, -1.77it/s, loss=0.0172, v_num=ypmf]Epoch 198:  40% 107/270 [01:16<-1:58:27, -1.74it/s, loss=0.0172, v_num=ypmf]Epoch 198:  40% 107/270 [01:16<-1:58:27, -1.74it/s, loss=0.0172, v_num=ypmf]Epoch 198:  40% 107/270 [01:17<-1:58:27, -1.74it/s, loss=0.0173, v_num=ypmf]Epoch 198:  40% 108/270 [01:17<-1:58:26, -1.71it/s, loss=0.0173, v_num=ypmf]Epoch 198:  40% 108/270 [01:17<-1:58:26, -1.71it/s, loss=0.0173, v_num=ypmf]Epoch 198:  40% 108/270 [01:17<-1:58:26, -1.71it/s, loss=0.0172, v_num=ypmf]Epoch 198:  40% 109/270 [01:18<-1:58:25, -1.68it/s, loss=0.0172, v_num=ypmf]Epoch 198:  40% 109/270 [01:18<-1:58:25, -1.68it/s, loss=0.0172, v_num=ypmf]Epoch 198:  40% 109/270 [01:18<-1:58:25, -1.68it/s, loss=0.0171, v_num=ypmf]Epoch 198:  41% 110/270 [01:19<-1:58:24, -1.66it/s, loss=0.0171, v_num=ypmf]Epoch 198:  41% 110/270 [01:19<-1:58:24, -1.66it/s, loss=0.0171, v_num=ypmf]Epoch 198:  41% 110/270 [01:19<-1:58:24, -1.65it/s, loss=0.0171, v_num=ypmf]Epoch 198:  41% 111/270 [01:19<-1:58:23, -1.63it/s, loss=0.0171, v_num=ypmf]Epoch 198:  41% 111/270 [01:19<-1:58:23, -1.63it/s, loss=0.0171, v_num=ypmf]Epoch 198:  41% 111/270 [01:19<-1:58:23, -1.63it/s, loss=0.017, v_num=ypmf] Epoch 198:  41% 112/270 [01:20<-1:58:22, -1.61it/s, loss=0.017, v_num=ypmf]Epoch 198:  41% 112/270 [01:20<-1:58:22, -1.61it/s, loss=0.017, v_num=ypmf]Epoch 198:  41% 112/270 [01:20<-1:58:22, -1.61it/s, loss=0.0169, v_num=ypmf]Epoch 198:  42% 113/270 [01:20<-1:58:21, -1.58it/s, loss=0.0169, v_num=ypmf]Epoch 198:  42% 113/270 [01:20<-1:58:21, -1.58it/s, loss=0.0169, v_num=ypmf]Epoch 198:  42% 113/270 [01:20<-1:58:21, -1.58it/s, loss=0.0168, v_num=ypmf]Epoch 198:  42% 114/270 [01:21<-1:58:21, -1.56it/s, loss=0.0168, v_num=ypmf]Epoch 198:  42% 114/270 [01:21<-1:58:21, -1.56it/s, loss=0.0168, v_num=ypmf]Epoch 198:  42% 114/270 [01:21<-1:58:20, -1.56it/s, loss=0.0168, v_num=ypmf]Epoch 198:  43% 115/270 [01:22<-1:58:20, -1.54it/s, loss=0.0168, v_num=ypmf]Epoch 198:  43% 115/270 [01:22<-1:58:20, -1.54it/s, loss=0.0168, v_num=ypmf]Epoch 198:  43% 115/270 [01:22<-1:58:19, -1.53it/s, loss=0.017, v_num=ypmf] Epoch 198:  43% 116/270 [01:22<-1:58:19, -1.51it/s, loss=0.017, v_num=ypmf]Epoch 198:  43% 116/270 [01:22<-1:58:19, -1.51it/s, loss=0.017, v_num=ypmf]Epoch 198:  43% 116/270 [01:22<-1:58:19, -1.51it/s, loss=0.0169, v_num=ypmf]Epoch 198:  43% 117/270 [01:23<-1:58:18, -1.49it/s, loss=0.0169, v_num=ypmf]Epoch 198:  43% 117/270 [01:23<-1:58:18, -1.49it/s, loss=0.0169, v_num=ypmf]Epoch 198:  43% 117/270 [01:23<-1:58:18, -1.49it/s, loss=0.0168, v_num=ypmf]Epoch 198:  44% 118/270 [01:23<-1:58:17, -1.47it/s, loss=0.0168, v_num=ypmf]Epoch 198:  44% 118/270 [01:23<-1:58:17, -1.47it/s, loss=0.0168, v_num=ypmf]Epoch 198:  44% 118/270 [01:23<-1:58:17, -1.47it/s, loss=0.0169, v_num=ypmf]Epoch 198:  44% 119/270 [01:24<-1:58:16, -1.45it/s, loss=0.0169, v_num=ypmf]Epoch 198:  44% 119/270 [01:24<-1:58:16, -1.45it/s, loss=0.0169, v_num=ypmf]Epoch 198:  44% 119/270 [01:24<-1:58:16, -1.45it/s, loss=0.0171, v_num=ypmf]Epoch 198:  44% 120/270 [01:24<-1:58:15, -1.43it/s, loss=0.0171, v_num=ypmf]Epoch 198:  44% 120/270 [01:24<-1:58:15, -1.43it/s, loss=0.0171, v_num=ypmf]Epoch 198:  44% 120/270 [01:25<-1:58:15, -1.42it/s, loss=0.0172, v_num=ypmf]Epoch 198:  45% 121/270 [01:25<-1:58:14, -1.40it/s, loss=0.0172, v_num=ypmf]Epoch 198:  45% 121/270 [01:25<-1:58:14, -1.40it/s, loss=0.0172, v_num=ypmf]Epoch 198:  45% 121/270 [01:25<-1:58:14, -1.40it/s, loss=0.0172, v_num=ypmf]Epoch 198:  45% 122/270 [01:26<-1:58:13, -1.38it/s, loss=0.0172, v_num=ypmf]Epoch 198:  45% 122/270 [01:26<-1:58:13, -1.38it/s, loss=0.0172, v_num=ypmf]Epoch 198:  45% 122/270 [01:26<-1:58:13, -1.38it/s, loss=0.0173, v_num=ypmf]Epoch 198:  46% 123/270 [01:26<-1:58:13, -1.36it/s, loss=0.0173, v_num=ypmf]Epoch 198:  46% 123/270 [01:26<-1:58:13, -1.36it/s, loss=0.0173, v_num=ypmf]Epoch 198:  46% 123/270 [01:26<-1:58:12, -1.36it/s, loss=0.0174, v_num=ypmf]Epoch 198:  46% 124/270 [01:27<-1:58:12, -1.34it/s, loss=0.0174, v_num=ypmf]Epoch 198:  46% 124/270 [01:27<-1:58:12, -1.34it/s, loss=0.0174, v_num=ypmf]Epoch 198:  46% 124/270 [01:27<-1:58:11, -1.34it/s, loss=0.0173, v_num=ypmf]Epoch 198:  46% 125/270 [01:27<-1:58:11, -1.32it/s, loss=0.0173, v_num=ypmf]Epoch 198:  46% 125/270 [01:27<-1:58:11, -1.32it/s, loss=0.0173, v_num=ypmf]Epoch 198:  46% 125/270 [01:28<-1:58:10, -1.32it/s, loss=0.0172, v_num=ypmf]Epoch 198:  47% 126/270 [01:28<-1:58:10, -1.30it/s, loss=0.0172, v_num=ypmf]Epoch 198:  47% 126/270 [01:28<-1:58:10, -1.30it/s, loss=0.0172, v_num=ypmf]Epoch 198:  47% 126/270 [01:28<-1:58:09, -1.30it/s, loss=0.0172, v_num=ypmf]Epoch 198:  47% 127/270 [01:29<-1:58:09, -1.28it/s, loss=0.0172, v_num=ypmf]Epoch 198:  47% 127/270 [01:29<-1:58:09, -1.28it/s, loss=0.0172, v_num=ypmf]Epoch 198:  47% 127/270 [01:29<-1:58:09, -1.28it/s, loss=0.0172, v_num=ypmf]Epoch 198:  47% 128/270 [01:29<-1:58:08, -1.26it/s, loss=0.0172, v_num=ypmf]Epoch 198:  47% 128/270 [01:29<-1:58:08, -1.26it/s, loss=0.0172, v_num=ypmf]Epoch 198:  47% 128/270 [01:29<-1:58:08, -1.26it/s, loss=0.0172, v_num=ypmf]Epoch 198:  48% 129/270 [01:30<-1:58:07, -1.24it/s, loss=0.0172, v_num=ypmf]Epoch 198:  48% 129/270 [01:30<-1:58:07, -1.24it/s, loss=0.0172, v_num=ypmf]Epoch 198:  48% 129/270 [01:30<-1:58:07, -1.24it/s, loss=0.0173, v_num=ypmf]Epoch 198:  48% 130/270 [01:30<-1:58:06, -1.22it/s, loss=0.0173, v_num=ypmf]Epoch 198:  48% 130/270 [01:30<-1:58:06, -1.22it/s, loss=0.0173, v_num=ypmf]Epoch 198:  48% 130/270 [01:30<-1:58:06, -1.22it/s, loss=0.0172, v_num=ypmf]Epoch 198:  49% 131/270 [01:31<-1:58:05, -1.20it/s, loss=0.0172, v_num=ypmf]Epoch 198:  49% 131/270 [01:31<-1:58:05, -1.20it/s, loss=0.0172, v_num=ypmf]Epoch 198:  49% 131/270 [01:31<-1:58:05, -1.20it/s, loss=0.0173, v_num=ypmf]Epoch 198:  49% 132/270 [01:31<-1:58:04, -1.19it/s, loss=0.0173, v_num=ypmf]Epoch 198:  49% 132/270 [01:31<-1:58:04, -1.19it/s, loss=0.0173, v_num=ypmf]Epoch 198:  49% 132/270 [01:32<-1:58:04, -1.18it/s, loss=0.0174, v_num=ypmf]Epoch 198:  49% 133/270 [01:32<-1:58:03, -1.17it/s, loss=0.0174, v_num=ypmf]Epoch 198:  49% 133/270 [01:32<-1:58:03, -1.17it/s, loss=0.0174, v_num=ypmf]Epoch 198:  49% 133/270 [01:32<-1:58:03, -1.17it/s, loss=0.0176, v_num=ypmf]Epoch 198:  50% 134/270 [01:33<-1:58:02, -1.15it/s, loss=0.0176, v_num=ypmf]Epoch 198:  50% 134/270 [01:33<-1:58:02, -1.15it/s, loss=0.0176, v_num=ypmf]Epoch 198:  50% 134/270 [01:33<-1:58:02, -1.15it/s, loss=0.0175, v_num=ypmf]Epoch 198:  50% 135/270 [01:33<-1:58:01, -1.13it/s, loss=0.0175, v_num=ypmf]Epoch 198:  50% 135/270 [01:33<-1:58:01, -1.13it/s, loss=0.0175, v_num=ypmf]Epoch 198:  50% 135/270 [01:33<-1:58:01, -1.13it/s, loss=0.0173, v_num=ypmf]Epoch 198:  50% 136/270 [01:34<-1:58:00, -1.12it/s, loss=0.0173, v_num=ypmf]Epoch 198:  50% 136/270 [01:34<-1:58:00, -1.12it/s, loss=0.0173, v_num=ypmf]Epoch 198:  50% 136/270 [01:34<-1:58:00, -1.11it/s, loss=0.0173, v_num=ypmf]Epoch 198:  51% 137/270 [01:34<-1:57:59, -1.10it/s, loss=0.0173, v_num=ypmf]Epoch 198:  51% 137/270 [01:34<-1:57:59, -1.10it/s, loss=0.0173, v_num=ypmf]Epoch 198:  51% 137/270 [01:35<-1:57:59, -1.09it/s, loss=0.0173, v_num=ypmf]Epoch 198:  51% 138/270 [01:35<-1:57:58, -1.08it/s, loss=0.0173, v_num=ypmf]Epoch 198:  51% 138/270 [01:35<-1:57:58, -1.08it/s, loss=0.0173, v_num=ypmf]Epoch 198:  51% 138/270 [01:35<-1:57:58, -1.08it/s, loss=0.0174, v_num=ypmf]Epoch 198:  51% 139/270 [01:36<-1:57:57, -1.06it/s, loss=0.0174, v_num=ypmf]Epoch 198:  51% 139/270 [01:36<-1:57:57, -1.06it/s, loss=0.0174, v_num=ypmf]Epoch 198:  51% 139/270 [01:36<-1:57:57, -1.06it/s, loss=0.0172, v_num=ypmf]Epoch 198:  52% 140/270 [01:36<-1:57:56, -1.05it/s, loss=0.0172, v_num=ypmf]Epoch 198:  52% 140/270 [01:36<-1:57:56, -1.05it/s, loss=0.0172, v_num=ypmf]Epoch 198:  52% 140/270 [01:36<-1:57:56, -1.04it/s, loss=0.0171, v_num=ypmf]Epoch 198:  52% 141/270 [01:37<-1:57:55, -1.03it/s, loss=0.0171, v_num=ypmf]Epoch 198:  52% 141/270 [01:37<-1:57:55, -1.03it/s, loss=0.0171, v_num=ypmf]Epoch 198:  52% 141/270 [01:37<-1:57:55, -1.03it/s, loss=0.0172, v_num=ypmf]Epoch 198:  53% 142/270 [01:37<-1:57:54, -1.01it/s, loss=0.0172, v_num=ypmf]Epoch 198:  53% 142/270 [01:37<-1:57:54, -1.01it/s, loss=0.0172, v_num=ypmf]Epoch 198:  53% 142/270 [01:37<-1:57:54, -1.01it/s, loss=0.0172, v_num=ypmf]Epoch 198:  53% 143/270 [01:38<-1:57:53, -1.00it/s, loss=0.0172, v_num=ypmf]Epoch 198:  53% 143/270 [01:38<-1:57:53, -1.00it/s, loss=0.0172, v_num=ypmf]Epoch 198:  53% 143/270 [01:38<-1:57:53, -1.00it/s, loss=0.0171, v_num=ypmf]Epoch 198:  53% 144/270 [01:38<-1:57:52, -0.98it/s, loss=0.0171, v_num=ypmf]Epoch 198:  53% 144/270 [01:38<-1:57:52, -0.98it/s, loss=0.0171, v_num=ypmf]Epoch 198:  53% 144/270 [01:38<-1:57:52, -0.98it/s, loss=0.0171, v_num=ypmf]Epoch 198:  54% 145/270 [01:39<-1:57:51, -0.97it/s, loss=0.0171, v_num=ypmf]Epoch 198:  54% 145/270 [01:39<-1:57:51, -0.97it/s, loss=0.0171, v_num=ypmf]Epoch 198:  54% 145/270 [01:39<-1:57:51, -0.97it/s, loss=0.0171, v_num=ypmf]Epoch 198:  54% 146/270 [01:39<-1:57:50, -0.95it/s, loss=0.0171, v_num=ypmf]Epoch 198:  54% 146/270 [01:39<-1:57:50, -0.95it/s, loss=0.0171, v_num=ypmf]Epoch 198:  54% 146/270 [01:39<-1:57:50, -0.95it/s, loss=0.017, v_num=ypmf] Epoch 198:  54% 147/270 [01:40<-1:57:49, -0.94it/s, loss=0.017, v_num=ypmf]Epoch 198:  54% 147/270 [01:40<-1:57:49, -0.94it/s, loss=0.017, v_num=ypmf]Epoch 198:  54% 147/270 [01:40<-1:57:49, -0.94it/s, loss=0.0172, v_num=ypmf]Epoch 198:  55% 148/270 [01:40<-1:57:48, -0.92it/s, loss=0.0172, v_num=ypmf]Epoch 198:  55% 148/270 [01:40<-1:57:48, -0.92it/s, loss=0.0172, v_num=ypmf]Epoch 198:  55% 148/270 [01:40<-1:57:48, -0.92it/s, loss=0.0172, v_num=ypmf]Epoch 198:  55% 149/270 [01:41<-1:57:47, -0.91it/s, loss=0.0172, v_num=ypmf]Epoch 198:  55% 149/270 [01:41<-1:57:47, -0.91it/s, loss=0.0172, v_num=ypmf]Epoch 198:  55% 149/270 [01:41<-1:57:47, -0.91it/s, loss=0.0171, v_num=ypmf]Epoch 198:  56% 150/270 [01:41<-1:57:46, -0.89it/s, loss=0.0171, v_num=ypmf]Epoch 198:  56% 150/270 [01:41<-1:57:46, -0.89it/s, loss=0.0171, v_num=ypmf]Epoch 198:  56% 150/270 [01:42<-1:57:46, -0.89it/s, loss=0.0172, v_num=ypmf]Epoch 198:  56% 151/270 [01:42<-1:57:45, -0.88it/s, loss=0.0172, v_num=ypmf]Epoch 198:  56% 151/270 [01:42<-1:57:45, -0.88it/s, loss=0.0172, v_num=ypmf]Epoch 198:  56% 151/270 [01:42<-1:57:45, -0.88it/s, loss=0.0172, v_num=ypmf]Epoch 198:  56% 152/270 [01:43<-1:57:44, -0.86it/s, loss=0.0172, v_num=ypmf]Epoch 198:  56% 152/270 [01:43<-1:57:44, -0.86it/s, loss=0.0172, v_num=ypmf]Epoch 198:  56% 152/270 [01:43<-1:57:43, -0.86it/s, loss=0.0171, v_num=ypmf]Epoch 198:  57% 153/270 [01:43<-1:57:42, -0.85it/s, loss=0.0171, v_num=ypmf]Epoch 198:  57% 153/270 [01:43<-1:57:42, -0.85it/s, loss=0.0171, v_num=ypmf]Epoch 198:  57% 153/270 [01:44<-1:57:41, -0.84it/s, loss=0.017, v_num=ypmf] Epoch 198:  57% 154/270 [01:45<-1:57:40, -0.83it/s, loss=0.017, v_num=ypmf]Epoch 198:  57% 154/270 [01:45<-1:57:40, -0.83it/s, loss=0.017, v_num=ypmf]Epoch 198:  57% 154/270 [01:45<-1:57:40, -0.83it/s, loss=0.017, v_num=ypmf]Epoch 198:  57% 155/270 [01:45<-1:57:39, -0.81it/s, loss=0.017, v_num=ypmf]Epoch 198:  57% 155/270 [01:45<-1:57:39, -0.81it/s, loss=0.017, v_num=ypmf]Epoch 198:  57% 155/270 [01:45<-1:57:39, -0.81it/s, loss=0.017, v_num=ypmf]Epoch 198:  58% 156/270 [01:46<-1:57:38, -0.80it/s, loss=0.017, v_num=ypmf]Epoch 198:  58% 156/270 [01:46<-1:57:38, -0.80it/s, loss=0.017, v_num=ypmf]Epoch 198:  58% 156/270 [01:46<-1:57:38, -0.80it/s, loss=0.0171, v_num=ypmf]Epoch 198:  58% 157/270 [01:46<-1:57:37, -0.79it/s, loss=0.0171, v_num=ypmf]Epoch 198:  58% 157/270 [01:46<-1:57:37, -0.79it/s, loss=0.0171, v_num=ypmf]Epoch 198:  58% 157/270 [01:46<-1:57:37, -0.79it/s, loss=0.0171, v_num=ypmf]Epoch 198:  59% 158/270 [01:47<-1:57:36, -0.77it/s, loss=0.0171, v_num=ypmf]Epoch 198:  59% 158/270 [01:47<-1:57:36, -0.77it/s, loss=0.0171, v_num=ypmf]Epoch 198:  59% 158/270 [01:47<-1:57:36, -0.77it/s, loss=0.017, v_num=ypmf] Epoch 198:  59% 159/270 [01:47<-1:57:35, -0.76it/s, loss=0.017, v_num=ypmf]Epoch 198:  59% 159/270 [01:47<-1:57:35, -0.76it/s, loss=0.017, v_num=ypmf]Epoch 198:  59% 159/270 [01:47<-1:57:35, -0.76it/s, loss=0.017, v_num=ypmf]Epoch 198:  59% 160/270 [01:48<-1:57:33, -0.75it/s, loss=0.017, v_num=ypmf]Epoch 198:  59% 160/270 [01:48<-1:57:33, -0.75it/s, loss=0.017, v_num=ypmf]Epoch 198:  59% 160/270 [01:48<-1:57:33, -0.75it/s, loss=0.017, v_num=ypmf]Epoch 198:  60% 161/270 [01:48<-1:57:32, -0.74it/s, loss=0.017, v_num=ypmf]Epoch 198:  60% 161/270 [01:48<-1:57:32, -0.74it/s, loss=0.017, v_num=ypmf]Epoch 198:  60% 161/270 [01:49<-1:57:32, -0.73it/s, loss=0.0169, v_num=ypmf]Epoch 198:  60% 162/270 [01:49<-1:57:31, -0.72it/s, loss=0.0169, v_num=ypmf]Epoch 198:  60% 162/270 [01:49<-1:57:31, -0.72it/s, loss=0.0169, v_num=ypmf]Epoch 198:  60% 162/270 [01:49<-1:57:30, -0.72it/s, loss=0.0168, v_num=ypmf]Epoch 198:  60% 163/270 [01:50<-1:57:29, -0.71it/s, loss=0.0168, v_num=ypmf]Epoch 198:  60% 163/270 [01:50<-1:57:29, -0.71it/s, loss=0.0168, v_num=ypmf]Epoch 198:  60% 163/270 [01:50<-1:57:29, -0.71it/s, loss=0.0168, v_num=ypmf]Epoch 198:  61% 164/270 [01:50<-1:57:28, -0.70it/s, loss=0.0168, v_num=ypmf]Epoch 198:  61% 164/270 [01:50<-1:57:28, -0.70it/s, loss=0.0168, v_num=ypmf]Epoch 198:  61% 164/270 [01:50<-1:57:28, -0.69it/s, loss=0.017, v_num=ypmf] Epoch 198:  61% 165/270 [01:51<-1:57:27, -0.68it/s, loss=0.017, v_num=ypmf]Epoch 198:  61% 165/270 [01:51<-1:57:27, -0.68it/s, loss=0.017, v_num=ypmf]Epoch 198:  61% 165/270 [01:51<-1:57:26, -0.68it/s, loss=0.0171, v_num=ypmf]Epoch 198:  61% 166/270 [01:51<-1:57:25, -0.67it/s, loss=0.0171, v_num=ypmf]Epoch 198:  61% 166/270 [01:51<-1:57:25, -0.67it/s, loss=0.0171, v_num=ypmf]Epoch 198:  61% 166/270 [01:52<-1:57:25, -0.67it/s, loss=0.0171, v_num=ypmf]Epoch 198:  62% 167/270 [01:52<-1:57:24, -0.66it/s, loss=0.0171, v_num=ypmf]Epoch 198:  62% 167/270 [01:52<-1:57:24, -0.66it/s, loss=0.0171, v_num=ypmf]Epoch 198:  62% 167/270 [01:52<-1:57:24, -0.66it/s, loss=0.017, v_num=ypmf] Epoch 198:  62% 168/270 [01:52<-1:57:23, -0.65it/s, loss=0.017, v_num=ypmf]Epoch 198:  62% 168/270 [01:52<-1:57:23, -0.65it/s, loss=0.017, v_num=ypmf]Epoch 198:  62% 168/270 [01:53<-1:57:22, -0.64it/s, loss=0.0171, v_num=ypmf]Epoch 198:  63% 169/270 [01:53<-1:57:21, -0.63it/s, loss=0.0171, v_num=ypmf]Epoch 198:  63% 169/270 [01:53<-1:57:21, -0.63it/s, loss=0.0171, v_num=ypmf]Epoch 198:  63% 169/270 [01:53<-1:57:21, -0.63it/s, loss=0.0171, v_num=ypmf]Epoch 198:  63% 170/270 [01:54<-1:57:20, -0.62it/s, loss=0.0171, v_num=ypmf]Epoch 198:  63% 170/270 [01:54<-1:57:20, -0.62it/s, loss=0.0171, v_num=ypmf]Epoch 198:  63% 170/270 [01:54<-1:57:19, -0.62it/s, loss=0.017, v_num=ypmf] Epoch 198:  63% 171/270 [01:54<-1:57:18, -0.61it/s, loss=0.017, v_num=ypmf]Epoch 198:  63% 171/270 [01:54<-1:57:18, -0.61it/s, loss=0.017, v_num=ypmf]Epoch 198:  63% 171/270 [01:55<-1:57:18, -0.61it/s, loss=0.0171, v_num=ypmf]Epoch 198:  64% 172/270 [01:55<-1:57:16, -0.60it/s, loss=0.0171, v_num=ypmf]Epoch 198:  64% 172/270 [01:55<-1:57:16, -0.60it/s, loss=0.0171, v_num=ypmf]Epoch 198:  64% 172/270 [01:55<-1:57:16, -0.60it/s, loss=0.017, v_num=ypmf] Epoch 198:  64% 173/270 [01:56<-1:57:15, -0.59it/s, loss=0.017, v_num=ypmf]Epoch 198:  64% 173/270 [01:56<-1:57:15, -0.59it/s, loss=0.017, v_num=ypmf]Epoch 198:  64% 173/270 [01:56<-1:57:15, -0.58it/s, loss=0.0171, v_num=ypmf]Epoch 198:  64% 174/270 [01:56<-1:57:13, -0.57it/s, loss=0.0171, v_num=ypmf]Epoch 198:  64% 174/270 [01:56<-1:57:13, -0.57it/s, loss=0.0171, v_num=ypmf]Epoch 198:  64% 174/270 [01:57<-1:57:13, -0.57it/s, loss=0.0171, v_num=ypmf]Epoch 198:  65% 175/270 [01:57<-1:57:11, -0.56it/s, loss=0.0171, v_num=ypmf]Epoch 198:  65% 175/270 [01:57<-1:57:11, -0.56it/s, loss=0.0171, v_num=ypmf]Epoch 198:  65% 175/270 [01:57<-1:57:11, -0.56it/s, loss=0.0173, v_num=ypmf]Epoch 198:  65% 176/270 [01:58<-1:57:10, -0.55it/s, loss=0.0173, v_num=ypmf]Epoch 198:  65% 176/270 [01:58<-1:57:10, -0.55it/s, loss=0.0173, v_num=ypmf]Epoch 198:  65% 176/270 [01:58<-1:57:09, -0.55it/s, loss=0.0173, v_num=ypmf]Epoch 198:  66% 177/270 [01:58<-1:57:08, -0.54it/s, loss=0.0173, v_num=ypmf]Epoch 198:  66% 177/270 [01:58<-1:57:08, -0.54it/s, loss=0.0173, v_num=ypmf]Epoch 198:  66% 177/270 [01:58<-1:57:08, -0.54it/s, loss=0.0174, v_num=ypmf]Epoch 198:  66% 178/270 [01:59<-1:57:06, -0.53it/s, loss=0.0174, v_num=ypmf]Epoch 198:  66% 178/270 [01:59<-1:57:06, -0.53it/s, loss=0.0174, v_num=ypmf]Epoch 198:  66% 178/270 [01:59<-1:57:06, -0.53it/s, loss=0.0174, v_num=ypmf]Epoch 198:  66% 179/270 [01:59<-1:57:05, -0.52it/s, loss=0.0174, v_num=ypmf]Epoch 198:  66% 179/270 [01:59<-1:57:05, -0.52it/s, loss=0.0174, v_num=ypmf]Epoch 198:  66% 179/270 [02:00<-1:57:04, -0.52it/s, loss=0.0174, v_num=ypmf]Epoch 198:  67% 180/270 [02:00<-1:57:03, -0.51it/s, loss=0.0174, v_num=ypmf]Epoch 198:  67% 180/270 [02:00<-1:57:03, -0.51it/s, loss=0.0174, v_num=ypmf]Epoch 198:  67% 180/270 [02:00<-1:57:02, -0.51it/s, loss=0.0174, v_num=ypmf]Epoch 198:  67% 181/270 [02:01<-1:57:01, -0.50it/s, loss=0.0174, v_num=ypmf]Epoch 198:  67% 181/270 [02:01<-1:57:01, -0.50it/s, loss=0.0174, v_num=ypmf]Epoch 198:  67% 181/270 [02:01<-1:57:01, -0.49it/s, loss=0.0174, v_num=ypmf]Epoch 198:  67% 182/270 [02:01<-1:56:59, -0.49it/s, loss=0.0174, v_num=ypmf]Epoch 198:  67% 182/270 [02:01<-1:56:59, -0.49it/s, loss=0.0174, v_num=ypmf]Epoch 198:  67% 182/270 [02:01<-1:56:59, -0.48it/s, loss=0.0174, v_num=ypmf]Epoch 198:  68% 183/270 [02:02<-1:56:57, -0.48it/s, loss=0.0174, v_num=ypmf]Epoch 198:  68% 183/270 [02:02<-1:56:57, -0.48it/s, loss=0.0174, v_num=ypmf]Epoch 198:  68% 183/270 [02:02<-1:56:57, -0.47it/s, loss=0.0175, v_num=ypmf]Epoch 198:  68% 184/270 [02:02<-1:56:55, -0.46it/s, loss=0.0175, v_num=ypmf]Epoch 198:  68% 184/270 [02:02<-1:56:55, -0.46it/s, loss=0.0175, v_num=ypmf]Epoch 198:  68% 184/270 [02:03<-1:56:54, -0.46it/s, loss=0.0173, v_num=ypmf]Epoch 198:  69% 185/270 [02:03<-1:56:53, -0.45it/s, loss=0.0173, v_num=ypmf]Epoch 198:  69% 185/270 [02:03<-1:56:53, -0.45it/s, loss=0.0173, v_num=ypmf]Epoch 198:  69% 185/270 [02:03<-1:56:52, -0.45it/s, loss=0.0174, v_num=ypmf]Epoch 198:  69% 186/270 [02:04<-1:56:51, -0.44it/s, loss=0.0174, v_num=ypmf]Epoch 198:  69% 186/270 [02:04<-1:56:51, -0.44it/s, loss=0.0174, v_num=ypmf]Epoch 198:  69% 186/270 [02:04<-1:56:50, -0.44it/s, loss=0.0175, v_num=ypmf]Epoch 198:  69% 187/270 [02:04<-1:56:49, -0.43it/s, loss=0.0175, v_num=ypmf]Epoch 198:  69% 187/270 [02:04<-1:56:49, -0.43it/s, loss=0.0175, v_num=ypmf]Epoch 198:  69% 187/270 [02:05<-1:56:48, -0.43it/s, loss=0.0175, v_num=ypmf]Epoch 198:  70% 188/270 [02:05<-1:56:46, -0.42it/s, loss=0.0175, v_num=ypmf]Epoch 198:  70% 188/270 [02:05<-1:56:46, -0.42it/s, loss=0.0175, v_num=ypmf]Epoch 198:  70% 188/270 [02:05<-1:56:46, -0.42it/s, loss=0.0173, v_num=ypmf]Epoch 198:  70% 189/270 [02:06<-1:56:44, -0.41it/s, loss=0.0173, v_num=ypmf]Epoch 198:  70% 189/270 [02:06<-1:56:44, -0.41it/s, loss=0.0173, v_num=ypmf]Epoch 198:  70% 189/270 [02:06<-1:56:43, -0.41it/s, loss=0.0172, v_num=ypmf]Epoch 198:  70% 190/270 [02:06<-1:56:41, -0.40it/s, loss=0.0172, v_num=ypmf]Epoch 198:  70% 190/270 [02:06<-1:56:41, -0.40it/s, loss=0.0172, v_num=ypmf]Epoch 198:  70% 190/270 [02:07<-1:56:41, -0.40it/s, loss=0.0173, v_num=ypmf]Epoch 198:  71% 191/270 [02:07<-1:56:39, -0.39it/s, loss=0.0173, v_num=ypmf]Epoch 198:  71% 191/270 [02:07<-1:56:39, -0.39it/s, loss=0.0173, v_num=ypmf]Epoch 198:  71% 191/270 [02:07<-1:56:39, -0.39it/s, loss=0.0171, v_num=ypmf]Epoch 198:  71% 192/270 [02:08<-1:56:37, -0.38it/s, loss=0.0171, v_num=ypmf]Epoch 198:  71% 192/270 [02:08<-1:56:37, -0.38it/s, loss=0.0171, v_num=ypmf]Epoch 198:  71% 192/270 [02:08<-1:56:36, -0.38it/s, loss=0.0172, v_num=ypmf]Epoch 198:  71% 193/270 [02:08<-1:56:34, -0.37it/s, loss=0.0172, v_num=ypmf]Epoch 198:  71% 193/270 [02:08<-1:56:34, -0.37it/s, loss=0.0172, v_num=ypmf]Epoch 198:  71% 193/270 [02:08<-1:56:34, -0.37it/s, loss=0.0173, v_num=ypmf]Epoch 198:  72% 194/270 [02:09<-1:56:31, -0.36it/s, loss=0.0173, v_num=ypmf]Epoch 198:  72% 194/270 [02:09<-1:56:31, -0.36it/s, loss=0.0173, v_num=ypmf]Epoch 198:  72% 194/270 [02:09<-1:56:31, -0.36it/s, loss=0.0172, v_num=ypmf]Epoch 198:  72% 195/270 [02:09<-1:56:29, -0.35it/s, loss=0.0172, v_num=ypmf]Epoch 198:  72% 195/270 [02:09<-1:56:29, -0.35it/s, loss=0.0172, v_num=ypmf]Epoch 198:  72% 195/270 [02:10<-1:56:28, -0.35it/s, loss=0.0171, v_num=ypmf]Epoch 198:  73% 196/270 [02:10<-1:56:26, -0.34it/s, loss=0.0171, v_num=ypmf]Epoch 198:  73% 196/270 [02:10<-1:56:26, -0.34it/s, loss=0.0171, v_num=ypmf]Epoch 198:  73% 196/270 [02:10<-1:56:26, -0.34it/s, loss=0.0172, v_num=ypmf]Epoch 198:  73% 197/270 [02:11<-1:56:23, -0.34it/s, loss=0.0172, v_num=ypmf]Epoch 198:  73% 197/270 [02:11<-1:56:23, -0.34it/s, loss=0.0172, v_num=ypmf]Epoch 198:  73% 197/270 [02:11<-1:56:23, -0.34it/s, loss=0.0171, v_num=ypmf]Epoch 198:  73% 198/270 [02:11<-1:56:20, -0.33it/s, loss=0.0171, v_num=ypmf]Epoch 198:  73% 198/270 [02:11<-1:56:20, -0.33it/s, loss=0.0171, v_num=ypmf]Epoch 198:  73% 198/270 [02:11<-1:56:20, -0.33it/s, loss=0.0171, v_num=ypmf]Epoch 198:  74% 199/270 [02:12<-1:56:17, -0.32it/s, loss=0.0171, v_num=ypmf]Epoch 198:  74% 199/270 [02:12<-1:56:17, -0.32it/s, loss=0.0171, v_num=ypmf]Epoch 198:  74% 199/270 [02:12<-1:56:17, -0.32it/s, loss=0.0172, v_num=ypmf]Epoch 198:  74% 200/270 [02:12<-1:56:14, -0.31it/s, loss=0.0172, v_num=ypmf]Epoch 198:  74% 200/270 [02:12<-1:56:14, -0.31it/s, loss=0.0172, v_num=ypmf]Epoch 198:  74% 200/270 [02:12<-1:56:14, -0.31it/s, loss=0.0172, v_num=ypmf]Epoch 198:  74% 201/270 [02:13<-1:56:11, -0.30it/s, loss=0.0172, v_num=ypmf]Epoch 198:  74% 201/270 [02:13<-1:56:11, -0.30it/s, loss=0.0172, v_num=ypmf]Epoch 198:  74% 201/270 [02:13<-1:56:10, -0.30it/s, loss=0.0172, v_num=ypmf]Epoch 198:  75% 202/270 [02:14<-1:56:07, -0.29it/s, loss=0.0172, v_num=ypmf]Epoch 198:  75% 202/270 [02:14<-1:56:07, -0.29it/s, loss=0.0172, v_num=ypmf]Epoch 198:  75% 202/270 [02:14<-1:56:06, -0.29it/s, loss=0.0173, v_num=ypmf]Epoch 198:  75% 203/270 [02:14<-1:56:03, -0.28it/s, loss=0.0173, v_num=ypmf]Epoch 198:  75% 203/270 [02:14<-1:56:03, -0.28it/s, loss=0.0173, v_num=ypmf]Epoch 198:  75% 203/270 [02:15<-1:56:02, -0.28it/s, loss=0.0171, v_num=ypmf]Epoch 198:  76% 204/270 [02:15<-1:55:59, -0.27it/s, loss=0.0171, v_num=ypmf]Epoch 198:  76% 204/270 [02:15<-1:55:59, -0.27it/s, loss=0.0171, v_num=ypmf]Epoch 198:  76% 204/270 [02:15<-1:55:58, -0.27it/s, loss=0.0172, v_num=ypmf]Epoch 198:  76% 205/270 [02:16<-1:55:55, -0.26it/s, loss=0.0172, v_num=ypmf]Epoch 198:  76% 205/270 [02:16<-1:55:55, -0.26it/s, loss=0.0172, v_num=ypmf]Epoch 198:  76% 205/270 [02:16<-1:55:54, -0.26it/s, loss=0.0171, v_num=ypmf]Epoch 198:  76% 206/270 [02:16<-1:55:50, -0.26it/s, loss=0.0171, v_num=ypmf]Epoch 198:  76% 206/270 [02:16<-1:55:50, -0.26it/s, loss=0.0171, v_num=ypmf]Epoch 198:  76% 206/270 [02:16<-1:55:50, -0.26it/s, loss=0.017, v_num=ypmf] Epoch 198:  77% 207/270 [02:17<-1:55:46, -0.25it/s, loss=0.017, v_num=ypmf]Epoch 198:  77% 207/270 [02:17<-1:55:46, -0.25it/s, loss=0.017, v_num=ypmf]Epoch 198:  77% 207/270 [02:17<-1:55:45, -0.25it/s, loss=0.017, v_num=ypmf]Epoch 198:  77% 208/270 [02:18<-1:55:41, -0.24it/s, loss=0.017, v_num=ypmf]Epoch 198:  77% 208/270 [02:18<-1:55:41, -0.24it/s, loss=0.017, v_num=ypmf]Epoch 198:  77% 208/270 [02:18<-1:55:41, -0.24it/s, loss=0.0171, v_num=ypmf]Epoch 198:  77% 209/270 [02:18<-1:55:36, -0.23it/s, loss=0.0171, v_num=ypmf]Epoch 198:  77% 209/270 [02:18<-1:55:36, -0.23it/s, loss=0.0171, v_num=ypmf]Epoch 198:  77% 209/270 [02:19<-1:55:34, -0.23it/s, loss=0.0172, v_num=ypmf]Epoch 198:  78% 210/270 [02:20<-1:55:29, -0.22it/s, loss=0.0172, v_num=ypmf]Epoch 198:  78% 210/270 [02:20<-1:55:29, -0.22it/s, loss=0.0172, v_num=ypmf]Epoch 198:  78% 210/270 [02:20<-1:55:29, -0.22it/s, loss=0.0172, v_num=ypmf]Epoch 198:  78% 211/270 [02:20<-1:55:24, -0.21it/s, loss=0.0172, v_num=ypmf]Epoch 198:  78% 211/270 [02:20<-1:55:24, -0.21it/s, loss=0.0172, v_num=ypmf]Epoch 198:  78% 211/270 [02:21<-1:55:22, -0.21it/s, loss=0.0173, v_num=ypmf]Epoch 198:  79% 212/270 [02:22<-1:55:16, -0.20it/s, loss=0.0173, v_num=ypmf]Epoch 198:  79% 212/270 [02:22<-1:55:16, -0.20it/s, loss=0.0173, v_num=ypmf]Epoch 198:  79% 212/270 [02:22<-1:55:16, -0.20it/s, loss=0.0172, v_num=ypmf]Epoch 198:  79% 213/270 [02:22<-1:55:10, -0.20it/s, loss=0.0172, v_num=ypmf]Epoch 198:  79% 213/270 [02:22<-1:55:10, -0.20it/s, loss=0.0172, v_num=ypmf]Epoch 198:  79% 213/270 [02:22<-1:55:10, -0.20it/s, loss=0.0172, v_num=ypmf]Epoch 198:  79% 214/270 [02:23<-1:55:04, -0.19it/s, loss=0.0172, v_num=ypmf]Epoch 198:  79% 214/270 [02:23<-1:55:04, -0.19it/s, loss=0.0172, v_num=ypmf]Epoch 198:  79% 214/270 [02:23<-1:55:03, -0.19it/s, loss=0.0172, v_num=ypmf]Epoch 198:  80% 215/270 [02:23<-1:54:57, -0.18it/s, loss=0.0172, v_num=ypmf]Epoch 198:  80% 215/270 [02:23<-1:54:57, -0.18it/s, loss=0.0172, v_num=ypmf]Epoch 198:  80% 215/270 [02:23<-1:54:56, -0.18it/s, loss=0.0174, v_num=ypmf]Epoch 198:  80% 216/270 [02:24<-1:54:49, -0.17it/s, loss=0.0174, v_num=ypmf]Epoch 198:  80% 216/270 [02:24<-1:54:49, -0.17it/s, loss=0.0174, v_num=ypmf]Epoch 198:  80% 216/270 [02:25<-1:54:46, -0.17it/s, loss=0.0172, v_num=ypmf]Epoch 198:  80% 217/270 [02:25<-1:54:39, -0.16it/s, loss=0.0172, v_num=ypmf]Epoch 198:  80% 217/270 [02:25<-1:54:39, -0.16it/s, loss=0.0172, v_num=ypmf]Epoch 198:  80% 217/270 [02:26<-1:54:38, -0.16it/s, loss=0.0173, v_num=ypmf]Epoch 198:  81% 218/270 [02:26<-1:54:29, -0.16it/s, loss=0.0173, v_num=ypmf]Epoch 198:  81% 218/270 [02:26<-1:54:29, -0.16it/s, loss=0.0173, v_num=ypmf]Epoch 198:  81% 218/270 [02:26<-1:54:29, -0.16it/s, loss=0.0173, v_num=ypmf]Epoch 198:  81% 219/270 [02:26<-1:54:20, -0.15it/s, loss=0.0173, v_num=ypmf]Epoch 198:  81% 219/270 [02:26<-1:54:20, -0.15it/s, loss=0.0173, v_num=ypmf]Epoch 198:  81% 219/270 [02:27<-1:54:19, -0.15it/s, loss=0.0172, v_num=ypmf]Epoch 198:  81% 220/270 [02:27<-1:54:09, -0.14it/s, loss=0.0172, v_num=ypmf]Epoch 198:  81% 220/270 [02:27<-1:54:09, -0.14it/s, loss=0.0172, v_num=ypmf]Epoch 198:  81% 220/270 [02:28<-1:54:08, -0.14it/s, loss=0.0175, v_num=ypmf]Epoch 198:  82% 221/270 [02:28<-1:53:57, -0.13it/s, loss=0.0175, v_num=ypmf]Epoch 198:  82% 221/270 [02:28<-1:53:57, -0.13it/s, loss=0.0175, v_num=ypmf]Epoch 198:  82% 221/270 [02:28<-1:53:56, -0.13it/s, loss=0.0175, v_num=ypmf]Epoch 198:  82% 222/270 [02:29<-1:53:44, -0.13it/s, loss=0.0175, v_num=ypmf]Epoch 198:  82% 222/270 [02:29<-1:53:44, -0.13it/s, loss=0.0175, v_num=ypmf]Epoch 198:  82% 222/270 [02:29<-1:53:44, -0.13it/s, loss=0.0174, v_num=ypmf]Epoch 198:  83% 223/270 [02:29<-1:53:30, -0.12it/s, loss=0.0174, v_num=ypmf]Epoch 198:  83% 223/270 [02:29<-1:53:30, -0.12it/s, loss=0.0174, v_num=ypmf]Epoch 198:  83% 223/270 [02:29<-1:53:29, -0.12it/s, loss=0.0174, v_num=ypmf]Epoch 198:  83% 224/270 [02:30<-1:53:14, -0.11it/s, loss=0.0174, v_num=ypmf]Epoch 198:  83% 224/270 [02:30<-1:53:14, -0.11it/s, loss=0.0174, v_num=ypmf]Epoch 198:  83% 224/270 [02:30<-1:53:14, -0.11it/s, loss=0.0174, v_num=ypmf]Epoch 198:  83% 225/270 [02:30<-1:52:57, -0.11it/s, loss=0.0174, v_num=ypmf]Epoch 198:  83% 225/270 [02:30<-1:52:57, -0.11it/s, loss=0.0174, v_num=ypmf]Epoch 198:  83% 225/270 [02:31<-1:52:56, -0.11it/s, loss=0.0174, v_num=ypmf]Epoch 198:  84% 226/270 [02:31<-1:52:36, -0.10it/s, loss=0.0174, v_num=ypmf]Epoch 198:  84% 226/270 [02:31<-1:52:36, -0.10it/s, loss=0.0174, v_num=ypmf]Epoch 198:  84% 226/270 [02:31<-1:52:36, -0.10it/s, loss=0.0174, v_num=ypmf]Epoch 198:  84% 227/270 [02:31<-1:52:14, -0.09it/s, loss=0.0174, v_num=ypmf]Epoch 198:  84% 227/270 [02:31<-1:52:14, -0.09it/s, loss=0.0174, v_num=ypmf]Epoch 198:  84% 227/270 [02:32<-1:52:11, -0.09it/s, loss=0.0174, v_num=ypmf]Epoch 198:  84% 228/270 [02:33<-1:51:46, -0.08it/s, loss=0.0174, v_num=ypmf]Epoch 198:  84% 228/270 [02:33<-1:51:46, -0.08it/s, loss=0.0174, v_num=ypmf]Epoch 198:  84% 228/270 [02:33<-1:51:45, -0.08it/s, loss=0.0173, v_num=ypmf]Epoch 198:  85% 229/270 [02:33<-1:51:15, -0.08it/s, loss=0.0173, v_num=ypmf]Epoch 198:  85% 229/270 [02:33<-1:51:15, -0.08it/s, loss=0.0173, v_num=ypmf]Epoch 198:  85% 229/270 [02:33<-1:51:15, -0.08it/s, loss=0.0172, v_num=ypmf]Epoch 198:  85% 230/270 [02:34<-1:50:40, -0.07it/s, loss=0.0172, v_num=ypmf]Epoch 198:  85% 230/270 [02:34<-1:50:40, -0.07it/s, loss=0.0172, v_num=ypmf]Epoch 198:  85% 230/270 [02:34<-1:50:39, -0.07it/s, loss=0.0173, v_num=ypmf]Epoch 198:  86% 231/270 [02:34<-1:49:57, -0.06it/s, loss=0.0173, v_num=ypmf]Epoch 198:  86% 231/270 [02:34<-1:49:57, -0.06it/s, loss=0.0173, v_num=ypmf]Epoch 198:  86% 231/270 [02:35<-1:49:56, -0.06it/s, loss=0.0173, v_num=ypmf]Epoch 198:  86% 232/270 [02:35<-1:49:03, -0.06it/s, loss=0.0173, v_num=ypmf]Epoch 198:  86% 232/270 [02:35<-1:49:03, -0.06it/s, loss=0.0173, v_num=ypmf]Epoch 198:  86% 232/270 [02:35<-1:49:03, -0.06it/s, loss=0.0173, v_num=ypmf]Epoch 198:  86% 233/270 [02:36<-1:47:58, -0.05it/s, loss=0.0173, v_num=ypmf]Epoch 198:  86% 233/270 [02:36<-1:47:58, -0.05it/s, loss=0.0173, v_num=ypmf]Epoch 198:  86% 233/270 [02:36<-1:47:57, -0.05it/s, loss=0.0174, v_num=ypmf]Epoch 198:  87% 234/270 [02:36<-1:46:34, -0.04it/s, loss=0.0174, v_num=ypmf]Epoch 198:  87% 234/270 [02:36<-1:46:34, -0.04it/s, loss=0.0174, v_num=ypmf]Epoch 198:  87% 234/270 [02:36<-1:46:34, -0.04it/s, loss=0.0173, v_num=ypmf]Epoch 198:  87% 235/270 [02:37<-1:44:43, -0.04it/s, loss=0.0173, v_num=ypmf]Epoch 198:  87% 235/270 [02:37<-1:44:43, -0.04it/s, loss=0.0173, v_num=ypmf]Epoch 198:  87% 235/270 [02:37<-1:44:41, -0.04it/s, loss=0.0173, v_num=ypmf]Epoch 198:  87% 236/270 [02:37<-1:42:07, -0.03it/s, loss=0.0173, v_num=ypmf]Epoch 198:  87% 236/270 [02:37<-1:42:07, -0.03it/s, loss=0.0173, v_num=ypmf]Epoch 198:  87% 236/270 [02:38<-1:42:05, -0.03it/s, loss=0.0172, v_num=ypmf]Epoch 198:  88% 237/270 [02:38<-1:38:12, -0.03it/s, loss=0.0172, v_num=ypmf]Epoch 198:  88% 237/270 [02:38<-1:38:12, -0.03it/s, loss=0.0172, v_num=ypmf]Epoch 198:  88% 237/270 [02:38<-1:38:10, -0.03it/s, loss=0.0172, v_num=ypmf]Epoch 198:  88% 238/270 [02:39<-1:31:42, -0.02it/s, loss=0.0172, v_num=ypmf]Epoch 198:  88% 238/270 [02:39<-1:31:42, -0.02it/s, loss=0.0172, v_num=ypmf]Epoch 198:  88% 238/270 [02:39<-1:31:40, -0.02it/s, loss=0.0172, v_num=ypmf]Epoch 198:  89% 239/270 [02:39<-1:18:42, -0.01it/s, loss=0.0172, v_num=ypmf]Epoch 198:  89% 239/270 [02:39<-1:18:42, -0.01it/s, loss=0.0172, v_num=ypmf]Epoch 198:  89% 239/270 [02:40<-1:18:40, -0.01it/s, loss=0.0171, v_num=ypmf]Epoch 198:  89% 240/270 [02:40<-2:39:50, -0.01it/s, loss=0.0171, v_num=ypmf]Epoch 198:  89% 240/270 [02:40<-2:39:50, -0.01it/s, loss=0.0171, v_num=ypmf]Epoch 198:  89% 240/270 [02:40<-2:39:44, -0.01it/s, loss=0.017, v_num=ypmf] Epoch 198:  89% 241/270 [02:41<?, ?it/s, loss=0.017, v_num=ypmf]           Epoch 198:  89% 241/270 [02:41<?, ?it/s, loss=0.017, v_num=ypmf]Epoch 198:  89% 241/270 [02:41<?, ?it/s, loss=0.0169, v_num=ypmf]Epoch 198:  90% 242/270 [02:41<1:15:22, 161.53s/it, loss=0.0169, v_num=ypmf]Epoch 198:  90% 242/270 [02:41<1:15:22, 161.53s/it, loss=0.0169, v_num=ypmf]Epoch 198:  90% 242/270 [02:41<1:15:31, 161.85s/it, loss=0.017, v_num=ypmf] Epoch 198:  90% 243/270 [02:42<36:30, 81.12s/it, loss=0.017, v_num=ypmf]   Epoch 198:  90% 243/270 [02:42<36:30, 81.12s/it, loss=0.017, v_num=ypmf]Epoch 198:  90% 243/270 [02:42<36:32, 81.22s/it, loss=0.0171, v_num=ypmf]Epoch 198:  90% 244/270 [02:42<23:31, 54.29s/it, loss=0.0171, v_num=ypmf]Epoch 198:  90% 244/270 [02:42<23:31, 54.29s/it, loss=0.0171, v_num=ypmf]Epoch 198:  90% 244/270 [02:43<23:34, 54.40s/it, loss=0.017, v_num=ypmf] Epoch 198:  91% 245/270 [02:43<17:02, 40.90s/it, loss=0.017, v_num=ypmf]Epoch 198:  91% 245/270 [02:43<17:02, 40.90s/it, loss=0.017, v_num=ypmf]Epoch 198:  91% 245/270 [02:43<17:03, 40.96s/it, loss=0.017, v_num=ypmf]Epoch 198:  91% 246/270 [02:44<13:08, 32.85s/it, loss=0.017, v_num=ypmf]Epoch 198:  91% 246/270 [02:44<13:08, 32.85s/it, loss=0.017, v_num=ypmf]Epoch 198:  91% 246/270 [02:44<13:09, 32.90s/it, loss=0.0171, v_num=ypmf]Epoch 198:  91% 247/270 [02:44<10:32, 27.49s/it, loss=0.0171, v_num=ypmf]Epoch 198:  91% 247/270 [02:44<10:32, 27.49s/it, loss=0.0171, v_num=ypmf]Epoch 198:  91% 247/270 [02:45<10:32, 27.52s/it, loss=0.017, v_num=ypmf] Epoch 198:  92% 248/270 [02:45<08:40, 23.64s/it, loss=0.017, v_num=ypmf]Epoch 198:  92% 248/270 [02:45<08:40, 23.64s/it, loss=0.017, v_num=ypmf]Epoch 198:  92% 248/270 [02:45<08:40, 23.66s/it, loss=0.0171, v_num=ypmf]Epoch 198:  92% 249/270 [02:45<07:15, 20.74s/it, loss=0.0171, v_num=ypmf]Epoch 198:  92% 249/270 [02:45<07:15, 20.74s/it, loss=0.0171, v_num=ypmf]Epoch 198:  92% 249/270 [02:46<07:16, 20.77s/it, loss=0.0171, v_num=ypmf]Epoch 198:  93% 250/270 [02:46<06:10, 18.50s/it, loss=0.0171, v_num=ypmf]Epoch 198:  93% 250/270 [02:46<06:10, 18.50s/it, loss=0.0171, v_num=ypmf]Epoch 198:  93% 250/270 [02:46<06:10, 18.52s/it, loss=0.017, v_num=ypmf] 
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 283161. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 323626. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 282053. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 306178. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 262183. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 339471. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 291387. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 346679. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 272019. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 308840. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 289771. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 360255. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batchValidation: 0it [00:00, ?it/s]_size` from an ambiguous collection. The batch size we found is 284996. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 256640. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 279269. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 309090. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 316854. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 300274. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
[A
Validation:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.27it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.27it/s][AEpoch 198:  93% 251/270 [02:48<05:19, 16.82s/it, loss=0.017, v_num=ypmf]Epoch 198:  93% 251/270 [02:48<05:19, 16.82s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  10% 2/20 [00:01<00:14,  1.23it/s][A
Validation DataLoader 0:  10% 2/20 [00:01<00:14,  1.23it/s][AEpoch 198:  93% 252/270 [02:49<04:37, 15.39s/it, loss=0.017, v_num=ypmf]Epoch 198:  93% 252/270 [02:49<04:37, 15.39s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  15% 3/20 [00:02<00:16,  1.00it/s][A
Validation DataLoader 0:  15% 3/20 [00:02<00:16,  1.00it/s][AEpoch 198:  94% 253/270 [02:50<04:01, 14.21s/it, loss=0.017, v_num=ypmf]Epoch 198:  94% 253/270 [02:50<04:01, 14.21s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  20% 4/20 [00:03<00:14,  1.13it/s][A
Validation DataLoader 0:  20% 4/20 [00:03<00:14,  1.13it/s][AEpoch 198:  94% 254/270 [02:51<03:30, 13.17s/it, loss=0.017, v_num=ypmf]Epoch 198:  94% 254/270 [02:51<03:30, 13.17s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  25% 5/20 [00:04<00:13,  1.14it/s][A
Validation DataLoader 0:  25% 5/20 [00:04<00:13,  1.14it/s][AEpoch 198:  94% 255/270 [02:52<03:04, 12.29s/it, loss=0.017, v_num=ypmf]Epoch 198:  94% 255/270 [02:52<03:04, 12.29s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  30% 6/20 [00:04<00:11,  1.24it/s][A
Validation DataLoader 0:  30% 6/20 [00:04<00:11,  1.24it/s][AEpoch 198:  95% 256/270 [02:52<02:41, 11.52s/it, loss=0.017, v_num=ypmf]Epoch 198:  95% 256/270 [02:52<02:41, 11.52s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  35% 7/20 [00:07<00:16,  1.25s/it][A
Validation DataLoader 0:  35% 7/20 [00:07<00:16,  1.25s/it][AEpoch 198:  95% 257/270 [02:54<02:22, 10.93s/it, loss=0.017, v_num=ypmf]Epoch 198:  95% 257/270 [02:54<02:22, 10.93s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  40% 8/20 [00:08<00:14,  1.24s/it][A
Validation DataLoader 0:  40% 8/20 [00:08<00:14,  1.24s/it][AEpoch 198:  96% 258/270 [02:56<02:04, 10.36s/it, loss=0.017, v_num=ypmf]Epoch 198:  96% 258/270 [02:56<02:04, 10.36s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  45% 9/20 [00:09<00:11,  1.08s/it][A
Validation DataLoader 0:  45% 9/20 [00:09<00:11,  1.08s/it][AEpoch 198:  96% 259/270 [02:56<01:48,  9.83s/it, loss=0.017, v_num=ypmf]Epoch 198:  96% 259/270 [02:56<01:48,  9.83s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  50% 10/20 [00:09<00:09,  1.08it/s][A
Validation DataLoader 0:  50% 10/20 [00:09<00:09,  1.08it/s][AEpoch 198:  96% 260/270 [02:57<01:33,  9.34s/it, loss=0.017, v_num=ypmf]Epoch 198:  96% 260/270 [02:57<01:33,  9.34s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  55% 11/20 [00:10<00:07,  1.15it/s][A
Validation DataLoader 0:  55% 11/20 [00:10<00:07,  1.15it/s][AEpoch 198:  97% 261/270 [02:58<01:20,  8.91s/it, loss=0.017, v_num=ypmf]Epoch 198:  97% 261/270 [02:58<01:20,  8.91s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  60% 12/20 [00:12<00:08,  1.11s/it][A
Validation DataLoader 0:  60% 12/20 [00:12<00:08,  1.11s/it][AEpoch 198:  97% 262/270 [02:59<01:08,  8.57s/it, loss=0.017, v_num=ypmf]Epoch 198:  97% 262/270 [02:59<01:08,  8.57s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  65% 13/20 [00:12<00:07,  1.03s/it][A
Validation DataLoader 0:  65% 13/20 [00:12<00:07,  1.03s/it][AEpoch 198:  97% 263/270 [03:00<00:57,  8.21s/it, loss=0.017, v_num=ypmf]Epoch 198:  97% 263/270 [03:00<00:57,  8.21s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  70% 14/20 [00:13<00:05,  1.08it/s][A
Validation DataLoader 0:  70% 14/20 [00:13<00:05,  1.08it/s][AEpoch 198:  98% 264/270 [03:01<00:47,  7.89s/it, loss=0.017, v_num=ypmf]Epoch 198:  98% 264/270 [03:01<00:47,  7.89s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  75% 15/20 [00:14<00:04,  1.05it/s][A
Validation DataLoader 0:  75% 15/20 [00:14<00:04,  1.05it/s][AEpoch 198:  98% 265/270 [03:02<00:37,  7.60s/it, loss=0.017, v_num=ypmf]Epoch 198:  98% 265/270 [03:02<00:37,  7.60s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  80% 16/20 [00:15<00:03,  1.04it/s][A
Validation DataLoader 0:  80% 16/20 [00:15<00:03,  1.04it/s][AEpoch 198:  99% 266/270 [03:03<00:29,  7.34s/it, loss=0.017, v_num=ypmf]Epoch 198:  99% 266/270 [03:03<00:29,  7.34s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  85% 17/20 [00:16<00:02,  1.03it/s][A
Validation DataLoader 0:  85% 17/20 [00:16<00:02,  1.03it/s][AEpoch 198:  99% 267/270 [03:04<00:21,  7.09s/it, loss=0.017, v_num=ypmf]Epoch 198:  99% 267/270 [03:04<00:21,  7.09s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  90% 18/20 [00:17<00:01,  1.08it/s][A
Validation DataLoader 0:  90% 18/20 [00:17<00:01,  1.08it/s][AEpoch 198:  99% 268/270 [03:05<00:13,  6.86s/it, loss=0.017, v_num=ypmf]Epoch 198:  99% 268/270 [03:05<00:13,  6.86s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0:  95% 19/20 [00:18<00:00,  1.08it/s][A
Validation DataLoader 0:  95% 19/20 [00:18<00:00,  1.08it/s][AEpoch 198: 100% 269/270 [03:06<00:06,  6.65s/it, loss=0.017, v_num=ypmf]Epoch 198: 100% 269/270 [03:06<00:06,  6.65s/it, loss=0.017, v_num=ypmf]
Validation DataLoader 0: 100% 20/20 [00:18<00:00,  1.22it/s][A
Validation DataLoader 0: 100% 20/20 [00:18<00:00,  1.22it/s][AEpoch 198: 100% 270/270 [03:06<00:00,  6.44s/it, loss=0.017, v_num=ypmf]Epoch 198: 100% 270/270 [03:06<00:00,  6.44s/it, loss=0.017, v_num=ypmf]Epoch 198: 100% 270/270 [03:08<00:00,  6.49s/it, loss=0.017, v_num=ypmf]
                                                            [AEpoch 198: 100% 270/270 [03:08<00:00,  6.49s/it, loss=0.017, v_num=ypmf]Epoch 198:   0% 0/270 [00:00<00:00, -9273644.62it/s, loss=0.017, v_num=ypmf]Epoch 199:   0% 0/270 [00:00<00:00, -1858138.35it/s, loss=0.017, v_num=ypmf]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch 199:   0% 1/270 [00:01<-1:59:59, -150.41it/s, loss=0.017, v_num=ypmf] Epoch 199:   0% 1/270 [00:01<-1:59:59, -150.39it/s, loss=0.017, v_num=ypmf]Epoch 199:   0% 1/270 [00:01<-1:59:58, -129.35it/s, loss=0.017, v_num=ypmf]Epoch 199:   1% 2/270 [00:02<-1:59:58, -103.68it/s, loss=0.017, v_num=ypmf]Epoch 199:   1% 2/270 [00:02<-1:59:58, -103.67it/s, loss=0.017, v_num=ypmf]Epoch 199:   1% 2/270 [00:02<-1:59:58, -97.54it/s, loss=0.0171, v_num=ypmf]Epoch 199:   1% 3/270 [00:02<-1:59:57, -80.82it/s, loss=0.0171, v_num=ypmf]Epoch 199:   1% 3/270 [00:02<-1:59:57, -80.82it/s, loss=0.0171, v_num=ypmf]Epoch 199:   1% 3/270 [00:03<-1:59:57, -76.85it/s, loss=0.017, v_num=ypmf] Epoch 199:   1% 4/270 [00:03<-1:59:57, -71.19it/s, loss=0.017, v_num=ypmf]Epoch 199:   1% 4/270 [00:03<-1:59:57, -71.18it/s, loss=0.017, v_num=ypmf]Epoch 199:   1% 4/270 [00:03<-1:59:56, -65.69it/s, loss=0.0171, v_num=ypmf]Epoch 199:   2% 5/270 [00:04<-1:59:56, -58.49it/s, loss=0.0171, v_num=ypmf]Epoch 199:   2% 5/270 [00:04<-1:59:56, -58.49it/s, loss=0.0171, v_num=ypmf]Epoch 199:   2% 5/270 [00:04<-1:59:56, -55.62it/s, loss=0.017, v_num=ypmf] Epoch 199:   2% 6/270 [00:04<-1:59:55, -50.31it/s, loss=0.017, v_num=ypmf]Epoch 199:   2% 6/270 [00:04<-1:59:55, -50.31it/s, loss=0.017, v_num=ypmf]Epoch 199:   2% 6/270 [00:04<-1:59:55, -48.82it/s, loss=0.0171, v_num=ypmf]Epoch 199:   3% 7/270 [00:05<-1:59:55, -45.16it/s, loss=0.0171, v_num=ypmf]Epoch 199:   3% 7/270 [00:05<-1:59:55, -45.15it/s, loss=0.0171, v_num=ypmf]Epoch 199:   3% 7/270 [00:05<-1:59:54, -43.49it/s, loss=0.017, v_num=ypmf] Epoch 199:   3% 8/270 [00:05<-1:59:54, -40.52it/s, loss=0.017, v_num=ypmf]Epoch 199:   3% 8/270 [00:05<-1:59:54, -40.52it/s, loss=0.017, v_num=ypmf]Epoch 199:   3% 8/270 [00:05<-1:59:54, -39.73it/s, loss=0.0171, v_num=ypmf]Epoch 199:   3% 9/270 [00:06<-1:59:53, -36.74it/s, loss=0.0171, v_num=ypmf]Epoch 199:   3% 9/270 [00:06<-1:59:53, -36.74it/s, loss=0.0171, v_num=ypmf]Epoch 199:   3% 9/270 [00:06<-1:59:53, -35.93it/s, loss=0.0171, v_num=ypmf]Epoch 199:   4% 10/270 [00:06<-1:59:53, -33.89it/s, loss=0.0171, v_num=ypmf]Epoch 199:   4% 10/270 [00:06<-1:59:53, -33.89it/s, loss=0.0171, v_num=ypmf]Epoch 199:   4% 10/270 [00:06<-1:59:53, -33.31it/s, loss=0.017, v_num=ypmf] Epoch 199:   4% 11/270 [00:07<-1:59:52, -31.20it/s, loss=0.017, v_num=ypmf]Epoch 199:   4% 11/270 [00:07<-1:59:52, -31.20it/s, loss=0.017, v_num=ypmf]Epoch 199:   4% 11/270 [00:07<-1:59:52, -30.60it/s, loss=0.017, v_num=ypmf]Epoch 199:   4% 12/270 [00:07<-1:59:52, -29.12it/s, loss=0.017, v_num=ypmf]Epoch 199:   4% 12/270 [00:07<-1:59:52, -29.12it/s, loss=0.017, v_num=ypmf]Epoch 199:   4% 12/270 [00:08<-1:59:51, -27.83it/s, loss=0.017, v_num=ypmf]Epoch 199:   5% 13/270 [00:08<-1:59:51, -26.48it/s, loss=0.017, v_num=ypmf]Epoch 199:   5% 13/270 [00:08<-1:59:51, -26.47it/s, loss=0.017, v_num=ypmf]Epoch 199:   5% 13/270 [00:08<-1:59:51, -26.09it/s, loss=0.017, v_num=ypmf]Epoch 199:   5% 14/270 [00:09<-1:59:50, -24.92it/s, loss=0.017, v_num=ypmf]Epoch 199:   5% 14/270 [00:09<-1:59:50, -24.92it/s, loss=0.017, v_num=ypmf]Epoch 199:   5% 14/270 [00:09<-1:59:50, -24.48it/s, loss=0.017, v_num=ypmf]Epoch 199:   6% 15/270 [00:09<-1:59:50, -23.47it/s, loss=0.017, v_num=ypmf]Epoch 199:   6% 15/270 [00:09<-1:59:50, -23.47it/s, loss=0.017, v_num=ypmf]Epoch 199:   6% 15/270 [00:09<-1:59:50, -23.19it/s, loss=0.0171, v_num=ypmf]Epoch 199:   6% 16/270 [00:10<-1:59:49, -22.12it/s, loss=0.0171, v_num=ypmf]Epoch 199:   6% 16/270 [00:10<-1:59:49, -22.12it/s, loss=0.0171, v_num=ypmf]Epoch 199:   6% 16/270 [00:10<-1:59:49, -22.03it/s, loss=0.017, v_num=ypmf] Epoch 199:   6% 17/270 [00:10<-1:59:49, -21.37it/s, loss=0.017, v_num=ypmf]Epoch 199:   6% 17/270 [00:10<-1:59:49, -21.37it/s, loss=0.017, v_num=ypmf]Epoch 199:   6% 17/270 [00:10<-1:59:48, -20.63it/s, loss=0.0171, v_num=ypmf]Epoch 199:   7% 18/270 [00:11<-1:59:48, -19.71it/s, loss=0.0171, v_num=ypmf]Epoch 199:   7% 18/270 [00:11<-1:59:48, -19.71it/s, loss=0.0171, v_num=ypmf]Epoch 199:   7% 18/270 [00:11<-1:59:47, -19.37it/s, loss=0.017, v_num=ypmf] Epoch 199:   7% 19/270 [00:11<-1:59:47, -18.74it/s, loss=0.017, v_num=ypmf]Epoch 199:   7% 19/270 [00:11<-1:59:47, -18.74it/s, loss=0.017, v_num=ypmf]Epoch 199:   7% 19/270 [00:12<-1:59:47, -18.34it/s, loss=0.0171, v_num=ypmf]Epoch 199:   7% 20/270 [00:12<-1:59:46, -17.65it/s, loss=0.0171, v_num=ypmf]Epoch 199:   7% 20/270 [00:12<-1:59:46, -17.65it/s, loss=0.0171, v_num=ypmf]Epoch 199:   7% 20/270 [00:12<-1:59:46, -17.45it/s, loss=0.017, v_num=ypmf] Epoch 199:   8% 21/270 [00:13<-1:59:46, -16.82it/s, loss=0.017, v_num=ypmf]Epoch 199:   8% 21/270 [00:13<-1:59:46, -16.82it/s, loss=0.017, v_num=ypmf]Epoch 199:   8% 21/270 [00:13<-1:59:45, -16.54it/s, loss=0.017, v_num=ypmf]Epoch 199:   8% 22/270 [00:13<-1:59:45, -16.03it/s, loss=0.017, v_num=ypmf]Epoch 199:   8% 22/270 [00:13<-1:59:45, -16.03it/s, loss=0.017, v_num=ypmf]Epoch 199:   8% 22/270 [00:13<-1:59:45, -15.78it/s, loss=0.017, v_num=ypmf]Epoch 199:   9% 23/270 [00:14<-1:59:44, -15.31it/s, loss=0.017, v_num=ypmf]Epoch 199:   9% 23/270 [00:14<-1:59:44, -15.31it/s, loss=0.017, v_num=ypmf]Epoch 199:   9% 23/270 [00:14<-1:59:44, -15.19it/s, loss=0.0171, v_num=ypmf]Epoch 199:   9% 24/270 [00:14<-1:59:44, -14.86it/s, loss=0.0171, v_num=ypmf]Epoch 199:   9% 24/270 [00:14<-1:59:44, -14.86it/s, loss=0.0171, v_num=ypmf]Epoch 199:   9% 24/270 [00:14<-1:59:44, -14.50it/s, loss=0.0171, v_num=ypmf]Epoch 199:   9% 25/270 [00:15<-1:59:43, -13.97it/s, loss=0.0171, v_num=ypmf]Epoch 199:   9% 25/270 [00:15<-1:59:43, -13.97it/s, loss=0.0171, v_num=ypmf]Epoch 199:   9% 25/270 [00:15<-1:59:43, -13.83it/s, loss=0.0171, v_num=ypmf]Epoch 199:  10% 26/270 [00:15<-1:59:42, -13.48it/s, loss=0.0171, v_num=ypmf]Epoch 199:  10% 26/270 [00:15<-1:59:42, -13.48it/s, loss=0.0171, v_num=ypmf]Epoch 199:  10% 26/270 [00:16<-1:59:42, -13.31it/s, loss=0.017, v_num=ypmf] Epoch 199:  10% 27/270 [00:16<-1:59:42, -12.96it/s, loss=0.017, v_num=ypmf]Epoch 199:  10% 27/270 [00:16<-1:59:42, -12.96it/s, loss=0.017, v_num=ypmf]Epoch 199:  10% 27/270 [00:16<-1:59:41, -12.75it/s, loss=0.0171, v_num=ypmf]Epoch 199:  10% 28/270 [00:17<-1:59:41, -12.41it/s, loss=0.0171, v_num=ypmf]Epoch 199:  10% 28/270 [00:17<-1:59:41, -12.41it/s, loss=0.0171, v_num=ypmf]Epoch 199:  10% 28/270 [00:17<-1:59:41, -12.22it/s, loss=0.0172, v_num=ypmf]Epoch 199:  11% 29/270 [00:17<-1:59:40, -11.95it/s, loss=0.0172, v_num=ypmf]Epoch 199:  11% 29/270 [00:17<-1:59:40, -11.95it/s, loss=0.0172, v_num=ypmf]Epoch 199:  11% 29/270 [00:18<-1:59:40, -11.75it/s, loss=0.0173, v_num=ypmf]Epoch 199:  11% 30/270 [00:18<-1:59:40, -11.44it/s, loss=0.0173, v_num=ypmf]Epoch 199:  11% 30/270 [00:18<-1:59:40, -11.44it/s, loss=0.0173, v_num=ypmf]Epoch 199:  11% 30/270 [00:18<-1:59:39, -11.29it/s, loss=0.0173, v_num=ypmf]Epoch 199:  11% 31/270 [00:19<-1:59:39, -11.00it/s, loss=0.0173, v_num=ypmf]Epoch 199:  11% 31/270 [00:19<-1:59:39, -11.00it/s, loss=0.0173, v_num=ypmf]Epoch 199:  11% 31/270 [00:19<-1:59:38, -10.83it/s, loss=0.0173, v_num=ypmf]Epoch 199:  12% 32/270 [00:19<-1:59:38, -10.54it/s, loss=0.0173, v_num=ypmf]Epoch 199:  12% 32/270 [00:19<-1:59:38, -10.54it/s, loss=0.0173, v_num=ypmf]Epoch 199:  12% 32/270 [00:19<-1:59:38, -10.47it/s, loss=0.0172, v_num=ypmf]Epoch 199:  12% 33/270 [00:20<-1:59:37, -10.22it/s, loss=0.0172, v_num=ypmf]Epoch 199:  12% 33/270 [00:20<-1:59:37, -10.22it/s, loss=0.0172, v_num=ypmf]Epoch 199:  12% 33/270 [00:20<-1:59:37, -10.12it/s, loss=0.0173, v_num=ypmf]Epoch 199:  13% 34/270 [00:20<-1:59:37, -9.89it/s, loss=0.0173, v_num=ypmf] Epoch 199:  13% 34/270 [00:20<-1:59:37, -9.89it/s, loss=0.0173, v_num=ypmf]Epoch 199:  13% 34/270 [00:21<-1:59:36, -9.83it/s, loss=0.0172, v_num=ypmf]Epoch 199:  13% 35/270 [00:21<-1:59:36, -9.60it/s, loss=0.0172, v_num=ypmf]Epoch 199:  13% 35/270 [00:21<-1:59:36, -9.60it/s, loss=0.0172, v_num=ypmf]Epoch 199:  13% 35/270 [00:21<-1:59:36, -9.51it/s, loss=0.0171, v_num=ypmf]Epoch 199:  13% 36/270 [00:21<-1:59:35, -9.32it/s, loss=0.0171, v_num=ypmf]Epoch 199:  13% 36/270 [00:21<-1:59:35, -9.32it/s, loss=0.0171, v_num=ypmf]Epoch 199:  13% 36/270 [00:22<-1:59:35, -9.22it/s, loss=0.0173, v_num=ypmf]Epoch 199:  14% 37/270 [00:22<-1:59:35, -9.01it/s, loss=0.0173, v_num=ypmf]Epoch 199:  14% 37/270 [00:22<-1:59:35, -9.01it/s, loss=0.0173, v_num=ypmf]Epoch 199:  14% 37/270 [00:22<-1:59:34, -8.87it/s, loss=0.0173, v_num=ypmf]Epoch 199:  14% 38/270 [00:23<-1:59:34, -8.64it/s, loss=0.0173, v_num=ypmf]Epoch 199:  14% 38/270 [00:23<-1:59:34, -8.64it/s, loss=0.0173, v_num=ypmf]Epoch 199:  14% 38/270 [00:23<-1:59:33, -8.59it/s, loss=0.0172, v_num=ypmf]Epoch 199:  14% 39/270 [00:24<-1:59:33, -8.40it/s, loss=0.0172, v_num=ypmf]Epoch 199:  14% 39/270 [00:24<-1:59:33, -8.40it/s, loss=0.0172, v_num=ypmf]Epoch 199:  14% 39/270 [00:24<-1:59:33, -8.36it/s, loss=0.0172, v_num=ypmf]Epoch 199:  15% 40/270 [00:24<-1:59:32, -8.18it/s, loss=0.0172, v_num=ypmf]Epoch 199:  15% 40/270 [00:24<-1:59:32, -8.18it/s, loss=0.0172, v_num=ypmf]Epoch 199:  15% 40/270 [00:24<-1:59:32, -8.14it/s, loss=0.0172, v_num=ypmf]Epoch 199:  15% 41/270 [00:25<-1:59:32, -7.93it/s, loss=0.0172, v_num=ypmf]Epoch 199:  15% 41/270 [00:25<-1:59:32, -7.93it/s, loss=0.0172, v_num=ypmf]Epoch 199:  15% 41/270 [00:25<-1:59:32, -7.91it/s, loss=0.0172, v_num=ypmf]Epoch 199:  16% 42/270 [00:25<-1:59:31, -7.76it/s, loss=0.0172, v_num=ypmf]Epoch 199:  16% 42/270 [00:25<-1:59:31, -7.76it/s, loss=0.0172, v_num=ypmf]Epoch 199:  16% 42/270 [00:25<-1:59:31, -7.67it/s, loss=0.0172, v_num=ypmf]Epoch 199:  16% 43/270 [00:26<-1:59:30, -7.54it/s, loss=0.0172, v_num=ypmf]Epoch 199:  16% 43/270 [00:26<-1:59:30, -7.54it/s, loss=0.0172, v_num=ypmf]Epoch 199:  16% 43/270 [00:26<-1:59:30, -7.45it/s, loss=0.0171, v_num=ypmf]Epoch 199:  16% 44/270 [00:26<-1:59:30, -7.31it/s, loss=0.0171, v_num=ypmf]Epoch 199:  16% 44/270 [00:26<-1:59:30, -7.31it/s, loss=0.0171, v_num=ypmf]Epoch 199:  16% 44/270 [00:27<-1:59:29, -7.24it/s, loss=0.017, v_num=ypmf] Epoch 199:  17% 45/270 [00:27<-1:59:29, -7.12it/s, loss=0.017, v_num=ypmf]Epoch 199:  17% 45/270 [00:27<-1:59:29, -7.12it/s, loss=0.017, v_num=ypmf]Epoch 199:  17% 45/270 [00:27<-1:59:29, -7.06it/s, loss=0.017, v_num=ypmf]Epoch 199:  17% 46/270 [00:28<-1:59:28, -6.92it/s, loss=0.017, v_num=ypmf]Epoch 199:  17% 46/270 [00:28<-1:59:28, -6.92it/s, loss=0.017, v_num=ypmf]Epoch 199:  17% 46/270 [00:28<-1:59:28, -6.89it/s, loss=0.0169, v_num=ypmf]Epoch 199:  17% 47/270 [00:28<-1:59:28, -6.77it/s, loss=0.0169, v_num=ypmf]Epoch 199:  17% 47/270 [00:28<-1:59:28, -6.77it/s, loss=0.0169, v_num=ypmf]Epoch 199:  17% 47/270 [00:28<-1:59:27, -6.74it/s, loss=0.0169, v_num=ypmf]Epoch 199:  18% 48/270 [00:29<-1:59:27, -6.61it/s, loss=0.0169, v_num=ypmf]Epoch 199:  18% 48/270 [00:29<-1:59:27, -6.61it/s, loss=0.0169, v_num=ypmf]Epoch 199:  18% 48/270 [00:29<-1:59:27, -6.57it/s, loss=0.0167, v_num=ypmf]Epoch 199:  18% 49/270 [00:29<-1:59:26, -6.44it/s, loss=0.0167, v_num=ypmf]Epoch 199:  18% 49/270 [00:29<-1:59:26, -6.44it/s, loss=0.0167, v_num=ypmf]Epoch 199:  18% 49/270 [00:29<-1:59:26, -6.41it/s, loss=0.0166, v_num=ypmf]Epoch 199:  19% 50/270 [00:30<-1:59:26, -6.32it/s, loss=0.0166, v_num=ypmf]Epoch 199:  19% 50/270 [00:30<-1:59:26, -6.32it/s, loss=0.0166, v_num=ypmf]Epoch 199:  19% 50/270 [00:30<-1:59:25, -6.25it/s, loss=0.0166, v_num=ypmf]Epoch 199:  19% 51/270 [00:30<-1:59:25, -6.14it/s, loss=0.0166, v_num=ypmf]Epoch 199:  19% 51/270 [00:30<-1:59:25, -6.14it/s, loss=0.0166, v_num=ypmf]Epoch 199:  19% 51/270 [00:31<-1:59:25, -6.10it/s, loss=0.0166, v_num=ypmf]Epoch 199:  19% 52/270 [00:31<-1:59:24, -5.99it/s, loss=0.0166, v_num=ypmf]Epoch 199:  19% 52/270 [00:31<-1:59:24, -5.99it/s, loss=0.0166, v_num=ypmf]Epoch 199:  19% 52/270 [00:31<-1:59:24, -5.93it/s, loss=0.0166, v_num=ypmf]Epoch 199:  20% 53/270 [00:32<-1:59:23, -5.83it/s, loss=0.0166, v_num=ypmf]Epoch 199:  20% 53/270 [00:32<-1:59:23, -5.83it/s, loss=0.0166, v_num=ypmf]Epoch 199:  20% 53/270 [00:32<-1:59:23, -5.79it/s, loss=0.0166, v_num=ypmf]Epoch 199:  20% 54/270 [00:32<-1:59:23, -5.69it/s, loss=0.0166, v_num=ypmf]Epoch 199:  20% 54/270 [00:32<-1:59:23, -5.69it/s, loss=0.0166, v_num=ypmf]Epoch 199:  20% 54/270 [00:33<-1:59:22, -5.67it/s, loss=0.0166, v_num=ypmf]Epoch 199:  20% 55/270 [00:33<-1:59:22, -5.58it/s, loss=0.0166, v_num=ypmf]Epoch 199:  20% 55/270 [00:33<-1:59:22, -5.58it/s, loss=0.0166, v_num=ypmf]Epoch 199:  20% 55/270 [00:33<-1:59:22, -5.55it/s, loss=0.0166, v_num=ypmf]Epoch 199:  21% 56/270 [00:33<-1:59:21, -5.45it/s, loss=0.0166, v_num=ypmf]Epoch 199:  21% 56/270 [00:33<-1:59:21, -5.45it/s, loss=0.0166, v_num=ypmf]Epoch 199:  21% 56/270 [00:34<-1:59:21, -5.43it/s, loss=0.0165, v_num=ypmf]Epoch 199:  21% 57/270 [00:34<-1:59:21, -5.34it/s, loss=0.0165, v_num=ypmf]Epoch 199:  21% 57/270 [00:34<-1:59:21, -5.34it/s, loss=0.0165, v_num=ypmf]Epoch 199:  21% 57/270 [00:34<-1:59:20, -5.31it/s, loss=0.0165, v_num=ypmf]Epoch 199:  21% 58/270 [00:35<-1:59:20, -5.23it/s, loss=0.0165, v_num=ypmf]Epoch 199:  21% 58/270 [00:35<-1:59:20, -5.23it/s, loss=0.0165, v_num=ypmf]Epoch 199:  21% 58/270 [00:35<-1:59:20, -5.18it/s, loss=0.0166, v_num=ypmf]Epoch 199:  22% 59/270 [00:35<-1:59:19, -5.10it/s, loss=0.0166, v_num=ypmf]Epoch 199:  22% 59/270 [00:35<-1:59:19, -5.10it/s, loss=0.0166, v_num=ypmf]Epoch 199:  22% 59/270 [00:35<-1:59:19, -5.08it/s, loss=0.0167, v_num=ypmf]Epoch 199:  22% 60/270 [00:36<-1:59:18, -5.00it/s, loss=0.0167, v_num=ypmf]Epoch 199:  22% 60/270 [00:36<-1:59:18, -5.00it/s, loss=0.0167, v_num=ypmf]Epoch 199:  22% 60/270 [00:36<-1:59:18, -4.97it/s, loss=0.0167, v_num=ypmf]Epoch 199:  23% 61/270 [00:36<-1:59:18, -4.89it/s, loss=0.0167, v_num=ypmf]Epoch 199:  23% 61/270 [00:36<-1:59:18, -4.89it/s, loss=0.0167, v_num=ypmf]Epoch 199:  23% 61/270 [00:36<-1:59:18, -4.87it/s, loss=0.0167, v_num=ypmf]Epoch 199:  23% 62/270 [00:37<-1:59:17, -4.79it/s, loss=0.0167, v_num=ypmf]Epoch 199:  23% 62/270 [00:37<-1:59:17, -4.79it/s, loss=0.0167, v_num=ypmf]Epoch 199:  23% 62/270 [00:37<-1:59:17, -4.77it/s, loss=0.0167, v_num=ypmf]Epoch 199:  23% 63/270 [00:38<-1:59:16, -4.68it/s, loss=0.0167, v_num=ypmf]Epoch 199:  23% 63/270 [00:38<-1:59:16, -4.68it/s, loss=0.0167, v_num=ypmf]Epoch 199:  23% 63/270 [00:38<-1:59:16, -4.66it/s, loss=0.0166, v_num=ypmf]Epoch 199:  24% 64/270 [00:38<-1:59:16, -4.60it/s, loss=0.0166, v_num=ypmf]Epoch 199:  24% 64/270 [00:38<-1:59:16, -4.60it/s, loss=0.0166, v_num=ypmf]Epoch 199:  24% 64/270 [00:38<-1:59:15, -4.57it/s, loss=0.0167, v_num=ypmf]Epoch 199:  24% 65/270 [00:39<-1:59:15, -4.50it/s, loss=0.0167, v_num=ypmf]Epoch 199:  24% 65/270 [00:39<-1:59:15, -4.50it/s, loss=0.0167, v_num=ypmf]Epoch 199:  24% 65/270 [00:39<-1:59:15, -4.48it/s, loss=0.0166, v_num=ypmf]Epoch 199:  24% 66/270 [00:39<-1:59:14, -4.40it/s, loss=0.0166, v_num=ypmf]Epoch 199:  24% 66/270 [00:39<-1:59:14, -4.40it/s, loss=0.0166, v_num=ypmf]Epoch 199:  24% 66/270 [00:39<-1:59:14, -4.39it/s, loss=0.0167, v_num=ypmf]Epoch 199:  25% 67/270 [00:40<-1:59:14, -4.33it/s, loss=0.0167, v_num=ypmf]Epoch 199:  25% 67/270 [00:40<-1:59:14, -4.33it/s, loss=0.0167, v_num=ypmf]Epoch 199:  25% 67/270 [00:40<-1:59:13, -4.31it/s, loss=0.0167, v_num=ypmf]Epoch 199:  25% 68/270 [00:40<-1:59:13, -4.25it/s, loss=0.0167, v_num=ypmf]Epoch 199:  25% 68/270 [00:40<-1:59:13, -4.25it/s, loss=0.0167, v_num=ypmf]Epoch 199:  25% 68/270 [00:41<-1:59:13, -4.22it/s, loss=0.0167, v_num=ypmf]Epoch 199:  26% 69/270 [00:41<-1:59:12, -4.15it/s, loss=0.0167, v_num=ypmf]Epoch 199:  26% 69/270 [00:41<-1:59:12, -4.15it/s, loss=0.0167, v_num=ypmf]Epoch 199:  26% 69/270 [00:41<-1:59:12, -4.12it/s, loss=0.0168, v_num=ypmf]Epoch 199:  26% 70/270 [00:42<-1:59:11, -4.06it/s, loss=0.0168, v_num=ypmf]Epoch 199:  26% 70/270 [00:42<-1:59:11, -4.06it/s, loss=0.0168, v_num=ypmf]Epoch 199:  26% 70/270 [00:42<-1:59:11, -4.04it/s, loss=0.0168, v_num=ypmf]Epoch 199:  26% 71/270 [00:42<-1:59:10, -3.97it/s, loss=0.0168, v_num=ypmf]Epoch 199:  26% 71/270 [00:42<-1:59:10, -3.97it/s, loss=0.0168, v_num=ypmf]Epoch 199:  26% 71/270 [00:42<-1:59:10, -3.96it/s, loss=0.0168, v_num=ypmf]Epoch 199:  27% 72/270 [00:43<-1:59:10, -3.91it/s, loss=0.0168, v_num=ypmf]Epoch 199:  27% 72/270 [00:43<-1:59:10, -3.91it/s, loss=0.0168, v_num=ypmf]Epoch 199:  27% 72/270 [00:43<-1:59:10, -3.88it/s, loss=0.0169, v_num=ypmf]Epoch 199:  27% 73/270 [00:43<-1:59:09, -3.83it/s, loss=0.0169, v_num=ypmf]Epoch 199:  27% 73/270 [00:43<-1:59:09, -3.83it/s, loss=0.0169, v_num=ypmf]Epoch 199:  27% 73/270 [00:44<-1:59:09, -3.81it/s, loss=0.0167, v_num=ypmf]Epoch 199:  27% 74/270 [00:44<-1:59:08, -3.75it/s, loss=0.0167, v_num=ypmf]Epoch 199:  27% 74/270 [00:44<-1:59:08, -3.75it/s, loss=0.0167, v_num=ypmf]Epoch 199:  27% 74/270 [00:44<-1:59:08, -3.74it/s, loss=0.0167, v_num=ypmf]Epoch 199:  28% 75/270 [00:44<-1:59:08, -3.69it/s, loss=0.0167, v_num=ypmf]Epoch 199:  28% 75/270 [00:44<-1:59:08, -3.69it/s, loss=0.0167, v_num=ypmf]Epoch 199:  28% 75/270 [00:45<-1:59:07, -3.66it/s, loss=0.0168, v_num=ypmf]Epoch 199:  28% 76/270 [00:45<-1:59:07, -3.60it/s, loss=0.0168, v_num=ypmf]Epoch 199:  28% 76/270 [00:45<-1:59:07, -3.60it/s, loss=0.0168, v_num=ypmf]Epoch 199:  28% 76/270 [00:46<-1:59:06, -3.58it/s, loss=0.0167, v_num=ypmf]Epoch 199:  29% 77/270 [00:46<-1:59:06, -3.53it/s, loss=0.0167, v_num=ypmf]Epoch 199:  29% 77/270 [00:46<-1:59:06, -3.53it/s, loss=0.0167, v_num=ypmf]Epoch 199:  29% 77/270 [00:46<-1:59:06, -3.51it/s, loss=0.0167, v_num=ypmf]Epoch 199:  29% 78/270 [00:47<-1:59:05, -3.46it/s, loss=0.0167, v_num=ypmf]Epoch 199:  29% 78/270 [00:47<-1:59:05, -3.46it/s, loss=0.0167, v_num=ypmf]Epoch 199:  29% 78/270 [00:47<-1:59:05, -3.45it/s, loss=0.0167, v_num=ypmf]Epoch 199:  29% 79/270 [00:47<-1:59:04, -3.39it/s, loss=0.0167, v_num=ypmf]Epoch 199:  29% 79/270 [00:47<-1:59:04, -3.39it/s, loss=0.0167, v_num=ypmf]Epoch 199:  29% 79/270 [00:47<-1:59:04, -3.38it/s, loss=0.0166, v_num=ypmf]Epoch 199:  30% 80/270 [00:48<-1:59:03, -3.33it/s, loss=0.0166, v_num=ypmf]Epoch 199:  30% 80/270 [00:48<-1:59:03, -3.33it/s, loss=0.0166, v_num=ypmf]Epoch 199:  30% 80/270 [00:48<-1:59:03, -3.32it/s, loss=0.0167, v_num=ypmf]Epoch 199:  30% 81/270 [00:48<-1:59:03, -3.27it/s, loss=0.0167, v_num=ypmf]Epoch 199:  30% 81/270 [00:48<-1:59:03, -3.27it/s, loss=0.0167, v_num=ypmf]Epoch 199:  30% 81/270 [00:49<-1:59:02, -3.26it/s, loss=0.0167, v_num=ypmf]Epoch 199:  30% 82/270 [00:49<-1:59:02, -3.21it/s, loss=0.0167, v_num=ypmf]Epoch 199:  30% 82/270 [00:49<-1:59:02, -3.21it/s, loss=0.0167, v_num=ypmf]Epoch 199:  30% 82/270 [00:49<-1:59:02, -3.20it/s, loss=0.0168, v_num=ypmf]Epoch 199:  31% 83/270 [00:50<-1:59:01, -3.15it/s, loss=0.0168, v_num=ypmf]Epoch 199:  31% 83/270 [00:50<-1:59:01, -3.15it/s, loss=0.0168, v_num=ypmf]Epoch 199:  31% 83/270 [00:50<-1:59:01, -3.15it/s, loss=0.0169, v_num=ypmf]Epoch 199:  31% 84/270 [00:50<-1:59:01, -3.11it/s, loss=0.0169, v_num=ypmf]Epoch 199:  31% 84/270 [00:50<-1:59:01, -3.11it/s, loss=0.0169, v_num=ypmf]Epoch 199:  31% 84/270 [00:50<-1:59:00, -3.10it/s, loss=0.0168, v_num=ypmf]Epoch 199:  31% 85/270 [00:51<-1:59:00, -3.05it/s, loss=0.0168, v_num=ypmf]Epoch 199:  31% 85/270 [00:51<-1:59:00, -3.05it/s, loss=0.0168, v_num=ypmf]Epoch 199:  31% 85/270 [00:51<-1:59:00, -3.04it/s, loss=0.0169, v_num=ypmf]Epoch 199:  32% 86/270 [00:51<-1:58:59, -3.00it/s, loss=0.0169, v_num=ypmf]Epoch 199:  32% 86/270 [00:51<-1:58:59, -3.00it/s, loss=0.0169, v_num=ypmf]Epoch 199:  32% 86/270 [00:51<-1:58:59, -2.99it/s, loss=0.0168, v_num=ypmf]Epoch 199:  32% 87/270 [00:52<-1:58:58, -2.94it/s, loss=0.0168, v_num=ypmf]Epoch 199:  32% 87/270 [00:52<-1:58:58, -2.94it/s, loss=0.0168, v_num=ypmf]Epoch 199:  32% 87/270 [00:52<-1:58:58, -2.93it/s, loss=0.0168, v_num=ypmf]Epoch 199:  33% 88/270 [00:52<-1:58:58, -2.90it/s, loss=0.0168, v_num=ypmf]Epoch 199:  33% 88/270 [00:52<-1:58:58, -2.90it/s, loss=0.0168, v_num=ypmf]Epoch 199:  33% 88/270 [00:53<-1:58:57, -2.88it/s, loss=0.0169, v_num=ypmf]Epoch 199:  33% 89/270 [00:53<-1:58:57, -2.84it/s, loss=0.0169, v_num=ypmf]Epoch 199:  33% 89/270 [00:53<-1:58:57, -2.84it/s, loss=0.0169, v_num=ypmf]Epoch 199:  33% 89/270 [00:53<-1:58:56, -2.83it/s, loss=0.0169, v_num=ypmf]Epoch 199:  33% 90/270 [00:54<-1:58:56, -2.79it/s, loss=0.0169, v_num=ypmf]Epoch 199:  33% 90/270 [00:54<-1:58:56, -2.79it/s, loss=0.0169, v_num=ypmf]Epoch 199:  33% 90/270 [00:54<-1:58:56, -2.78it/s, loss=0.0169, v_num=ypmf]Epoch 199:  34% 91/270 [00:54<-1:58:55, -2.74it/s, loss=0.0169, v_num=ypmf]Epoch 199:  34% 91/270 [00:54<-1:58:55, -2.74it/s, loss=0.0169, v_num=ypmf]Epoch 199:  34% 91/270 [00:54<-1:58:55, -2.73it/s, loss=0.0169, v_num=ypmf]Epoch 199:  34% 92/270 [00:55<-1:58:54, -2.70it/s, loss=0.0169, v_num=ypmf]Epoch 199:  34% 92/270 [00:55<-1:58:54, -2.70it/s, loss=0.0169, v_num=ypmf]Epoch 199:  34% 92/270 [00:55<-1:58:54, -2.69it/s, loss=0.0169, v_num=ypmf]Epoch 199:  34% 93/270 [00:55<-1:58:54, -2.64it/s, loss=0.0169, v_num=ypmf]Epoch 199:  34% 93/270 [00:55<-1:58:54, -2.64it/s, loss=0.0169, v_num=ypmf]Epoch 199:  34% 93/270 [00:56<-1:58:53, -2.64it/s, loss=0.0168, v_num=ypmf]Epoch 199:  35% 94/270 [00:56<-1:58:53, -2.60it/s, loss=0.0168, v_num=ypmf]Epoch 199:  35% 94/270 [00:56<-1:58:53, -2.60it/s, loss=0.0168, v_num=ypmf]Epoch 199:  35% 94/270 [00:56<-1:58:53, -2.59it/s, loss=0.0167, v_num=ypmf]Epoch 199:  35% 95/270 [00:57<-1:58:52, -2.56it/s, loss=0.0167, v_num=ypmf]Epoch 199:  35% 95/270 [00:57<-1:58:52, -2.56it/s, loss=0.0167, v_num=ypmf]Epoch 199:  35% 95/270 [00:57<-1:58:52, -2.55it/s, loss=0.0168, v_num=ypmf]Epoch 199:  36% 96/270 [00:57<-1:58:52, -2.52it/s, loss=0.0168, v_num=ypmf]Epoch 199:  36% 96/270 [00:57<-1:58:52, -2.52it/s, loss=0.0168, v_num=ypmf]Epoch 199:  36% 96/270 [00:57<-1:58:51, -2.51it/s, loss=0.017, v_num=ypmf] Epoch 199:  36% 97/270 [00:58<-1:58:51, -2.48it/s, loss=0.017, v_num=ypmf]Epoch 199:  36% 97/270 [00:58<-1:58:51, -2.48it/s, loss=0.017, v_num=ypmf]Epoch 199:  36% 97/270 [00:58<-1:58:50, -2.47it/s, loss=0.017, v_num=ypmf]Epoch 199:  36% 98/270 [00:58<-1:58:50, -2.44it/s, loss=0.017, v_num=ypmf]Epoch 199:  36% 98/270 [00:58<-1:58:50, -2.44it/s, loss=0.017, v_num=ypmf]Epoch 199:  36% 98/270 [00:58<-1:58:50, -2.43it/s, loss=0.0171, v_num=ypmf]Epoch 199:  37% 99/270 [00:59<-1:58:49, -2.39it/s, loss=0.0171, v_num=ypmf]Epoch 199:  37% 99/270 [00:59<-1:58:49, -2.39it/s, loss=0.0171, v_num=ypmf]Epoch 199:  37% 99/270 [00:59<-1:58:49, -2.39it/s, loss=0.0171, v_num=ypmf]Epoch 199:  37% 100/270 [00:59<-1:58:48, -2.36it/s, loss=0.0171, v_num=ypmf]Epoch 199:  37% 100/270 [00:59<-1:58:48, -2.36it/s, loss=0.0171, v_num=ypmf]Epoch 199:  37% 100/270 [00:59<-1:58:48, -2.35it/s, loss=0.0171, v_num=ypmf]Epoch 199:  37% 101/270 [01:00<-1:58:48, -2.32it/s, loss=0.0171, v_num=ypmf]Epoch 199:  37% 101/270 [01:00<-1:58:48, -2.32it/s, loss=0.0171, v_num=ypmf]Epoch 199:  37% 101/270 [01:00<-1:58:47, -2.31it/s, loss=0.017, v_num=ypmf] Epoch 199:  38% 102/270 [01:00<-1:58:47, -2.28it/s, loss=0.017, v_num=ypmf]Epoch 199:  38% 102/270 [01:00<-1:58:47, -2.28it/s, loss=0.017, v_num=ypmf]Epoch 199:  38% 102/270 [01:01<-1:58:47, -2.27it/s, loss=0.0168, v_num=ypmf]Epoch 199:  38% 103/270 [01:01<-1:58:46, -2.25it/s, loss=0.0168, v_num=ypmf]Epoch 199:  38% 103/270 [01:01<-1:58:46, -2.25it/s, loss=0.0168, v_num=ypmf]Epoch 199:  38% 103/270 [01:01<-1:58:46, -2.24it/s, loss=0.0169, v_num=ypmf]Epoch 199:  39% 104/270 [01:02<-1:58:45, -2.20it/s, loss=0.0169, v_num=ypmf]Epoch 199:  39% 104/270 [01:02<-1:58:45, -2.20it/s, loss=0.0169, v_num=ypmf]Epoch 199:  39% 104/270 [01:02<-1:58:45, -2.20it/s, loss=0.0168, v_num=ypmf]Epoch 199:  39% 105/270 [01:02<-1:58:44, -2.17it/s, loss=0.0168, v_num=ypmf]Epoch 199:  39% 105/270 [01:02<-1:58:44, -2.17it/s, loss=0.0168, v_num=ypmf]Epoch 199:  39% 105/270 [01:02<-1:58:44, -2.16it/s, loss=0.0169, v_num=ypmf]Epoch 199:  39% 106/270 [01:03<-1:58:44, -2.13it/s, loss=0.0169, v_num=ypmf]Epoch 199:  39% 106/270 [01:03<-1:58:44, -2.13it/s, loss=0.0169, v_num=ypmf]Epoch 199:  39% 106/270 [01:03<-1:58:43, -2.13it/s, loss=0.017, v_num=ypmf] Epoch 199:  40% 107/270 [01:03<-1:58:43, -2.10it/s, loss=0.017, v_num=ypmf]Epoch 199:  40% 107/270 [01:03<-1:58:43, -2.10it/s, loss=0.017, v_num=ypmf]Epoch 199:  40% 107/270 [01:04<-1:58:42, -2.09it/s, loss=0.017, v_num=ypmf]Epoch 199:  40% 108/270 [01:04<-1:58:42, -2.06it/s, loss=0.017, v_num=ypmf]Epoch 199:  40% 108/270 [01:04<-1:58:42, -2.06it/s, loss=0.017, v_num=ypmf]Epoch 199:  40% 108/270 [01:04<-1:58:42, -2.06it/s, loss=0.0168, v_num=ypmf]Epoch 199:  40% 109/270 [01:05<-1:58:41, -2.03it/s, loss=0.0168, v_num=ypmf]Epoch 199:  40% 109/270 [01:05<-1:58:41, -2.03it/s, loss=0.0168, v_num=ypmf]Epoch 199:  40% 109/270 [01:05<-1:58:41, -2.02it/s, loss=0.0168, v_num=ypmf]Epoch 199:  41% 110/270 [01:05<-1:58:40, -2.00it/s, loss=0.0168, v_num=ypmf]Epoch 199:  41% 110/270 [01:05<-1:58:40, -2.00it/s, loss=0.0168, v_num=ypmf]Epoch 199:  41% 110/270 [01:05<-1:58:40, -1.99it/s, loss=0.0168, v_num=ypmf]Epoch 199:  41% 111/270 [01:06<-1:58:40, -1.97it/s, loss=0.0168, v_num=ypmf]Epoch 199:  41% 111/270 [01:06<-1:58:40, -1.97it/s, loss=0.0168, v_num=ypmf]Epoch 199:  41% 111/270 [01:06<-1:58:39, -1.96it/s, loss=0.0169, v_num=ypmf]Epoch 199:  41% 112/270 [01:06<-1:58:39, -1.94it/s, loss=0.0169, v_num=ypmf]Epoch 199:  41% 112/270 [01:06<-1:58:39, -1.94it/s, loss=0.0169, v_num=ypmf]Epoch 199:  41% 112/270 [01:06<-1:58:39, -1.93it/s, loss=0.0169, v_num=ypmf]Epoch 199:  42% 113/270 [01:07<-1:58:38, -1.91it/s, loss=0.0169, v_num=ypmf]Epoch 199:  42% 113/270 [01:07<-1:58:38, -1.91it/s, loss=0.0169, v_num=ypmf]Epoch 199:  42% 113/270 [01:07<-1:58:38, -1.90it/s, loss=0.017, v_num=ypmf] Epoch 199:  42% 114/270 [01:07<-1:58:38, -1.88it/s, loss=0.017, v_num=ypmf]Epoch 199:  42% 114/270 [01:07<-1:58:38, -1.88it/s, loss=0.017, v_num=ypmf]Epoch 199:  42% 114/270 [01:07<-1:58:37, -1.87it/s, loss=0.0171, v_num=ypmf]Epoch 199:  43% 115/270 [01:08<-1:58:37, -1.85it/s, loss=0.0171, v_num=ypmf]Epoch 199:  43% 115/270 [01:08<-1:58:37, -1.85it/s, loss=0.0171, v_num=ypmf]Epoch 199:  43% 115/270 [01:08<-1:58:36, -1.84it/s, loss=0.017, v_num=ypmf] Epoch 199:  43% 116/270 [01:08<-1:58:36, -1.82it/s, loss=0.017, v_num=ypmf]Epoch 199:  43% 116/270 [01:08<-1:58:36, -1.82it/s, loss=0.017, v_num=ypmf]Epoch 199:  43% 116/270 [01:08<-1:58:36, -1.81it/s, loss=0.0168, v_num=ypmf]Epoch 199:  43% 117/270 [01:09<-1:58:35, -1.79it/s, loss=0.0168, v_num=ypmf]Epoch 199:  43% 117/270 [01:09<-1:58:35, -1.79it/s, loss=0.0168, v_num=ypmf]Epoch 199:  43% 117/270 [01:09<-1:58:35, -1.78it/s, loss=0.0168, v_num=ypmf]Epoch 199:  44% 118/270 [01:09<-1:58:34, -1.76it/s, loss=0.0168, v_num=ypmf]Epoch 199:  44% 118/270 [01:09<-1:58:34, -1.76it/s, loss=0.0168, v_num=ypmf]Epoch 199:  44% 118/270 [01:10<-1:58:34, -1.75it/s, loss=0.0167, v_num=ypmf]Epoch 199:  44% 119/270 [01:10<-1:58:33, -1.73it/s, loss=0.0167, v_num=ypmf]Epoch 199:  44% 119/270 [01:10<-1:58:33, -1.73it/s, loss=0.0167, v_num=ypmf]Epoch 199:  44% 119/270 [01:10<-1:58:33, -1.73it/s, loss=0.0168, v_num=ypmf]Epoch 199:  44% 120/270 [01:11<-1:58:32, -1.70it/s, loss=0.0168, v_num=ypmf]Epoch 199:  44% 120/270 [01:11<-1:58:32, -1.70it/s, loss=0.0168, v_num=ypmf]Epoch 199:  44% 120/270 [01:11<-1:58:32, -1.70it/s, loss=0.0168, v_num=ypmf]Epoch 199:  45% 121/270 [01:11<-1:58:32, -1.68it/s, loss=0.0168, v_num=ypmf]Epoch 199:  45% 121/270 [01:11<-1:58:32, -1.68it/s, loss=0.0168, v_num=ypmf]Epoch 199:  45% 121/270 [01:11<-1:58:31, -1.67it/s, loss=0.0168, v_num=ypmf]Epoch 199:  45% 122/270 [01:11<-1:58:31, -1.65it/s, loss=0.0168, v_num=ypmf]Epoch 199:  45% 122/270 [01:11<-1:58:31, -1.65it/s, loss=0.0168, v_num=ypmf]Epoch 199:  45% 122/270 [01:12<-1:58:31, -1.65it/s, loss=0.017, v_num=ypmf] Epoch 199:  46% 123/270 [01:12<-1:58:30, -1.62it/s, loss=0.017, v_num=ypmf]Epoch 199:  46% 123/270 [01:12<-1:58:30, -1.62it/s, loss=0.017, v_num=ypmf]Epoch 199:  46% 123/270 [01:12<-1:58:30, -1.62it/s, loss=0.0169, v_num=ypmf]Epoch 199:  46% 124/270 [01:13<-1:58:29, -1.60it/s, loss=0.0169, v_num=ypmf]Epoch 199:  46% 124/270 [01:13<-1:58:29, -1.60it/s, loss=0.0169, v_num=ypmf]Epoch 199:  46% 124/270 [01:13<-1:58:29, -1.59it/s, loss=0.017, v_num=ypmf] Epoch 199:  46% 125/270 [01:13<-1:58:28, -1.57it/s, loss=0.017, v_num=ypmf]Epoch 199:  46% 125/270 [01:13<-1:58:28, -1.57it/s, loss=0.017, v_num=ypmf]Epoch 199:  46% 125/270 [01:13<-1:58:28, -1.57it/s, loss=0.0171, v_num=ypmf]Epoch 199:  47% 126/270 [01:14<-1:58:27, -1.55it/s, loss=0.0171, v_num=ypmf]Epoch 199:  47% 126/270 [01:14<-1:58:27, -1.55it/s, loss=0.0171, v_num=ypmf]Epoch 199:  47% 126/270 [01:14<-1:58:27, -1.54it/s, loss=0.017, v_num=ypmf] Epoch 199:  47% 127/270 [01:14<-1:58:27, -1.52it/s, loss=0.017, v_num=ypmf]Epoch 199:  47% 127/270 [01:14<-1:58:27, -1.52it/s, loss=0.017, v_num=ypmf]Epoch 199:  47% 127/270 [01:14<-1:58:26, -1.52it/s, loss=0.017, v_num=ypmf]Epoch 199:  47% 128/270 [01:15<-1:58:26, -1.50it/s, loss=0.017, v_num=ypmf]Epoch 199:  47% 128/270 [01:15<-1:58:26, -1.50it/s, loss=0.017, v_num=ypmf]Epoch 199:  47% 128/270 [01:15<-1:58:26, -1.50it/s, loss=0.0172, v_num=ypmf]Epoch 199:  48% 129/270 [01:15<-1:58:25, -1.47it/s, loss=0.0172, v_num=ypmf]Epoch 199:  48% 129/270 [01:15<-1:58:25, -1.47it/s, loss=0.0172, v_num=ypmf]Epoch 199:  48% 129/270 [01:16<-1:58:25, -1.47it/s, loss=0.0172, v_num=ypmf]Epoch 199:  48% 130/270 [01:16<-1:58:24, -1.45it/s, loss=0.0172, v_num=ypmf]Epoch 199:  48% 130/270 [01:16<-1:58:24, -1.45it/s, loss=0.0172, v_num=ypmf]Epoch 199:  48% 130/270 [01:16<-1:58:24, -1.45it/s, loss=0.0172, v_num=ypmf]Epoch 199:  49% 131/270 [01:17<-1:58:23, -1.43it/s, loss=0.0172, v_num=ypmf]Epoch 199:  49% 131/270 [01:17<-1:58:23, -1.43it/s, loss=0.0172, v_num=ypmf]Epoch 199:  49% 131/270 [01:17<-1:58:23, -1.43it/s, loss=0.0171, v_num=ypmf]Epoch 199:  49% 132/270 [01:17<-1:58:22, -1.41it/s, loss=0.0171, v_num=ypmf]Epoch 199:  49% 132/270 [01:17<-1:58:22, -1.41it/s, loss=0.0171, v_num=ypmf]Epoch 199:  49% 132/270 [01:17<-1:58:22, -1.40it/s, loss=0.0172, v_num=ypmf]Epoch 199:  49% 133/270 [01:18<-1:58:21, -1.38it/s, loss=0.0172, v_num=ypmf]Epoch 199:  49% 133/270 [01:18<-1:58:21, -1.38it/s, loss=0.0172, v_num=ypmf]Epoch 199:  49% 133/270 [01:18<-1:58:21, -1.38it/s, loss=0.0172, v_num=ypmf]Epoch 199:  50% 134/270 [01:18<-1:58:21, -1.36it/s, loss=0.0172, v_num=ypmf]Epoch 199:  50% 134/270 [01:18<-1:58:21, -1.36it/s, loss=0.0172, v_num=ypmf]Epoch 199:  50% 134/270 [01:18<-1:58:20, -1.36it/s, loss=0.0173, v_num=ypmf]Epoch 199:  50% 135/270 [01:19<-1:58:20, -1.34it/s, loss=0.0173, v_num=ypmf]Epoch 199:  50% 135/270 [01:19<-1:58:20, -1.34it/s, loss=0.0173, v_num=ypmf]Epoch 199:  50% 135/270 [01:19<-1:58:19, -1.34it/s, loss=0.0172, v_num=ypmf]Epoch 199:  50% 136/270 [01:19<-1:58:19, -1.32it/s, loss=0.0172, v_num=ypmf]Epoch 199:  50% 136/270 [01:19<-1:58:19, -1.32it/s, loss=0.0172, v_num=ypmf]Epoch 199:  50% 136/270 [01:19<-1:58:19, -1.31it/s, loss=0.0173, v_num=ypmf]Epoch 199:  51% 137/270 [01:20<-1:58:18, -1.29it/s, loss=0.0173, v_num=ypmf]Epoch 199:  51% 137/270 [01:20<-1:58:18, -1.29it/s, loss=0.0173, v_num=ypmf]Epoch 199:  51% 137/270 [01:20<-1:58:17, -1.29it/s, loss=0.0173, v_num=ypmf]Epoch 199:  51% 138/270 [01:20<-1:58:17, -1.27it/s, loss=0.0173, v_num=ypmf]Epoch 199:  51% 138/270 [01:20<-1:58:17, -1.27it/s, loss=0.0173, v_num=ypmf]Epoch 199:  51% 138/270 [01:21<-1:58:16, -1.27it/s, loss=0.0173, v_num=ypmf]Epoch 199:  51% 139/270 [01:21<-1:58:16, -1.25it/s, loss=0.0173, v_num=ypmf]Epoch 199:  51% 139/270 [01:21<-1:58:16, -1.25it/s, loss=0.0173, v_num=ypmf]Epoch 199:  51% 139/270 [01:21<-1:58:16, -1.25it/s, loss=0.0171, v_num=ypmf]Epoch 199:  52% 140/270 [01:22<-1:58:15, -1.23it/s, loss=0.0171, v_num=ypmf]Epoch 199:  52% 140/270 [01:22<-1:58:15, -1.23it/s, loss=0.0171, v_num=ypmf]Epoch 199:  52% 140/270 [01:22<-1:58:14, -1.22it/s, loss=0.0171, v_num=ypmf]Epoch 199:  52% 141/270 [01:22<-1:58:13, -1.21it/s, loss=0.0171, v_num=ypmf]Epoch 199:  52% 141/270 [01:22<-1:58:13, -1.21it/s, loss=0.0171, v_num=ypmf]Epoch 199:  52% 141/270 [01:23<-1:58:13, -1.20it/s, loss=0.0171, v_num=ypmf]Epoch 199:  53% 142/270 [01:23<-1:58:13, -1.19it/s, loss=0.0171, v_num=ypmf]Epoch 199:  53% 142/270 [01:23<-1:58:13, -1.19it/s, loss=0.0171, v_num=ypmf]Epoch 199:  53% 142/270 [01:23<-1:58:12, -1.19it/s, loss=0.017, v_num=ypmf] Epoch 199:  53% 143/270 [01:23<-1:58:12, -1.17it/s, loss=0.017, v_num=ypmf]Epoch 199:  53% 143/270 [01:23<-1:58:12, -1.17it/s, loss=0.017, v_num=ypmf]Epoch 199:  53% 143/270 [01:24<-1:58:11, -1.16it/s, loss=0.017, v_num=ypmf]Epoch 199:  53% 144/270 [01:24<-1:58:11, -1.15it/s, loss=0.017, v_num=ypmf]Epoch 199:  53% 144/270 [01:24<-1:58:11, -1.15it/s, loss=0.017, v_num=ypmf]Epoch 199:  53% 144/270 [01:24<-1:58:10, -1.14it/s, loss=0.0169, v_num=ypmf]Epoch 199:  54% 145/270 [01:25<-1:58:10, -1.13it/s, loss=0.0169, v_num=ypmf]Epoch 199:  54% 145/270 [01:25<-1:58:10, -1.13it/s, loss=0.0169, v_num=ypmf]Epoch 199:  54% 145/270 [01:25<-1:58:09, -1.12it/s, loss=0.0169, v_num=ypmf]Epoch 199:  54% 146/270 [01:25<-1:58:08, -1.11it/s, loss=0.0169, v_num=ypmf]Epoch 199:  54% 146/270 [01:25<-1:58:08, -1.11it/s, loss=0.0169, v_num=ypmf]Epoch 199:  54% 146/270 [01:26<-1:58:08, -1.10it/s, loss=0.0169, v_num=ypmf]Epoch 199:  54% 147/270 [01:26<-1:58:07, -1.09it/s, loss=0.0169, v_num=ypmf]Epoch 199:  54% 147/270 [01:26<-1:58:07, -1.09it/s, loss=0.0169, v_num=ypmf]Epoch 199:  54% 147/270 [01:26<-1:58:07, -1.08it/s, loss=0.0169, v_num=ypmf]Epoch 199:  55% 148/270 [01:26<-1:58:06, -1.07it/s, loss=0.0169, v_num=ypmf]Epoch 199:  55% 148/270 [01:26<-1:58:06, -1.07it/s, loss=0.0169, v_num=ypmf]Epoch 199:  55% 148/270 [01:27<-1:58:06, -1.06it/s, loss=0.0168, v_num=ypmf]Epoch 199:  55% 149/270 [01:27<-1:58:05, -1.05it/s, loss=0.0168, v_num=ypmf]Epoch 199:  55% 149/270 [01:27<-1:58:05, -1.05it/s, loss=0.0168, v_num=ypmf]Epoch 199:  55% 149/270 [01:27<-1:58:05, -1.05it/s, loss=0.0168, v_num=ypmf]Epoch 199:  56% 150/270 [01:28<-1:58:04, -1.03it/s, loss=0.0168, v_num=ypmf]Epoch 199:  56% 150/270 [01:28<-1:58:04, -1.03it/s, loss=0.0168, v_num=ypmf]Epoch 199:  56% 150/270 [01:28<-1:58:04, -1.03it/s, loss=0.0168, v_num=ypmf]Epoch 199:  56% 151/270 [01:28<-1:58:03, -1.01it/s, loss=0.0168, v_num=ypmf]Epoch 199:  56% 151/270 [01:28<-1:58:03, -1.01it/s, loss=0.0168, v_num=ypmf]Epoch 199:  56% 151/270 [01:29<-1:58:03, -1.01it/s, loss=0.0169, v_num=ypmf]Epoch 199:  56% 152/270 [01:29<-1:58:02, -0.99it/s, loss=0.0169, v_num=ypmf]Epoch 199:  56% 152/270 [01:29<-1:58:02, -0.99it/s, loss=0.0169, v_num=ypmf]Epoch 199:  56% 152/270 [01:29<-1:58:02, -0.99it/s, loss=0.0169, v_num=ypmf]Epoch 199:  57% 153/270 [01:30<-1:58:01, -0.98it/s, loss=0.0169, v_num=ypmf]Epoch 199:  57% 153/270 [01:30<-1:58:01, -0.98it/s, loss=0.0169, v_num=ypmf]Epoch 199:  57% 153/270 [01:30<-1:58:00, -0.97it/s, loss=0.017, v_num=ypmf] Epoch 199:  57% 154/270 [01:30<-1:57:59, -0.96it/s, loss=0.017, v_num=ypmf]Epoch 199:  57% 154/270 [01:30<-1:57:59, -0.96it/s, loss=0.017, v_num=ypmf]Epoch 199:  57% 154/270 [01:30<-1:57:59, -0.96it/s, loss=0.0169, v_num=ypmf]Epoch 199:  57% 155/270 [01:31<-1:57:58, -0.94it/s, loss=0.0169, v_num=ypmf]Epoch 199:  57% 155/270 [01:31<-1:57:58, -0.94it/s, loss=0.0169, v_num=ypmf]Epoch 199:  57% 155/270 [01:31<-1:57:58, -0.94it/s, loss=0.0168, v_num=ypmf]Epoch 199:  58% 156/270 [01:31<-1:57:57, -0.92it/s, loss=0.0168, v_num=ypmf]Epoch 199:  58% 156/270 [01:31<-1:57:57, -0.92it/s, loss=0.0168, v_num=ypmf]Epoch 199:  58% 156/270 [01:32<-1:57:57, -0.92it/s, loss=0.0168, v_num=ypmf]Epoch 199:  58% 157/270 [01:32<-1:57:56, -0.91it/s, loss=0.0168, v_num=ypmf]Epoch 199:  58% 157/270 [01:32<-1:57:56, -0.91it/s, loss=0.0168, v_num=ypmf]Epoch 199:  58% 157/270 [01:32<-1:57:56, -0.91it/s, loss=0.0169, v_num=ypmf]Epoch 199:  59% 158/270 [01:32<-1:57:55, -0.89it/s, loss=0.0169, v_num=ypmf]Epoch 199:  59% 158/270 [01:32<-1:57:55, -0.89it/s, loss=0.0169, v_num=ypmf]Epoch 199:  59% 158/270 [01:33<-1:57:55, -0.89it/s, loss=0.0169, v_num=ypmf]Epoch 199:  59% 159/270 [01:33<-1:57:54, -0.88it/s, loss=0.0169, v_num=ypmf]Epoch 199:  59% 159/270 [01:33<-1:57:54, -0.88it/s, loss=0.0169, v_num=ypmf]Epoch 199:  59% 159/270 [01:33<-1:57:53, -0.87it/s, loss=0.017, v_num=ypmf] Epoch 199:  59% 160/270 [01:34<-1:57:53, -0.86it/s, loss=0.017, v_num=ypmf]Epoch 199:  59% 160/270 [01:34<-1:57:53, -0.86it/s, loss=0.017, v_num=ypmf]Epoch 199:  59% 160/270 [01:34<-1:57:52, -0.86it/s, loss=0.017, v_num=ypmf]Epoch 199:  60% 161/270 [01:34<-1:57:51, -0.84it/s, loss=0.017, v_num=ypmf]Epoch 199:  60% 161/270 [01:34<-1:57:51, -0.84it/s, loss=0.017, v_num=ypmf]Epoch 199:  60% 161/270 [01:34<-1:57:51, -0.84it/s, loss=0.017, v_num=ypmf]Epoch 199:  60% 162/270 [01:35<-1:57:50, -0.83it/s, loss=0.017, v_num=ypmf]Epoch 199:  60% 162/270 [01:35<-1:57:50, -0.83it/s, loss=0.017, v_num=ypmf]Epoch 199:  60% 162/270 [01:35<-1:57:50, -0.83it/s, loss=0.0169, v_num=ypmf]Epoch 199:  60% 163/270 [01:36<-1:57:49, -0.81it/s, loss=0.0169, v_num=ypmf]Epoch 199:  60% 163/270 [01:36<-1:57:49, -0.81it/s, loss=0.0169, v_num=ypmf]Epoch 199:  60% 163/270 [01:36<-1:57:48, -0.81it/s, loss=0.017, v_num=ypmf] Epoch 199:  61% 164/270 [01:36<-1:57:47, -0.80it/s, loss=0.017, v_num=ypmf]Epoch 199:  61% 164/270 [01:36<-1:57:47, -0.80it/s, loss=0.017, v_num=ypmf]Epoch 199:  61% 164/270 [01:36<-1:57:47, -0.80it/s, loss=0.017, v_num=ypmf]Epoch 199:  61% 165/270 [01:37<-1:57:46, -0.78it/s, loss=0.017, v_num=ypmf]Epoch 199:  61% 165/270 [01:37<-1:57:46, -0.78it/s, loss=0.017, v_num=ypmf]Epoch 199:  61% 165/270 [01:37<-1:57:46, -0.78it/s, loss=0.017, v_num=ypmf]Epoch 199:  61% 166/270 [01:37<-1:57:45, -0.77it/s, loss=0.017, v_num=ypmf]Epoch 199:  61% 166/270 [01:37<-1:57:45, -0.77it/s, loss=0.017, v_num=ypmf]Epoch 199:  61% 166/270 [01:37<-1:57:45, -0.77it/s, loss=0.0169, v_num=ypmf]Epoch 199:  62% 167/270 [01:38<-1:57:44, -0.75it/s, loss=0.0169, v_num=ypmf]Epoch 199:  62% 167/270 [01:38<-1:57:44, -0.75it/s, loss=0.0169, v_num=ypmf]Epoch 199:  62% 167/270 [01:38<-1:57:43, -0.75it/s, loss=0.017, v_num=ypmf] Epoch 199:  62% 168/270 [01:38<-1:57:42, -0.74it/s, loss=0.017, v_num=ypmf]Epoch 199:  62% 168/270 [01:38<-1:57:42, -0.74it/s, loss=0.017, v_num=ypmf]Epoch 199:  62% 168/270 [01:39<-1:57:42, -0.74it/s, loss=0.0169, v_num=ypmf]Epoch 199:  63% 169/270 [01:39<-1:57:41, -0.72it/s, loss=0.0169, v_num=ypmf]Epoch 199:  63% 169/270 [01:39<-1:57:41, -0.72it/s, loss=0.0169, v_num=ypmf]Epoch 199:  63% 169/270 [01:39<-1:57:41, -0.72it/s, loss=0.0169, v_num=ypmf]Epoch 199:  63% 170/270 [01:40<-1:57:40, -0.71it/s, loss=0.0169, v_num=ypmf]Epoch 199:  63% 170/270 [01:40<-1:57:40, -0.71it/s, loss=0.0169, v_num=ypmf]Epoch 199:  63% 170/270 [01:40<-1:57:39, -0.71it/s, loss=0.017, v_num=ypmf] Epoch 199:  63% 171/270 [01:40<-1:57:38, -0.69it/s, loss=0.017, v_num=ypmf]Epoch 199:  63% 171/270 [01:40<-1:57:38, -0.69it/s, loss=0.017, v_num=ypmf]Epoch 199:  63% 171/270 [01:40<-1:57:38, -0.69it/s, loss=0.0169, v_num=ypmf]Epoch 199:  64% 172/270 [01:41<-1:57:37, -0.68it/s, loss=0.0169, v_num=ypmf]Epoch 199:  64% 172/270 [01:41<-1:57:37, -0.68it/s, loss=0.0169, v_num=ypmf]Epoch 199:  64% 172/270 [01:41<-1:57:36, -0.68it/s, loss=0.0168, v_num=ypmf]Epoch 199:  64% 173/270 [01:41<-1:57:35, -0.67it/s, loss=0.0168, v_num=ypmf]Epoch 199:  64% 173/270 [01:41<-1:57:35, -0.67it/s, loss=0.0168, v_num=ypmf]Epoch 199:  64% 173/270 [01:41<-1:57:35, -0.67it/s, loss=0.0167, v_num=ypmf]Epoch 199:  64% 174/270 [01:42<-1:57:34, -0.66it/s, loss=0.0167, v_num=ypmf]Epoch 199:  64% 174/270 [01:42<-1:57:34, -0.66it/s, loss=0.0167, v_num=ypmf]Epoch 199:  64% 174/270 [01:42<-1:57:34, -0.65it/s, loss=0.0167, v_num=ypmf]Epoch 199:  65% 175/270 [01:42<-1:57:32, -0.64it/s, loss=0.0167, v_num=ypmf]Epoch 199:  65% 175/270 [01:42<-1:57:32, -0.64it/s, loss=0.0167, v_num=ypmf]Epoch 199:  65% 175/270 [01:43<-1:57:32, -0.64it/s, loss=0.0168, v_num=ypmf]Epoch 199:  65% 176/270 [01:43<-1:57:31, -0.63it/s, loss=0.0168, v_num=ypmf]Epoch 199:  65% 176/270 [01:43<-1:57:31, -0.63it/s, loss=0.0168, v_num=ypmf]Epoch 199:  65% 176/270 [01:43<-1:57:31, -0.63it/s, loss=0.0169, v_num=ypmf]Epoch 199:  66% 177/270 [01:43<-1:57:29, -0.62it/s, loss=0.0169, v_num=ypmf]Epoch 199:  66% 177/270 [01:43<-1:57:29, -0.62it/s, loss=0.0169, v_num=ypmf]Epoch 199:  66% 177/270 [01:44<-1:57:29, -0.61it/s, loss=0.0168, v_num=ypmf]Epoch 199:  66% 178/270 [01:44<-1:57:28, -0.60it/s, loss=0.0168, v_num=ypmf]Epoch 199:  66% 178/270 [01:44<-1:57:28, -0.60it/s, loss=0.0168, v_num=ypmf]Epoch 199:  66% 178/270 [01:44<-1:57:27, -0.60it/s, loss=0.0169, v_num=ypmf]Epoch 199:  66% 179/270 [01:45<-1:57:26, -0.59it/s, loss=0.0169, v_num=ypmf]Epoch 199:  66% 179/270 [01:45<-1:57:26, -0.59it/s, loss=0.0169, v_num=ypmf]Epoch 199:  66% 179/270 [01:45<-1:57:26, -0.59it/s, loss=0.0168, v_num=ypmf]Epoch 199:  67% 180/270 [01:45<-1:57:24, -0.58it/s, loss=0.0168, v_num=ypmf]Epoch 199:  67% 180/270 [01:45<-1:57:24, -0.58it/s, loss=0.0168, v_num=ypmf]Epoch 199:  67% 180/270 [01:46<-1:57:24, -0.57it/s, loss=0.0169, v_num=ypmf]Epoch 199:  67% 181/270 [01:46<-1:57:23, -0.56it/s, loss=0.0169, v_num=ypmf]Epoch 199:  67% 181/270 [01:46<-1:57:23, -0.56it/s, loss=0.0169, v_num=ypmf]Epoch 199:  67% 181/270 [01:46<-1:57:22, -0.56it/s, loss=0.0169, v_num=ypmf]Epoch 199:  67% 182/270 [01:47<-1:57:21, -0.55it/s, loss=0.0169, v_num=ypmf]Epoch 199:  67% 182/270 [01:47<-1:57:21, -0.55it/s, loss=0.0169, v_num=ypmf]Epoch 199:  67% 182/270 [01:47<-1:57:20, -0.55it/s, loss=0.0169, v_num=ypmf]Epoch 199:  68% 183/270 [01:47<-1:57:19, -0.54it/s, loss=0.0169, v_num=ypmf]Epoch 199:  68% 183/270 [01:47<-1:57:19, -0.54it/s, loss=0.0169, v_num=ypmf]Epoch 199:  68% 183/270 [01:47<-1:57:19, -0.54it/s, loss=0.0169, v_num=ypmf]Epoch 199:  68% 184/270 [01:48<-1:57:17, -0.53it/s, loss=0.0169, v_num=ypmf]Epoch 199:  68% 184/270 [01:48<-1:57:17, -0.53it/s, loss=0.0169, v_num=ypmf]Epoch 199:  68% 184/270 [01:48<-1:57:17, -0.53it/s, loss=0.0169, v_num=ypmf]Epoch 199:  69% 185/270 [01:48<-1:57:15, -0.51it/s, loss=0.0169, v_num=ypmf]Epoch 199:  69% 185/270 [01:48<-1:57:15, -0.51it/s, loss=0.0169, v_num=ypmf]Epoch 199:  69% 185/270 [01:48<-1:57:15, -0.51it/s, loss=0.0169, v_num=ypmf]Epoch 199:  69% 186/270 [01:49<-1:57:13, -0.50it/s, loss=0.0169, v_num=ypmf]Epoch 199:  69% 186/270 [01:49<-1:57:13, -0.50it/s, loss=0.0169, v_num=ypmf]Epoch 199:  69% 186/270 [01:49<-1:57:13, -0.50it/s, loss=0.0169, v_num=ypmf]Epoch 199:  69% 187/270 [01:49<-1:57:12, -0.49it/s, loss=0.0169, v_num=ypmf]Epoch 199:  69% 187/270 [01:49<-1:57:12, -0.49it/s, loss=0.0169, v_num=ypmf]Epoch 199:  69% 187/270 [01:50<-1:57:11, -0.49it/s, loss=0.0169, v_num=ypmf]Epoch 199:  70% 188/270 [01:50<-1:57:10, -0.48it/s, loss=0.0169, v_num=ypmf]Epoch 199:  70% 188/270 [01:50<-1:57:10, -0.48it/s, loss=0.0169, v_num=ypmf]Epoch 199:  70% 188/270 [01:50<-1:57:09, -0.48it/s, loss=0.017, v_num=ypmf] Epoch 199:  70% 189/270 [01:51<-1:57:07, -0.47it/s, loss=0.017, v_num=ypmf]Epoch 199:  70% 189/270 [01:51<-1:57:07, -0.47it/s, loss=0.017, v_num=ypmf]Epoch 199:  70% 189/270 [01:51<-1:57:07, -0.47it/s, loss=0.0169, v_num=ypmf]Epoch 199:  70% 190/270 [01:51<-1:57:05, -0.46it/s, loss=0.0169, v_num=ypmf]Epoch 199:  70% 190/270 [01:51<-1:57:05, -0.46it/s, loss=0.0169, v_num=ypmf]Epoch 199:  70% 190/270 [01:51<-1:57:05, -0.46it/s, loss=0.0169, v_num=ypmf]Epoch 199:  71% 191/270 [01:52<-1:57:03, -0.44it/s, loss=0.0169, v_num=ypmf]Epoch 199:  71% 191/270 [01:52<-1:57:03, -0.44it/s, loss=0.0169, v_num=ypmf]Epoch 199:  71% 191/270 [01:52<-1:57:03, -0.44it/s, loss=0.0169, v_num=ypmf]Epoch 199:  71% 192/270 [01:52<-1:57:01, -0.43it/s, loss=0.0169, v_num=ypmf]Epoch 199:  71% 192/270 [01:52<-1:57:01, -0.43it/s, loss=0.0169, v_num=ypmf]Epoch 199:  71% 192/270 [01:52<-1:57:01, -0.43it/s, loss=0.017, v_num=ypmf] Epoch 199:  71% 193/270 [01:53<-1:56:59, -0.42it/s, loss=0.017, v_num=ypmf]Epoch 199:  71% 193/270 [01:53<-1:56:59, -0.42it/s, loss=0.017, v_num=ypmf]Epoch 199:  71% 193/270 [01:53<-1:56:58, -0.42it/s, loss=0.017, v_num=ypmf]Epoch 199:  72% 194/270 [01:54<-1:56:56, -0.41it/s, loss=0.017, v_num=ypmf]Epoch 199:  72% 194/270 [01:54<-1:56:56, -0.41it/s, loss=0.017, v_num=ypmf]Epoch 199:  72% 194/270 [01:54<-1:56:56, -0.41it/s, loss=0.017, v_num=ypmf]Epoch 199:  72% 195/270 [01:54<-1:56:53, -0.40it/s, loss=0.017, v_num=ypmf]Epoch 199:  72% 195/270 [01:54<-1:56:53, -0.40it/s, loss=0.017, v_num=ypmf]Epoch 199:  72% 195/270 [01:54<-1:56:53, -0.40it/s, loss=0.0169, v_num=ypmf]Epoch 199:  73% 196/270 [01:55<-1:56:51, -0.39it/s, loss=0.0169, v_num=ypmf]Epoch 199:  73% 196/270 [01:55<-1:56:51, -0.39it/s, loss=0.0169, v_num=ypmf]Epoch 199:  73% 196/270 [01:55<-1:56:51, -0.39it/s, loss=0.017, v_num=ypmf] Epoch 199:  73% 197/270 [01:55<-1:56:48, -0.38it/s, loss=0.017, v_num=ypmf]Epoch 199:  73% 197/270 [01:55<-1:56:48, -0.38it/s, loss=0.017, v_num=ypmf]Epoch 199:  73% 197/270 [01:56<-1:56:48, -0.38it/s, loss=0.017, v_num=ypmf]Epoch 199:  73% 198/270 [01:56<-1:56:46, -0.37it/s, loss=0.017, v_num=ypmf]Epoch 199:  73% 198/270 [01:56<-1:56:46, -0.37it/s, loss=0.017, v_num=ypmf]Epoch 199:  73% 198/270 [01:56<-1:56:45, -0.37it/s, loss=0.017, v_num=ypmf]Epoch 199:  74% 199/270 [01:56<-1:56:43, -0.36it/s, loss=0.017, v_num=ypmf]Epoch 199:  74% 199/270 [01:56<-1:56:43, -0.36it/s, loss=0.017, v_num=ypmf]Epoch 199:  74% 199/270 [01:57<-1:56:42, -0.36it/s, loss=0.0172, v_num=ypmf]Epoch 199:  74% 200/270 [01:57<-1:56:40, -0.35it/s, loss=0.0172, v_num=ypmf]Epoch 199:  74% 200/270 [01:57<-1:56:40, -0.35it/s, loss=0.0172, v_num=ypmf]Epoch 199:  74% 200/270 [01:57<-1:56:39, -0.35it/s, loss=0.0171, v_num=ypmf]Epoch 199:  74% 201/270 [01:58<-1:56:37, -0.34it/s, loss=0.0171, v_num=ypmf]Epoch 199:  74% 201/270 [01:58<-1:56:37, -0.34it/s, loss=0.0171, v_num=ypmf]Epoch 199:  74% 201/270 [01:58<-1:56:36, -0.34it/s, loss=0.0172, v_num=ypmf]Epoch 199:  75% 202/270 [01:58<-1:56:33, -0.33it/s, loss=0.0172, v_num=ypmf]Epoch 199:  75% 202/270 [01:58<-1:56:33, -0.33it/s, loss=0.0172, v_num=ypmf]Epoch 199:  75% 202/270 [01:58<-1:56:33, -0.33it/s, loss=0.0172, v_num=ypmf]Epoch 199:  75% 203/270 [01:59<-1:56:30, -0.32it/s, loss=0.0172, v_num=ypmf]Epoch 199:  75% 203/270 [01:59<-1:56:30, -0.32it/s, loss=0.0172, v_num=ypmf]Epoch 199:  75% 203/270 [01:59<-1:56:30, -0.32it/s, loss=0.0172, v_num=ypmf]Epoch 199:  76% 204/270 [01:59<-1:56:27, -0.31it/s, loss=0.0172, v_num=ypmf]Epoch 199:  76% 204/270 [01:59<-1:56:27, -0.31it/s, loss=0.0172, v_num=ypmf]Epoch 199:  76% 204/270 [02:00<-1:56:26, -0.31it/s, loss=0.0172, v_num=ypmf]Epoch 199:  76% 205/270 [02:00<-1:56:23, -0.30it/s, loss=0.0172, v_num=ypmf]Epoch 199:  76% 205/270 [02:00<-1:56:23, -0.30it/s, loss=0.0172, v_num=ypmf]Epoch 199:  76% 205/270 [02:00<-1:56:23, -0.30it/s, loss=0.0171, v_num=ypmf]Epoch 199:  76% 206/270 [02:01<-1:56:19, -0.29it/s, loss=0.0171, v_num=ypmf]Epoch 199:  76% 206/270 [02:01<-1:56:19, -0.29it/s, loss=0.0171, v_num=ypmf]Epoch 199:  76% 206/270 [02:01<-1:56:19, -0.29it/s, loss=0.0171, v_num=ypmf]Epoch 199:  77% 207/270 [02:01<-1:56:15, -0.28it/s, loss=0.0171, v_num=ypmf]Epoch 199:  77% 207/270 [02:01<-1:56:15, -0.28it/s, loss=0.0171, v_num=ypmf]Epoch 199:  77% 207/270 [02:01<-1:56:15, -0.28it/s, loss=0.017, v_num=ypmf] Epoch 199:  77% 208/270 [02:02<-1:56:11, -0.27it/s, loss=0.017, v_num=ypmf]Epoch 199:  77% 208/270 [02:02<-1:56:11, -0.27it/s, loss=0.017, v_num=ypmf]Epoch 199:  77% 208/270 [02:02<-1:56:11, -0.27it/s, loss=0.017, v_num=ypmf]Epoch 199:  77% 209/270 [02:02<-1:56:06, -0.26it/s, loss=0.017, v_num=ypmf]Epoch 199:  77% 209/270 [02:02<-1:56:06, -0.26it/s, loss=0.017, v_num=ypmf]Epoch 199:  77% 209/270 [02:03<-1:56:06, -0.26it/s, loss=0.017, v_num=ypmf]Epoch 199:  78% 210/270 [02:03<-1:56:02, -0.25it/s, loss=0.017, v_num=ypmf]Epoch 199:  78% 210/270 [02:03<-1:56:02, -0.25it/s, loss=0.017, v_num=ypmf]Epoch 199:  78% 210/270 [02:03<-1:56:01, -0.25it/s, loss=0.0169, v_num=ypmf]Epoch 199:  78% 211/270 [02:03<-1:55:57, -0.24it/s, loss=0.0169, v_num=ypmf]Epoch 199:  78% 211/270 [02:03<-1:55:57, -0.24it/s, loss=0.0169, v_num=ypmf]Epoch 199:  78% 211/270 [02:04<-1:55:57, -0.24it/s, loss=0.0171, v_num=ypmf]Epoch 199:  79% 212/270 [02:04<-1:55:51, -0.23it/s, loss=0.0171, v_num=ypmf]Epoch 199:  79% 212/270 [02:04<-1:55:51, -0.23it/s, loss=0.0171, v_num=ypmf]Epoch 199:  79% 212/270 [02:04<-1:55:51, -0.23it/s, loss=0.017, v_num=ypmf] Epoch 199:  79% 213/270 [02:05<-1:55:46, -0.22it/s, loss=0.017, v_num=ypmf]Epoch 199:  79% 213/270 [02:05<-1:55:46, -0.22it/s, loss=0.017, v_num=ypmf]Epoch 199:  79% 213/270 [02:05<-1:55:45, -0.22it/s, loss=0.0171, v_num=ypmf]Epoch 199:  79% 214/270 [02:05<-1:55:40, -0.22it/s, loss=0.0171, v_num=ypmf]Epoch 199:  79% 214/270 [02:05<-1:55:40, -0.22it/s, loss=0.0171, v_num=ypmf]Epoch 199:  79% 214/270 [02:05<-1:55:40, -0.21it/s, loss=0.0171, v_num=ypmf]Epoch 199:  80% 215/270 [02:06<-1:55:34, -0.21it/s, loss=0.0171, v_num=ypmf]Epoch 199:  80% 215/270 [02:06<-1:55:34, -0.21it/s, loss=0.0171, v_num=ypmf]Epoch 199:  80% 215/270 [02:06<-1:55:33, -0.21it/s, loss=0.0171, v_num=ypmf]Epoch 199:  80% 216/270 [02:06<-1:55:26, -0.20it/s, loss=0.0171, v_num=ypmf]Epoch 199:  80% 216/270 [02:06<-1:55:26, -0.20it/s, loss=0.0171, v_num=ypmf]Epoch 199:  80% 216/270 [02:07<-1:55:26, -0.20it/s, loss=0.0171, v_num=ypmf]Epoch 199:  80% 217/270 [02:07<-1:55:19, -0.19it/s, loss=0.0171, v_num=ypmf]Epoch 199:  80% 217/270 [02:07<-1:55:19, -0.19it/s, loss=0.0171, v_num=ypmf]Epoch 199:  80% 217/270 [02:07<-1:55:19, -0.19it/s, loss=0.0171, v_num=ypmf]Epoch 199:  81% 218/270 [02:07<-1:55:11, -0.18it/s, loss=0.0171, v_num=ypmf]Epoch 199:  81% 218/270 [02:07<-1:55:11, -0.18it/s, loss=0.0171, v_num=ypmf]Epoch 199:  81% 218/270 [02:08<-1:55:11, -0.18it/s, loss=0.0171, v_num=ypmf]Epoch 199:  81% 219/270 [02:08<-1:55:02, -0.17it/s, loss=0.0171, v_num=ypmf]Epoch 199:  81% 219/270 [02:08<-1:55:02, -0.17it/s, loss=0.0171, v_num=ypmf]Epoch 199:  81% 219/270 [02:08<-1:55:02, -0.17it/s, loss=0.017, v_num=ypmf] Epoch 199:  81% 220/270 [02:09<-1:54:53, -0.16it/s, loss=0.017, v_num=ypmf]Epoch 199:  81% 220/270 [02:09<-1:54:53, -0.16it/s, loss=0.017, v_num=ypmf]Epoch 199:  81% 220/270 [02:09<-1:54:52, -0.16it/s, loss=0.017, v_num=ypmf]Epoch 199:  82% 221/270 [02:09<-1:54:42, -0.15it/s, loss=0.017, v_num=ypmf]Epoch 199:  82% 221/270 [02:09<-1:54:42, -0.15it/s, loss=0.017, v_num=ypmf]Epoch 199:  82% 221/270 [02:09<-1:54:42, -0.15it/s, loss=0.0169, v_num=ypmf]Epoch 199:  82% 222/270 [02:10<-1:54:31, -0.15it/s, loss=0.0169, v_num=ypmf]Epoch 199:  82% 222/270 [02:10<-1:54:31, -0.15it/s, loss=0.0169, v_num=ypmf]Epoch 199:  82% 222/270 [02:10<-1:54:31, -0.15it/s, loss=0.0171, v_num=ypmf]Epoch 199:  83% 223/270 [02:10<-1:54:19, -0.14it/s, loss=0.0171, v_num=ypmf]Epoch 199:  83% 223/270 [02:10<-1:54:19, -0.14it/s, loss=0.0171, v_num=ypmf]Epoch 199:  83% 223/270 [02:11<-1:54:18, -0.14it/s, loss=0.017, v_num=ypmf] Epoch 199:  83% 224/270 [02:11<-1:54:05, -0.13it/s, loss=0.017, v_num=ypmf]Epoch 199:  83% 224/270 [02:11<-1:54:05, -0.13it/s, loss=0.017, v_num=ypmf]Epoch 199:  83% 224/270 [02:11<-1:54:05, -0.13it/s, loss=0.0172, v_num=ypmf]Epoch 199:  83% 225/270 [02:11<-1:53:50, -0.12it/s, loss=0.0172, v_num=ypmf]Epoch 199:  83% 225/270 [02:11<-1:53:50, -0.12it/s, loss=0.0172, v_num=ypmf]Epoch 199:  83% 225/270 [02:12<-1:53:49, -0.12it/s, loss=0.0175, v_num=ypmf]Epoch 199:  84% 226/270 [02:12<-1:53:32, -0.11it/s, loss=0.0175, v_num=ypmf]Epoch 199:  84% 226/270 [02:12<-1:53:32, -0.11it/s, loss=0.0175, v_num=ypmf]Epoch 199:  84% 226/270 [02:12<-1:53:31, -0.11it/s, loss=0.0177, v_num=ypmf]Epoch 199:  84% 227/270 [02:13<-1:53:11, -0.11it/s, loss=0.0177, v_num=ypmf]Epoch 199:  84% 227/270 [02:13<-1:53:11, -0.11it/s, loss=0.0177, v_num=ypmf]Epoch 199:  84% 227/270 [02:13<-1:53:11, -0.10it/s, loss=0.0177, v_num=ypmf]Epoch 199:  84% 228/270 [02:13<-1:52:48, -0.10it/s, loss=0.0177, v_num=ypmf]Epoch 199:  84% 228/270 [02:13<-1:52:48, -0.10it/s, loss=0.0177, v_num=ypmf]Epoch 199:  84% 228/270 [02:13<-1:52:48, -0.10it/s, loss=0.0177, v_num=ypmf]Epoch 199:  85% 229/270 [02:14<-1:52:22, -0.09it/s, loss=0.0177, v_num=ypmf]Epoch 199:  85% 229/270 [02:14<-1:52:22, -0.09it/s, loss=0.0177, v_num=ypmf]Epoch 199:  85% 229/270 [02:14<-1:52:21, -0.09it/s, loss=0.0177, v_num=ypmf]Epoch 199:  85% 230/270 [02:14<-1:51:50, -0.08it/s, loss=0.0177, v_num=ypmf]Epoch 199:  85% 230/270 [02:14<-1:51:50, -0.08it/s, loss=0.0177, v_num=ypmf]Epoch 199:  85% 230/270 [02:15<-1:51:49, -0.08it/s, loss=0.0178, v_num=ypmf]Epoch 199:  86% 231/270 [02:15<-1:51:12, -0.07it/s, loss=0.0178, v_num=ypmf]Epoch 199:  86% 231/270 [02:15<-1:51:12, -0.07it/s, loss=0.0178, v_num=ypmf]Epoch 199:  86% 231/270 [02:15<-1:51:12, -0.07it/s, loss=0.0176, v_num=ypmf]Epoch 199:  86% 232/270 [02:15<-1:50:26, -0.07it/s, loss=0.0176, v_num=ypmf]Epoch 199:  86% 232/270 [02:15<-1:50:26, -0.07it/s, loss=0.0176, v_num=ypmf]Epoch 199:  86% 232/270 [02:16<-1:50:26, -0.07it/s, loss=0.0176, v_num=ypmf]Epoch 199:  86% 233/270 [02:16<-1:49:29, -0.06it/s, loss=0.0176, v_num=ypmf]Epoch 199:  86% 233/270 [02:16<-1:49:29, -0.06it/s, loss=0.0176, v_num=ypmf]Epoch 199:  86% 233/270 [02:16<-1:49:28, -0.06it/s, loss=0.0175, v_num=ypmf]Epoch 199:  87% 234/270 [02:17<-1:48:15, -0.05it/s, loss=0.0175, v_num=ypmf]Epoch 199:  87% 234/270 [02:17<-1:48:15, -0.05it/s, loss=0.0175, v_num=ypmf]Epoch 199:  87% 234/270 [02:17<-1:48:14, -0.05it/s, loss=0.0174, v_num=ypmf]Epoch 199:  87% 235/270 [02:17<-1:46:37, -0.04it/s, loss=0.0174, v_num=ypmf]Epoch 199:  87% 235/270 [02:17<-1:46:37, -0.04it/s, loss=0.0174, v_num=ypmf]Epoch 199:  87% 235/270 [02:17<-1:46:36, -0.04it/s, loss=0.0174, v_num=ypmf]Epoch 199:  87% 236/270 [02:18<-1:44:20, -0.04it/s, loss=0.0174, v_num=ypmf]Epoch 199:  87% 236/270 [02:18<-1:44:20, -0.04it/s, loss=0.0174, v_num=ypmf]Epoch 199:  87% 236/270 [02:18<-1:44:19, -0.04it/s, loss=0.0173, v_num=ypmf]Epoch 199:  88% 237/270 [02:19<-1:40:54, -0.03it/s, loss=0.0173, v_num=ypmf]Epoch 199:  88% 237/270 [02:19<-1:40:54, -0.03it/s, loss=0.0173, v_num=ypmf]Epoch 199:  88% 237/270 [02:19<-1:40:52, -0.03it/s, loss=0.0173, v_num=ypmf]Epoch 199:  88% 238/270 [02:19<-1:35:12, -0.02it/s, loss=0.0173, v_num=ypmf]Epoch 199:  88% 238/270 [02:19<-1:35:12, -0.02it/s, loss=0.0173, v_num=ypmf]Epoch 199:  88% 238/270 [02:19<-1:35:10, -0.02it/s, loss=0.0174, v_num=ypmf]Epoch 199:  89% 239/270 [02:20<-1:23:48, -0.01it/s, loss=0.0174, v_num=ypmf]Epoch 199:  89% 239/270 [02:20<-1:23:48, -0.01it/s, loss=0.0174, v_num=ypmf]Epoch 199:  89% 239/270 [02:20<-1:23:45, -0.01it/s, loss=0.0172, v_num=ypmf]Epoch 199:  89% 240/270 [02:20<-2:49:38, -0.01it/s, loss=0.0172, v_num=ypmf]Epoch 199:  89% 240/270 [02:20<-2:49:38, -0.01it/s, loss=0.0172, v_num=ypmf]Epoch 199:  89% 240/270 [02:20<-2:49:35, -0.01it/s, loss=0.0172, v_num=ypmf]Epoch 199:  89% 241/270 [02:21<?, ?it/s, loss=0.0172, v_num=ypmf]           Epoch 199:  89% 241/270 [02:21<?, ?it/s, loss=0.0172, v_num=ypmf]Epoch 199:  89% 241/270 [02:21<?, ?it/s, loss=0.0171, v_num=ypmf]Epoch 199:  90% 242/270 [02:21<1:06:11, 141.83s/it, loss=0.0171, v_num=ypmf]Epoch 199:  90% 242/270 [02:21<1:06:11, 141.83s/it, loss=0.0171, v_num=ypmf]Epoch 199:  90% 242/270 [02:22<1:06:18, 142.10s/it, loss=0.0171, v_num=ypmf]Epoch 199:  90% 243/270 [02:22<32:02, 71.21s/it, loss=0.0171, v_num=ypmf]   Epoch 199:  90% 243/270 [02:22<32:02, 71.21s/it, loss=0.0171, v_num=ypmf]Epoch 199:  90% 243/270 [02:22<32:05, 71.30s/it, loss=0.0173, v_num=ypmf]Epoch 199:  90% 244/270 [02:22<20:38, 47.65s/it, loss=0.0173, v_num=ypmf]Epoch 199:  90% 244/270 [02:22<20:38, 47.65s/it, loss=0.0173, v_num=ypmf]Epoch 199:  90% 244/270 [02:23<20:42, 47.79s/it, loss=0.0172, v_num=ypmf]Epoch 199:  91% 245/270 [02:23<14:58, 35.94s/it, loss=0.0172, v_num=ypmf]Epoch 199:  91% 245/270 [02:23<14:58, 35.94s/it, loss=0.0172, v_num=ypmf]Epoch 199:  91% 245/270 [02:23<14:59, 35.98s/it, loss=0.0169, v_num=ypmf]Epoch 199:  91% 246/270 [02:24<11:32, 28.87s/it, loss=0.0169, v_num=ypmf]Epoch 199:  91% 246/270 [02:24<11:32, 28.87s/it, loss=0.0169, v_num=ypmf]Epoch 199:  91% 246/270 [02:24<11:33, 28.91s/it, loss=0.0168, v_num=ypmf]Epoch 199:  91% 247/270 [02:24<09:15, 24.14s/it, loss=0.0168, v_num=ypmf]Epoch 199:  91% 247/270 [02:24<09:15, 24.14s/it, loss=0.0168, v_num=ypmf]Epoch 199:  91% 247/270 [02:25<09:16, 24.18s/it, loss=0.0169, v_num=ypmf]Epoch 199:  92% 248/270 [02:25<07:37, 20.78s/it, loss=0.0169, v_num=ypmf]Epoch 199:  92% 248/270 [02:25<07:37, 20.78s/it, loss=0.0169, v_num=ypmf]Epoch 199:  92% 248/270 [02:25<07:37, 20.82s/it, loss=0.0169, v_num=ypmf]Epoch 199:  92% 249/270 [02:26<06:23, 18.28s/it, loss=0.0169, v_num=ypmf]Epoch 199:  92% 249/270 [02:26<06:23, 18.28s/it, loss=0.0169, v_num=ypmf]Epoch 199:  92% 249/270 [02:26<06:24, 18.30s/it, loss=0.0168, v_num=ypmf]Epoch 199:  93% 250/270 [02:26<05:26, 16.32s/it, loss=0.0168, v_num=ypmf]Epoch 199:  93% 250/270 [02:26<05:26, 16.32s/it, loss=0.0168, v_num=ypmf]Epoch 199:  93% 250/270 [02:27<05:26, 16.33s/it, loss=0.0167, v_num=ypmf]
Validation: 0it [00:00, ?it/s]/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 246886. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 309690. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 248876. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 327843. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 325852. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 279884. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 312942. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 329855. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 327479. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 319634. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 290032. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 389299. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
[A
Validation:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.30it/s][A
Validation DataLoader 0:   5% 1/20 [00:00<00:08,  2.30it/s][AEpoch 199:  93% 251/270 [02:27<04:40, 14.76s/it, loss=0.0167, v_num=ypmf]Epoch 199:  93% 251/270 [02:27<04:40, 14.76s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  10% 2/20 [00:01<00:16,  1.12it/s][A
Validation DataLoader 0:  10% 2/20 [00:01<00:16,  1.12it/s][AEpoch 199:  93% 252/270 [02:28<04:03, 13.53s/it, loss=0.0167, v_num=ypmf]Epoch 199:  93% 252/270 [02:28<04:03, 13.53s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  15% 3/20 [00:02<00:15,  1.06it/s][A
Validation DataLoader 0:  15% 3/20 [00:02<00:15,  1.06it/s][AEpoch 199:  94% 253/270 [02:29<03:32, 12.49s/it, loss=0.0167, v_num=ypmf]Epoch 199:  94% 253/270 [02:29<03:32, 12.49s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  20% 4/20 [00:03<00:13,  1.19it/s][A
Validation DataLoader 0:  20% 4/20 [00:03<00:13,  1.19it/s][AEpoch 199:  94% 254/270 [02:30<03:05, 11.58s/it, loss=0.0167, v_num=ypmf]Epoch 199:  94% 254/270 [02:30<03:05, 11.58s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  25% 5/20 [00:04<00:11,  1.25it/s][A
Validation DataLoader 0:  25% 5/20 [00:04<00:11,  1.25it/s][AEpoch 199:  94% 255/270 [02:31<02:42, 10.80s/it, loss=0.0167, v_num=ypmf]Epoch 199:  94% 255/270 [02:31<02:42, 10.80s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  30% 6/20 [00:04<00:10,  1.32it/s][A
Validation DataLoader 0:  30% 6/20 [00:04<00:10,  1.32it/s][AEpoch 199:  95% 256/270 [02:31<02:21, 10.13s/it, loss=0.0167, v_num=ypmf]Epoch 199:  95% 256/270 [02:31<02:21, 10.13s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  35% 7/20 [00:05<00:10,  1.30it/s][A
Validation DataLoader 0:  35% 7/20 [00:05<00:10,  1.30it/s][AEpoch 199:  95% 257/270 [02:32<02:04,  9.55s/it, loss=0.0167, v_num=ypmf]Epoch 199:  95% 257/270 [02:32<02:04,  9.55s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  40% 8/20 [00:06<00:09,  1.28it/s][A
Validation DataLoader 0:  40% 8/20 [00:06<00:09,  1.28it/s][AEpoch 199:  96% 258/270 [02:33<01:48,  9.03s/it, loss=0.0167, v_num=ypmf]Epoch 199:  96% 258/270 [02:33<01:48,  9.03s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  45% 9/20 [00:07<00:08,  1.31it/s][A
Validation DataLoader 0:  45% 9/20 [00:07<00:08,  1.31it/s][AEpoch 199:  96% 259/270 [02:34<01:34,  8.57s/it, loss=0.0167, v_num=ypmf]Epoch 199:  96% 259/270 [02:34<01:34,  8.57s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  50% 10/20 [00:07<00:06,  1.43it/s][A
Validation DataLoader 0:  50% 10/20 [00:07<00:06,  1.43it/s][AEpoch 199:  96% 260/270 [02:34<01:21,  8.15s/it, loss=0.0167, v_num=ypmf]Epoch 199:  96% 260/270 [02:34<01:21,  8.15s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  55% 11/20 [00:08<00:06,  1.41it/s][A
Validation DataLoader 0:  55% 11/20 [00:08<00:06,  1.41it/s][AEpoch 199:  97% 261/270 [02:35<01:09,  7.78s/it, loss=0.0167, v_num=ypmf]Epoch 199:  97% 261/270 [02:35<01:09,  7.78s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  60% 12/20 [00:09<00:06,  1.30it/s][A
Validation DataLoader 0:  60% 12/20 [00:09<00:06,  1.30it/s][AEpoch 199:  97% 262/270 [02:36<00:59,  7.45s/it, loss=0.0167, v_num=ypmf]Epoch 199:  97% 262/270 [02:36<00:59,  7.45s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  65% 13/20 [00:10<00:05,  1.27it/s][A
Validation DataLoader 0:  65% 13/20 [00:10<00:05,  1.27it/s][AEpoch 199:  97% 263/270 [02:37<00:50,  7.15s/it, loss=0.0167, v_num=ypmf]Epoch 199:  97% 263/270 [02:37<00:50,  7.15s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  70% 14/20 [00:10<00:04,  1.27it/s][A
Validation DataLoader 0:  70% 14/20 [00:10<00:04,  1.27it/s][AEpoch 199:  98% 264/270 [02:38<00:41,  6.87s/it, loss=0.0167, v_num=ypmf]Epoch 199:  98% 264/270 [02:38<00:41,  6.87s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  75% 15/20 [00:11<00:04,  1.21it/s][A
Validation DataLoader 0:  75% 15/20 [00:11<00:04,  1.21it/s][AEpoch 199:  98% 265/270 [02:38<00:33,  6.62s/it, loss=0.0167, v_num=ypmf]Epoch 199:  98% 265/270 [02:38<00:33,  6.62s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  80% 16/20 [00:12<00:03,  1.28it/s][A
Validation DataLoader 0:  80% 16/20 [00:12<00:03,  1.28it/s][AEpoch 199:  99% 266/270 [02:39<00:25,  6.39s/it, loss=0.0167, v_num=ypmf]Epoch 199:  99% 266/270 [02:39<00:25,  6.39s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  85% 17/20 [00:13<00:02,  1.31it/s][A
Validation DataLoader 0:  85% 17/20 [00:13<00:02,  1.31it/s][AEpoch 199:  99% 267/270 [02:40<00:18,  6.17s/it, loss=0.0167, v_num=ypmf]Epoch 199:  99% 267/270 [02:40<00:18,  6.17s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  90% 18/20 [00:13<00:01,  1.34it/s][A
Validation DataLoader 0:  90% 18/20 [00:13<00:01,  1.34it/s][AEpoch 199:  99% 268/270 [02:41<00:11,  5.97s/it, loss=0.0167, v_num=ypmf]Epoch 199:  99% 268/270 [02:41<00:11,  5.97s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0:  95% 19/20 [00:14<00:00,  1.19it/s][A
Validation DataLoader 0:  95% 19/20 [00:14<00:00,  1.19it/s][AEpoch 199: 100% 269/270 [02:42<00:05,  5.79s/it, loss=0.0167, v_num=ypmf]Epoch 199: 100% 269/270 [02:42<00:05,  5.79s/it, loss=0.0167, v_num=ypmf]
Validation DataLoader 0: 100% 20/20 [00:15<00:00,  1.31it/s][A
Validation DataLoader 0: 100% 20/20 [00:15<00:00,  1.31it/s][AEpoch 199: 100% 270/270 [02:42<00:00,  5.61s/it, loss=0.0167, v_num=ypmf]Epoch 199: 100% 270/270 [02:42<00:00,  5.61s/it, loss=0.0167, v_num=ypmf]Epoch 199: 100% 270/270 [02:43<00:00,  5.63s/it, loss=0.0167, v_num=ypmf]
                                                            [AEpoch 199: 100% 270/270 [02:43<00:00,  5.63s/it, loss=0.0167, v_num=ypmf]Epoch 199: 100% 270/270 [02:43<00:00,  5.64s/it, loss=0.0167, v_num=ypmf]
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.006 MB of 0.006 MB uploaded (0.000 MB deduped)/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/global/cfs/cdirs/m3443/usr/pmtuan/conda/exatrkx_hsf/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
wandb: \ 0.006 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: | 0.006 MB of 0.554 MB uploaded (0.000 MB deduped)wandb: / 0.006 MB of 0.554 MB uploaded (0.000 MB deduped)wandb: - 0.111 MB of 0.554 MB uploaded (0.000 MB deduped)wandb: \ 0.554 MB of 0.554 MB uploaded (0.000 MB deduped)wandb: | 0.554 MB of 0.554 MB uploaded (0.000 MB deduped)wandb: / 0.554 MB of 0.554 MB uploaded (0.000 MB deduped)wandb: - 0.554 MB of 0.554 MB uploaded (0.000 MB deduped)wandb: \ 0.554 MB of 0.554 MB uploaded (0.000 MB deduped)wandb: | 0.554 MB of 0.554 MB uploaded (0.000 MB deduped)wandb: / 0.554 MB of 0.554 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          current_lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:           custom_f1 ‚ñá‚ñÇ‚ñà‚ñÜ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñà‚ñÖ
wandb:          double_auc ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñà‚ñÉ‚ñÖ‚ñÅ‚ñÇ‚ñá‚ñÖ
wandb:               epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:             sig_auc ‚ñÖ‚ñá‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñà‚ñá
wandb:             sig_eff ‚ñÖ‚ñÉ‚ñà‚ñÑ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÖ
wandb:      sig_fake_ratio ‚ñÜ‚ñÜ‚ñÅ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÇ‚ñÖ
wandb:             sig_pur ‚ñÖ‚ñà‚ñÅ‚ñà‚ñÑ‚ñá‚ñÇ‚ñÑ‚ñÅ‚ñÖ‚ñÜ‚ñÑ‚ñÖ
wandb:             tot_auc ‚ñÑ‚ñÅ‚ñà‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñÇ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÅ
wandb:             tot_eff ‚ñÑ‚ñÅ‚ñà‚ñÇ‚ñÖ‚ñÇ‚ñà‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÜ‚ñÖ
wandb:             tot_pur ‚ñÜ‚ñÖ‚ñÅ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÑ
wandb:          train_loss ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:            val_loss ‚ñÜ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñá
wandb: 
wandb: Run summary:
wandb:          current_lr 0.005
wandb:           custom_f1 0.95707
wandb:          double_auc 0.96339
wandb:               epoch 199
wandb:             sig_auc 0.97694
wandb:             sig_eff 0.93386
wandb:      sig_fake_ratio 22.50238
wandb:             sig_pur 0.41425
wandb:             tot_auc 0.98612
wandb:             tot_eff 0.73764
wandb:             tot_pur 0.98148
wandb:          train_loss 0.01694
wandb: trainer/global_step 3008
wandb:            val_loss 0.01708
wandb: 
wandb: Synced stellar-haze-19: https://wandb.ai/pmtuan/ITk_Toy_HeteroGNN/runs/soshypmf
wandb: Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /global/cfs/cdirs/m3443/data/lightning_models/lightning_checkpoints/wandb/run-20220928_194243-soshypmf/logs
