{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "# External imports\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import auc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import seaborn as sns\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "import wandb\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"../../..\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LightningModules.GNN.Models.interaction_gnn import InteractionGNN\n",
    "from LightningModules.GNN.Models.checkpoint_pyramid import CheckpointedPyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"example_gnn.yaml\") as f:\n",
    "    hparams = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CheckpointedPyramid(hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Weight Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not linear!\n",
      "Not linear!\n",
      "Linear!\n",
      "Not linear!\n",
      "Not linear!\n",
      "Linear!\n",
      "Not linear!\n",
      "Not linear!\n",
      "Linear!\n",
      "Not linear!\n",
      "Linear!\n",
      "Not linear!\n",
      "Not linear!\n",
      "Linear!\n",
      "Not linear!\n",
      "Not linear!\n",
      "Linear!\n",
      "Not linear!\n",
      "Not linear!\n",
      "Linear!\n",
      "Not linear!\n",
      "Linear!\n",
      "Not linear!\n",
      "Not linear!\n",
      "Linear!\n",
      "Not linear!\n",
      "Not linear!\n",
      "Linear!\n"
     ]
    }
   ],
   "source": [
    "for layer in model.modules():\n",
    "    if type(layer) is Linear:\n",
    "        torch.nn.init.sparse_(layer.weight, 0.1)\n",
    "        layer.bias.data.fill_(0)\n",
    "        print(\"Linear!\")\n",
    "        # print(layer.weight)\n",
    "        # print(layer.bias)\n",
    "    else:\n",
    "        print(\"Not linear!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0023, -0.0288,  0.0074,  ..., -0.0551, -0.0289,  0.0239],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weight.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2aab7cbcc810>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(layer.weight.flatten().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2aab7d84da50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(layer.bias.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyG recommendation (Xavier uniform with 0 bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2aab7d914050>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(layer.weight.flatten().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xavier normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2aab7d7b7c50>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(layer.weight.flatten().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaiming uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2aab7d8f9590>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(layer.weight.flatten().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaiming normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2aab860e7610>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFgCAYAAABqo8hyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAdbklEQVR4nO3de5ScdZ3n8fcnIZ1uIh1CupPppmECbvAssG5GWsaZ8cbiSGR3BFlXYWfkso6RBWbX4y57QOYcPc7hMBfR1VFwoyKwx+GigGYUQWAYmTlHLonDhssIBIRDpdsmIZowkkST+u4f9VR4UulLdaee+tXl8zqnTj31q6cq3/Tl00/9nt/v9ygiMDOzNOalLsDMrJs5hM3MEnIIm5kl5BA2M0vIIWxmltAhqQsoyurVq+Ouu+5KXYaZdTfNtEPHHglv3bo1dQlmZjPq2BA2M2sHDmEzs4QcwmZmCTmEzcwScgibmSXkEDYzS8ghbGaWkEPYzCwhh7CZWUIOYTOzhBzCZmYJFRbCkq6T9JKkx3Ntt0h6NLs9L+nRrH2FpJ25576ce81Jkh6TtEnSFyTNuCCGmVm7KHIVteuBLwI3Vhsi4oPVbUlXA9tz+z8bEasmeZ9rgY8ADwF3AquB7xdQr5lZ0xV2JBwRDwDbJnsuO5r9AHDTdO8haQjoj4gHo3JF0huBMxtdq3WvcrlMqVSiVCpRLpdTl2NdKNV6wm8DJiLimVzbMZL+CdgB/GlE/ANwJFDK7VPK2iYlaQ2wBuDoo49ueNHWOcrlMmNjY4yPj/OJ2zcSlLnqrFUMDQ0BMDw8zLx5PmVixUsVwuew/1HwOHB0RLws6STg25JOmO2bRsRaYC3A6OhoNKRS60hjY2NccM3d7NqxjUXLVrB31w4uvWUD/YND7Ny+la9fdBojIyOpy7Qu0PQQlnQIcBZwUrUtInYDu7PtDZKeBY4DNgP534SRrM3soPUtHtjvcW//Ug5dsixRNdatUnzeehfwk4jY180gaVDS/Gz7WGAl8FxEjAM7JL0l60c+F/hOgprNzApR5BC1m4AfAW+QVJL04eypsznwhNzbgY3ZkLVvARdGRPWk3kXAV4FNwLN4ZISZdZDCuiMi4pwp2s+fpO024LYp9l8PnNjQ4szMWoRP/5qZJdSxl7w3a5TqcDbw0DVrPIew2RRqxxIjPHTNGs4hbDaF2rHEPQt7UpdkHcghbDaN2rHE4O4JayyHsFmNKJcZHx/PHhz4fPUIGdw9YQfPIWxdofbodTq7XtnGpbdMsHfXKyxatmLSfSY7QjabC4ewdYXao9eZ9PYvZW/PgqLLMnMIW/fw0au1IoewdZWZ+nvNms0hbF2lnv5es2ZyCFvXmWt/7wFH0b7aoTWAQ9isTrVH0Z68YY3gEDabBY+asEZzCFtHy6//UNSJOM+gs4PhELaOVrv+Q5H/BngGnc2eQ9g6XjPGB3sMss2VPzeZmSXkEDYzS8ghbGaWkEPYzCwhh7CZWUIeHWEdpTpmt1wuAzAxMeGFeqylOYSto+THBc/vPcwL9VjLcwhbx6mO2Z3f2+8pxtby3CdsZpaQj4TN5shLW1ojOITN5shLW1ojOITNDoKXtrSD5T5hM7OEHMJmZgk5hM3MEnKfsHWEZlxBw6wIDmHrCM24goZZEQrrjpB0naSXJD2ea/uUpM2SHs1up+eeu1zSJklPSTot1746a9sk6bKi6rX217d4gN7+I1KXYTYrRfYJXw+snqT9cxGxKrvdCSDpeOBs4ITsNddImi9pPvAl4D3A8cA52b7W5crlMqVSiVKptG+xHrN2VFh3REQ8IGlFnbufAdwcEbuBn0raBJycPbcpIp4DkHRztu+TDS7X2kztxTXN2lWK0RGXSNqYdVcsydqOBF7M7VPK2qZqN6Nv8UBLXmDTR+k2G80O4WuB1wOrgHHg6ka+uaQ1ktZLWr9ly5ZGvrVZ3apH6RdcczdjY2Opy7EW19QQjoiJiNgbEWXgK7zW5bAZOCq360jWNlX7VO+/NiJGI2J0cHCwscWbzUKrHqVb62lqCEsayj18H1AdObEOOFvSQknHACuBh4FHgJWSjpHUQ+Xk3bpm1mxmVqTCTsxJugl4JzAgqQR8EninpFVUhtM/D3wUICKekHQrlRNue4CLI2Jv9j6XAHcD84HrIuKJomo2Oxhe2tLmosjREedM0vy1afa/ErhykvY7gTsbWJpZIby0pc2FZ8yZNZCXtrTZ8gI+ZmYJOYTNzBJyCJuZJeQ+YbOC5EdLDA8PM2+ej3nsQA5hs4JUR0ss6FnA1y86jZGRkdQlWQtyCJsVqLd/qYeq2bT8+cjMLCGHsJlZQu6OsLZ2wFRhszbjELa2VjtV2KzdOISt7XmqsLUz9wmbmSXkEDYzS8ghbGaWkEPYzCwhh7CZWUIOYTOzhBzCZmYJOYTNzBJyCJuZJeQQNjNLyCFsZpaQ144wK5gvc2TTcQibFcyXObLpOITNmsCXObKp+HORmVlCPhK2tlIulxkbG6v0sfpKGtYBHMLWVsbGxrjgmrvZtWObr6RhHcEhbG2nb/FA6hLMGsZ9wmZmCTmEzcwScgibmSXkEDYzS8ghbGaWUGEhLOk6SS9JejzX9leSfiJpo6Q7JB2eta+QtFPSo9nty7nXnCTpMUmbJH1Bkoqq2cys2Yo8Er4eWF3Tdg9wYkS8EXgauDz33LMRsSq7XZhrvxb4CLAyu9W+p5lZ2yoshCPiAWBbTdsPImJP9vBBYNqVTCQNAf0R8WBEBHAjcGYR9ZoVrbqaWqlUolwupy7HWkTKPuH/Anw/9/gYSf8k6YeS3pa1HQmUcvuUsrZJSVojab2k9Vu2bGl8xWYHobKa2gYuuOZuxsbGUpdjLSLJjDlJVwB7gG9kTePA0RHxsqSTgG9LOmG27xsRa4G1AKOjo15ZwFqOV1OzWk0PYUnnA/8BODXrYiAidgO7s+0Nkp4FjgM2s3+XxUjWZl3GC/dYp2pqCEtaDfwv4B0R8WqufRDYFhF7JR1L5QTccxGxTdIOSW8BHgLOBf66mTVba/DCPdapCgthSTcB7wQGJJWAT1IZDbEQuCcbafZgNhLi7cCnJf0aKAMXRkT1pN5FVEZa9FHpQ873I1sX8cI91okKC+GIOGeS5q9Nse9twG1TPLceOLGBpZmZtQzPmDMzS8ghbGaWkEPYzCwhh7CZWUK+vJFZk1WnL1cNDw8zb56Ph7qVQ9isySrTlyfoHxxi5/atfP2i0xgZmXYZFetgDmGzBHr7l3LokmWpy7AW4M9AZmYJOYTNzBJyd4S1nOpiPeCTVtb5/NNtLae6WI/X3bVu4CNha0lerMe6hY+EzcwS8pGwtaz8pAYv5m6dyiFsLSs/qeHnLz7txdytI7k7wlpadVJDb/8RqUsxK4RD2MwsIXdHmLUAj43uXv5Om7UAj43uXj4SNmsRHhvdnRzCZgntt7ZwAEpajiXgEDZLqDoMb++uV1i0bAU9C3tSl2RN5hA2S6y3fyl7exakLsMS8Yk5M7OEHMJmZgk5hM3MEnIIm5kl5BA2M0vIIWxmlpCHqFnLqK6f4LWDrZs4hK1lVNdP2LVjm9cOtq7hELaW4vUTrNu4T9jMLCGHsJlZQg5hM7OECg1hSddJeknS47m2IyTdI+mZ7H5J1i5JX5C0SdJGSW/Kvea8bP9nJJ1XZM1mZs1U9JHw9cDqmrbLgPsiYiVwX/YY4D3Ayuy2BrgWKqENfBL4beBk4JPV4DYza3eFhnBEPABsq2k+A7gh274BODPXfmNUPAgcLmkIOA24JyK2RcTPgXs4MNjNzNpSij7h5RGRXUqAnwHLs+0jgRdz+5WytqnaDyBpjaT1ktZv2bKlsVVbw5XLZUqlEqVSiXK5nLocsySSnpiLiKCBc6MiYm1EjEbE6ODgYKPe1grii1ua1RnCkn6vnrY6TWTdDGT3L2Xtm4GjcvuNZG1TtVsH6Fs84Aka1tXqPRL+6zrb6rEOqI5wOA/4Tq793GyUxFuA7Vm3xd3AuyUtyU7IvTtrMzNre9NOW5b0O8DvAoOSPp57qh+YP9ObS7oJeCcwIKlEZZTDnwO3Svow8ALwgWz3O4HTgU3Aq8AFABGxTdKfAY9k+306ImpP9lkbO+CKw2ZdZKa1I3qA12X7HZZr3wG8f6Y3j4hzpnjq1En2DeDiKd7nOuC6mf49a0+1Vxw26ybThnBE/BD4oaTrI+KFJtVkXchXHLZuVe8qagslrQVW5F8TEf+uiKLMzLpFvSH8TeDLwFeBvcWVY2bw2gL3AMPDw8yb52VeOlW9IbwnIq4ttBIz26c6hhrg6xedxsjISOKKrCj1hvDfSroIuAPYXW30KAWz4nj8dHeoN4Sr43ovzbUFcGxjyzEz6y51hXBEHFN0IWZm3aiuEJZ07mTtEXFjY8sxM+su9XZHvDm33UtlssWPAYewmdlBqLc74k/yjyUdDtxcSEVmZl1krpe8/yXgfmKzBjtgHQ0lLceaoN4+4b/ltaVV5gP/Gri1qKLMulXtOho9C3tSl2QFq/dI+DO57T3ACxFRKqAes67ndTS6S11zIbOFfH5CZSW1JcCviizKzKxb1HtljQ8ADwP/icr6vw9JmnEpSzMzm1693RFXAG+OiJcAJA0C9wLfKqowM7NuUO/STPOqAZx5eRavNTOzKdR7JHyXpLuBm7LHH6RyOSIzMzsIM11j7l8ByyPiUklnAW/NnvoR8I2iizPrdvlxw15XuDPNdCT8v4HLASLiduB2AEn/JnvuDwqtzqzLVccNL+hZ4HWFO9RMIbw8Ih6rbYyIxyStKKQiM9tPb/9ST9roYDN9tjl8muf6GlmImVk3mimE10v6SG2jpD8GNhRTkplZ95ipO+JjwB2S/pDXQncU6AHeV2Rh1rmqF7EcHx9/bUUSsy41bQhHxATwu5JOAU7Mmr8XEX9XeGXWsaoXsdy1YxuLlq1IXY5ZUvWuJ3w/cH/BtVgX8UUszSo86NDMLKG5LupuZk3kSRudyyFs1gY8aaNzOYTN2oQnbXQmf6YxM0vIR8LWNB4fbHYgh7A1jccHmx3IIWxN5fHBZvtrep+wpDdIejR32yHpY5I+JWlzrv303Gsul7RJ0lOSTmt2zWZmRWn6kXBEPAWsApA0H9gM3AFcAHwuIj6T31/S8cDZwAnAMHCvpOMiYm9TCzczK0Dq0RGnAs9GxAvT7HMGcHNE7I6InwKbgJObUp2ZWcFSh/DZvHbdOoBLJG2UdJ2kJVnbkcCLuX1KWZuZWdtLFsKSeoD3At/Mmq4FXk+lq2IcuHoO77lG0npJ67ds2dKwWs3MipLySPg9wI+z5TKJiImI2BsRZeArvNblsBk4Kve6kaztABGxNiJGI2J0cHCwwNLNzBojZQifQ64rQtJQ7rn3AY9n2+uAsyUtlHQMsBJ4uGlVmpkVKMk4YUmLgN8HPppr/ktJq6jMpXq++lxEPCHpVuBJYA9wsUdGmFmnSBLCEfFLYGlN24em2f9K4Mqi6zIza7bUoyPMzLqaQ9jMLCGHsJlZQg5hM7OEHMJmZgl5KUsrnBdzbxxf8LPzOIStcF7MvXF8wc/O4xC2pvBi7o3jC352FoewWRtyt0TncAibtSF3S3QOh7BZm3K3RGdwCFthPCrCbGYOYSuMR0WYzcwhbIXyqAiz6fmUqplZQg5hM7OEHMJmZgk5hM3MEnIIm5kl5BA2M0vIQ9TM2pjXkGh/DmGzNuY1JNqfQ9iszXkNifbmzy5mZgk5hM3MEnJ3hDWcV08zq59D2BrOq6eZ1c8hbA2TPwLu6/fqaWb1cAhbw/gI2Gz2HMLWUF4/2Gx2PDrCzCwhHwmbdZBqvzx4GnO7cAibdYDqGhLj4+N84vaNIDyNuU04hM06QHUNib27XmHRshWextxGHMJmHaK3fyl7exakLsNmKVmHkaTnJT0m6VFJ67O2IyTdI+mZ7H5J1i5JX5C0SdJGSW9KVbeZWSOl7rU/JSJWRcRo9vgy4L6IWAnclz0GeA+wMrutAa5teqVmZgVIHcK1zgBuyLZvAM7Mtd8YFQ8Ch0saSlGgmVkjpQzhAH4gaYOkNVnb8ogYz7Z/BizPto8EXsy9tpS17UfSGknrJa3fsmVLUXWbmTVMyhNzb42IzZKWAfdI+kn+yYgISbNagysi1gJrAUZHR71+l5m1vGRHwhGxObt/CbgDOBmYqHYzZPcvZbtvBo7KvXwkazMza2tJQljSIkmHVbeBdwOPA+uA87LdzgO+k22vA87NRkm8Bdie67YwM2tbqbojlgN3SKrW8DcRcZekR4BbJX0YeAH4QLb/ncDpwCbgVeCC5pdsZtZ4SUI4Ip4D/u0k7S8Dp07SHsDFTSjNzKypWm2ImplZV3EIm5kl5BA2M0vIC/jYnNWuXWtms+cQtjmrXlMuosxVZ62qNHqKjNmsOITtoPQtHmDn9q1cesuGfWvZmln9HMLWEF7LtrVUr7QBvsxRq3MIm3Wg6pU2Dlkwn6vOWsXQUGXRQQdy63EIm3Wo3v6l7N21g0tv2UD/4BA7t2/1dedakEPYrMP19i/l0CXLUpdhU/DnEjOzhBzCZmYJOYTNzBJyn7DNWnWm3Pj4uCdnmB0kh7DNWnWm3K4d2zw5w+wgOYRtTvoWD6QuwWbJEzhak0PYrEtUJ3As6Fng8cItxCFs1kV6+5fSs7AndRmW488jZmYJOYTNzBJyCJuZJeQQNjNLyCfmrC75Sxl5koZZ4ziErS7VCRp9iwf4+YtPe5KGWYO4O8Lq1rd4gEOXLKO3/4jUpZh1DIewmVlCDmEzs4QcwmZmCTmEzcwS8ugIsy7j1dRai0PYrMt4NbXW4hA260JeTa11OIRtWr6UkVmxHMI2rdpLGR2auiBrGPcNtwaHsM3IlzLqTO4bbg1N/9Mn6ShJ90t6UtITkv571v4pSZslPZrdTs+95nJJmyQ9Jem0ZtfcjcrlMqVSyd0QHa63f6n/yCaW4kh4D/A/IuLHkg4DNki6J3vucxHxmfzOko4HzgZOAIaBeyUdFxF7m1p1l/EVlc2ao+khHBHjwHi2/YqkfwaOnOYlZwA3R8Ru4KeSNgEnAz8qvNgu5yMks+Il7YmXtAL4LeChrOkSSRslXSdpSdZ2JPBi7mUlpghtSWskrZe0fsuWLQVVbWbWOMlCWNLrgNuAj0XEDuBa4PXAKipHylfP9j0jYm1EjEbE6ODgYEPr7RbuC+4+1VESpVKJcrmcupyuk2R0hKQFVAL4GxFxO0BETOSe/wrw3ezhZuCo3MtHsjYrgPuCu49HSaSVYnSEgK8B/xwRn821D+V2ex/weLa9Djhb0kJJxwArgYebVW836ls84IXbu4xHSaST4kj494APAY9JejRr+wRwjqRVVD4EPw98FCAinpB0K/AklZEVF3tkhJl1ihSjI/4R0CRP3TnNa64EriysKDPzDLpEPGPOAK8RYe4bTsUhbIBPyFmFV1drPoew7eMTMwbulmg2h7CZ7cfdEs3lEDazA7hbonn8OcPMLCEfCXc5j4owS8sh3OU8KsIsLYeweVSEWUIOYTOblIeqNYdDuEu5L9hm4qFqzeEQ7lLuC7Z6eKha8RzCXcx9wWbpOYS7jLshbK6qPzvgPuJGcgh3iXz4fuL2jex6xd0QNjvVLizAfcQN5BDuErV9wL2TrehsNon8KIm+/oHJVwO3OXMIdxH3AdtcVEdJ7N31CouWrfCJugZzCJvZjHr7l7K3Z0HqMjqSQ9jMZsWTOBrLIWxms+JJHI3lEO5QtcOJzBrJkzgaxyHcoaqjISLKXHXWqkqjxwWbtRyHcAfrWzzAzu1bufSWDfvObJtZa3EId5jJZsT5zLY1Q74LDHzSrl4O4Q7jhXms2WpnY/YdXvkE5pN29XEIdyBPyrBmqA5Vq50Kf+iSZalLaysOYTObk9qZdJ4KPzcOYTObM59vOHgO4TaWPxFSLpcBmJiY8FA0S86z6urnEG5j1ZNwfYsH+PmLTzO/9zAPRbOW4Fl19XMIt7m+xQMcumQZO7dvZX5vvz8aWsvo7V/KggWHMD4+vu+T2rx583xkXMMh3Eaq3Q/uerB2kT95N7/3MA5ZMJ+rzlrF8uXLAYcyOIRb2mShWx0KlO96ODRxnWbTqZ68m9/bz95dO/bN4Jzfe9i+7orh4eGuvXSSQ7iF1Bu6vcJdD9a28qFcXQSomy+d5BBOqHals/xsN4eudYPaSydFdN+oirYJYUmrgc8D84GvRsSfJy7poE220llff2W2m0PXukHthI9Kd8XEvr7joaGhjg/jtghhSfOBLwG/D5SARySti4gn01b2mukuB17bzVA1MTFBX/8AO3d4pTPrXrUTPnr7l+7rO649kVdr3rx5B/xeTbZPdU3t2jW2W6Efui1CGDgZ2BQRzwFIuhk4A2hoCJdKpTm/dnx8nI9ffz8Anz3/FIaGhg54bve//IJ5CxdR3v3LffeHDh697yQFwK4dL1ce/+rXdd+/urCn0oUxi9fM9b6Z/1an///8b81w33sYu1/5BX/ylR/s9zuTv3/dEcvYMf7TSZ+r3i9YsIDPnn8KwH6/o7WP87+ztYrso1ZE649xkvR+YHVE/HH2+EPAb0fEJTX7rQHWZA/fALwMbG1mrdMYoHVqgdaqp5Vqgdaqx7VMrZXqmaqWrRGxeroXtsuRcF0iYi2wtvpY0vqIGE1Y0j6tVAu0Vj2tVAu0Vj2uZWqtVM/B1NIuvd2bgaNyj0eyNjOzttYuIfwIsFLSMZJ6gLOBdYlrMjM7aG3RHREReyRdAtxNZYjadRHxRB0vXTvzLk3TSrVAa9XTSrVAa9XjWqbWSvXMuZa2ODFnZtap2qU7wsysIzmEzcwS6qgQlnSEpHskPZPdL5lm335JJUlfTFWLpN+U9GNJj0p6QtKFRdQyi3pWSfpRVstGSR9MVUu2312SfiHpuwXUsFrSU5I2SbpskucXSrole/4hSSsaXcMs63l79rOyJxs3n7KWj0t6MvsZuU/Sbyas5UJJj2W/Q/8o6fiiaqmnntx+/1FSSJp52FpEdMwN+Evgsmz7MuAvptn388DfAF9MVQvQAyzMtl8HPA8MJ6znOGBltj0MjAOHp/o+AacCfwB8t8H//nzgWeDY7Hvw/4Dja/a5CPhytn02cEsR35dZ1LMCeCNwI/D+xLWcAhyabf/Xor42ddbSn9t+L3BXyq9Ntt9hwAPAg8DoTO/bUUfCVKYy35Bt3wCcOdlOkk4ClgM/SFlLRPwqInZnDxdS7CeTeup5OiKeybbHgJeAwRS1ZDXcB7xSwL+/bxp8RPwKqE6Dn6rGbwGnSirqesIz1hMRz0fERmD6hRKaU8v9EfFq9vBBKuP2U9WyI/dwEcVe5qCenxuAPwP+AthVz5t2Wggvj4jxbPtnVIJ2P5LmAVcD/zN1LVk9R0naCLxI5YhwLGU9ubpOpvLX/tnUtRTgSCpf76pS1jbpPhGxB9gOLE1YT7PMtpYPA99PWYukiyU9S+UT1n8rqJa66pH0JuCoiPhevW/aFuOE8yTdC/zGJE9dkX8QESFpsr+KFwF3RkTpYA9sGlALEfEi8EZJw8C3JX0rIiZS1ZO9zxDwf4HzImJOR16NqsVal6Q/AkaBd6SsIyK+BHxJ0n8G/hQ4L0Ud2QHeZ4HzZ/O6tgvhiHjXVM9JmpA0FBHjWZC8NMluvwO8TdJFVPpheyT9S0RM2cleYC359xqT9DjwNioff2etEfVI6ge+B1wREQ/OpY5G1VKgeqbBV/cpSToEWExlQahU9TRLXbVIeheVP6jvyHWpJakl52bg2oJqqaeew4ATgb/PDvB+A1gn6b0RsX6qN+207oh1vPZX8DzgO7U7RMQfRsTREbGCSpfEjXMJ4EbUImlEUl+2vQR4K/BUAbXUW08PcAeVr8mc/hA0qpaC1TMNPl/j+4G/i+ysS6J6mmXGWiT9FvB/gPdGRJF/QOupZWXu4b8HnklVT0Rsj4iBiFiR5cuDVL5GUwZw9YUdc6PSZ3cflW/EvcARWfsolatx1O5/PsWNjpixFiqL1G+kcpZ1I7Am5dcG+CPg18CjuduqVN8n4B+ALcBOKv1vpzWwhtOBp6n0eV+RtX06+6UB6AW+CWwCHgaOLfhnd6Z63px9DX5J5Yj8iYS13AtM5H5G1iWs5fPAE1kd9wMnpPw+1ez799QxOsLTls3MEuq07ggzs7biEDYzS8ghbGaWkEPYzCwhh7CZWUIOYTOzhBzCZmYJ/X9IL8+timdD3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(layer.weight.flatten().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2aab8640cd10>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(layer.weight.flatten().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.15 s, sys: 834 ms, total: 4.98 s\n",
      "Wall time: 1.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = model.trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(cell_data=[52573, 11], edge_index=[2, 40419], event_file=\"/project/projectdirs/m3443/data/ITk-upgrade/processed/full_events_v4/event000010001\", hid=[52573], modulewise_true_edges=[2, 46739], nhits=[52573], pid=[52573], primary=[52573], pt=[52573], signal_true_edges=[2, 13312], x=[52573, 3], y=[40419], y_pid=[287180])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9715)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.y.sum() / sample.signal_true_edges.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3199)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.y.sum() / sample.edge_index.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "edges = sample.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pid = sample.pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 287180])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5314)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample.pid[edges[0]] == sample.pid[edges[1]]).sum() / sample.edge_index.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Memory Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up dataset\n",
      "Loading events\n",
      "Events loaded!\n",
      "Events processed!\n",
      "Loading events\n",
      "Events loaded!\n",
      "Events processed!\n",
      "Loading events\n",
      "Events loaded!\n",
      "Events processed!\n",
      "CPU times: user 119 ms, sys: 354 ms, total: 472 ms\n",
      "Wall time: 897 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = model.trainset[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(cell_data=[96465, 11], edge_index=[2, 261315], event_file=\"/global/cfs/cdirs/m3443/data/ITk-upgrade/processed/full_events_v4/event000010001\", hid=[96465], modulewise_true_edges=[2, 37882], nhits=[96465], pid=[96465], primary=[96465], pt=[96465], signal_true_edges=[2, 5305], x=[96465, 3], y=[261315], y_pid=[261315])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "you can only change requires_grad flags of leaf variables.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_221189/4159830440.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_peak_memory_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/exa/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/u2/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/Pipelines/Common_Tracking_Example/notebooks/ITk/../../LightningModules/GNN/Models/interaction_gnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# Encode the graph features into the hidden space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: you can only change requires_grad flags of leaf variables."
     ]
    }
   ],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "output = model(\n",
    "    torch.cat([sample.x.to(device), sample.cell_data.to(device)], dim=-1),\n",
    "    sample.edge_index.to(device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.max_memory_allocated() / 1024**3, \"Gb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_spacepoints = 10000\n",
    "included_spacepoints = torch.randperm(len(sample.x))[:num_spacepoints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.23 s, sys: 8.45 s, total: 13.7 s\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "included_edges = sample.edge_index[:, ..., None].cpu() == included_spacepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "included_edges = included_edges.any(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_edges = np.isin(sample.edge_index.cpu(), included_spacepoints).any(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "included_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5790920257568359\n",
      "1.3435134887695312\n",
      "1.9847655296325684\n",
      "2.6116480827331543\n",
      "3.185835838317871\n",
      "3.735934257507324\n",
      "4.259364604949951\n",
      "4.746316909790039\n",
      "5.193796634674072\n",
      "5.612252235412598\n",
      "5.989464282989502\n",
      "6.338123321533203\n",
      "6.654370307922363\n",
      "6.938986778259277\n",
      "7.183849811553955\n",
      "7.39341402053833\n",
      "7.569871425628662\n",
      "7.715198993682861\n",
      "7.831214427947998\n",
      "7.911214828491211\n"
     ]
    }
   ],
   "source": [
    "memory = []\n",
    "\n",
    "for i in np.arange(1000, 21000, 1000):\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    included_spacepoints = torch.randperm(len(sample.x))[:i]\n",
    "    included_edges = np.isin(sample.edge_index.cpu(), included_spacepoints).any(0)\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    output = model(sample.x, sample.edge_index[:, included_edges])\n",
    "\n",
    "    memory.append(torch.cuda.max_memory_allocated() / 1024**3)\n",
    "    print(torch.cuda.max_memory_allocated() / 1024**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2aab74fa9e90>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1000, 21000, 1000), memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_spacepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.plugins import DeepSpeedPlugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Enabling DeepSpeed FP16.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-10-01 17:58:50,044] [WARNING] [partition_parameters.py:456:__init__] zero.Init: the `config` argument is deprecated. Please use `config_dict_or_path` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have not specified an optimizer or scheduler within the DeepSpeed config.Using `configure_optimizers` to define optimizer and scheduler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ZeRO Stage 3\n",
      "Using /global/u2/d/danieltm/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "/global/u2/d/danieltm/.cache/torch_extensions/utils/utils.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-adef7bd7a973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moffload_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     ), precision=16)\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader)\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;31m# plugin will setup fitting (e.g. ddp will launch child processes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pre_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0;31m# restore optimizers, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_pre_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_hyperparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mpre_dispatch\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_move_optimizer_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_optimizers_in_pre_dispatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/deepspeed.py\u001b[0m in \u001b[0;36mpre_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_deepspeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarrier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/deepspeed.py\u001b[0m in \u001b[0;36minit_deepspeed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_deepspeed_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_deepspeed_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/deepspeed.py\u001b[0m in \u001b[0;36m_initialize_deepspeed_train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mdist_init_required\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         )\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/deepspeed/__init__.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(args, model, optimizer, model_parameters, training_data, lr_scheduler, mpu, dist_init_required, collate_fn, config, config_params)\u001b[0m\n\u001b[1;32m    139\u001b[0m                                  \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                                  \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                                  config_params=config_params)\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mmpu\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mpu must be None with pipeline parallelism\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/deepspeed/runtime/engine.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, model, optimizer, model_parameters, training_data, lr_scheduler, mpu, dist_init_required, collate_fn, config, config_params, dont_change_device)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_parameters\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_lr_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/deepspeed/runtime/engine.py\u001b[0m in \u001b[0;36m_configure_optimizer\u001b[0;34m(self, client_optimizer, model_parameters)\u001b[0m\n\u001b[1;32m    840\u001b[0m                         \u001b[0;34m\"**** You are using ZeRO with an untested optimizer, proceed with caution *****\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                     )\n\u001b[0;32m--> 842\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_zero_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot enable both amp with (legacy) fp16 mode\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/deepspeed/runtime/engine.py\u001b[0m in \u001b[0;36m_configure_zero_optimizer\u001b[0;34m(self, optimizer)\u001b[0m\n\u001b[1;32m   1106\u001b[0m                 \u001b[0mgradient_predivide_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_predivide_factor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m                 aio_config=self.aio_config())\n\u001b[0m\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/deepspeed/runtime/zero/stage3.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, module, init_optimizer, timers, static_loss_scale, dynamic_loss_scale, dynamic_loss_args, verbose, contiguous_gradients, reduce_bucket_size, prefetch_bucket_size, max_reuse_distance, max_live_parameters, param_persistence_threshold, dp_process_group, reduce_scatter, overlap_comm, offload_optimizer_config, offload_param_config, sub_group_size, mpu, clip_grad, allreduce_always_fp32, postscale_gradients, gradient_predivide_factor, gradient_accumulation_steps, elastic_checkpoint, aio_config)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;31m# Load pre-built or JIT compile (un)flatten ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mutil_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUtilsBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/deepspeed/ops/op_builder/builder.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjit_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/deepspeed/ops/op_builder/builder.py\u001b[0m in \u001b[0;36mjit_load\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mextra_cuda_cflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_empty_entries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnvcc_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mextra_ldflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_empty_entries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_ldflags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0mbuild_duration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0mis_python_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0mis_standalone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         keep_intermediates=keep_intermediates)\n\u001b[0m\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1316\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_exec_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_import_module_from_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_python_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_import_module_from_library\u001b[0;34m(module_name, path, is_python_module)\u001b[0m\n\u001b[1;32m   1699\u001b[0m         \u001b[0;31m# https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_from_file_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1701\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1702\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m         \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mmodule_from_spec\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mcreate_module\u001b[0;34m(self, spec)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /global/u2/d/danieltm/.cache/torch_extensions/utils/utils.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "logger = WandbLogger(project=\"ITk_0.5GeV_GNN\", group=\"InitialTest\")\n",
    "trainer = Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=1,\n",
    "    logger=logger,\n",
    "    plugins=DeepSpeedPlugin(\n",
    "        stage=3,\n",
    "        offload_optimizer=True,\n",
    "        offload_parameters=True,\n",
    "    ),\n",
    "    precision=16,\n",
    ")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up dataset\n",
      "Loading events\n",
      "Events loaded!\n",
      "Events processed!\n",
      "Loading events\n",
      "Events loaded!\n",
      "Events processed!\n",
      "Loading events\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events loaded!\n",
      "Events processed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmurnanedaniel\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/murnanedaniel/ITk_1GeVSignal_Barrel_GNN/runs/1r86whpb\" target=\"_blank\">cosmic-bird-956</a></strong> to <a href=\"https://wandb.ai/murnanedaniel/ITk_1GeVSignal_Barrel_GNN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type       | Params\n",
      "--------------------------------------------\n",
      "0 | node_encoder | Sequential | 137 K \n",
      "1 | edge_network | Sequential | 174 K \n",
      "2 | node_network | Sequential | 330 K \n",
      "--------------------------------------------\n",
      "642 K     Trainable params\n",
      "0         Non-trainable params\n",
      "642 K     Total params\n",
      "2.569     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  91%|█████████ | 500/550 [14:59<01:29,  1.80s/it, loss=0.557, v_num=whpb]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████▏| 502/550 [15:00<01:26,  1.79s/it, loss=0.557, v_num=whpb]\n",
      "Validating:   4%|▍         | 2/50 [00:01<00:37,  1.30it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 504/550 [15:01<01:22,  1.79s/it, loss=0.557, v_num=whpb]\n",
      "Validating:   8%|▊         | 4/50 [00:02<00:30,  1.50it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 506/550 [15:02<01:18,  1.78s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  12%|█▏        | 6/50 [00:03<00:26,  1.64it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 508/550 [15:03<01:14,  1.78s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  16%|█▌        | 8/50 [00:05<00:24,  1.72it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 510/550 [15:04<01:10,  1.77s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  20%|██        | 10/50 [00:06<00:24,  1.66it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 512/550 [15:06<01:07,  1.77s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  24%|██▍       | 12/50 [00:07<00:24,  1.57it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 514/550 [15:07<01:03,  1.77s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  28%|██▊       | 14/50 [00:08<00:22,  1.60it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 516/550 [15:08<00:59,  1.76s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  32%|███▏      | 16/50 [00:10<00:22,  1.50it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 518/550 [15:10<00:56,  1.76s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  36%|███▌      | 18/50 [00:12<00:24,  1.30it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 520/550 [15:12<00:52,  1.75s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  40%|████      | 20/50 [00:13<00:23,  1.27it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 522/550 [15:13<00:49,  1.75s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  44%|████▍     | 22/50 [00:15<00:20,  1.34it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 524/550 [15:14<00:45,  1.75s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  48%|████▊     | 24/50 [00:16<00:17,  1.47it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 526/550 [15:16<00:41,  1.74s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  52%|█████▏    | 26/50 [00:17<00:15,  1.55it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 528/550 [15:17<00:38,  1.74s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  56%|█████▌    | 28/50 [00:18<00:15,  1.42it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▋| 530/550 [15:19<00:34,  1.73s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  60%|██████    | 30/50 [00:20<00:13,  1.52it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 532/550 [15:20<00:31,  1.73s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  64%|██████▍   | 32/50 [00:21<00:11,  1.51it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 534/550 [15:21<00:27,  1.73s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  68%|██████▊   | 34/50 [00:23<00:11,  1.45it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 536/550 [15:23<00:24,  1.72s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  72%|███████▏  | 36/50 [00:24<00:08,  1.59it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 538/550 [15:24<00:20,  1.72s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  76%|███████▌  | 38/50 [00:25<00:07,  1.53it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 540/550 [15:25<00:17,  1.71s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  80%|████████  | 40/50 [00:27<00:06,  1.43it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▊| 542/550 [15:26<00:13,  1.71s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  84%|████████▍ | 42/50 [00:28<00:05,  1.42it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 544/550 [15:28<00:10,  1.71s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  88%|████████▊ | 44/50 [00:29<00:03,  1.51it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 546/550 [15:29<00:06,  1.70s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  92%|█████████▏| 46/50 [00:30<00:02,  1.62it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 548/550 [15:30<00:03,  1.70s/it, loss=0.557, v_num=whpb]\n",
      "Validating:  96%|█████████▌| 48/50 [00:32<00:01,  1.70it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 550/550 [15:31<00:00,  1.69s/it, loss=0.557, v_num=whpb]\n",
      "Epoch 0: 100%|██████████| 550/550 [15:32<00:00,  1.70s/it, loss=0.557, v_num=whpb]\n",
      "Epoch 1:  84%|████████▍ | 464/550 [13:53<02:34,  1.80s/it, loss=0.368, v_num=whpb]"
     ]
    }
   ],
   "source": [
    "logger = WandbLogger(\n",
    "    project=hparams[\"project\"], group=\"InitialTest\", save_dir=hparams[\"artifacts\"]\n",
    ")\n",
    "trainer = Trainer(\n",
    "    gpus=1, max_epochs=hparams[\"max_epochs\"], logger=logger\n",
    ")  # , precision=16)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Classified Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/global/cfs/cdirs/m3443/data/lightning_models/lightning_checkpoints/ITk_0.5GeV_Barrel_GNN/jrqroc1z/checkpoints/epoch=71-step=27808.ckpt\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "model = CheckpointedPyramid.load_from_checkpoint(checkpoint_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up dataset\n",
      "Loading events\n",
      "Events loaded!\n",
      "Events processed!\n",
      "Loading events\n",
      "Events loaded!\n",
      "Events processed!\n",
      "Loading events\n",
      "Events loaded!\n",
      "Events processed!\n"
     ]
    }
   ],
   "source": [
    "model.hparams[\"datatype_split\"] = [200, 1, 10]\n",
    "model.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/project/projectdirs/m3443/data/ITk-upgrade/processed/gnn_processed/0.5GeV_barrel_y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[21428], cell_data=[21428, 11], edge_index=[2, 182327], event_file=[1], hid=[21428], modulewise_true_edges=[2, 17889], nhits=[21428], pid=[21428], primary=[21428], pt=[21428], ptr=[2], signal_true_edges=[2, 14822], x=[21428, 3], y=[182327], y_pid=[182327])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0277, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([5.8932e-02, 1.9480e-04, 2.3910e-04,  ..., 1.0017e-04, 2.6190e-05,\n",
      "        4.1214e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010001\n",
      "Batch(batch=[20316], cell_data=[20316, 11], edge_index=[2, 160427], event_file=[1], hid=[20316], modulewise_true_edges=[2, 16859], nhits=[20316], pid=[20316], primary=[20316], pt=[20316], ptr=[2], signal_true_edges=[2, 13654], x=[20316, 3], y=[160427], y_pid=[160427])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0301, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([6.6138e-03, 4.3948e-05, 1.0922e-04,  ..., 2.7575e-04, 2.6210e-04,\n",
      "        2.8092e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010002\n",
      "Batch(batch=[26360], cell_data=[26360, 11], edge_index=[2, 263389], event_file=[1], hid=[26360], modulewise_true_edges=[2, 21995], nhits=[26360], pid=[26360], primary=[26360], pt=[26360], ptr=[2], signal_true_edges=[2, 18093], x=[26360, 3], y=[263389], y_pid=[263389])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0263, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.8291e-03, 3.0076e-03, 3.2153e-04,  ..., 1.0838e-04, 3.1777e-05,\n",
      "        4.8927e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010003\n",
      "Batch(batch=[18174], cell_data=[18174, 11], edge_index=[2, 129874], event_file=[1], hid=[18174], modulewise_true_edges=[2, 15083], nhits=[18174], pid=[18174], primary=[18174], pt=[18174], ptr=[2], signal_true_edges=[2, 12223], x=[18174, 3], y=[129874], y_pid=[129874])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0307, device='cuda:0'), 'preds': tensor([False,  True, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([5.5092e-06, 8.9512e-01, 1.9343e-01,  ..., 6.6806e-01, 5.4391e-04,\n",
      "        1.5399e-03], device='cuda:0'), 'truth': tensor([False,  True, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010004\n",
      "Batch(batch=[24514], cell_data=[24514, 11], edge_index=[2, 229935], event_file=[1], hid=[24514], modulewise_true_edges=[2, 20441], nhits=[24514], pid=[24514], primary=[24514], pt=[24514], ptr=[2], signal_true_edges=[2, 16733], x=[24514, 3], y=[229935], y_pid=[229935])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0265, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.7308e-05, 2.0252e-03, 1.1878e-05,  ..., 2.1065e-05, 3.6906e-05,\n",
      "        1.4867e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010005\n",
      "Batch(batch=[23987], cell_data=[23987, 11], edge_index=[2, 219135], event_file=[1], hid=[23987], modulewise_true_edges=[2, 19975], nhits=[23987], pid=[23987], primary=[23987], pt=[23987], ptr=[2], signal_true_edges=[2, 16222], x=[23987, 3], y=[219135], y_pid=[219135])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0284, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.8506e-04, 8.0432e-05, 6.9039e-02,  ..., 4.1239e-04, 3.3575e-05,\n",
      "        1.8252e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010006\n",
      "Batch(batch=[26395], cell_data=[26395, 11], edge_index=[2, 265622], event_file=[1], hid=[26395], modulewise_true_edges=[2, 21990], nhits=[26395], pid=[26395], primary=[26395], pt=[26395], ptr=[2], signal_true_edges=[2, 18135], x=[26395, 3], y=[265622], y_pid=[265622])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0268, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.9568e-03, 2.2322e-03, 1.2444e-04,  ..., 3.8781e-05, 5.6611e-05,\n",
      "        2.4844e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010007\n",
      "Batch(batch=[23642], cell_data=[23642, 11], edge_index=[2, 210727], event_file=[1], hid=[23642], modulewise_true_edges=[2, 19656], nhits=[23642], pid=[23642], primary=[23642], pt=[23642], ptr=[2], signal_true_edges=[2, 15961], x=[23642, 3], y=[210727], y_pid=[210727])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0271, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([1.1837e-03, 4.6246e-02, 1.4159e-04,  ..., 9.8720e-01, 4.9774e-05,\n",
      "        5.9327e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ...,  True, False, False], device='cuda:0')}\n",
      "event000010008\n",
      "Batch(batch=[21644], cell_data=[21644, 11], edge_index=[2, 179556], event_file=[1], hid=[21644], modulewise_true_edges=[2, 18054], nhits=[21644], pid=[21644], primary=[21644], pt=[21644], ptr=[2], signal_true_edges=[2, 14731], x=[21644, 3], y=[179556], y_pid=[179556])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0282, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([5.8943e-05, 9.3955e-05, 2.6439e-05,  ..., 9.2367e-05, 5.7389e-03,\n",
      "        1.1963e-03], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010009\n",
      "Batch(batch=[18579], cell_data=[18579, 11], edge_index=[2, 139011], event_file=[1], hid=[18579], modulewise_true_edges=[2, 15524], nhits=[18579], pid=[18579], primary=[18579], pt=[18579], ptr=[2], signal_true_edges=[2, 12736], x=[18579, 3], y=[139011], y_pid=[139011])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0293, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.1584e-05, 1.9329e-03, 7.6443e-04,  ..., 3.9833e-05, 6.0347e-03,\n",
      "        1.9427e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000010\n",
      "Batch(batch=[23755], cell_data=[23755, 11], edge_index=[2, 215329], event_file=[1], hid=[23755], modulewise_true_edges=[2, 19805], nhits=[23755], pid=[23755], primary=[23755], pt=[23755], ptr=[2], signal_true_edges=[2, 16093], x=[23755, 3], y=[215329], y_pid=[215329])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0279, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([7.2475e-05, 2.1563e-04, 6.6669e-03,  ..., 6.9244e-05, 2.1823e-05,\n",
      "        4.2965e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010011\n",
      "Batch(batch=[24486], cell_data=[24486, 11], edge_index=[2, 230724], event_file=[1], hid=[24486], modulewise_true_edges=[2, 20471], nhits=[24486], pid=[24486], primary=[24486], pt=[24486], ptr=[2], signal_true_edges=[2, 16737], x=[24486, 3], y=[230724], y_pid=[230724])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0274, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.8733e-05, 5.9391e-05, 1.1947e-03,  ..., 2.1761e-05, 8.3078e-05,\n",
      "        1.0664e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010012\n",
      "Batch(batch=[27800], cell_data=[27800, 11], edge_index=[2, 290018], event_file=[1], hid=[27800], modulewise_true_edges=[2, 23195], nhits=[27800], pid=[27800], primary=[27800], pt=[27800], ptr=[2], signal_true_edges=[2, 19120], x=[27800, 3], y=[290018], y_pid=[290018])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0257, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([5.2905e-05, 2.1112e-05, 3.5255e-05,  ..., 3.2448e-05, 3.7968e-05,\n",
      "        2.2730e-02], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000013\n",
      "Batch(batch=[22254], cell_data=[22254, 11], edge_index=[2, 188603], event_file=[1], hid=[22254], modulewise_true_edges=[2, 18592], nhits=[22254], pid=[22254], primary=[22254], pt=[22254], ptr=[2], signal_true_edges=[2, 14831], x=[22254, 3], y=[188603], y_pid=[188603])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0312, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.1150e-01, 3.1438e-03, 4.6768e-02,  ..., 2.1072e-04, 8.9660e-05,\n",
      "        1.5756e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000014\n",
      "Batch(batch=[26079], cell_data=[26079, 11], edge_index=[2, 255023], event_file=[1], hid=[26079], modulewise_true_edges=[2, 21710], nhits=[26079], pid=[26079], primary=[26079], pt=[26079], ptr=[2], signal_true_edges=[2, 17521], x=[26079, 3], y=[255023], y_pid=[255023])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0260, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([6.0003e-05, 3.0932e-05, 5.0317e-04,  ..., 3.3822e-05, 4.3899e-04,\n",
      "        1.6267e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010015\n",
      "Batch(batch=[28271], cell_data=[28271, 11], edge_index=[2, 294995], event_file=[1], hid=[28271], modulewise_true_edges=[2, 23563], nhits=[28271], pid=[28271], primary=[28271], pt=[28271], ptr=[2], signal_true_edges=[2, 19285], x=[28271, 3], y=[294995], y_pid=[294995])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0253, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.1327e-04, 9.9773e-05, 1.1746e-02,  ..., 1.0135e-04, 1.3799e-03,\n",
      "        1.7338e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000016\n",
      "Batch(batch=[20984], cell_data=[20984, 11], edge_index=[2, 178083], event_file=[1], hid=[20984], modulewise_true_edges=[2, 17572], nhits=[20984], pid=[20984], primary=[20984], pt=[20984], ptr=[2], signal_true_edges=[2, 14676], x=[20984, 3], y=[178083], y_pid=[178083])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0283, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.9859e-05, 8.7187e-04, 3.1649e-04,  ..., 3.1234e-05, 2.5594e-05,\n",
      "        4.3685e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010017\n",
      "Batch(batch=[21778], cell_data=[21778, 11], edge_index=[2, 183149], event_file=[1], hid=[21778], modulewise_true_edges=[2, 18105], nhits=[21778], pid=[21778], primary=[21778], pt=[21778], ptr=[2], signal_true_edges=[2, 14739], x=[21778, 3], y=[183149], y_pid=[183149])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0275, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False,  True, False], device='cuda:0'), 'score': tensor([3.9194e-05, 1.8531e-05, 3.3895e-04,  ..., 8.6424e-02, 9.2667e-01,\n",
      "        7.2236e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False,  True, False], device='cuda:0')}\n",
      "event000010018\n",
      "Batch(batch=[22293], cell_data=[22293, 11], edge_index=[2, 192130], event_file=[1], hid=[22293], modulewise_true_edges=[2, 18618], nhits=[22293], pid=[22293], primary=[22293], pt=[22293], ptr=[2], signal_true_edges=[2, 15249], x=[22293, 3], y=[192130], y_pid=[192130])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0286, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.9632e-03, 6.7009e-04, 3.3854e-04,  ..., 3.8907e-05, 3.1622e-05,\n",
      "        4.6801e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010019\n",
      "Batch(batch=[20172], cell_data=[20172, 11], edge_index=[2, 160441], event_file=[1], hid=[20172], modulewise_true_edges=[2, 16722], nhits=[20172], pid=[20172], primary=[20172], pt=[20172], ptr=[2], signal_true_edges=[2, 13308], x=[20172, 3], y=[160441], y_pid=[160441])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0298, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True,  True, False], device='cuda:0'), 'score': tensor([4.2272e-05, 4.3531e-04, 4.1149e-05,  ..., 9.5398e-01, 9.6773e-01,\n",
      "        4.3507e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')}\n",
      "event000010020\n",
      "Batch(batch=[24021], cell_data=[24021, 11], edge_index=[2, 219822], event_file=[1], hid=[24021], modulewise_true_edges=[2, 20020], nhits=[24021], pid=[24021], primary=[24021], pt=[24021], ptr=[2], signal_true_edges=[2, 16230], x=[24021, 3], y=[219822], y_pid=[219822])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0274, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([6.7873e-04, 4.3362e-04, 3.8116e-02,  ..., 3.4574e-05, 5.2713e-05,\n",
      "        3.6613e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010021\n",
      "Batch(batch=[23001], cell_data=[23001, 11], edge_index=[2, 207274], event_file=[1], hid=[23001], modulewise_true_edges=[2, 19226], nhits=[23001], pid=[23001], primary=[23001], pt=[23001], ptr=[2], signal_true_edges=[2, 15492], x=[23001, 3], y=[207274], y_pid=[207274])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0281, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.9382e-04, 2.1594e-05, 2.9297e-03,  ..., 6.4310e-05, 2.7842e-05,\n",
      "        2.2965e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010022\n",
      "Batch(batch=[25299], cell_data=[25299, 11], edge_index=[2, 241603], event_file=[1], hid=[25299], modulewise_true_edges=[2, 21043], nhits=[25299], pid=[25299], primary=[25299], pt=[25299], ptr=[2], signal_true_edges=[2, 16918], x=[25299, 3], y=[241603], y_pid=[241603])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0268, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([5.9455e-05, 4.9416e-05, 7.0470e-04,  ..., 5.7158e-05, 1.8878e-03,\n",
      "        1.0594e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010023\n",
      "Batch(batch=[20795], cell_data=[20795, 11], edge_index=[2, 169503], event_file=[1], hid=[20795], modulewise_true_edges=[2, 17321], nhits=[20795], pid=[20795], primary=[20795], pt=[20795], ptr=[2], signal_true_edges=[2, 13960], x=[20795, 3], y=[169503], y_pid=[169503])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0283, device='cuda:0'), 'preds': tensor([ True, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([6.2110e-01, 2.3546e-05, 2.5641e-05,  ..., 2.1161e-05, 5.0279e-05,\n",
      "        4.2146e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010024\n",
      "Batch(batch=[24192], cell_data=[24192, 11], edge_index=[2, 224066], event_file=[1], hid=[24192], modulewise_true_edges=[2, 20247], nhits=[24192], pid=[24192], primary=[24192], pt=[24192], ptr=[2], signal_true_edges=[2, 16865], x=[24192, 3], y=[224066], y_pid=[224066])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0249, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.6826e-03, 4.4730e-02, 4.5096e-02,  ..., 2.3395e-04, 2.1430e-05,\n",
      "        1.9421e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010025\n",
      "Batch(batch=[21489], cell_data=[21489, 11], edge_index=[2, 178211], event_file=[1], hid=[21489], modulewise_true_edges=[2, 17876], nhits=[21489], pid=[21489], primary=[21489], pt=[21489], ptr=[2], signal_true_edges=[2, 14460], x=[21489, 3], y=[178211], y_pid=[178211])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0274, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.4567e-04, 3.5458e-03, 1.7688e-02,  ..., 1.2180e-04, 1.3061e-02,\n",
      "        4.0153e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010026\n",
      "Batch(batch=[26647], cell_data=[26647, 11], edge_index=[2, 268852], event_file=[1], hid=[26647], modulewise_true_edges=[2, 22304], nhits=[26647], pid=[26647], primary=[26647], pt=[26647], ptr=[2], signal_true_edges=[2, 18506], x=[26647, 3], y=[268852], y_pid=[268852])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0243, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.1196e-01, 8.7825e-02, 1.2804e-01,  ..., 2.9982e-05, 1.1824e-04,\n",
      "        1.9726e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010027\n",
      "Batch(batch=[20685], cell_data=[20685, 11], edge_index=[2, 169376], event_file=[1], hid=[20685], modulewise_true_edges=[2, 17289], nhits=[20685], pid=[20685], primary=[20685], pt=[20685], ptr=[2], signal_true_edges=[2, 14076], x=[20685, 3], y=[169376], y_pid=[169376])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0300, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.3465e-04, 5.4805e-03, 9.9128e-04,  ..., 4.9970e-04, 6.1716e-05,\n",
      "        6.0986e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010028\n",
      "Batch(batch=[21497], cell_data=[21497, 11], edge_index=[2, 179285], event_file=[1], hid=[21497], modulewise_true_edges=[2, 17902], nhits=[21497], pid=[21497], primary=[21497], pt=[21497], ptr=[2], signal_true_edges=[2, 14792], x=[21497, 3], y=[179285], y_pid=[179285])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0274, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.0511e-04, 4.2780e-05, 1.6422e-03,  ..., 1.2313e-04, 2.6159e-05,\n",
      "        3.8844e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010029\n",
      "Batch(batch=[25457], cell_data=[25457, 11], edge_index=[2, 242508], event_file=[1], hid=[25457], modulewise_true_edges=[2, 21173], nhits=[25457], pid=[25457], primary=[25457], pt=[25457], ptr=[2], signal_true_edges=[2, 17002], x=[25457, 3], y=[242508], y_pid=[242508])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0268, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([6.5089e-05, 4.5615e-05, 5.3410e-04,  ..., 1.3931e-04, 3.0329e-05,\n",
      "        8.0128e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010030\n",
      "Batch(batch=[22202], cell_data=[22202, 11], edge_index=[2, 194020], event_file=[1], hid=[22202], modulewise_true_edges=[2, 18520], nhits=[22202], pid=[22202], primary=[22202], pt=[22202], ptr=[2], signal_true_edges=[2, 15130], x=[22202, 3], y=[194020], y_pid=[194020])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0286, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.9504e-05, 6.4425e-05, 1.2948e-05,  ..., 4.8013e-01, 6.0664e-03,\n",
      "        6.8516e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010031\n",
      "Batch(batch=[23902], cell_data=[23902, 11], edge_index=[2, 217622], event_file=[1], hid=[23902], modulewise_true_edges=[2, 19955], nhits=[23902], pid=[23902], primary=[23902], pt=[23902], ptr=[2], signal_true_edges=[2, 16431], x=[23902, 3], y=[217622], y_pid=[217622])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0257, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.9839e-03, 3.9295e-02, 2.5791e-04,  ..., 4.6477e-05, 5.8254e-05,\n",
      "        2.5316e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010032\n",
      "Batch(batch=[19957], cell_data=[19957, 11], edge_index=[2, 157040], event_file=[1], hid=[19957], modulewise_true_edges=[2, 16641], nhits=[19957], pid=[19957], primary=[19957], pt=[19957], ptr=[2], signal_true_edges=[2, 13524], x=[19957, 3], y=[157040], y_pid=[157040])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0282, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.9326e-03, 1.2078e-03, 5.1929e-04,  ..., 1.0380e-02, 1.0188e-04,\n",
      "        4.0395e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010033\n",
      "Batch(batch=[24890], cell_data=[24890, 11], edge_index=[2, 234865], event_file=[1], hid=[24890], modulewise_true_edges=[2, 20812], nhits=[24890], pid=[24890], primary=[24890], pt=[24890], ptr=[2], signal_true_edges=[2, 16805], x=[24890, 3], y=[234865], y_pid=[234865])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0281, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.1425e-01, 5.4731e-02, 6.2647e-03,  ..., 3.3508e-05, 4.4361e-05,\n",
      "        3.9584e-01], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010034\n",
      "Batch(batch=[24625], cell_data=[24625, 11], edge_index=[2, 230806], event_file=[1], hid=[24625], modulewise_true_edges=[2, 20500], nhits=[24625], pid=[24625], primary=[24625], pt=[24625], ptr=[2], signal_true_edges=[2, 16572], x=[24625, 3], y=[230806], y_pid=[230806])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0267, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.6939e-01, 1.0924e-04, 1.2319e-01,  ..., 2.8514e-04, 3.4112e-03,\n",
      "        1.4595e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010035\n",
      "Batch(batch=[24600], cell_data=[24600, 11], edge_index=[2, 229699], event_file=[1], hid=[24600], modulewise_true_edges=[2, 20461], nhits=[24600], pid=[24600], primary=[24600], pt=[24600], ptr=[2], signal_true_edges=[2, 16746], x=[24600, 3], y=[229699], y_pid=[229699])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0268, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.0932e-05, 2.8524e-05, 3.4837e-02,  ..., 3.4418e-04, 4.4836e-04,\n",
      "        1.2705e-03], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010036\n",
      "Batch(batch=[23051], cell_data=[23051, 11], edge_index=[2, 207323], event_file=[1], hid=[23051], modulewise_true_edges=[2, 19185], nhits=[23051], pid=[23051], primary=[23051], pt=[23051], ptr=[2], signal_true_edges=[2, 15557], x=[23051, 3], y=[207323], y_pid=[207323])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0271, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.1492e-02, 4.0461e-05, 1.6262e-02,  ..., 4.1892e-05, 7.4595e-05,\n",
      "        4.2001e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010037\n",
      "Batch(batch=[20044], cell_data=[20044, 11], edge_index=[2, 157374], event_file=[1], hid=[20044], modulewise_true_edges=[2, 16641], nhits=[20044], pid=[20044], primary=[20044], pt=[20044], ptr=[2], signal_true_edges=[2, 13317], x=[20044, 3], y=[157374], y_pid=[157374])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0288, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.0449e-05, 5.1597e-05, 4.2985e-05,  ..., 1.9912e-04, 4.5393e-05,\n",
      "        9.1812e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010038\n",
      "Batch(batch=[16236], cell_data=[16236, 11], edge_index=[2, 108658], event_file=[1], hid=[16236], modulewise_true_edges=[2, 13530], nhits=[16236], pid=[16236], primary=[16236], pt=[16236], ptr=[2], signal_true_edges=[2, 10902], x=[16236, 3], y=[108658], y_pid=[108658])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0303, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([3.4304e-05, 2.6879e-05, 3.0470e-05,  ..., 9.7690e-01, 3.3015e-01,\n",
      "        2.9856e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ...,  True,  True, False], device='cuda:0')}\n",
      "event000010039\n",
      "Batch(batch=[23266], cell_data=[23266, 11], edge_index=[2, 211215], event_file=[1], hid=[23266], modulewise_true_edges=[2, 19459], nhits=[23266], pid=[23266], primary=[23266], pt=[23266], ptr=[2], signal_true_edges=[2, 15737], x=[23266, 3], y=[211215], y_pid=[211215])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0284, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.4802e-05, 2.7216e-04, 2.2414e-05,  ..., 4.5717e-05, 4.1340e-05,\n",
      "        2.8424e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010040\n",
      "Batch(batch=[23492], cell_data=[23492, 11], edge_index=[2, 210730], event_file=[1], hid=[23492], modulewise_true_edges=[2, 19582], nhits=[23492], pid=[23492], primary=[23492], pt=[23492], ptr=[2], signal_true_edges=[2, 15956], x=[23492, 3], y=[210730], y_pid=[210730])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0279, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([8.9607e-05, 4.8034e-05, 3.5344e-02,  ..., 4.9563e-05, 2.6898e-05,\n",
      "        7.6867e-03], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010041\n",
      "Batch(batch=[18930], cell_data=[18930, 11], edge_index=[2, 145588], event_file=[1], hid=[18930], modulewise_true_edges=[2, 15824], nhits=[18930], pid=[18930], primary=[18930], pt=[18930], ptr=[2], signal_true_edges=[2, 12945], x=[18930, 3], y=[145588], y_pid=[145588])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0305, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([8.6867e-04, 6.0473e-03, 4.3042e-03,  ..., 4.6396e-04, 9.5223e-05,\n",
      "        6.4586e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010042\n",
      "Batch(batch=[21069], cell_data=[21069, 11], edge_index=[2, 174786], event_file=[1], hid=[21069], modulewise_true_edges=[2, 17609], nhits=[21069], pid=[21069], primary=[21069], pt=[21069], ptr=[2], signal_true_edges=[2, 14519], x=[21069, 3], y=[174786], y_pid=[174786])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0272, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.0597e-05, 1.6860e-04, 2.2042e-04,  ..., 2.7521e-04, 1.2860e-04,\n",
      "        1.5116e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010043\n",
      "Batch(batch=[21988], cell_data=[21988, 11], edge_index=[2, 194110], event_file=[1], hid=[21988], modulewise_true_edges=[2, 18436], nhits=[21988], pid=[21988], primary=[21988], pt=[21988], ptr=[2], signal_true_edges=[2, 15034], x=[21988, 3], y=[194110], y_pid=[194110])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0278, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.6646e-05, 3.3266e-05, 2.3045e-04,  ..., 7.7550e-05, 6.9692e-05,\n",
      "        4.7959e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010044\n",
      "Batch(batch=[22205], cell_data=[22205, 11], edge_index=[2, 190772], event_file=[1], hid=[22205], modulewise_true_edges=[2, 18585], nhits=[22205], pid=[22205], primary=[22205], pt=[22205], ptr=[2], signal_true_edges=[2, 15176], x=[22205, 3], y=[190772], y_pid=[190772])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0290, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([9.4069e-05, 1.2017e-05, 1.4129e-05,  ..., 7.2563e-05, 7.4854e-05,\n",
      "        2.3651e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010045\n",
      "Batch(batch=[23591], cell_data=[23591, 11], edge_index=[2, 213906], event_file=[1], hid=[23591], modulewise_true_edges=[2, 19684], nhits=[23591], pid=[23591], primary=[23591], pt=[23591], ptr=[2], signal_true_edges=[2, 15987], x=[23591, 3], y=[213906], y_pid=[213906])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0269, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.0669e-04, 8.8372e-03, 6.6349e-05,  ..., 1.1393e-04, 3.2810e-05,\n",
      "        2.4101e-03], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010046\n",
      "Batch(batch=[23463], cell_data=[23463, 11], edge_index=[2, 210497], event_file=[1], hid=[23463], modulewise_true_edges=[2, 19543], nhits=[23463], pid=[23463], primary=[23463], pt=[23463], ptr=[2], signal_true_edges=[2, 15786], x=[23463, 3], y=[210497], y_pid=[210497])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0266, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.1381e-05, 2.9439e-03, 2.6106e-03,  ..., 5.5127e-05, 2.0711e-05,\n",
      "        2.9192e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010047\n",
      "Batch(batch=[22469], cell_data=[22469, 11], edge_index=[2, 194132], event_file=[1], hid=[22469], modulewise_true_edges=[2, 18730], nhits=[22469], pid=[22469], primary=[22469], pt=[22469], ptr=[2], signal_true_edges=[2, 15402], x=[22469, 3], y=[194132], y_pid=[194132])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0266, device='cuda:0'), 'preds': tensor([False,  True, False,  ..., False, False,  True], device='cuda:0'), 'score': tensor([2.0763e-04, 9.8187e-01, 2.8576e-05,  ..., 2.0120e-03, 1.0082e-04,\n",
      "        9.6499e-01], device='cuda:0'), 'truth': tensor([False,  True, False,  ..., False, False,  True], device='cuda:0')}\n",
      "event000010048\n",
      "Batch(batch=[20244], cell_data=[20244, 11], edge_index=[2, 158426], event_file=[1], hid=[20244], modulewise_true_edges=[2, 16864], nhits=[20244], pid=[20244], primary=[20244], pt=[20244], ptr=[2], signal_true_edges=[2, 13791], x=[20244, 3], y=[158426], y_pid=[158426])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0285, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([7.4808e-03, 2.0705e-03, 4.9004e-03,  ..., 2.3101e-05, 7.6211e-05,\n",
      "        3.8028e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010049\n",
      "Batch(batch=[25372], cell_data=[25372, 11], edge_index=[2, 247320], event_file=[1], hid=[25372], modulewise_true_edges=[2, 21201], nhits=[25372], pid=[25372], primary=[25372], pt=[25372], ptr=[2], signal_true_edges=[2, 17044], x=[25372, 3], y=[247320], y_pid=[247320])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0273, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.5404e-05, 2.5837e-03, 2.0746e-05,  ..., 1.5476e-04, 3.1724e-04,\n",
      "        2.4563e-03], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010050\n",
      "Batch(batch=[24311], cell_data=[24311, 11], edge_index=[2, 226932], event_file=[1], hid=[24311], modulewise_true_edges=[2, 20265], nhits=[24311], pid=[24311], primary=[24311], pt=[24311], ptr=[2], signal_true_edges=[2, 16244], x=[24311, 3], y=[226932], y_pid=[226932])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0277, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.6810e-04, 8.9705e-03, 1.5722e-04,  ..., 1.7312e-02, 3.3755e-05,\n",
      "        3.5054e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010051\n",
      "Batch(batch=[20326], cell_data=[20326, 11], edge_index=[2, 164099], event_file=[1], hid=[20326], modulewise_true_edges=[2, 16999], nhits=[20326], pid=[20326], primary=[20326], pt=[20326], ptr=[2], signal_true_edges=[2, 13736], x=[20326, 3], y=[164099], y_pid=[164099])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0306, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.0633e-05, 2.9040e-04, 4.0100e-03,  ..., 5.2398e-05, 8.8384e-05,\n",
      "        1.7701e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010052\n",
      "Batch(batch=[21261], cell_data=[21261, 11], edge_index=[2, 181810], event_file=[1], hid=[21261], modulewise_true_edges=[2, 17768], nhits=[21261], pid=[21261], primary=[21261], pt=[21261], ptr=[2], signal_true_edges=[2, 14261], x=[21261, 3], y=[181810], y_pid=[181810])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0288, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([5.0690e-03, 2.9500e-02, 9.0885e-02,  ..., 1.7456e-05, 6.5850e-05,\n",
      "        4.4361e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010053\n",
      "Batch(batch=[20059], cell_data=[20059, 11], edge_index=[2, 158190], event_file=[1], hid=[20059], modulewise_true_edges=[2, 16691], nhits=[20059], pid=[20059], primary=[20059], pt=[20059], ptr=[2], signal_true_edges=[2, 13471], x=[20059, 3], y=[158190], y_pid=[158190])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0287, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.1929e-05, 6.7708e-05, 8.8166e-04,  ..., 1.3474e-04, 8.1406e-05,\n",
      "        4.9389e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010054\n",
      "Batch(batch=[21406], cell_data=[21406, 11], edge_index=[2, 177296], event_file=[1], hid=[21406], modulewise_true_edges=[2, 17713], nhits=[21406], pid=[21406], primary=[21406], pt=[21406], ptr=[2], signal_true_edges=[2, 14057], x=[21406, 3], y=[177296], y_pid=[177296])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0300, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False,  True, False], device='cuda:0'), 'score': tensor([3.3905e-05, 2.8739e-04, 4.2974e-04,  ..., 2.2483e-05, 9.7090e-01,\n",
      "        6.9734e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False,  True, False], device='cuda:0')}\n",
      "event000010055\n",
      "Batch(batch=[19897], cell_data=[19897, 11], edge_index=[2, 154553], event_file=[1], hid=[19897], modulewise_true_edges=[2, 16557], nhits=[19897], pid=[19897], primary=[19897], pt=[19897], ptr=[2], signal_true_edges=[2, 13592], x=[19897, 3], y=[154553], y_pid=[154553])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0287, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([5.2905e-05, 5.1963e-04, 1.8148e-05,  ..., 1.7440e-04, 6.3725e-04,\n",
      "        6.5890e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010056\n",
      "Batch(batch=[24590], cell_data=[24590, 11], edge_index=[2, 229982], event_file=[1], hid=[24590], modulewise_true_edges=[2, 20462], nhits=[24590], pid=[24590], primary=[24590], pt=[24590], ptr=[2], signal_true_edges=[2, 16762], x=[24590, 3], y=[229982], y_pid=[229982])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0263, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.0791e-05, 1.5619e-05, 1.6156e-05,  ..., 7.6075e-05, 3.8013e-05,\n",
      "        2.3362e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010057\n",
      "Batch(batch=[23067], cell_data=[23067, 11], edge_index=[2, 200167], event_file=[1], hid=[23067], modulewise_true_edges=[2, 19232], nhits=[23067], pid=[23067], primary=[23067], pt=[23067], ptr=[2], signal_true_edges=[2, 15549], x=[23067, 3], y=[200167], y_pid=[200167])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0289, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.1319e-01, 5.9509e-02, 3.3829e-02,  ..., 3.3381e-05, 3.2910e-05,\n",
      "        2.3115e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010058\n",
      "Batch(batch=[19009], cell_data=[19009, 11], edge_index=[2, 145867], event_file=[1], hid=[19009], modulewise_true_edges=[2, 15904], nhits=[19009], pid=[19009], primary=[19009], pt=[19009], ptr=[2], signal_true_edges=[2, 12955], x=[19009, 3], y=[145867], y_pid=[145867])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0300, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([5.5587e-05, 3.9998e-05, 6.3491e-04,  ..., 9.9144e-01, 4.3867e-05,\n",
      "        4.6448e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ...,  True, False, False], device='cuda:0')}\n",
      "event000010059\n",
      "Batch(batch=[21360], cell_data=[21360, 11], edge_index=[2, 179272], event_file=[1], hid=[21360], modulewise_true_edges=[2, 17835], nhits=[21360], pid=[21360], primary=[21360], pt=[21360], ptr=[2], signal_true_edges=[2, 14508], x=[21360, 3], y=[179272], y_pid=[179272])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0272, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([6.7111e-06, 3.4442e-05, 1.7872e-05,  ..., 2.2247e-04, 5.5964e-05,\n",
      "        1.1830e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010060\n",
      "Batch(batch=[26474], cell_data=[26474, 11], edge_index=[2, 262703], event_file=[1], hid=[26474], modulewise_true_edges=[2, 22046], nhits=[26474], pid=[26474], primary=[26474], pt=[26474], ptr=[2], signal_true_edges=[2, 17877], x=[26474, 3], y=[262703], y_pid=[262703])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0256, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.0060e-04, 1.3641e-04, 2.2145e-04,  ..., 4.8095e-05, 5.2237e-05,\n",
      "        1.6237e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010061\n",
      "Batch(batch=[18672], cell_data=[18672, 11], edge_index=[2, 141484], event_file=[1], hid=[18672], modulewise_true_edges=[2, 15535], nhits=[18672], pid=[18672], primary=[18672], pt=[18672], ptr=[2], signal_true_edges=[2, 12639], x=[18672, 3], y=[141484], y_pid=[141484])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0282, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.0384e-04, 5.7002e-05, 1.7800e-04,  ..., 1.8303e-04, 1.5694e-04,\n",
      "        1.9847e-02], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010062\n",
      "Batch(batch=[23085], cell_data=[23085, 11], edge_index=[2, 207798], event_file=[1], hid=[23085], modulewise_true_edges=[2, 19281], nhits=[23085], pid=[23085], primary=[23085], pt=[23085], ptr=[2], signal_true_edges=[2, 15536], x=[23085, 3], y=[207798], y_pid=[207798])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0271, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([4.1020e-05, 2.7278e-04, 1.5352e-04,  ..., 7.5061e-01, 7.5349e-04,\n",
      "        5.9795e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ...,  True, False, False], device='cuda:0')}\n",
      "event000010063\n",
      "Batch(batch=[23697], cell_data=[23697, 11], edge_index=[2, 214963], event_file=[1], hid=[23697], modulewise_true_edges=[2, 19799], nhits=[23697], pid=[23697], primary=[23697], pt=[23697], ptr=[2], signal_true_edges=[2, 16201], x=[23697, 3], y=[214963], y_pid=[214963])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0267, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([6.3366e-04, 1.8387e-04, 4.5903e-02,  ..., 3.9525e-01, 2.9540e-03,\n",
      "        5.7770e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010064\n",
      "Batch(batch=[21622], cell_data=[21622, 11], edge_index=[2, 183387], event_file=[1], hid=[21622], modulewise_true_edges=[2, 18064], nhits=[21622], pid=[21622], primary=[21622], pt=[21622], ptr=[2], signal_true_edges=[2, 14521], x=[21622, 3], y=[183387], y_pid=[183387])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0311, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.4427e-05, 2.3581e-04, 1.4437e-03,  ..., 3.1329e-05, 5.7066e-05,\n",
      "        1.6575e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010065\n",
      "Batch(batch=[23119], cell_data=[23119, 11], edge_index=[2, 202007], event_file=[1], hid=[23119], modulewise_true_edges=[2, 19167], nhits=[23119], pid=[23119], primary=[23119], pt=[23119], ptr=[2], signal_true_edges=[2, 15637], x=[23119, 3], y=[202007], y_pid=[202007])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0279, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.6778e-05, 1.1579e-04, 1.4996e-03,  ..., 1.4667e-04, 3.4139e-05,\n",
      "        3.6363e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010066\n",
      "Batch(batch=[21566], cell_data=[21566, 11], edge_index=[2, 180863], event_file=[1], hid=[21566], modulewise_true_edges=[2, 18001], nhits=[21566], pid=[21566], primary=[21566], pt=[21566], ptr=[2], signal_true_edges=[2, 14643], x=[21566, 3], y=[180863], y_pid=[180863])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0286, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([6.9968e-05, 1.5640e-05, 9.0711e-05,  ..., 9.6668e-01, 4.9181e-05,\n",
      "        4.3000e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ...,  True, False, False], device='cuda:0')}\n",
      "event000010067\n",
      "Batch(batch=[20542], cell_data=[20542, 11], edge_index=[2, 163497], event_file=[1], hid=[20542], modulewise_true_edges=[2, 17188], nhits=[20542], pid=[20542], primary=[20542], pt=[20542], ptr=[2], signal_true_edges=[2, 13916], x=[20542, 3], y=[163497], y_pid=[163497])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0285, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([7.4331e-03, 5.3164e-03, 7.7827e-05,  ..., 9.7888e-01, 4.6369e-05,\n",
      "        4.6654e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ...,  True, False, False], device='cuda:0')}\n",
      "event000010068\n",
      "Batch(batch=[22088], cell_data=[22088, 11], edge_index=[2, 191522], event_file=[1], hid=[22088], modulewise_true_edges=[2, 18407], nhits=[22088], pid=[22088], primary=[22088], pt=[22088], ptr=[2], signal_true_edges=[2, 14993], x=[22088, 3], y=[191522], y_pid=[191522])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0276, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.4772e-02, 9.7031e-04, 1.7135e-03,  ..., 7.6329e-05, 7.4667e-05,\n",
      "        4.5143e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010069\n",
      "Batch(batch=[24220], cell_data=[24220, 11], edge_index=[2, 222231], event_file=[1], hid=[24220], modulewise_true_edges=[2, 20189], nhits=[24220], pid=[24220], primary=[24220], pt=[24220], ptr=[2], signal_true_edges=[2, 16693], x=[24220, 3], y=[222231], y_pid=[222231])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0271, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.1012e-03, 3.1110e-03, 5.5015e-05,  ..., 5.1927e-05, 4.6755e-05,\n",
      "        3.1561e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010070\n",
      "Batch(batch=[22226], cell_data=[22226, 11], edge_index=[2, 188755], event_file=[1], hid=[22226], modulewise_true_edges=[2, 18494], nhits=[22226], pid=[22226], primary=[22226], pt=[22226], ptr=[2], signal_true_edges=[2, 14856], x=[22226, 3], y=[188755], y_pid=[188755])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0294, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.4446e-05, 4.1455e-05, 3.4501e-05,  ..., 6.5738e-02, 2.2768e-01,\n",
      "        2.3874e-01], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010071\n",
      "Batch(batch=[23642], cell_data=[23642, 11], edge_index=[2, 215742], event_file=[1], hid=[23642], modulewise_true_edges=[2, 19711], nhits=[23642], pid=[23642], primary=[23642], pt=[23642], ptr=[2], signal_true_edges=[2, 16039], x=[23642, 3], y=[215742], y_pid=[215742])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0271, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([5.6729e-04, 9.1742e-05, 2.7560e-05,  ..., 9.9060e-05, 3.8563e-05,\n",
      "        1.6926e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010072\n",
      "Batch(batch=[24895], cell_data=[24895, 11], edge_index=[2, 234844], event_file=[1], hid=[24895], modulewise_true_edges=[2, 20719], nhits=[24895], pid=[24895], primary=[24895], pt=[24895], ptr=[2], signal_true_edges=[2, 16566], x=[24895, 3], y=[234844], y_pid=[234844])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0270, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.3928e-05, 2.1271e-03, 1.2295e-04,  ..., 4.5443e-05, 1.6429e-05,\n",
      "        3.0691e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010073\n",
      "Batch(batch=[24643], cell_data=[24643, 11], edge_index=[2, 230272], event_file=[1], hid=[24643], modulewise_true_edges=[2, 20423], nhits=[24643], pid=[24643], primary=[24643], pt=[24643], ptr=[2], signal_true_edges=[2, 16498], x=[24643, 3], y=[230272], y_pid=[230272])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0279, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([9.4117e-05, 3.9876e-03, 1.9045e-03,  ..., 9.6493e-01, 2.6163e-04,\n",
      "        2.4182e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ...,  True, False, False], device='cuda:0')}\n",
      "event000010074\n",
      "Batch(batch=[22444], cell_data=[22444, 11], edge_index=[2, 194757], event_file=[1], hid=[22444], modulewise_true_edges=[2, 18649], nhits=[22444], pid=[22444], primary=[22444], pt=[22444], ptr=[2], signal_true_edges=[2, 15235], x=[22444, 3], y=[194757], y_pid=[194757])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0285, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([2.5585e-05, 4.1630e-05, 1.1764e-03,  ..., 9.6123e-01, 1.8286e-04,\n",
      "        3.6776e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ...,  True, False, False], device='cuda:0')}\n",
      "event000010075\n",
      "Batch(batch=[26986], cell_data=[26986, 11], edge_index=[2, 274378], event_file=[1], hid=[26986], modulewise_true_edges=[2, 22497], nhits=[26986], pid=[26986], primary=[26986], pt=[26986], ptr=[2], signal_true_edges=[2, 18351], x=[26986, 3], y=[274378], y_pid=[274378])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0265, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.8392e-05, 3.3184e-05, 2.1380e-05,  ..., 2.4379e-01, 3.3575e-05,\n",
      "        4.1143e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010076\n",
      "Batch(batch=[23275], cell_data=[23275, 11], edge_index=[2, 210735], event_file=[1], hid=[23275], modulewise_true_edges=[2, 19416], nhits=[23275], pid=[23275], primary=[23275], pt=[23275], ptr=[2], signal_true_edges=[2, 15893], x=[23275, 3], y=[210735], y_pid=[210735])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0276, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.7892e-05, 1.4791e-03, 1.7706e-03,  ..., 7.3345e-04, 3.0102e-04,\n",
      "        5.6385e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010077\n",
      "Batch(batch=[26207], cell_data=[26207, 11], edge_index=[2, 262098], event_file=[1], hid=[26207], modulewise_true_edges=[2, 21864], nhits=[26207], pid=[26207], primary=[26207], pt=[26207], ptr=[2], signal_true_edges=[2, 17756], x=[26207, 3], y=[262098], y_pid=[262098])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0260, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.5842e-03, 1.6104e-05, 5.0756e-03,  ..., 4.8268e-05, 5.0638e-05,\n",
      "        4.9586e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010078\n",
      "Batch(batch=[25801], cell_data=[25801, 11], edge_index=[2, 252874], event_file=[1], hid=[25801], modulewise_true_edges=[2, 21598], nhits=[25801], pid=[25801], primary=[25801], pt=[25801], ptr=[2], signal_true_edges=[2, 17879], x=[25801, 3], y=[252874], y_pid=[252874])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0247, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.3130e-03, 1.9616e-04, 8.0913e-04,  ..., 2.4571e-04, 4.8742e-05,\n",
      "        2.3016e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010079\n",
      "Batch(batch=[26230], cell_data=[26230, 11], edge_index=[2, 258403], event_file=[1], hid=[26230], modulewise_true_edges=[2, 21951], nhits=[26230], pid=[26230], primary=[26230], pt=[26230], ptr=[2], signal_true_edges=[2, 17778], x=[26230, 3], y=[258403], y_pid=[258403])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0273, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.7564e-03, 9.4583e-02, 1.0307e-04,  ..., 3.2920e-05, 6.7346e-03,\n",
      "        5.7630e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010080\n",
      "Batch(batch=[23797], cell_data=[23797, 11], edge_index=[2, 213747], event_file=[1], hid=[23797], modulewise_true_edges=[2, 19761], nhits=[23797], pid=[23797], primary=[23797], pt=[23797], ptr=[2], signal_true_edges=[2, 16127], x=[23797, 3], y=[213747], y_pid=[213747])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0271, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.4113e-01, 1.1665e-02, 9.3211e-04,  ..., 1.0399e-04, 4.5965e-05,\n",
      "        2.3406e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010081\n",
      "Batch(batch=[25486], cell_data=[25486, 11], edge_index=[2, 244678], event_file=[1], hid=[25486], modulewise_true_edges=[2, 21298], nhits=[25486], pid=[25486], primary=[25486], pt=[25486], ptr=[2], signal_true_edges=[2, 17488], x=[25486, 3], y=[244678], y_pid=[244678])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0267, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.5380e-03, 4.7966e-04, 2.4349e-04,  ..., 4.2133e-05, 4.3409e-05,\n",
      "        1.1132e-03], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010082\n",
      "Batch(batch=[24671], cell_data=[24671, 11], edge_index=[2, 231550], event_file=[1], hid=[24671], modulewise_true_edges=[2, 20570], nhits=[24671], pid=[24671], primary=[24671], pt=[24671], ptr=[2], signal_true_edges=[2, 16610], x=[24671, 3], y=[231550], y_pid=[231550])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0262, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.3773e-02, 2.3399e-02, 2.5186e-02,  ..., 4.8462e-05, 2.0723e-04,\n",
      "        6.3018e-03], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010083\n",
      "Batch(batch=[25958], cell_data=[25958, 11], edge_index=[2, 251303], event_file=[1], hid=[25958], modulewise_true_edges=[2, 21544], nhits=[25958], pid=[25958], primary=[25958], pt=[25958], ptr=[2], signal_true_edges=[2, 17620], x=[25958, 3], y=[251303], y_pid=[251303])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0262, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.8403e-05, 5.6659e-04, 8.5219e-04,  ..., 1.7816e-04, 2.8170e-05,\n",
      "        4.4487e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010084\n",
      "Batch(batch=[23823], cell_data=[23823, 11], edge_index=[2, 216645], event_file=[1], hid=[23823], modulewise_true_edges=[2, 19871], nhits=[23823], pid=[23823], primary=[23823], pt=[23823], ptr=[2], signal_true_edges=[2, 16333], x=[23823, 3], y=[216645], y_pid=[216645])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0285, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.0090e-03, 9.2300e-03, 2.0131e-03,  ..., 5.2506e-05, 4.2051e-05,\n",
      "        2.6399e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010085\n",
      "Batch(batch=[27989], cell_data=[27989, 11], edge_index=[2, 291950], event_file=[1], hid=[27989], modulewise_true_edges=[2, 23309], nhits=[27989], pid=[27989], primary=[27989], pt=[27989], ptr=[2], signal_true_edges=[2, 18794], x=[27989, 3], y=[291950], y_pid=[291950])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0264, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.0654e-04, 3.2925e-04, 5.2019e-04,  ..., 2.0115e-04, 3.8058e-05,\n",
      "        2.1575e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010086\n",
      "Batch(batch=[20989], cell_data=[20989, 11], edge_index=[2, 169472], event_file=[1], hid=[20989], modulewise_true_edges=[2, 17483], nhits=[20989], pid=[20989], primary=[20989], pt=[20989], ptr=[2], signal_true_edges=[2, 14020], x=[20989, 3], y=[169472], y_pid=[169472])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0307, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.4305e-05, 2.8277e-03, 5.4026e-05,  ..., 1.6091e-01, 3.0217e-01,\n",
      "        2.9027e-01], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010087\n",
      "Batch(batch=[21528], cell_data=[21528, 11], edge_index=[2, 180078], event_file=[1], hid=[21528], modulewise_true_edges=[2, 18000], nhits=[21528], pid=[21528], primary=[21528], pt=[21528], ptr=[2], signal_true_edges=[2, 14729], x=[21528, 3], y=[180078], y_pid=[180078])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0286, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.8397e-05, 5.6118e-05, 1.6055e-05,  ..., 1.1888e-04, 5.9869e-03,\n",
      "        1.0097e-03], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010088\n",
      "Batch(batch=[26211], cell_data=[26211, 11], edge_index=[2, 260426], event_file=[1], hid=[26211], modulewise_true_edges=[2, 21851], nhits=[26211], pid=[26211], primary=[26211], pt=[26211], ptr=[2], signal_true_edges=[2, 17835], x=[26211, 3], y=[260426], y_pid=[260426])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0255, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([7.7402e-05, 2.2988e-04, 1.3472e-02,  ..., 3.2349e-05, 2.8207e-05,\n",
      "        4.9588e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010089\n",
      "Batch(batch=[26871], cell_data=[26871, 11], edge_index=[2, 271318], event_file=[1], hid=[26871], modulewise_true_edges=[2, 22340], nhits=[26871], pid=[26871], primary=[26871], pt=[26871], ptr=[2], signal_true_edges=[2, 18225], x=[26871, 3], y=[271318], y_pid=[271318])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0258, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.3711e-05, 1.7075e-05, 4.9174e-06,  ..., 3.0038e-05, 7.7120e-05,\n",
      "        2.2386e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010090\n",
      "Batch(batch=[23072], cell_data=[23072, 11], edge_index=[2, 202770], event_file=[1], hid=[23072], modulewise_true_edges=[2, 19164], nhits=[23072], pid=[23072], primary=[23072], pt=[23072], ptr=[2], signal_true_edges=[2, 15411], x=[23072, 3], y=[202770], y_pid=[202770])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0269, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.1087e-05, 3.2955e-05, 1.7788e-05,  ..., 6.4582e-04, 8.8760e-05,\n",
      "        9.6343e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010091\n",
      "Batch(batch=[27629], cell_data=[27629, 11], edge_index=[2, 284452], event_file=[1], hid=[27629], modulewise_true_edges=[2, 23081], nhits=[27629], pid=[27629], primary=[27629], pt=[27629], ptr=[2], signal_true_edges=[2, 18993], x=[27629, 3], y=[284452], y_pid=[284452])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0254, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([9.2289e-04, 5.1853e-04, 9.0564e-04,  ..., 3.5653e-04, 1.8060e-03,\n",
      "        4.0041e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010092\n",
      "Batch(batch=[27168], cell_data=[27168, 11], edge_index=[2, 276833], event_file=[1], hid=[27168], modulewise_true_edges=[2, 22648], nhits=[27168], pid=[27168], primary=[27168], pt=[27168], ptr=[2], signal_true_edges=[2, 18107], x=[27168, 3], y=[276833], y_pid=[276833])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0278, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.5219e-05, 5.8263e-04, 2.4054e-03,  ..., 1.0807e-04, 4.8506e-05,\n",
      "        1.9425e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010093\n",
      "Batch(batch=[23395], cell_data=[23395, 11], edge_index=[2, 208756], event_file=[1], hid=[23395], modulewise_true_edges=[2, 19538], nhits=[23395], pid=[23395], primary=[23395], pt=[23395], ptr=[2], signal_true_edges=[2, 15919], x=[23395, 3], y=[208756], y_pid=[208756])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0272, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.0915e-01, 1.5233e-01, 2.2718e-01,  ..., 3.9503e-05, 7.8346e-05,\n",
      "        4.5690e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010094\n",
      "Batch(batch=[26985], cell_data=[26985, 11], edge_index=[2, 274278], event_file=[1], hid=[26985], modulewise_true_edges=[2, 22550], nhits=[26985], pid=[26985], primary=[26985], pt=[26985], ptr=[2], signal_true_edges=[2, 18655], x=[26985, 3], y=[274278], y_pid=[274278])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0244, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.0628e-03, 2.3134e-02, 3.1008e-03,  ..., 9.4371e-05, 2.1377e-05,\n",
      "        2.1647e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010095\n",
      "Batch(batch=[23568], cell_data=[23568, 11], edge_index=[2, 212009], event_file=[1], hid=[23568], modulewise_true_edges=[2, 19644], nhits=[23568], pid=[23568], primary=[23568], pt=[23568], ptr=[2], signal_true_edges=[2, 15744], x=[23568, 3], y=[212009], y_pid=[212009])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0276, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.5157e-05, 3.2224e-03, 1.9598e-04,  ..., 4.2703e-05, 2.0285e-05,\n",
      "        1.7037e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010096\n",
      "Batch(batch=[22052], cell_data=[22052, 11], edge_index=[2, 185313], event_file=[1], hid=[22052], modulewise_true_edges=[2, 18309], nhits=[22052], pid=[22052], primary=[22052], pt=[22052], ptr=[2], signal_true_edges=[2, 14687], x=[22052, 3], y=[185313], y_pid=[185313])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0293, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False,  True], device='cuda:0'), 'score': tensor([6.8029e-05, 5.1015e-05, 1.1004e-01,  ..., 1.9289e-04, 3.0094e-04,\n",
      "        9.6407e-01], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False,  True], device='cuda:0')}\n",
      "event000010097\n",
      "Batch(batch=[27746], cell_data=[27746, 11], edge_index=[2, 285632], event_file=[1], hid=[27746], modulewise_true_edges=[2, 23033], nhits=[27746], pid=[27746], primary=[27746], pt=[27746], ptr=[2], signal_true_edges=[2, 18676], x=[27746, 3], y=[285632], y_pid=[285632])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0267, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.0493e-02, 1.4533e-04, 1.0111e-04,  ..., 7.5650e-05, 5.0674e-05,\n",
      "        9.1701e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010098\n",
      "Batch(batch=[30155], cell_data=[30155, 11], edge_index=[2, 339332], event_file=[1], hid=[30155], modulewise_true_edges=[2, 25152], nhits=[30155], pid=[30155], primary=[30155], pt=[30155], ptr=[2], signal_true_edges=[2, 20710], x=[30155, 3], y=[339332], y_pid=[339332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0259, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.8362e-03, 1.7142e-03, 3.0031e-04,  ..., 3.9011e-05, 5.4985e-05,\n",
      "        2.4782e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010099\n",
      "Batch(batch=[25299], cell_data=[25299, 11], edge_index=[2, 243802], event_file=[1], hid=[25299], modulewise_true_edges=[2, 21088], nhits=[25299], pid=[25299], primary=[25299], pt=[25299], ptr=[2], signal_true_edges=[2, 17164], x=[25299, 3], y=[243802], y_pid=[243802])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0267, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.7196e-03, 2.5953e-02, 3.0462e-04,  ..., 1.1948e-04, 2.6289e-05,\n",
      "        2.2371e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010100\n",
      "Batch(batch=[19559], cell_data=[19559, 11], edge_index=[2, 152600], event_file=[1], hid=[19559], modulewise_true_edges=[2, 16344], nhits=[19559], pid=[19559], primary=[19559], pt=[19559], ptr=[2], signal_true_edges=[2, 13381], x=[19559, 3], y=[152600], y_pid=[152600])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0305, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.1598e-05, 1.1349e-03, 2.9588e-04,  ..., 5.1157e-04, 2.6131e-02,\n",
      "        8.7195e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000101\n",
      "Batch(batch=[22073], cell_data=[22073, 11], edge_index=[2, 190863], event_file=[1], hid=[22073], modulewise_true_edges=[2, 18448], nhits=[22073], pid=[22073], primary=[22073], pt=[22073], ptr=[2], signal_true_edges=[2, 15205], x=[22073, 3], y=[190863], y_pid=[190863])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0270, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.0712e-05, 2.0438e-01, 3.6720e-03,  ..., 3.1538e-02, 4.9492e-05,\n",
      "        8.6040e-05], device='cuda:0'), 'truth': tensor([False,  True, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000102\n",
      "Batch(batch=[26009], cell_data=[26009, 11], edge_index=[2, 254544], event_file=[1], hid=[26009], modulewise_true_edges=[2, 21661], nhits=[26009], pid=[26009], primary=[26009], pt=[26009], ptr=[2], signal_true_edges=[2, 17569], x=[26009, 3], y=[254544], y_pid=[254544])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0256, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.1079e-04, 4.9411e-05, 1.5405e-05,  ..., 7.5754e-05, 2.2908e-05,\n",
      "        3.6678e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010103\n",
      "Batch(batch=[25279], cell_data=[25279, 11], edge_index=[2, 244897], event_file=[1], hid=[25279], modulewise_true_edges=[2, 21117], nhits=[25279], pid=[25279], primary=[25279], pt=[25279], ptr=[2], signal_true_edges=[2, 16933], x=[25279, 3], y=[244897], y_pid=[244897])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0289, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([5.8793e-05, 2.4439e-03, 4.9100e-04,  ..., 1.1216e-04, 1.0779e-04,\n",
      "        1.3233e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010104\n",
      "Batch(batch=[21221], cell_data=[21221, 11], edge_index=[2, 172402], event_file=[1], hid=[21221], modulewise_true_edges=[2, 17641], nhits=[21221], pid=[21221], primary=[21221], pt=[21221], ptr=[2], signal_true_edges=[2, 14391], x=[21221, 3], y=[172402], y_pid=[172402])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0288, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([7.7213e-06, 2.2527e-05, 1.0252e-04,  ..., 6.3637e-01, 1.2332e-03,\n",
      "        1.0909e-03], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010105\n",
      "Batch(batch=[24878], cell_data=[24878, 11], edge_index=[2, 239288], event_file=[1], hid=[24878], modulewise_true_edges=[2, 20672], nhits=[24878], pid=[24878], primary=[24878], pt=[24878], ptr=[2], signal_true_edges=[2, 16972], x=[24878, 3], y=[239288], y_pid=[239288])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0260, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([9.4757e-05, 8.5112e-05, 3.3899e-05,  ..., 4.9435e-03, 1.2156e-05,\n",
      "        4.9307e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000106\n",
      "Batch(batch=[25142], cell_data=[25142, 11], edge_index=[2, 242226], event_file=[1], hid=[25142], modulewise_true_edges=[2, 20921], nhits=[25142], pid=[25142], primary=[25142], pt=[25142], ptr=[2], signal_true_edges=[2, 16865], x=[25142, 3], y=[242226], y_pid=[242226])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0275, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([8.8148e-05, 1.3125e-05, 7.9452e-05,  ..., 5.3004e-04, 1.6330e-04,\n",
      "        5.9737e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000107\n",
      "Batch(batch=[25581], cell_data=[25581, 11], edge_index=[2, 254727], event_file=[1], hid=[25581], modulewise_true_edges=[2, 21234], nhits=[25581], pid=[25581], primary=[25581], pt=[25581], ptr=[2], signal_true_edges=[2, 17247], x=[25581, 3], y=[254727], y_pid=[254727])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0264, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.1366e-04, 4.2226e-05, 9.5936e-04,  ..., 5.3501e-04, 3.3787e-02,\n",
      "        4.9701e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000108\n",
      "Batch(batch=[24448], cell_data=[24448, 11], edge_index=[2, 224608], event_file=[1], hid=[24448], modulewise_true_edges=[2, 20369], nhits=[24448], pid=[24448], primary=[24448], pt=[24448], ptr=[2], signal_true_edges=[2, 16752], x=[24448, 3], y=[224608], y_pid=[224608])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0260, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([9.9236e-03, 3.5158e-03, 2.6857e-02,  ..., 8.8776e-05, 3.3814e-05,\n",
      "        4.2025e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010109\n",
      "Batch(batch=[24355], cell_data=[24355, 11], edge_index=[2, 223225], event_file=[1], hid=[24355], modulewise_true_edges=[2, 20268], nhits=[24355], pid=[24355], primary=[24355], pt=[24355], ptr=[2], signal_true_edges=[2, 16570], x=[24355, 3], y=[223225], y_pid=[223225])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0271, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.3583e-04, 3.1192e-04, 6.2212e-05,  ..., 9.5730e-04, 7.2087e-04,\n",
      "        1.0691e-03], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010110\n",
      "Batch(batch=[18036], cell_data=[18036, 11], edge_index=[2, 133814], event_file=[1], hid=[18036], modulewise_true_edges=[2, 15061], nhits=[18036], pid=[18036], primary=[18036], pt=[18036], ptr=[2], signal_true_edges=[2, 12384], x=[18036, 3], y=[133814], y_pid=[133814])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0309, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.0286e-05, 7.0910e-04, 1.3841e-03,  ..., 4.2195e-05, 6.4209e-05,\n",
      "        1.2214e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000111\n",
      "Batch(batch=[23168], cell_data=[23168, 11], edge_index=[2, 201642], event_file=[1], hid=[23168], modulewise_true_edges=[2, 19282], nhits=[23168], pid=[23168], primary=[23168], pt=[23168], ptr=[2], signal_true_edges=[2, 15580], x=[23168, 3], y=[201642], y_pid=[201642])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0292, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.2570e-04, 2.8729e-04, 6.4881e-04,  ..., 1.8084e-01, 3.0565e-01,\n",
      "        3.1347e-01], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010112\n",
      "Batch(batch=[29241], cell_data=[29241, 11], edge_index=[2, 320541], event_file=[1], hid=[29241], modulewise_true_edges=[2, 24365], nhits=[29241], pid=[29241], primary=[29241], pt=[29241], ptr=[2], signal_true_edges=[2, 19691], x=[29241, 3], y=[320541], y_pid=[320541])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0254, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.6532e-05, 6.2066e-03, 3.9550e-02,  ..., 5.4556e-03, 3.1796e-05,\n",
      "        7.5158e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010113\n",
      "Batch(batch=[23628], cell_data=[23628, 11], edge_index=[2, 213482], event_file=[1], hid=[23628], modulewise_true_edges=[2, 19704], nhits=[23628], pid=[23628], primary=[23628], pt=[23628], ptr=[2], signal_true_edges=[2, 15723], x=[23628, 3], y=[213482], y_pid=[213482])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0296, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([6.0220e-04, 4.9405e-03, 4.3308e-04,  ..., 9.6210e-01, 7.3593e-05,\n",
      "        1.5882e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ...,  True, False, False], device='cuda:0')}\n",
      "event000000114\n",
      "Batch(batch=[27140], cell_data=[27140, 11], edge_index=[2, 274606], event_file=[1], hid=[27140], modulewise_true_edges=[2, 22674], nhits=[27140], pid=[27140], primary=[27140], pt=[27140], ptr=[2], signal_true_edges=[2, 18281], x=[27140, 3], y=[274606], y_pid=[274606])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0273, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([5.1544e-03, 8.6951e-02, 1.1278e-04,  ..., 4.3933e-05, 3.9497e-03,\n",
      "        2.3325e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010115\n",
      "Batch(batch=[25969], cell_data=[25969, 11], edge_index=[2, 254168], event_file=[1], hid=[25969], modulewise_true_edges=[2, 21711], nhits=[25969], pid=[25969], primary=[25969], pt=[25969], ptr=[2], signal_true_edges=[2, 17581], x=[25969, 3], y=[254168], y_pid=[254168])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0276, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([9.1223e-05, 2.3455e-04, 3.2175e-05,  ..., 9.7437e-05, 2.5266e-05,\n",
      "        1.5981e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010116\n",
      "Batch(batch=[23783], cell_data=[23783, 11], edge_index=[2, 219843], event_file=[1], hid=[23783], modulewise_true_edges=[2, 19817], nhits=[23783], pid=[23783], primary=[23783], pt=[23783], ptr=[2], signal_true_edges=[2, 16160], x=[23783, 3], y=[219843], y_pid=[219843])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0285, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.6436e-05, 5.7233e-05, 4.7917e-03,  ..., 6.8551e-04, 9.9632e-05,\n",
      "        4.1932e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000117\n",
      "Batch(batch=[23505], cell_data=[23505, 11], edge_index=[2, 213786], event_file=[1], hid=[23505], modulewise_true_edges=[2, 19635], nhits=[23505], pid=[23505], primary=[23505], pt=[23505], ptr=[2], signal_true_edges=[2, 16064], x=[23505, 3], y=[213786], y_pid=[213786])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0275, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([4.2588e-05, 1.0220e-02, 1.0150e-04,  ..., 6.8705e-01, 1.6284e-04,\n",
      "        2.2449e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ...,  True, False, False], device='cuda:0')}\n",
      "event000010118\n",
      "Batch(batch=[26002], cell_data=[26002, 11], edge_index=[2, 257607], event_file=[1], hid=[26002], modulewise_true_edges=[2, 21702], nhits=[26002], pid=[26002], primary=[26002], pt=[26002], ptr=[2], signal_true_edges=[2, 17745], x=[26002, 3], y=[257607], y_pid=[257607])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0255, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False,  True, False], device='cuda:0'), 'score': tensor([5.4733e-05, 7.0443e-05, 1.9732e-04,  ..., 1.0244e-04, 9.6376e-01,\n",
      "        3.0793e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False,  True, False], device='cuda:0')}\n",
      "event000000119\n",
      "Batch(batch=[27990], cell_data=[27990, 11], edge_index=[2, 293284], event_file=[1], hid=[27990], modulewise_true_edges=[2, 23324], nhits=[27990], pid=[27990], primary=[27990], pt=[27990], ptr=[2], signal_true_edges=[2, 19084], x=[27990, 3], y=[293284], y_pid=[293284])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0260, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False,  True], device='cuda:0'), 'score': tensor([2.0620e-05, 6.6937e-05, 1.1328e-04,  ..., 3.8401e-05, 3.7021e-05,\n",
      "        9.6913e-01], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False,  True], device='cuda:0')}\n",
      "event000000120\n",
      "Batch(batch=[20270], cell_data=[20270, 11], edge_index=[2, 166859], event_file=[1], hid=[20270], modulewise_true_edges=[2, 16951], nhits=[20270], pid=[20270], primary=[20270], pt=[20270], ptr=[2], signal_true_edges=[2, 13681], x=[20270, 3], y=[166859], y_pid=[166859])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0288, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.7938e-04, 4.5361e-04, 2.5339e-05,  ..., 1.4150e-05, 7.1695e-05,\n",
      "        4.0707e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010121\n",
      "Batch(batch=[21427], cell_data=[21427, 11], edge_index=[2, 182382], event_file=[1], hid=[21427], modulewise_true_edges=[2, 17918], nhits=[21427], pid=[21427], primary=[21427], pt=[21427], ptr=[2], signal_true_edges=[2, 14736], x=[21427, 3], y=[182382], y_pid=[182382])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0275, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False,  True], device='cuda:0'), 'score': tensor([2.2868e-05, 7.8960e-05, 5.6107e-05,  ..., 3.0137e-04, 8.4017e-05,\n",
      "        6.0492e-01], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False,  True], device='cuda:0')}\n",
      "event000000122\n",
      "Batch(batch=[22425], cell_data=[22425, 11], edge_index=[2, 191290], event_file=[1], hid=[22425], modulewise_true_edges=[2, 18696], nhits=[22425], pid=[22425], primary=[22425], pt=[22425], ptr=[2], signal_true_edges=[2, 15134], x=[22425, 3], y=[191290], y_pid=[191290])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0299, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.1121e-01, 2.0706e-01, 5.9459e-03,  ..., 1.6552e-05, 1.9457e-05,\n",
      "        7.4300e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000123\n",
      "Batch(batch=[18155], cell_data=[18155, 11], edge_index=[2, 132522], event_file=[1], hid=[18155], modulewise_true_edges=[2, 15176], nhits=[18155], pid=[18155], primary=[18155], pt=[18155], ptr=[2], signal_true_edges=[2, 12348], x=[18155, 3], y=[132522], y_pid=[132522])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0303, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.4917e-04, 2.4622e-04, 4.7832e-05,  ..., 1.3050e-03, 2.0530e-05,\n",
      "        2.6360e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000124\n",
      "Batch(batch=[23716], cell_data=[23716, 11], edge_index=[2, 217821], event_file=[1], hid=[23716], modulewise_true_edges=[2, 19763], nhits=[23716], pid=[23716], primary=[23716], pt=[23716], ptr=[2], signal_true_edges=[2, 16003], x=[23716, 3], y=[217821], y_pid=[217821])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0295, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.8262e-02, 5.6761e-03, 6.3127e-02,  ..., 5.1812e-05, 1.3319e-03,\n",
      "        1.8220e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000125\n",
      "Batch(batch=[25636], cell_data=[25636, 11], edge_index=[2, 243968], event_file=[1], hid=[25636], modulewise_true_edges=[2, 21365], nhits=[25636], pid=[25636], primary=[25636], pt=[25636], ptr=[2], signal_true_edges=[2, 17497], x=[25636, 3], y=[243968], y_pid=[243968])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0275, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.5959e-04, 2.1891e-05, 2.6734e-04,  ..., 3.8765e-05, 4.0116e-05,\n",
      "        5.3696e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010126\n",
      "Batch(batch=[22100], cell_data=[22100, 11], edge_index=[2, 187641], event_file=[1], hid=[22100], modulewise_true_edges=[2, 18407], nhits=[22100], pid=[22100], primary=[22100], pt=[22100], ptr=[2], signal_true_edges=[2, 14767], x=[22100, 3], y=[187641], y_pid=[187641])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0307, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([7.8869e-05, 5.7906e-05, 1.2783e-03,  ..., 2.3254e-05, 2.5602e-05,\n",
      "        3.2586e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000127\n",
      "Batch(batch=[22529], cell_data=[22529, 11], edge_index=[2, 195382], event_file=[1], hid=[22529], modulewise_true_edges=[2, 18783], nhits=[22529], pid=[22529], primary=[22529], pt=[22529], ptr=[2], signal_true_edges=[2, 15381], x=[22529, 3], y=[195382], y_pid=[195382])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0262, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([6.6511e-06, 1.5743e-04, 1.6811e-04,  ..., 6.4352e-04, 1.6785e-04,\n",
      "        1.0979e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010128\n",
      "Batch(batch=[21765], cell_data=[21765, 11], edge_index=[2, 186183], event_file=[1], hid=[21765], modulewise_true_edges=[2, 18206], nhits=[21765], pid=[21765], primary=[21765], pt=[21765], ptr=[2], signal_true_edges=[2, 14990], x=[21765, 3], y=[186183], y_pid=[186183])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0303, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.9479e-04, 6.1992e-04, 1.4871e-05,  ..., 3.0404e-05, 1.1988e-04,\n",
      "        2.2725e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000129\n",
      "Batch(batch=[24785], cell_data=[24785, 11], edge_index=[2, 232879], event_file=[1], hid=[24785], modulewise_true_edges=[2, 20726], nhits=[24785], pid=[24785], primary=[24785], pt=[24785], ptr=[2], signal_true_edges=[2, 17225], x=[24785, 3], y=[232879], y_pid=[232879])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0257, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([6.1339e-05, 1.0687e-03, 9.9167e-04,  ..., 3.6985e-04, 1.2975e-04,\n",
      "        1.9548e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010130\n",
      "Batch(batch=[27324], cell_data=[27324, 11], edge_index=[2, 280140], event_file=[1], hid=[27324], modulewise_true_edges=[2, 22752], nhits=[27324], pid=[27324], primary=[27324], pt=[27324], ptr=[2], signal_true_edges=[2, 18293], x=[27324, 3], y=[280140], y_pid=[280140])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0278, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.2459e-01, 4.5693e-05, 1.3294e-05,  ..., 2.6540e-04, 1.4714e-05,\n",
      "        1.3092e-01], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000131\n",
      "Batch(batch=[24882], cell_data=[24882, 11], edge_index=[2, 234970], event_file=[1], hid=[24882], modulewise_true_edges=[2, 20752], nhits=[24882], pid=[24882], primary=[24882], pt=[24882], ptr=[2], signal_true_edges=[2, 16748], x=[24882, 3], y=[234970], y_pid=[234970])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0281, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([3.8484e-02, 1.7390e-04, 1.4012e-04,  ..., 9.6564e-01, 4.0380e-05,\n",
      "        5.4242e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010132\n",
      "Batch(batch=[26190], cell_data=[26190, 11], edge_index=[2, 260900], event_file=[1], hid=[26190], modulewise_true_edges=[2, 21847], nhits=[26190], pid=[26190], primary=[26190], pt=[26190], ptr=[2], signal_true_edges=[2, 17872], x=[26190, 3], y=[260900], y_pid=[260900])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0264, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([7.8210e-03, 2.9569e-03, 4.0773e-04,  ..., 1.1871e-03, 1.4280e-04,\n",
      "        4.7442e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010133\n",
      "Batch(batch=[18311], cell_data=[18311, 11], edge_index=[2, 132994], event_file=[1], hid=[18311], modulewise_true_edges=[2, 15264], nhits=[18311], pid=[18311], primary=[18311], pt=[18311], ptr=[2], signal_true_edges=[2, 12498], x=[18311, 3], y=[132994], y_pid=[132994])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0291, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([9.5436e-05, 3.4301e-04, 2.6945e-04,  ..., 2.3341e-04, 9.1429e-05,\n",
      "        4.2776e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010134\n",
      "Batch(batch=[25599], cell_data=[25599, 11], edge_index=[2, 251049], event_file=[1], hid=[25599], modulewise_true_edges=[2, 21381], nhits=[25599], pid=[25599], primary=[25599], pt=[25599], ptr=[2], signal_true_edges=[2, 17317], x=[25599, 3], y=[251049], y_pid=[251049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0269, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([6.1662e-03, 8.1916e-02, 1.3479e-01,  ..., 4.0655e-05, 7.7218e-05,\n",
      "        1.7149e-01], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010135\n",
      "Batch(batch=[21613], cell_data=[21613, 11], edge_index=[2, 181598], event_file=[1], hid=[21613], modulewise_true_edges=[2, 17987], nhits=[21613], pid=[21613], primary=[21613], pt=[21613], ptr=[2], signal_true_edges=[2, 14452], x=[21613, 3], y=[181598], y_pid=[181598])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0302, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False,  True], device='cuda:0'), 'score': tensor([8.1397e-04, 4.7949e-02, 9.3023e-03,  ..., 2.0329e-05, 4.2705e-05,\n",
      "        9.8637e-01], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000136\n",
      "Batch(batch=[25973], cell_data=[25973, 11], edge_index=[2, 254916], event_file=[1], hid=[25973], modulewise_true_edges=[2, 21708], nhits=[25973], pid=[25973], primary=[25973], pt=[25973], ptr=[2], signal_true_edges=[2, 17789], x=[25973, 3], y=[254916], y_pid=[254916])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0281, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([8.4315e-04, 7.1633e-06, 3.1027e-05,  ..., 6.1872e-05, 6.1587e-05,\n",
      "        2.4350e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000137\n",
      "Batch(batch=[19729], cell_data=[19729, 11], edge_index=[2, 150717], event_file=[1], hid=[19729], modulewise_true_edges=[2, 16411], nhits=[19729], pid=[19729], primary=[19729], pt=[19729], ptr=[2], signal_true_edges=[2, 13280], x=[19729, 3], y=[150717], y_pid=[150717])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0294, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([8.0145e-03, 6.0797e-04, 2.6274e-05,  ..., 3.7225e-05, 3.6188e-02,\n",
      "        1.0429e-01], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010138\n",
      "Batch(batch=[22131], cell_data=[22131, 11], edge_index=[2, 190511], event_file=[1], hid=[22131], modulewise_true_edges=[2, 18423], nhits=[22131], pid=[22131], primary=[22131], pt=[22131], ptr=[2], signal_true_edges=[2, 15008], x=[22131, 3], y=[190511], y_pid=[190511])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0285, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.8818e-02, 3.4210e-05, 4.4610e-05,  ..., 5.1276e-05, 4.3828e-04,\n",
      "        7.4277e-03], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010139\n",
      "Batch(batch=[22251], cell_data=[22251, 11], edge_index=[2, 194200], event_file=[1], hid=[22251], modulewise_true_edges=[2, 18565], nhits=[22251], pid=[22251], primary=[22251], pt=[22251], ptr=[2], signal_true_edges=[2, 15264], x=[22251, 3], y=[194200], y_pid=[194200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0267, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([6.6577e-06, 1.7977e-04, 2.6232e-04,  ..., 7.5326e-05, 2.3659e-04,\n",
      "        1.4625e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010140\n",
      "Batch(batch=[20928], cell_data=[20928, 11], edge_index=[2, 174177], event_file=[1], hid=[20928], modulewise_true_edges=[2, 17503], nhits=[20928], pid=[20928], primary=[20928], pt=[20928], ptr=[2], signal_true_edges=[2, 14286], x=[20928, 3], y=[174177], y_pid=[174177])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0287, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([5.3008e-04, 2.5560e-05, 2.9070e-05,  ..., 5.0525e-05, 7.4835e-05,\n",
      "        4.1288e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010141\n",
      "Batch(batch=[24229], cell_data=[24229, 11], edge_index=[2, 222482], event_file=[1], hid=[24229], modulewise_true_edges=[2, 20277], nhits=[24229], pid=[24229], primary=[24229], pt=[24229], ptr=[2], signal_true_edges=[2, 16379], x=[24229, 3], y=[222482], y_pid=[222482])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0288, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.4404e-03, 9.2044e-05, 1.0691e-02,  ..., 3.8442e-05, 7.9705e-05,\n",
      "        3.7347e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010142\n",
      "Batch(batch=[28556], cell_data=[28556, 11], edge_index=[2, 303016], event_file=[1], hid=[28556], modulewise_true_edges=[2, 23804], nhits=[28556], pid=[28556], primary=[28556], pt=[28556], ptr=[2], signal_true_edges=[2, 19430], x=[28556, 3], y=[303016], y_pid=[303016])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0255, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False,  True, False], device='cuda:0'), 'score': tensor([4.5035e-05, 4.4590e-04, 7.5031e-04,  ..., 3.4316e-05, 9.6569e-01,\n",
      "        5.2260e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False,  True, False], device='cuda:0')}\n",
      "event000000143\n",
      "Batch(batch=[22614], cell_data=[22614, 11], edge_index=[2, 195731], event_file=[1], hid=[22614], modulewise_true_edges=[2, 18805], nhits=[22614], pid=[22614], primary=[22614], pt=[22614], ptr=[2], signal_true_edges=[2, 15270], x=[22614, 3], y=[195731], y_pid=[195731])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0278, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([8.7758e-04, 2.3271e-05, 1.1501e-04,  ..., 6.4109e-05, 1.1227e-02,\n",
      "        7.1506e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010144\n",
      "Batch(batch=[24296], cell_data=[24296, 11], edge_index=[2, 223746], event_file=[1], hid=[24296], modulewise_true_edges=[2, 20211], nhits=[24296], pid=[24296], primary=[24296], pt=[24296], ptr=[2], signal_true_edges=[2, 16413], x=[24296, 3], y=[223746], y_pid=[223746])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0265, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([0.0009, 0.0006, 0.0002,  ..., 0.0003, 0.0057, 0.0002], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010145\n",
      "Batch(batch=[25526], cell_data=[25526, 11], edge_index=[2, 243679], event_file=[1], hid=[25526], modulewise_true_edges=[2, 21232], nhits=[25526], pid=[25526], primary=[25526], pt=[25526], ptr=[2], signal_true_edges=[2, 17374], x=[25526, 3], y=[243679], y_pid=[243679])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0263, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.8485e-04, 7.9807e-04, 3.3951e-02,  ..., 5.9222e-05, 4.9687e-01,\n",
      "        1.3045e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000146\n",
      "Batch(batch=[25880], cell_data=[25880, 11], edge_index=[2, 254895], event_file=[1], hid=[25880], modulewise_true_edges=[2, 21556], nhits=[25880], pid=[25880], primary=[25880], pt=[25880], ptr=[2], signal_true_edges=[2, 17553], x=[25880, 3], y=[254895], y_pid=[254895])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0279, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.2521e-03, 3.7544e-02, 1.5892e-04,  ..., 2.2477e-05, 2.7359e-01,\n",
      "        2.6250e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000147\n",
      "Batch(batch=[21202], cell_data=[21202, 11], edge_index=[2, 171785], event_file=[1], hid=[21202], modulewise_true_edges=[2, 17652], nhits=[21202], pid=[21202], primary=[21202], pt=[21202], ptr=[2], signal_true_edges=[2, 14222], x=[21202, 3], y=[171785], y_pid=[171785])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0280, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([6.8488e-03, 8.3692e-03, 4.6997e-05,  ..., 4.9232e-05, 4.4248e-05,\n",
      "        6.3928e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010148\n",
      "Batch(batch=[29037], cell_data=[29037, 11], edge_index=[2, 318205], event_file=[1], hid=[29037], modulewise_true_edges=[2, 24209], nhits=[29037], pid=[29037], primary=[29037], pt=[29037], ptr=[2], signal_true_edges=[2, 20010], x=[29037, 3], y=[318205], y_pid=[318205])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0256, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([6.7706e-05, 5.6242e-05, 4.6073e-05,  ..., 2.3813e-05, 5.9344e-05,\n",
      "        3.1122e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000149\n",
      "Batch(batch=[21701], cell_data=[21701, 11], edge_index=[2, 181504], event_file=[1], hid=[21701], modulewise_true_edges=[2, 18077], nhits=[21701], pid=[21701], primary=[21701], pt=[21701], ptr=[2], signal_true_edges=[2, 14450], x=[21701, 3], y=[181504], y_pid=[181504])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0287, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.1605e-05, 1.1624e-03, 9.8189e-05,  ..., 5.5554e-05, 3.3069e-05,\n",
      "        1.6466e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010150\n",
      "Batch(batch=[21804], cell_data=[21804, 11], edge_index=[2, 184463], event_file=[1], hid=[21804], modulewise_true_edges=[2, 18095], nhits=[21804], pid=[21804], primary=[21804], pt=[21804], ptr=[2], signal_true_edges=[2, 14643], x=[21804, 3], y=[184463], y_pid=[184463])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0280, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.5664e-03, 5.2227e-04, 3.0287e-04,  ..., 1.0678e-01, 4.6695e-04,\n",
      "        4.6649e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000151\n",
      "Batch(batch=[22327], cell_data=[22327, 11], edge_index=[2, 190444], event_file=[1], hid=[22327], modulewise_true_edges=[2, 18654], nhits=[22327], pid=[22327], primary=[22327], pt=[22327], ptr=[2], signal_true_edges=[2, 15558], x=[22327, 3], y=[190444], y_pid=[190444])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0256, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([1.2926e-04, 1.6860e-02, 4.6671e-04,  ..., 9.5122e-01, 3.5541e-05,\n",
      "        3.0695e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ...,  True, False, False], device='cuda:0')}\n",
      "event000000152\n",
      "Batch(batch=[23990], cell_data=[23990, 11], edge_index=[2, 219116], event_file=[1], hid=[23990], modulewise_true_edges=[2, 20024], nhits=[23990], pid=[23990], primary=[23990], pt=[23990], ptr=[2], signal_true_edges=[2, 16117], x=[23990, 3], y=[219116], y_pid=[219116])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0290, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.1302e-04, 6.7912e-03, 3.4995e-02,  ..., 8.3801e-05, 3.9479e-05,\n",
      "        1.5449e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000153\n",
      "Batch(batch=[24610], cell_data=[24610, 11], edge_index=[2, 229979], event_file=[1], hid=[24610], modulewise_true_edges=[2, 20526], nhits=[24610], pid=[24610], primary=[24610], pt=[24610], ptr=[2], signal_true_edges=[2, 16911], x=[24610, 3], y=[229979], y_pid=[229979])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0276, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([8.4963e-02, 1.3894e-03, 3.4503e-04,  ..., 2.0279e-05, 4.3114e-05,\n",
      "        3.2086e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010154\n",
      "Batch(batch=[21712], cell_data=[21712, 11], edge_index=[2, 184279], event_file=[1], hid=[21712], modulewise_true_edges=[2, 18133], nhits=[21712], pid=[21712], primary=[21712], pt=[21712], ptr=[2], signal_true_edges=[2, 14841], x=[21712, 3], y=[184279], y_pid=[184279])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0285, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.3179e-05, 1.1667e-05, 2.0778e-03,  ..., 4.0241e-05, 1.2057e-04,\n",
      "        4.5002e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000155\n",
      "Batch(batch=[23766], cell_data=[23766, 11], edge_index=[2, 213727], event_file=[1], hid=[23766], modulewise_true_edges=[2, 19847], nhits=[23766], pid=[23766], primary=[23766], pt=[23766], ptr=[2], signal_true_edges=[2, 15966], x=[23766, 3], y=[213727], y_pid=[213727])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0283, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.5380e-01, 5.1274e-02, 5.0234e-03,  ..., 3.4270e-05, 4.4856e-05,\n",
      "        3.9643e-01], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010156\n",
      "Batch(batch=[24395], cell_data=[24395, 11], edge_index=[2, 228049], event_file=[1], hid=[24395], modulewise_true_edges=[2, 20308], nhits=[24395], pid=[24395], primary=[24395], pt=[24395], ptr=[2], signal_true_edges=[2, 16898], x=[24395, 3], y=[228049], y_pid=[228049])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0274, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.2100e-05, 3.2618e-05, 3.8295e-06,  ..., 1.2927e-02, 3.0609e-04,\n",
      "        3.9196e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ...,  True, False, False], device='cuda:0')}\n",
      "event000000157\n",
      "Batch(batch=[22045], cell_data=[22045, 11], edge_index=[2, 186515], event_file=[1], hid=[22045], modulewise_true_edges=[2, 18325], nhits=[22045], pid=[22045], primary=[22045], pt=[22045], ptr=[2], signal_true_edges=[2, 14831], x=[22045, 3], y=[186515], y_pid=[186515])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0275, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.7883e-04, 3.1580e-04, 3.2030e-03,  ..., 5.5256e-05, 4.3350e-05,\n",
      "        2.3795e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010158\n",
      "Batch(batch=[24891], cell_data=[24891, 11], edge_index=[2, 237702], event_file=[1], hid=[24891], modulewise_true_edges=[2, 20779], nhits=[24891], pid=[24891], primary=[24891], pt=[24891], ptr=[2], signal_true_edges=[2, 16806], x=[24891, 3], y=[237702], y_pid=[237702])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0279, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([5.1875e-05, 6.3169e-04, 4.9292e-04,  ..., 8.4040e-05, 2.0093e-04,\n",
      "        1.0670e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010159\n",
      "Batch(batch=[24036], cell_data=[24036, 11], edge_index=[2, 225465], event_file=[1], hid=[24036], modulewise_true_edges=[2, 20068], nhits=[24036], pid=[24036], primary=[24036], pt=[24036], ptr=[2], signal_true_edges=[2, 16066], x=[24036, 3], y=[225465], y_pid=[225465])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0278, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([0.0001, 0.1035, 0.0001,  ..., 0.0003, 0.0002, 0.0023], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010160\n",
      "Batch(batch=[21409], cell_data=[21409, 11], edge_index=[2, 178497], event_file=[1], hid=[21409], modulewise_true_edges=[2, 17868], nhits=[21409], pid=[21409], primary=[21409], pt=[21409], ptr=[2], signal_true_edges=[2, 14381], x=[21409, 3], y=[178497], y_pid=[178497])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0293, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.9257e-05, 6.5575e-03, 1.2181e-05,  ..., 4.3502e-05, 2.5626e-04,\n",
      "        2.2689e-03], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010161\n",
      "Batch(batch=[22094], cell_data=[22094, 11], edge_index=[2, 191449], event_file=[1], hid=[22094], modulewise_true_edges=[2, 18410], nhits=[22094], pid=[22094], primary=[22094], pt=[22094], ptr=[2], signal_true_edges=[2, 14755], x=[22094, 3], y=[191449], y_pid=[191449])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0289, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.0951e-03, 2.8288e-05, 1.1236e-05,  ..., 6.2228e-05, 2.6809e-04,\n",
      "        1.9810e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010162\n",
      "Batch(batch=[21945], cell_data=[21945, 11], edge_index=[2, 183646], event_file=[1], hid=[21945], modulewise_true_edges=[2, 18299], nhits=[21945], pid=[21945], primary=[21945], pt=[21945], ptr=[2], signal_true_edges=[2, 15043], x=[21945, 3], y=[183646], y_pid=[183646])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0293, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.1246e-04, 2.6438e-05, 2.0487e-04,  ..., 2.3884e-03, 1.4630e-04,\n",
      "        5.5985e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000163\n",
      "Batch(batch=[21967], cell_data=[21967, 11], edge_index=[2, 185328], event_file=[1], hid=[21967], modulewise_true_edges=[2, 18369], nhits=[21967], pid=[21967], primary=[21967], pt=[21967], ptr=[2], signal_true_edges=[2, 15039], x=[21967, 3], y=[185328], y_pid=[185328])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0320, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.2196e-04, 9.2191e-04, 7.8292e-05,  ..., 9.7486e-05, 2.3100e-03,\n",
      "        2.7568e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000164\n",
      "Batch(batch=[26030], cell_data=[26030, 11], edge_index=[2, 256267], event_file=[1], hid=[26030], modulewise_true_edges=[2, 21782], nhits=[26030], pid=[26030], primary=[26030], pt=[26030], ptr=[2], signal_true_edges=[2, 17623], x=[26030, 3], y=[256267], y_pid=[256267])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0277, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([7.8929e-05, 1.1252e-05, 1.3028e-05,  ..., 3.4828e-04, 1.3423e-04,\n",
      "        1.2071e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010165\n",
      "Batch(batch=[26615], cell_data=[26615, 11], edge_index=[2, 263973], event_file=[1], hid=[26615], modulewise_true_edges=[2, 22218], nhits=[26615], pid=[26615], primary=[26615], pt=[26615], ptr=[2], signal_true_edges=[2, 18242], x=[26615, 3], y=[263973], y_pid=[263973])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0255, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.2101e-03, 4.2542e-03, 5.5475e-05,  ..., 2.9224e-05, 2.1648e-04,\n",
      "        5.3270e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000166\n",
      "Batch(batch=[23990], cell_data=[23990, 11], edge_index=[2, 216540], event_file=[1], hid=[23990], modulewise_true_edges=[2, 20015], nhits=[23990], pid=[23990], primary=[23990], pt=[23990], ptr=[2], signal_true_edges=[2, 16471], x=[23990, 3], y=[216540], y_pid=[216540])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0268, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([3.0038e-05, 1.6194e-04, 2.4803e-03,  ..., 9.8249e-01, 7.3784e-05,\n",
      "        1.5567e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ...,  True, False, False], device='cuda:0')}\n",
      "event000000167\n",
      "Batch(batch=[18818], cell_data=[18818, 11], edge_index=[2, 140604], event_file=[1], hid=[18818], modulewise_true_edges=[2, 15683], nhits=[18818], pid=[18818], primary=[18818], pt=[18818], ptr=[2], signal_true_edges=[2, 12949], x=[18818, 3], y=[140604], y_pid=[140604])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0298, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.9511e-03, 6.9441e-03, 7.0311e-03,  ..., 8.0280e-05, 3.6222e-05,\n",
      "        3.5295e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010168\n",
      "Batch(batch=[24048], cell_data=[24048, 11], edge_index=[2, 220810], event_file=[1], hid=[24048], modulewise_true_edges=[2, 20124], nhits=[24048], pid=[24048], primary=[24048], pt=[24048], ptr=[2], signal_true_edges=[2, 16349], x=[24048, 3], y=[220810], y_pid=[220810])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0288, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.9676e-04, 8.0016e-05, 1.1795e-05,  ..., 6.3407e-05, 8.5846e-05,\n",
      "        4.9635e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010169\n",
      "Batch(batch=[19165], cell_data=[19165, 11], edge_index=[2, 146042], event_file=[1], hid=[19165], modulewise_true_edges=[2, 16036], nhits=[19165], pid=[19165], primary=[19165], pt=[19165], ptr=[2], signal_true_edges=[2, 13080], x=[19165, 3], y=[146042], y_pid=[146042])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0287, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.9261e-03, 9.9931e-05, 1.7791e-04,  ..., 5.0335e-05, 5.1381e-05,\n",
      "        9.3331e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010170\n",
      "Batch(batch=[25082], cell_data=[25082, 11], edge_index=[2, 236686], event_file=[1], hid=[25082], modulewise_true_edges=[2, 20928], nhits=[25082], pid=[25082], primary=[25082], pt=[25082], ptr=[2], signal_true_edges=[2, 16923], x=[25082, 3], y=[236686], y_pid=[236686])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0281, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.0759e-05, 9.8052e-02, 6.6071e-03,  ..., 1.7775e-03, 4.3118e-04,\n",
      "        1.2438e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000171\n",
      "Batch(batch=[22044], cell_data=[22044, 11], edge_index=[2, 185534], event_file=[1], hid=[22044], modulewise_true_edges=[2, 18407], nhits=[22044], pid=[22044], primary=[22044], pt=[22044], ptr=[2], signal_true_edges=[2, 15320], x=[22044, 3], y=[185534], y_pid=[185534])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0262, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([2.4450e-02, 8.6181e-05, 2.3460e-02,  ..., 9.6130e-01, 4.4745e-04,\n",
      "        7.8622e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ...,  True, False, False], device='cuda:0')}\n",
      "event000000172\n",
      "Batch(batch=[21109], cell_data=[21109, 11], edge_index=[2, 175965], event_file=[1], hid=[21109], modulewise_true_edges=[2, 17658], nhits=[21109], pid=[21109], primary=[21109], pt=[21109], ptr=[2], signal_true_edges=[2, 14241], x=[21109, 3], y=[175965], y_pid=[175965])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0298, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False,  True, False], device='cuda:0'), 'score': tensor([1.9639e-05, 3.2927e-03, 1.5676e-03,  ..., 1.8737e-04, 8.7674e-01,\n",
      "        1.0207e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010173\n",
      "Batch(batch=[27265], cell_data=[27265, 11], edge_index=[2, 285405], event_file=[1], hid=[27265], modulewise_true_edges=[2, 22748], nhits=[27265], pid=[27265], primary=[27265], pt=[27265], ptr=[2], signal_true_edges=[2, 18348], x=[27265, 3], y=[285405], y_pid=[285405])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0273, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False,  True,  True], device='cuda:0'), 'score': tensor([4.1624e-05, 3.2465e-04, 8.2459e-05,  ..., 2.6239e-05, 9.8907e-01,\n",
      "        9.7327e-01], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False,  True,  True], device='cuda:0')}\n",
      "event000000174\n",
      "Batch(batch=[25500], cell_data=[25500, 11], edge_index=[2, 242646], event_file=[1], hid=[25500], modulewise_true_edges=[2, 21184], nhits=[25500], pid=[25500], primary=[25500], pt=[25500], ptr=[2], signal_true_edges=[2, 17100], x=[25500, 3], y=[242646], y_pid=[242646])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0268, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([5.4839e-03, 8.0450e-03, 4.6596e-05,  ..., 6.2179e-04, 6.0752e-05,\n",
      "        7.7638e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000175\n",
      "Batch(batch=[19472], cell_data=[19472, 11], edge_index=[2, 149459], event_file=[1], hid=[19472], modulewise_true_edges=[2, 16143], nhits=[19472], pid=[19472], primary=[19472], pt=[19472], ptr=[2], signal_true_edges=[2, 12975], x=[19472, 3], y=[149459], y_pid=[149459])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0288, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.4592e-03, 1.0340e-02, 2.7190e-04,  ..., 9.1478e-02, 3.5719e-04,\n",
      "        4.3448e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000176\n",
      "Batch(batch=[28992], cell_data=[28992, 11], edge_index=[2, 313013], event_file=[1], hid=[28992], modulewise_true_edges=[2, 24175], nhits=[28992], pid=[28992], primary=[28992], pt=[28992], ptr=[2], signal_true_edges=[2, 19701], x=[28992, 3], y=[313013], y_pid=[313013])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0256, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False,  True, False], device='cuda:0'), 'score': tensor([6.0759e-05, 1.4056e-04, 3.0133e-05,  ..., 1.1607e-04, 9.8359e-01,\n",
      "        5.6631e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False,  True, False], device='cuda:0')}\n",
      "event000000177\n",
      "Batch(batch=[28621], cell_data=[28621, 11], edge_index=[2, 305901], event_file=[1], hid=[28621], modulewise_true_edges=[2, 23864], nhits=[28621], pid=[28621], primary=[28621], pt=[28621], ptr=[2], signal_true_edges=[2, 19436], x=[28621, 3], y=[305901], y_pid=[305901])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0261, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False,  True, False], device='cuda:0'), 'score': tensor([4.4785e-05, 2.0683e-05, 5.7477e-05,  ..., 1.1321e-04, 9.6897e-01,\n",
      "        5.6181e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False,  True, False], device='cuda:0')}\n",
      "event000000178\n",
      "Batch(batch=[26291], cell_data=[26291, 11], edge_index=[2, 261504], event_file=[1], hid=[26291], modulewise_true_edges=[2, 21874], nhits=[26291], pid=[26291], primary=[26291], pt=[26291], ptr=[2], signal_true_edges=[2, 18057], x=[26291, 3], y=[261504], y_pid=[261504])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0272, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([6.1517e-05, 4.5783e-05, 2.2114e-05,  ..., 5.0539e-05, 7.6098e-02,\n",
      "        5.4320e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000179\n",
      "Batch(batch=[21776], cell_data=[21776, 11], edge_index=[2, 187209], event_file=[1], hid=[21776], modulewise_true_edges=[2, 18166], nhits=[21776], pid=[21776], primary=[21776], pt=[21776], ptr=[2], signal_true_edges=[2, 14647], x=[21776, 3], y=[187209], y_pid=[187209])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0266, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.9320e-04, 1.2029e-04, 4.6774e-04,  ..., 2.1659e-05, 1.7823e-04,\n",
      "        3.2409e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010180\n",
      "Batch(batch=[19353], cell_data=[19353, 11], edge_index=[2, 147811], event_file=[1], hid=[19353], modulewise_true_edges=[2, 16168], nhits=[19353], pid=[19353], primary=[19353], pt=[19353], ptr=[2], signal_true_edges=[2, 12975], x=[19353, 3], y=[147811], y_pid=[147811])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0302, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([1.5250e-03, 2.0158e-04, 3.7291e-03,  ..., 9.6390e-01, 8.9069e-05,\n",
      "        1.0101e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000000181\n",
      "Batch(batch=[18559], cell_data=[18559, 11], edge_index=[2, 134555], event_file=[1], hid=[18559], modulewise_true_edges=[2, 15464], nhits=[18559], pid=[18559], primary=[18559], pt=[18559], ptr=[2], signal_true_edges=[2, 12558], x=[18559, 3], y=[134555], y_pid=[134555])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0312, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.6839e-05, 9.0052e-04, 3.0269e-03,  ..., 4.4498e-04, 3.1657e-03,\n",
      "        2.0060e-03], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010182\n",
      "Batch(batch=[24152], cell_data=[24152, 11], edge_index=[2, 225351], event_file=[1], hid=[24152], modulewise_true_edges=[2, 20148], nhits=[24152], pid=[24152], primary=[24152], pt=[24152], ptr=[2], signal_true_edges=[2, 16551], x=[24152, 3], y=[225351], y_pid=[225351])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0262, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.2800e-04, 1.4228e-04, 2.8483e-05,  ..., 4.3819e-04, 1.1565e-04,\n",
      "        1.3990e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010183\n",
      "Batch(batch=[20888], cell_data=[20888, 11], edge_index=[2, 177182], event_file=[1], hid=[20888], modulewise_true_edges=[2, 17456], nhits=[20888], pid=[20888], primary=[20888], pt=[20888], ptr=[2], signal_true_edges=[2, 14211], x=[20888, 3], y=[177182], y_pid=[177182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0279, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.9609e-02, 2.7642e-03, 2.5132e-03,  ..., 7.0621e-05, 6.8549e-05,\n",
      "        3.9951e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010184\n",
      "Batch(batch=[20897], cell_data=[20897, 11], edge_index=[2, 171570], event_file=[1], hid=[20897], modulewise_true_edges=[2, 17476], nhits=[20897], pid=[20897], primary=[20897], pt=[20897], ptr=[2], signal_true_edges=[2, 14282], x=[20897, 3], y=[171570], y_pid=[171570])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0288, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False,  True, False], device='cuda:0'), 'score': tensor([2.5621e-05, 1.7640e-03, 7.4631e-04,  ..., 2.2852e-05, 9.9012e-01,\n",
      "        2.7526e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False,  True, False], device='cuda:0')}\n",
      "event000010185\n",
      "Batch(batch=[22861], cell_data=[22861, 11], edge_index=[2, 201583], event_file=[1], hid=[22861], modulewise_true_edges=[2, 19128], nhits=[22861], pid=[22861], primary=[22861], pt=[22861], ptr=[2], signal_true_edges=[2, 15573], x=[22861, 3], y=[201583], y_pid=[201583])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0291, device='cuda:0'), 'preds': tensor([False, False, False,  ...,  True, False, False], device='cuda:0'), 'score': tensor([1.3035e-03, 1.0984e-02, 1.7737e-02,  ..., 5.2016e-01, 1.2968e-03,\n",
      "        1.2180e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ...,  True, False, False], device='cuda:0')}\n",
      "event000010186\n",
      "Batch(batch=[20949], cell_data=[20949, 11], edge_index=[2, 170832], event_file=[1], hid=[20949], modulewise_true_edges=[2, 17451], nhits=[20949], pid=[20949], primary=[20949], pt=[20949], ptr=[2], signal_true_edges=[2, 14307], x=[20949, 3], y=[170832], y_pid=[170832])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0301, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([5.2825e-05, 5.0589e-06, 2.3923e-05,  ..., 4.6092e-05, 7.5313e-05,\n",
      "        3.7623e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010187\n",
      "Batch(batch=[22599], cell_data=[22599, 11], edge_index=[2, 199883], event_file=[1], hid=[22599], modulewise_true_edges=[2, 18878], nhits=[22599], pid=[22599], primary=[22599], pt=[22599], ptr=[2], signal_true_edges=[2, 15586], x=[22599, 3], y=[199883], y_pid=[199883])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0266, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.9250e-04, 1.5633e-05, 2.5136e-05,  ..., 2.5498e-05, 6.2169e-05,\n",
      "        3.8308e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010188\n",
      "Batch(batch=[20255], cell_data=[20255, 11], edge_index=[2, 162410], event_file=[1], hid=[20255], modulewise_true_edges=[2, 16937], nhits=[20255], pid=[20255], primary=[20255], pt=[20255], ptr=[2], signal_true_edges=[2, 13838], x=[20255, 3], y=[162410], y_pid=[162410])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0284, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([8.0753e-05, 5.8817e-05, 1.5963e-05,  ..., 8.8803e-05, 1.2826e-04,\n",
      "        2.2728e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010189\n",
      "Batch(batch=[18642], cell_data=[18642, 11], edge_index=[2, 139495], event_file=[1], hid=[18642], modulewise_true_edges=[2, 15558], nhits=[18642], pid=[18642], primary=[18642], pt=[18642], ptr=[2], signal_true_edges=[2, 12575], x=[18642, 3], y=[139495], y_pid=[139495])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0283, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False,  True, False], device='cuda:0'), 'score': tensor([3.9038e-05, 3.4212e-05, 3.7444e-05,  ..., 2.4208e-05, 8.0125e-01,\n",
      "        3.8291e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False,  True, False], device='cuda:0')}\n",
      "event000010190\n",
      "Batch(batch=[19746], cell_data=[19746, 11], edge_index=[2, 151553], event_file=[1], hid=[19746], modulewise_true_edges=[2, 16439], nhits=[19746], pid=[19746], primary=[19746], pt=[19746], ptr=[2], signal_true_edges=[2, 13442], x=[19746, 3], y=[151553], y_pid=[151553])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0291, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.7727e-02, 9.2097e-03, 9.2384e-05,  ..., 6.8048e-05, 3.6769e-05,\n",
      "        4.7552e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010191\n",
      "Batch(batch=[25071], cell_data=[25071, 11], edge_index=[2, 235671], event_file=[1], hid=[25071], modulewise_true_edges=[2, 20878], nhits=[25071], pid=[25071], primary=[25071], pt=[25071], ptr=[2], signal_true_edges=[2, 17070], x=[25071, 3], y=[235671], y_pid=[235671])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0266, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.1352e-04, 2.8451e-04, 1.4616e-04,  ..., 2.2116e-05, 2.5532e-05,\n",
      "        3.7846e-01], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010192\n",
      "Batch(batch=[25233], cell_data=[25233, 11], edge_index=[2, 243718], event_file=[1], hid=[25233], modulewise_true_edges=[2, 21059], nhits=[25233], pid=[25233], primary=[25233], pt=[25233], ptr=[2], signal_true_edges=[2, 17014], x=[25233, 3], y=[243718], y_pid=[243718])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0265, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([7.7452e-02, 1.7562e-02, 1.0309e-04,  ..., 4.9020e-05, 4.7171e-05,\n",
      "        2.6958e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010193\n",
      "Batch(batch=[25609], cell_data=[25609, 11], edge_index=[2, 247034], event_file=[1], hid=[25609], modulewise_true_edges=[2, 21389], nhits=[25609], pid=[25609], primary=[25609], pt=[25609], ptr=[2], signal_true_edges=[2, 17570], x=[25609, 3], y=[247034], y_pid=[247034])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0266, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.0720e-05, 2.8929e-03, 1.7065e-03,  ..., 2.7835e-05, 2.5893e-05,\n",
      "        1.9524e-01], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010194\n",
      "Batch(batch=[25504], cell_data=[25504, 11], edge_index=[2, 243823], event_file=[1], hid=[25504], modulewise_true_edges=[2, 21226], nhits=[25504], pid=[25504], primary=[25504], pt=[25504], ptr=[2], signal_true_edges=[2, 17115], x=[25504, 3], y=[243823], y_pid=[243823])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0276, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([3.9302e-05, 3.1778e-04, 3.2147e-05,  ..., 2.1247e-05, 1.5442e-05,\n",
      "        2.7480e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010195\n",
      "Batch(batch=[24671], cell_data=[24671, 11], edge_index=[2, 234030], event_file=[1], hid=[24671], modulewise_true_edges=[2, 20604], nhits=[24671], pid=[24671], primary=[24671], pt=[24671], ptr=[2], signal_true_edges=[2, 16753], x=[24671, 3], y=[234030], y_pid=[234030])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0265, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([4.0506e-04, 4.3564e-05, 2.6988e-05,  ..., 5.6897e-05, 2.9755e-05,\n",
      "        3.9353e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010196\n",
      "Batch(batch=[27572], cell_data=[27572, 11], edge_index=[2, 283056], event_file=[1], hid=[27572], modulewise_true_edges=[2, 23018], nhits=[27572], pid=[27572], primary=[27572], pt=[27572], ptr=[2], signal_true_edges=[2, 18503], x=[27572, 3], y=[283056], y_pid=[283056])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0269, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([9.4377e-03, 2.2092e-02, 5.9347e-02,  ..., 1.8834e-04, 5.4948e-05,\n",
      "        4.6814e-01], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010197\n",
      "Batch(batch=[24538], cell_data=[24538, 11], edge_index=[2, 228165], event_file=[1], hid=[24538], modulewise_true_edges=[2, 20463], nhits=[24538], pid=[24538], primary=[24538], pt=[24538], ptr=[2], signal_true_edges=[2, 16808], x=[24538, 3], y=[228165], y_pid=[228165])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0261, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([8.1559e-05, 1.0506e-04, 2.2779e-04,  ..., 2.2130e-04, 1.1408e-04,\n",
      "        4.9012e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010198\n",
      "Batch(batch=[21515], cell_data=[21515, 11], edge_index=[2, 181244], event_file=[1], hid=[21515], modulewise_true_edges=[2, 17959], nhits=[21515], pid=[21515], primary=[21515], pt=[21515], ptr=[2], signal_true_edges=[2, 14493], x=[21515, 3], y=[181244], y_pid=[181244])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0279, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([1.8192e-03, 4.0027e-03, 2.5388e-04,  ..., 2.1401e-05, 4.9649e-05,\n",
      "        5.2289e-05], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010199\n",
      "Batch(batch=[25595], cell_data=[25595, 11], edge_index=[2, 246318], event_file=[1], hid=[25595], modulewise_true_edges=[2, 21413], nhits=[25595], pid=[25595], primary=[25595], pt=[25595], ptr=[2], signal_true_edges=[2, 17466], x=[25595, 3], y=[246318], y_pid=[246318])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.0265, device='cuda:0'), 'preds': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'score': tensor([2.8601e-05, 3.3959e-04, 3.5899e-05,  ..., 3.4032e-03, 2.2949e-04,\n",
      "        5.2252e-04], device='cuda:0'), 'truth': tensor([False, False, False,  ..., False, False, False], device='cuda:0')}\n",
      "event000010200\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in model.train_dataloader():\n",
    "\n",
    "        print(batch)\n",
    "\n",
    "        output = model.shared_evaluation(batch.to(device), 0, log=False)\n",
    "\n",
    "        print(output)\n",
    "        print(os.path.split(batch.event_file[0])[-1])\n",
    "\n",
    "        gnn_results = np.vstack(\n",
    "            [\n",
    "                batch.edge_index.cpu().numpy(),\n",
    "                output[\"score\"][: int(len(output[\"score\"]) / 2)].cpu().numpy(),\n",
    "                output[\"truth\"].cpu().numpy(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        gnn_recarray = np.rec.fromarrays(\n",
    "            gnn_results, names=[\"senders\", \"receivers\", \"score\", \"truth\"]\n",
    "        )\n",
    "\n",
    "        with open(\n",
    "            os.path.join(\n",
    "                output_dir, os.path.split(batch.event_file[0])[-1][-4:] + \".npz\"\n",
    "            ),\n",
    "            \"wb\",\n",
    "        ) as f:\n",
    "            np.save(f, gnn_recarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/global/cfs/cdirs/m3443/data/lightning_models/lightning_checkpoints/ITk_0.5GeV_Barrel_GNN/dzk1s8aq/checkpoints/epoch=44-step=29148.ckpt\"\n",
    "# checkpoint_path = \"/global/cfs/cdirs/m3443/data/lightning_models/lightning_checkpoints/ITk_0.5GeV_Barrel_GNN/jrqroc1z/checkpoints/epoch=71-step=27808.ckpt\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "model = CheckpointedPyramid.load_from_checkpoint(checkpoint_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up dataset\n",
      "Loading events\n",
      "Events loaded!\n",
      "Events processed!\n",
      "Loading events\n",
      "Events loaded!\n",
      "Events processed!\n",
      "Loading events\n",
      "Events loaded!\n",
      "Events processed!\n"
     ]
    }
   ],
   "source": [
    "model.hparams[\"datatype_split\"] = [10, 1, 1]\n",
    "model.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "def tracks_from_gnn(\n",
    "    hit_id,\n",
    "    score,\n",
    "    senders,\n",
    "    receivers,\n",
    "    edge_score_cut=0.0,\n",
    "    epsilon=0.25,\n",
    "    min_samples=2,\n",
    "    **kwargs\n",
    "):\n",
    "\n",
    "    n_nodes = hit_id.shape[0]\n",
    "    if edge_score_cut > 0:\n",
    "        cuts = score > edge_score_cut\n",
    "        score, senders, receivers = score[cuts], senders[cuts], receivers[cuts]\n",
    "\n",
    "    # prepare the DBSCAN input, which the adjancy matrix with its value being the edge socre.\n",
    "    e_csr = sp.sparse.csr_matrix(\n",
    "        (score, (senders, receivers)), shape=(n_nodes, n_nodes), dtype=np.float32\n",
    "    )\n",
    "    # rescale the duplicated edges\n",
    "    e_csr.data[e_csr.data > 1] = e_csr.data[e_csr.data > 1] / 2.0\n",
    "    # invert to treat score as an inverse distance\n",
    "    e_csr.data = 1 - e_csr.data\n",
    "    # make it symmetric\n",
    "    e_csr_bi = sp.sparse.coo_matrix(\n",
    "        (\n",
    "            np.hstack([e_csr.tocoo().data, e_csr.tocoo().data]),\n",
    "            np.hstack(\n",
    "                [\n",
    "                    np.vstack([e_csr.tocoo().row, e_csr.tocoo().col]),\n",
    "                    np.vstack([e_csr.tocoo().col, e_csr.tocoo().row]),\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # DBSCAN get track candidates\n",
    "    clustering = DBSCAN(\n",
    "        eps=epsilon, metric=\"precomputed\", min_samples=min_samples\n",
    "    ).fit_predict(e_csr_bi)\n",
    "    track_labels = np.vstack(\n",
    "        [np.unique(e_csr_bi.tocoo().row), clustering[np.unique(e_csr_bi.tocoo().row)]]\n",
    "    )\n",
    "    track_labels = pd.DataFrame(track_labels.T)\n",
    "    track_labels.columns = [\"hit_id\", \"track_id\"]\n",
    "    new_hit_id = np.apply_along_axis(lambda x: hit_id[x], 0, track_labels.hit_id.values)\n",
    "    tracks = pd.DataFrame.from_dict(\n",
    "        {\"hit_id\": new_hit_id, \"track_id\": track_labels.track_id}\n",
    "    )\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = model.valset[0].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    results = model.shared_evaluation(sample.to(device), 0, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = results[\"score\"][: int(len(results[\"score\"]) / 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:199: EfficiencyWarning: Precomputed sparse input was not sorted by data.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reconstructed = tracks_from_gnn(\n",
    "    sample.hid,\n",
    "    preds.cpu().numpy(),\n",
    "    sample.edge_index[0],\n",
    "    sample.edge_index[1],\n",
    "    epsilon=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Debug!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/project/projectdirs/m3443/data/ITk-upgrade/processed/full_events_v4/event000010320'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.event_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:199: EfficiencyWarning: Precomputed sparse input was not sorted by data.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reconstructed = tracks_from_gnn(\n",
    "    sample.hid,\n",
    "    sample.y_pid.float().cpu(),\n",
    "    sample.edge_index[0],\n",
    "    sample.edge_index[1],\n",
    "    epsilon=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:199: EfficiencyWarning: Precomputed sparse input was not sorted by data.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reconstructed = tracks_from_gnn(\n",
    "    sample.hid,\n",
    "    sample.y.float().cpu(),\n",
    "    sample.edge_index[0],\n",
    "    sample.edge_index[1],\n",
    "    epsilon=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds = results[\"score\"][: int(len(results[\"score\"]) / 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:199: EfficiencyWarning: Precomputed sparse input was not sorted by data.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reconstructed = tracks_from_gnn(\n",
    "    sample.hid,\n",
    "    preds.cpu().numpy(),\n",
    "    sample.edge_index[0],\n",
    "    sample.edge_index[1],\n",
    "    epsilon=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3060"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reconstructed.track_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hit_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cluster_index_1</th>\n",
       "      <th>cluster_index_2</th>\n",
       "      <th>particle_id</th>\n",
       "      <th>hardware</th>\n",
       "      <th>cluster_x_1</th>\n",
       "      <th>cluster_y_1</th>\n",
       "      <th>...</th>\n",
       "      <th>phi_angle_1</th>\n",
       "      <th>norm_x</th>\n",
       "      <th>norm_y</th>\n",
       "      <th>norm_z_1</th>\n",
       "      <th>cluster_x_2</th>\n",
       "      <th>cluster_y_2</th>\n",
       "      <th>cluster_z_2</th>\n",
       "      <th>eta_angle_2</th>\n",
       "      <th>phi_angle_2</th>\n",
       "      <th>norm_z_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-48.2613</td>\n",
       "      <td>-15.05020</td>\n",
       "      <td>-263.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>14550000033</td>\n",
       "      <td>PIXEL</td>\n",
       "      <td>-48.2613</td>\n",
       "      <td>-15.05020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-53.5710</td>\n",
       "      <td>-13.59470</td>\n",
       "      <td>-263.00</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>16300000987</td>\n",
       "      <td>PIXEL</td>\n",
       "      <td>-53.5710</td>\n",
       "      <td>-13.59470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-38.5103</td>\n",
       "      <td>-4.58297</td>\n",
       "      <td>-263.00</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>PIXEL</td>\n",
       "      <td>-38.5103</td>\n",
       "      <td>-4.58297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-52.1110</td>\n",
       "      <td>-12.55960</td>\n",
       "      <td>-263.00</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>PIXEL</td>\n",
       "      <td>-52.1110</td>\n",
       "      <td>-12.55960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-45.5552</td>\n",
       "      <td>-17.87730</td>\n",
       "      <td>-263.00</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>PIXEL</td>\n",
       "      <td>-45.5552</td>\n",
       "      <td>-17.87730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287959</th>\n",
       "      <td>286626</td>\n",
       "      <td>896.4170</td>\n",
       "      <td>-128.11900</td>\n",
       "      <td>2854.25</td>\n",
       "      <td>406990</td>\n",
       "      <td>406997</td>\n",
       "      <td>15050000173</td>\n",
       "      <td>STRIP</td>\n",
       "      <td>878.6620</td>\n",
       "      <td>-125.24100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878.429</td>\n",
       "      <td>-126.863</td>\n",
       "      <td>2860.75</td>\n",
       "      <td>1.32464</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287960</th>\n",
       "      <td>286627</td>\n",
       "      <td>898.4870</td>\n",
       "      <td>-128.45800</td>\n",
       "      <td>2854.25</td>\n",
       "      <td>406990</td>\n",
       "      <td>407001</td>\n",
       "      <td>0</td>\n",
       "      <td>STRIP</td>\n",
       "      <td>878.6620</td>\n",
       "      <td>-125.24100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>928.314</td>\n",
       "      <td>-132.368</td>\n",
       "      <td>2860.75</td>\n",
       "      <td>1.32464</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287961</th>\n",
       "      <td>286628</td>\n",
       "      <td>901.3200</td>\n",
       "      <td>-106.77600</td>\n",
       "      <td>2854.25</td>\n",
       "      <td>406991</td>\n",
       "      <td>407002</td>\n",
       "      <td>15310000473</td>\n",
       "      <td>STRIP</td>\n",
       "      <td>931.1220</td>\n",
       "      <td>-110.91000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>931.278</td>\n",
       "      <td>-109.593</td>\n",
       "      <td>2860.75</td>\n",
       "      <td>1.11586</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287962</th>\n",
       "      <td>286629</td>\n",
       "      <td>901.9050</td>\n",
       "      <td>-129.09600</td>\n",
       "      <td>2854.25</td>\n",
       "      <td>406994</td>\n",
       "      <td>407001</td>\n",
       "      <td>14610000680</td>\n",
       "      <td>STRIP</td>\n",
       "      <td>928.1680</td>\n",
       "      <td>-133.38800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>928.314</td>\n",
       "      <td>-132.368</td>\n",
       "      <td>2860.75</td>\n",
       "      <td>1.32464</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287963</th>\n",
       "      <td>286630</td>\n",
       "      <td>949.0630</td>\n",
       "      <td>-177.61200</td>\n",
       "      <td>2854.25</td>\n",
       "      <td>406995</td>\n",
       "      <td>407000</td>\n",
       "      <td>15760001263</td>\n",
       "      <td>STRIP</td>\n",
       "      <td>921.8010</td>\n",
       "      <td>-171.96200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>921.403</td>\n",
       "      <td>-174.083</td>\n",
       "      <td>2860.75</td>\n",
       "      <td>1.32464</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286631 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hit_id         x          y        z  cluster_index_1  \\\n",
       "0            0  -48.2613  -15.05020  -263.00                0   \n",
       "1            1  -53.5710  -13.59470  -263.00                1   \n",
       "2            2  -38.5103   -4.58297  -263.00                2   \n",
       "3            3  -52.1110  -12.55960  -263.00                3   \n",
       "4            4  -45.5552  -17.87730  -263.00                4   \n",
       "...        ...       ...        ...      ...              ...   \n",
       "287959  286626  896.4170 -128.11900  2854.25           406990   \n",
       "287960  286627  898.4870 -128.45800  2854.25           406990   \n",
       "287961  286628  901.3200 -106.77600  2854.25           406991   \n",
       "287962  286629  901.9050 -129.09600  2854.25           406994   \n",
       "287963  286630  949.0630 -177.61200  2854.25           406995   \n",
       "\n",
       "        cluster_index_2  particle_id hardware  cluster_x_1  cluster_y_1  ...  \\\n",
       "0                    -1  14550000033    PIXEL     -48.2613    -15.05020  ...   \n",
       "1                    -1  16300000987    PIXEL     -53.5710    -13.59470  ...   \n",
       "2                    -1            0    PIXEL     -38.5103     -4.58297  ...   \n",
       "3                    -1            0    PIXEL     -52.1110    -12.55960  ...   \n",
       "4                    -1            0    PIXEL     -45.5552    -17.87730  ...   \n",
       "...                 ...          ...      ...          ...          ...  ...   \n",
       "287959           406997  15050000173    STRIP     878.6620   -125.24100  ...   \n",
       "287960           407001            0    STRIP     878.6620   -125.24100  ...   \n",
       "287961           407002  15310000473    STRIP     931.1220   -110.91000  ...   \n",
       "287962           407001  14610000680    STRIP     928.1680   -133.38800  ...   \n",
       "287963           407000  15760001263    STRIP     921.8010   -171.96200  ...   \n",
       "\n",
       "        phi_angle_1  norm_x  norm_y  norm_z_1  cluster_x_2  cluster_y_2  \\\n",
       "0          0.982794     0.0     0.0      -1.0       -1.000       -1.000   \n",
       "1          0.982794     0.0     0.0      -1.0       -1.000       -1.000   \n",
       "2          0.982794     0.0     0.0      -1.0       -1.000       -1.000   \n",
       "3          0.982794     0.0     0.0      -1.0       -1.000       -1.000   \n",
       "4          0.982794     0.0     0.0      -1.0       -1.000       -1.000   \n",
       "...             ...     ...     ...       ...          ...          ...   \n",
       "287959     0.006379     0.0     0.0       1.0      878.429     -126.863   \n",
       "287960     0.006379     0.0     0.0       1.0      928.314     -132.368   \n",
       "287961     0.006379     0.0     0.0       1.0      931.278     -109.593   \n",
       "287962     0.006379     0.0     0.0       1.0      928.314     -132.368   \n",
       "287963     0.006402     0.0     0.0       1.0      921.403     -174.083   \n",
       "\n",
       "        cluster_z_2  eta_angle_2  phi_angle_2  norm_z_2  \n",
       "0             -1.00     -1.00000    -1.000000      -1.0  \n",
       "1             -1.00     -1.00000    -1.000000      -1.0  \n",
       "2             -1.00     -1.00000    -1.000000      -1.0  \n",
       "3             -1.00     -1.00000    -1.000000      -1.0  \n",
       "4             -1.00     -1.00000    -1.000000      -1.0  \n",
       "...             ...          ...          ...       ...  \n",
       "287959      2860.75      1.32464     0.006379      -1.0  \n",
       "287960      2860.75      1.32464     0.006379      -1.0  \n",
       "287961      2860.75      1.11586     0.006380      -1.0  \n",
       "287962      2860.75      1.32464     0.006379      -1.0  \n",
       "287963      2860.75      1.32464     0.006379      -1.0  \n",
       "\n",
       "[286631 rows x 26 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79475"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(~particles.particle_id.isin(sample.pid.numpy())).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3647"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isin(np.unique(sample.pid.numpy()), particles.particle_id).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>particle_id</th>\n",
       "      <th>subevent</th>\n",
       "      <th>barcode</th>\n",
       "      <th>px</th>\n",
       "      <th>py</th>\n",
       "      <th>pz</th>\n",
       "      <th>pt</th>\n",
       "      <th>eta</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "      <th>radius</th>\n",
       "      <th>status</th>\n",
       "      <th>charge</th>\n",
       "      <th>pdgId</th>\n",
       "      <th>pass</th>\n",
       "      <th>vProdNIn</th>\n",
       "      <th>vProdNOut</th>\n",
       "      <th>vProdStatus</th>\n",
       "      <th>vProdBarcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>341</td>\n",
       "      <td>0</td>\n",
       "      <td>341</td>\n",
       "      <td>-5358.240</td>\n",
       "      <td>-75545.1000</td>\n",
       "      <td>-75545.1000</td>\n",
       "      <td>75.734900</td>\n",
       "      <td>-2.079050</td>\n",
       "      <td>0.022396</td>\n",
       "      <td>-0.004489</td>\n",
       "      <td>-0.317639</td>\n",
       "      <td>0.022841</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>YES</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>384</td>\n",
       "      <td>-4309.840</td>\n",
       "      <td>1828.0500</td>\n",
       "      <td>1828.0500</td>\n",
       "      <td>4.681510</td>\n",
       "      <td>-0.586767</td>\n",
       "      <td>0.022396</td>\n",
       "      <td>-0.004489</td>\n",
       "      <td>-0.317639</td>\n",
       "      <td>0.022841</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-211</td>\n",
       "      <td>YES</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>-286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>411</td>\n",
       "      <td>0</td>\n",
       "      <td>411</td>\n",
       "      <td>973.045</td>\n",
       "      <td>6355.6900</td>\n",
       "      <td>6355.6900</td>\n",
       "      <td>6.429750</td>\n",
       "      <td>-0.380966</td>\n",
       "      <td>0.022396</td>\n",
       "      <td>-0.004489</td>\n",
       "      <td>-0.317639</td>\n",
       "      <td>0.022841</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-211</td>\n",
       "      <td>YES</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>-298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>412</td>\n",
       "      <td>0</td>\n",
       "      <td>412</td>\n",
       "      <td>-872.362</td>\n",
       "      <td>5241.9500</td>\n",
       "      <td>5241.9500</td>\n",
       "      <td>5.314040</td>\n",
       "      <td>-0.470596</td>\n",
       "      <td>0.022396</td>\n",
       "      <td>-0.004489</td>\n",
       "      <td>-0.317639</td>\n",
       "      <td>0.022841</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>211</td>\n",
       "      <td>YES</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>-298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>414</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>422.775</td>\n",
       "      <td>381.4980</td>\n",
       "      <td>381.4980</td>\n",
       "      <td>0.569455</td>\n",
       "      <td>-0.972907</td>\n",
       "      <td>0.022396</td>\n",
       "      <td>-0.004489</td>\n",
       "      <td>-0.317639</td>\n",
       "      <td>0.022841</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>321</td>\n",
       "      <td>NO</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>-298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90280</th>\n",
       "      <td>69390200062</td>\n",
       "      <td>6939</td>\n",
       "      <td>200062</td>\n",
       "      <td>-919.706</td>\n",
       "      <td>481.3740</td>\n",
       "      <td>481.3740</td>\n",
       "      <td>1.038070</td>\n",
       "      <td>1.854760</td>\n",
       "      <td>-90.222800</td>\n",
       "      <td>52.417200</td>\n",
       "      <td>397.204000</td>\n",
       "      <td>104.344000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2212</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1201</td>\n",
       "      <td>-200056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90311</th>\n",
       "      <td>69390200121</td>\n",
       "      <td>6939</td>\n",
       "      <td>200121</td>\n",
       "      <td>356.238</td>\n",
       "      <td>-544.3130</td>\n",
       "      <td>-544.3130</td>\n",
       "      <td>0.650524</td>\n",
       "      <td>1.187110</td>\n",
       "      <td>11.094400</td>\n",
       "      <td>-21.894300</td>\n",
       "      <td>85.201100</td>\n",
       "      <td>24.544700</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2212</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1121</td>\n",
       "      <td>-200087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90312</th>\n",
       "      <td>69390200122</td>\n",
       "      <td>6939</td>\n",
       "      <td>200122</td>\n",
       "      <td>595.151</td>\n",
       "      <td>-485.6930</td>\n",
       "      <td>-485.6930</td>\n",
       "      <td>0.768181</td>\n",
       "      <td>-0.250527</td>\n",
       "      <td>11.094400</td>\n",
       "      <td>-21.894300</td>\n",
       "      <td>85.201100</td>\n",
       "      <td>24.544700</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-211</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1121</td>\n",
       "      <td>-200087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90481</th>\n",
       "      <td>69390200458</td>\n",
       "      <td>6939</td>\n",
       "      <td>200458</td>\n",
       "      <td>454.584</td>\n",
       "      <td>-296.5630</td>\n",
       "      <td>-296.5630</td>\n",
       "      <td>0.542767</td>\n",
       "      <td>-0.022513</td>\n",
       "      <td>177.854000</td>\n",
       "      <td>-160.609000</td>\n",
       "      <td>-782.106000</td>\n",
       "      <td>239.640000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2212</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1121</td>\n",
       "      <td>-200244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90482</th>\n",
       "      <td>69390200459</td>\n",
       "      <td>6939</td>\n",
       "      <td>200459</td>\n",
       "      <td>691.964</td>\n",
       "      <td>-48.8827</td>\n",
       "      <td>-48.8827</td>\n",
       "      <td>0.693688</td>\n",
       "      <td>-0.377444</td>\n",
       "      <td>177.854000</td>\n",
       "      <td>-160.609000</td>\n",
       "      <td>-782.106000</td>\n",
       "      <td>239.640000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2212</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1121</td>\n",
       "      <td>-200244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3647 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       particle_id  subevent  barcode        px          py          pz  \\\n",
       "237            341         0      341 -5358.240 -75545.1000 -75545.1000   \n",
       "258            384         0      384 -4309.840   1828.0500   1828.0500   \n",
       "274            411         0      411   973.045   6355.6900   6355.6900   \n",
       "275            412         0      412  -872.362   5241.9500   5241.9500   \n",
       "277            414         0      414   422.775    381.4980    381.4980   \n",
       "...            ...       ...      ...       ...         ...         ...   \n",
       "90280  69390200062      6939   200062  -919.706    481.3740    481.3740   \n",
       "90311  69390200121      6939   200121   356.238   -544.3130   -544.3130   \n",
       "90312  69390200122      6939   200122   595.151   -485.6930   -485.6930   \n",
       "90481  69390200458      6939   200458   454.584   -296.5630   -296.5630   \n",
       "90482  69390200459      6939   200459   691.964    -48.8827    -48.8827   \n",
       "\n",
       "              pt       eta          vx          vy          vz      radius  \\\n",
       "237    75.734900 -2.079050    0.022396   -0.004489   -0.317639    0.022841   \n",
       "258     4.681510 -0.586767    0.022396   -0.004489   -0.317639    0.022841   \n",
       "274     6.429750 -0.380966    0.022396   -0.004489   -0.317639    0.022841   \n",
       "275     5.314040 -0.470596    0.022396   -0.004489   -0.317639    0.022841   \n",
       "277     0.569455 -0.972907    0.022396   -0.004489   -0.317639    0.022841   \n",
       "...          ...       ...         ...         ...         ...         ...   \n",
       "90280   1.038070  1.854760  -90.222800   52.417200  397.204000  104.344000   \n",
       "90311   0.650524  1.187110   11.094400  -21.894300   85.201100   24.544700   \n",
       "90312   0.768181 -0.250527   11.094400  -21.894300   85.201100   24.544700   \n",
       "90481   0.542767 -0.022513  177.854000 -160.609000 -782.106000  239.640000   \n",
       "90482   0.693688 -0.377444  177.854000 -160.609000 -782.106000  239.640000   \n",
       "\n",
       "       status  charge  pdgId pass  vProdNIn  vProdNOut  vProdStatus  \\\n",
       "237         1     1.0    -11  YES         1          2            0   \n",
       "258         1    -1.0   -211  YES         5         14            0   \n",
       "274         1    -1.0   -211  YES        11         21            0   \n",
       "275         1     1.0    211  YES        11         21            0   \n",
       "277         1     1.0    321   NO        11         21            0   \n",
       "...       ...     ...    ...  ...       ...        ...          ...   \n",
       "90280       1    -1.0  -2212   NO         1          1         1201   \n",
       "90311       1     1.0   2212   NO         1          3         1121   \n",
       "90312       1    -1.0   -211   NO         1          3         1121   \n",
       "90481       1     1.0   2212   NO         1          8         1121   \n",
       "90482       1     1.0   2212   NO         1          8         1121   \n",
       "\n",
       "       vProdBarcode  \n",
       "237            -263  \n",
       "258            -286  \n",
       "274            -298  \n",
       "275            -298  \n",
       "277            -298  \n",
       "...             ...  \n",
       "90280       -200056  \n",
       "90311       -200087  \n",
       "90312       -200087  \n",
       "90481       -200244  \n",
       "90482       -200244  \n",
       "\n",
       "[3647 rows x 20 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particles[particles.particle_id.isin(sample.pid.numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8114)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.y.sum() / sample.modulewise_true_edges.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(cell_data=[24364, 11], edge_index=[2, 229455], event_file=\"/project/projectdirs/m3443/data/ITk-upgrade/processed/full_events_v4/event000010320\", hid=[24364], modulewise_true_edges=[2, 20334], nhits=[24364], pid=[24364], primary=[24364], pt=[24364], signal_true_edges=[2, 16755], x=[24364, 3], y=[229455], y_pid=[229455])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_truth(evtid, raw_csv_path):\n",
    "    \"\"\"Return dataframes of true tracks and particles from CSV files.\"\"\"\n",
    "\n",
    "    file_prefix = os.path.join(raw_csv_path, \"event00001{:04}\".format(evtid))\n",
    "    print(file_prefix)\n",
    "\n",
    "    truth_fname = file_prefix + \"-truth.csv\"\n",
    "    particle_fname = file_prefix + \"-particles.csv\"\n",
    "\n",
    "    truth = pd.read_csv(truth_fname)\n",
    "    # <TODO: why are there duplicated hit-id?, >\n",
    "    truth.drop_duplicates(subset=[\"hit_id\"], inplace=True)\n",
    "\n",
    "    particles = pd.read_csv(particle_fname)\n",
    "    particles[\"pt\"] = particles.pt.values / 1000.0  # to be GeV\n",
    "\n",
    "    return truth, particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/data/ITk-upgrade/processed/full_events_v4/event000010320\n"
     ]
    }
   ],
   "source": [
    "truth, particles = get_truth(\n",
    "    int(sample.event_file[-4:]),\n",
    "    \"/global/cfs/cdirs/m3443/data/ITk-upgrade/processed/full_events_v4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def evaluate_reco_tracks(\n",
    "    truth: pd.DataFrame,\n",
    "    reconstructed: pd.DataFrame,\n",
    "    particles: pd.DataFrame,\n",
    "    min_hits_truth=9,\n",
    "    min_hits_reco=5,\n",
    "    min_pt=1.0,\n",
    "    frac_reco_matched=0.5,\n",
    "    frac_truth_matched=0.5,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"Return\n",
    "\n",
    "\n",
    "    Args:\n",
    "        truth: a dataframe with columns of ['hit_id', 'particle_id']\n",
    "        reconstructed: a dataframe with columns of ['hit_id', 'track_id']\n",
    "        particles: a dataframe with columns of\n",
    "            ['particle_id', 'pt', 'eta', 'radius', 'vz'].\n",
    "            where radius = sqrt(vx**2 + vy**2) and\n",
    "            ['vx', 'vy', 'vz'] are the production vertex of the particle\n",
    "        min_hits_truth: minimum number of hits for truth tracks\n",
    "        min_hits_reco:  minimum number of hits for reconstructed tracks\n",
    "\n",
    "    Returns:\n",
    "        A tuple of (\n",
    "            n_true_tracks: int, number of true tracks\n",
    "            n_reco_tracks: int, number of reconstructed tracks\n",
    "            n_matched_reco_tracks: int, number of reconstructed tracks\n",
    "                matched to true tracks\n",
    "            matched_pids: np.narray, a list of particle IDs matched\n",
    "                by reconstructed tracks\n",
    "        )\n",
    "    \"\"\"\n",
    "    # just in case particle_id == 0 included in truth.\n",
    "    if \"particle_id\" in truth.columns:\n",
    "        truth = truth[truth.particle_id > 0]\n",
    "\n",
    "    # get number of spacepoints in each reconstructed tracks\n",
    "    n_reco_hits = (\n",
    "        reconstructed.track_id.value_counts(sort=False)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"track_id\", \"track_id\": \"n_reco_hits\"})\n",
    "    )\n",
    "\n",
    "    # only tracks with a minimum number of spacepoints are considered\n",
    "    n_reco_hits = n_reco_hits[n_reco_hits.n_reco_hits >= min_hits_reco]\n",
    "    reconstructed = reconstructed[\n",
    "        reconstructed.track_id.isin(n_reco_hits.track_id.values)\n",
    "    ]\n",
    "\n",
    "    # get number of spacepoints in each particle\n",
    "    hits = truth.merge(particles, on=\"particle_id\", how=\"left\")\n",
    "    n_true_hits = (\n",
    "        hits.particle_id.value_counts(sort=False)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"particle_id\", \"particle_id\": \"n_true_hits\"})\n",
    "    )\n",
    "\n",
    "    # only particles leaves at least min_hits_truth spacepoints\n",
    "    # and with pT >= min_pt are considered.\n",
    "    particles = particles.merge(n_true_hits, on=[\"particle_id\"], how=\"left\")\n",
    "\n",
    "    is_trackable = particles.n_true_hits >= min_hits_truth\n",
    "\n",
    "    # event has 3 columnes [track_id, particle_id, hit_id]\n",
    "    event = pd.merge(reconstructed, truth, on=[\"hit_id\"], how=\"left\")\n",
    "\n",
    "    # n_common_hits and n_shared should be exactly the same\n",
    "    # for a specific track id and particle id\n",
    "\n",
    "    # Each track_id will be assigned to multiple particles.\n",
    "    # To determine which particle the track candidate is matched to,\n",
    "    # we use the particle id that yields a maximum value of n_common_hits / n_reco_hits,\n",
    "    # which means the majority of the spacepoints associated with the reconstructed\n",
    "    # track candidate comes from that true track.\n",
    "    # However, the other way may not be true.\n",
    "    reco_matching = (\n",
    "        event.groupby([\"track_id\", \"particle_id\"])\n",
    "        .size()\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"n_common_hits\"})\n",
    "    )\n",
    "\n",
    "    # Each particle will be assigned to multiple reconstructed tracks\n",
    "    truth_matching = (\n",
    "        event.groupby([\"particle_id\", \"track_id\"])\n",
    "        .size()\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"n_shared\"})\n",
    "    )\n",
    "\n",
    "    # add number of hits to each of the maching dataframe\n",
    "    reco_matching = reco_matching.merge(n_reco_hits, on=[\"track_id\"], how=\"left\")\n",
    "    truth_matching = truth_matching.merge(n_true_hits, on=[\"particle_id\"], how=\"left\")\n",
    "\n",
    "    # calculate matching fraction\n",
    "    reco_matching = reco_matching.assign(\n",
    "        purity_reco=np.true_divide(\n",
    "            reco_matching.n_common_hits, reco_matching.n_reco_hits\n",
    "        )\n",
    "    )\n",
    "    truth_matching = truth_matching.assign(\n",
    "        purity_true=np.true_divide(truth_matching.n_shared, truth_matching.n_true_hits)\n",
    "    )\n",
    "\n",
    "    # select the best match\n",
    "    reco_matching[\"purity_reco_max\"] = reco_matching.groupby(\"track_id\")[\n",
    "        \"purity_reco\"\n",
    "    ].transform(max)\n",
    "    truth_matching[\"purity_true_max\"] = truth_matching.groupby(\"track_id\")[\n",
    "        \"purity_true\"\n",
    "    ].transform(max)\n",
    "\n",
    "    matched_reco_tracks = reco_matching[\n",
    "        (reco_matching.purity_reco_max >= frac_reco_matched)\n",
    "        & (reco_matching.purity_reco == reco_matching.purity_reco_max)\n",
    "    ]\n",
    "\n",
    "    matched_true_particles = truth_matching[\n",
    "        (truth_matching.purity_true_max >= frac_truth_matched)\n",
    "        & (truth_matching.purity_true == truth_matching.purity_true_max)\n",
    "    ]\n",
    "\n",
    "    # now, let's combine the two majority criteria\n",
    "    # reconstructed tracks must be in both matched dataframe\n",
    "    # and the so matched particle should be the same\n",
    "    # in this way, each track should be only assigned\n",
    "    combined_match = matched_true_particles.merge(\n",
    "        matched_reco_tracks, on=[\"track_id\", \"particle_id\"], how=\"inner\"\n",
    "    )\n",
    "\n",
    "    n_reco_tracks = n_reco_hits.shape[0]\n",
    "    n_true_tracks = particles.shape[0]\n",
    "\n",
    "    # For GNN, there are non-negaliable cases where GNN-based\n",
    "    # track candidates are matched to particles not considered as interesting.\n",
    "    # which means there are paticles in matched_pids that do not exist in particles.\n",
    "    matched_pids = np.unique(combined_match.particle_id)\n",
    "\n",
    "    is_matched = particles.particle_id.isin(matched_pids).values\n",
    "    n_matched_particles = np.sum(is_matched)\n",
    "\n",
    "    n_matched_tracks = reco_matching[\n",
    "        reco_matching.purity_reco >= frac_reco_matched\n",
    "    ].shape[0]\n",
    "    n_matched_tracks_poi = reco_matching[\n",
    "        (reco_matching.purity_reco >= frac_reco_matched)\n",
    "        & (reco_matching.particle_id.isin(particles.particle_id.values))\n",
    "    ].shape[0]\n",
    "    # print(n_matched_tracks_poi, n_matched_tracks)\n",
    "\n",
    "    # num_particles_matched_to = reco_matched.groupby(\"particle_id\")['track_id']\\\n",
    "    #     .count().reset_index().rename(columns={\"track_id\": \"n_tracks_matched\"})\n",
    "    # n_duplicated_tracks = num_particles_matched_to.shape[0]\n",
    "    n_duplicated_tracks = n_matched_tracks_poi - n_matched_particles\n",
    "\n",
    "    particles = particles.assign(is_matched=is_matched, is_trackable=is_trackable)\n",
    "\n",
    "    return (\n",
    "        n_true_tracks,\n",
    "        n_reco_tracks,\n",
    "        n_matched_particles,\n",
    "        n_matched_tracks,\n",
    "        n_duplicated_tracks,\n",
    "        n_matched_tracks_poi,\n",
    "        particles,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles = particles[(particles.pt > 0.5) & (particles.eta < 1) & (particles.eta > -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    n_true_tracks,\n",
    "    n_reco_tracks,\n",
    "    n_matched_true_tracks,\n",
    "    n_matched_reco_tracks,\n",
    "    n_duplicated_reco_tracks,\n",
    "    n_matched_reco_tracks_poi,\n",
    "    particles,\n",
    ") = evaluate_reco_tracks(\n",
    "    truth, reconstructed, particles, min_pt=0.5, min_hits_truth=9, min_hits_reco=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18538, 2185, 1061, 2183, 26, 1087)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    (\n",
    "        n_true_tracks,\n",
    "        n_reco_tracks,\n",
    "        n_matched_true_tracks,\n",
    "        n_matched_reco_tracks,\n",
    "        n_duplicated_reco_tracks,\n",
    "        n_matched_reco_tracks_poi,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18538, 1963, 986, 1963, 14, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    (\n",
    "        n_true_tracks,\n",
    "        n_reco_tracks,\n",
    "        n_matched_true_tracks,\n",
    "        n_matched_reco_tracks,\n",
    "        n_duplicated_reco_tracks,\n",
    "        n_matched_reco_tracks_poi,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18538, 2469, 1016, 2470, 159, 1175)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    (\n",
    "        n_true_tracks,\n",
    "        n_reco_tracks,\n",
    "        n_matched_true_tracks,\n",
    "        n_matched_reco_tracks,\n",
    "        n_duplicated_reco_tracks,\n",
    "        n_matched_reco_tracks_poi,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff = (\n",
    "    particles.is_trackable & particles.is_matched\n",
    ").sum() / particles.is_trackable.sum()\n",
    "pur = n_matched_reco_tracks / n_reco_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficiency: 0.8566844919786096 Purity: 1.0004050222762253\n"
     ]
    }
   ],
   "source": [
    "print(\"Efficiency:\", eff, \"Purity:\", pur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/homes/d/danieltm/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:199: EfficiencyWarning: Precomputed sparse input was not sorted by data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/data/ITk-upgrade/processed/full_events_v4/event000010001\n",
      "Epsilon: 0.1 Efficiency: 0.9068100358422939 Purity: 1.0017248814144029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/homes/d/danieltm/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:199: EfficiencyWarning: Precomputed sparse input was not sorted by data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/data/ITk-upgrade/processed/full_events_v4/event000010001\n",
      "Epsilon: 0.12222222222222223 Efficiency: 0.9127837514934289 Purity: 1.0025839793281655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/homes/d/danieltm/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:199: EfficiencyWarning: Precomputed sparse input was not sorted by data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/data/ITk-upgrade/processed/full_events_v4/event000010001\n",
      "Epsilon: 0.14444444444444443 Efficiency: 0.9151732377538829 Purity: 1.0017174753112923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/homes/d/danieltm/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:199: EfficiencyWarning: Precomputed sparse input was not sorted by data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/data/ITk-upgrade/processed/full_events_v4/event000010001\n",
      "Epsilon: 0.16666666666666666 Efficiency: 0.9163679808841099 Purity: 1.002585092632486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/homes/d/danieltm/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:199: EfficiencyWarning: Precomputed sparse input was not sorted by data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/data/ITk-upgrade/processed/full_events_v4/event000010001\n",
      "Epsilon: 0.18888888888888888 Efficiency: 0.9127837514934289 Purity: 1.0034408602150537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/homes/d/danieltm/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:199: EfficiencyWarning: Precomputed sparse input was not sorted by data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/data/ITk-upgrade/processed/full_events_v4/event000010001\n",
      "Epsilon: 0.2111111111111111 Efficiency: 0.9080047789725209 Purity: 1.0043177892918826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/homes/d/danieltm/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:199: EfficiencyWarning: Precomputed sparse input was not sorted by data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/data/ITk-upgrade/processed/full_events_v4/event000010001\n",
      "Epsilon: 0.2333333333333333 Efficiency: 0.9044205495818399 Purity: 1.0052015604681404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/homes/d/danieltm/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:199: EfficiencyWarning: Precomputed sparse input was not sorted by data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/data/ITk-upgrade/processed/full_events_v4/event000010001\n",
      "Epsilon: 0.25555555555555554 Efficiency: 0.899641577060932 Purity: 1.0060869565217392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/homes/d/danieltm/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:199: EfficiencyWarning: Precomputed sparse input was not sorted by data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/data/ITk-upgrade/processed/full_events_v4/event000010001\n",
      "Epsilon: 0.2777777777777778 Efficiency: 0.8936678614097969 Purity: 1.002177700348432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exa/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/global/homes/d/danieltm/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:199: EfficiencyWarning: Precomputed sparse input was not sorted by data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3443/data/ITk-upgrade/processed/full_events_v4/event000010001\n",
      "Epsilon: 0.3 Efficiency: 0.8841099163679809 Purity: 1.0\n"
     ]
    }
   ],
   "source": [
    "for epsilon in np.linspace(0.1, 0.3, 10):\n",
    "\n",
    "    sample = model.trainset[0].cpu()\n",
    "    with torch.no_grad():\n",
    "        results = model.shared_evaluation(sample.to(device), 0, log=False)\n",
    "    sample = sample.cpu()\n",
    "    preds = results[\"score\"][: int(len(results[\"score\"]) / 2)]\n",
    "    reconstructed = tracks_from_gnn(\n",
    "        sample.hid,\n",
    "        preds.cpu(),\n",
    "        sample.edge_index[0],\n",
    "        sample.edge_index[1],\n",
    "        epsilon=epsilon,\n",
    "    )\n",
    "\n",
    "    truth, particles = get_truth(\n",
    "        int(sample.event_file[-4:]),\n",
    "        \"/global/cfs/cdirs/m3443/data/ITk-upgrade/processed/full_events_v4\",\n",
    "    )\n",
    "    particles = particles[\n",
    "        (particles.pt > 0.5) & (particles.eta < 1) & (particles.eta > -1)\n",
    "    ]\n",
    "    (\n",
    "        n_true_tracks,\n",
    "        n_reco_tracks,\n",
    "        n_matched_true_tracks,\n",
    "        n_matched_reco_tracks,\n",
    "        n_duplicated_reco_tracks,\n",
    "        n_matched_reco_tracks_poi,\n",
    "        particles,\n",
    "    ) = evaluate_reco_tracks(\n",
    "        truth,\n",
    "        reconstructed,\n",
    "        min_hits_truth=9,\n",
    "        min_hits_reco=3,\n",
    "        particles=particles,\n",
    "        min_pt=0.5,\n",
    "    )\n",
    "\n",
    "    eff = (\n",
    "        particles.is_trackable & particles.is_matched\n",
    "    ).sum() / particles.is_trackable.sum()\n",
    "    pur = n_matched_reco_tracks / n_reco_tracks\n",
    "    print(\"Epsilon:\", epsilon, \"Efficiency:\", eff, \"Purity:\", pur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "ExaPerlmutter",
   "language": "python",
   "name": "exa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
