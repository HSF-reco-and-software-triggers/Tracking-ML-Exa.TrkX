{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Metric Learning in Embedded Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# External imports\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import auc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "import torch.nn.functional as F\n",
    "import frnn\n",
    "import wandb\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "\n",
    "from LightningModules.SuperEmbedding.super_embedding_base import SuperEmbeddingBase\n",
    "from LightningModules.Embedding.utils import build_edges, graph_intersection\n",
    "from LightningModules.Embedding.Models.layerless_embedding import LayerlessEmbedding\n",
    "from LightningModules.Embedding.embedding_base import EmbeddingBase\n",
    "from LightningModules.GNN.utils import make_mlp\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class UndirectedHalfTwinEmbedding(EmbeddingBase):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__(hparams)\n",
    "        \"\"\"\n",
    "        Initialise the Lightning Module that can scan over different embedding training regimes\n",
    "        \"\"\"\n",
    "\n",
    "        # Construct the MLP architecture\n",
    "        if \"ci\" in hparams[\"regime\"]:\n",
    "            in_channels = hparams[\"spatial_channels\"] + hparams[\"cell_channels\"]\n",
    "        else:\n",
    "            in_channels = hparams[\"spatial_channels\"]\n",
    "\n",
    "        torch.manual_seed(0)\n",
    "\n",
    "        self.net1 = make_mlp(\n",
    "            in_channels,\n",
    "            [hparams[\"emb_hidden\"]] * hparams[\"nb_layer\"] + [hparams[\"emb_dim\"]],\n",
    "            hidden_activation=\"Tanh\",\n",
    "            output_activation=None,\n",
    "            layer_norm=True,\n",
    "        )\n",
    "\n",
    "        self.net2 = make_mlp(\n",
    "            in_channels,\n",
    "            [hparams[\"emb_hidden\"]] * hparams[\"nb_layer\"] + [hparams[\"emb_dim\"]],\n",
    "            hidden_activation=\"Tanh\",\n",
    "            output_activation=None,\n",
    "            layer_norm=True,\n",
    "        )\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1_out = self.net1(x)\n",
    "        x2_out = self.net2(x)\n",
    "        \n",
    "        if \"norm\" in self.hparams[\"regime\"]:\n",
    "            return F.normalize(x1_out), F.normalize(x2_out)\n",
    "        else:\n",
    "            return x1_out, x2_out\n",
    "\n",
    "    def append_hnm_pairs(self, e_spatial, query, query_indices, spatial, r_train=None, knn=None):\n",
    "        if r_train is None:\n",
    "            r_train = self.hparams[\"r_train\"]\n",
    "        if knn is None:\n",
    "            knn = self.hparams[\"knn\"]\n",
    "\n",
    "        knn_edges = build_edges(\n",
    "                query,\n",
    "                spatial,\n",
    "                query_indices,\n",
    "                r_train,\n",
    "                knn,\n",
    "                remove_self_loops=True\n",
    "            )\n",
    "\n",
    "        e_spatial = torch.cat(\n",
    "            [\n",
    "                e_spatial,\n",
    "                knn_edges,\n",
    "            ],\n",
    "            axis=-1,\n",
    "        )\n",
    "\n",
    "        return e_spatial\n",
    "\n",
    "    def get_hinge_distance(self, spatial1, spatial2, e_spatial, y_cluster):\n",
    "\n",
    "        hinge = y_cluster.float().to(self.device)\n",
    "        hinge[hinge == 0] = -1\n",
    "\n",
    "        reference = spatial1[e_spatial[0]]\n",
    "        neighbors = spatial2[e_spatial[1]]\n",
    "        d = torch.sum((reference - neighbors) ** 2, dim=-1)\n",
    "\n",
    "        return hinge, d\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch (``list``, required): A list of ``torch.tensor`` objects\n",
    "            batch (``int``, required): The index of the batch\n",
    "\n",
    "        Returns:\n",
    "            ``torch.tensor`` The loss function as a tensor\n",
    "        \"\"\"\n",
    "\n",
    "        # Instantiate empty prediction edge list\n",
    "        e_spatial = torch.empty([2, 0], dtype=torch.int64, device=self.device)\n",
    "\n",
    "        # Forward pass of model, handling whether Cell Information (ci) is included\n",
    "        input_data = self.get_input_data(batch)\n",
    "\n",
    "        spatial1, spatial2 = self(input_data)\n",
    "\n",
    "        query_indices, query = self.get_query_points(batch, spatial1)\n",
    "\n",
    "        # Append Hard Negative Mining (hnm) with KNN graph\n",
    "        if \"hnm\" in self.hparams[\"regime\"]:\n",
    "            e_spatial = self.append_hnm_pairs(e_spatial, query, query_indices, spatial2)\n",
    "            # print(e_spatial.shape[1] / len(query))\n",
    "\n",
    "        # Append random edges pairs (rp) for stability\n",
    "        if \"rp\" in self.hparams[\"regime\"]:\n",
    "            e_spatial = self.append_random_pairs(e_spatial, query_indices, spatial2)\n",
    "\n",
    "        # Instantiate bidirectional truth (since KNN prediction will be bidirectional)\n",
    "        e_bidir = torch.cat(\n",
    "            [batch.signal_true_edges, batch.signal_true_edges.flip(0)], axis=-1\n",
    "        )\n",
    "\n",
    "        # Calculate truth from intersection between Prediction graph and Truth graph\n",
    "        e_spatial, y_cluster = self.get_truth(batch, e_spatial, e_bidir)\n",
    "        new_weights = y_cluster.to(self.device) * self.hparams[\"weight\"]\n",
    "\n",
    "        # Append all positive examples and their truth and weighting\n",
    "        e_spatial, y_cluster, new_weights = self.get_true_pairs(\n",
    "            e_spatial, y_cluster, new_weights, e_bidir\n",
    "        )\n",
    "\n",
    "        hinge, d = self.get_hinge_distance(spatial1, spatial2, e_spatial, y_cluster)\n",
    "\n",
    "        # Give negative examples a weight of 1 (note that there may still be TRUE examples that are weightless)\n",
    "\n",
    "        negative_loss = torch.nn.functional.hinge_embedding_loss(\n",
    "            d[hinge == -1],\n",
    "            hinge[hinge == -1],\n",
    "            margin=self.hparams[\"margin\"]**2,\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "\n",
    "        positive_loss = torch.nn.functional.hinge_embedding_loss(\n",
    "            d[hinge == 1],\n",
    "            hinge[hinge == 1],\n",
    "            margin=self.hparams[\"margin\"]**2,\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "\n",
    "        loss = negative_loss + self.hparams[\"weight\"] * positive_loss\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def shared_evaluation(self, batch, batch_idx, knn_radius, knn_num, log=False):\n",
    "\n",
    "        input_data = self.get_input_data(batch)\n",
    "        spatial1, spatial2 = self(input_data)\n",
    "\n",
    "        e_bidir = torch.cat(\n",
    "            [batch.signal_true_edges, batch.signal_true_edges.flip(0)], axis=-1\n",
    "        )\n",
    "\n",
    "        # Build whole KNN graph\n",
    "        e_spatial = build_edges(\n",
    "            spatial1, spatial2, indices=None, r_max=knn_radius, k_max=knn_num, remove_self_loops=True\n",
    "        )\n",
    "\n",
    "        e_spatial, y_cluster = self.get_truth(batch, e_spatial, e_bidir)\n",
    "\n",
    "        hinge, d = self.get_hinge_distance(\n",
    "            spatial1, spatial2, e_spatial.to(self.device), y_cluster\n",
    "        )\n",
    "\n",
    "        loss = torch.nn.functional.hinge_embedding_loss(\n",
    "            d, hinge, margin=self.hparams[\"margin\"]**2, reduction=\"mean\"\n",
    "        )\n",
    "\n",
    "        cluster_true = e_bidir.shape[1]\n",
    "        cluster_true_positive = y_cluster.sum()\n",
    "        cluster_positive = len(e_spatial[0])\n",
    "\n",
    "        eff = torch.tensor(cluster_true_positive / cluster_true)\n",
    "        pur = torch.tensor(cluster_true_positive / cluster_positive)\n",
    "\n",
    "        if log:\n",
    "            current_lr = self.optimizers().param_groups[0][\"lr\"]\n",
    "            self.log_dict(\n",
    "                {\"val_loss\": loss, \"eff\": eff, \"pur\": pur, \"current_lr\": current_lr}\n",
    "            )\n",
    "        logging.info(\"Efficiency: {}\".format(eff))\n",
    "        logging.info(\"Purity: {}\".format(pur))\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"preds\": e_spatial,\n",
    "            \"truth\": y_cluster,\n",
    "            \"truth_graph\": e_bidir,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectedHalfTwinEmbedding(UndirectedHalfTwinEmbedding):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__(hparams)\n",
    "        \"\"\"\n",
    "        Initialise the Lightning Module that can scan over different embedding training regimes\n",
    "        \"\"\"\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch (``list``, required): A list of ``torch.tensor`` objects\n",
    "            batch (``int``, required): The index of the batch\n",
    "\n",
    "        Returns:\n",
    "            ``torch.tensor`` The loss function as a tensor\n",
    "        \"\"\"\n",
    "\n",
    "        # Instantiate empty prediction edge list\n",
    "        e_spatial = torch.empty([2, 0], dtype=torch.int64, device=self.device)\n",
    "\n",
    "        # Forward pass of model, handling whether Cell Information (ci) is included\n",
    "        input_data = self.get_input_data(batch)\n",
    "\n",
    "        spatial1, spatial2 = self(input_data)\n",
    "\n",
    "        query_indices, query = self.get_query_points(batch, spatial1)\n",
    "\n",
    "        # Append Hard Negative Mining (hnm) with KNN graph\n",
    "        if \"hnm\" in self.hparams[\"regime\"]:\n",
    "            e_spatial = self.append_hnm_pairs(e_spatial, query, query_indices, spatial2)\n",
    "\n",
    "        # Append random edges pairs (rp) for stability\n",
    "        if \"rp\" in self.hparams[\"regime\"]:\n",
    "            e_spatial = self.append_random_pairs(e_spatial, query_indices, spatial2)\n",
    "\n",
    "        # Instantiate bidirectional truth (since KNN prediction will be bidirectional)\n",
    "        e_bidir = batch.signal_true_edges\n",
    "\n",
    "        # Calculate truth from intersection between Prediction graph and Truth graph\n",
    "        e_spatial, y_cluster = self.get_truth(batch, e_spatial, e_bidir)\n",
    "        new_weights = y_cluster.to(self.device) * self.hparams[\"weight\"]\n",
    "\n",
    "        # Append all positive examples and their truth and weighting\n",
    "        e_spatial, y_cluster, new_weights = self.get_true_pairs(\n",
    "            e_spatial, y_cluster, new_weights, e_bidir\n",
    "        )\n",
    "\n",
    "        hinge, d = self.get_hinge_distance(spatial1, spatial2, e_spatial, y_cluster)\n",
    "\n",
    "        negative_loss = torch.nn.functional.hinge_embedding_loss(\n",
    "            d[hinge == -1],\n",
    "            hinge[hinge == -1],\n",
    "            margin=self.hparams[\"margin\"]**2,\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "\n",
    "        positive_loss = torch.nn.functional.hinge_embedding_loss(\n",
    "            d[hinge == 1],\n",
    "            hinge[hinge == 1],\n",
    "            margin=self.hparams[\"margin\"]**2,\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "\n",
    "        loss = negative_loss + self.hparams[\"weight\"] * positive_loss\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def shared_evaluation(self, batch, batch_idx, knn_radius, knn_num, log=False):\n",
    "\n",
    "        input_data = self.get_input_data(batch)\n",
    "        spatial1, spatial2 = self(input_data)\n",
    "\n",
    "        e_bidir = batch.signal_true_edges\n",
    "\n",
    "        # Build whole KNN graph\n",
    "        e_spatial = build_edges(\n",
    "            spatial1, spatial2, indices=None, r_max=knn_radius, k_max=knn_num\n",
    "        )\n",
    "\n",
    "        e_spatial, y_cluster = self.get_truth(batch, e_spatial, e_bidir)\n",
    "\n",
    "        hinge, d = self.get_hinge_distance(\n",
    "            spatial1, spatial2, e_spatial.to(self.device), y_cluster\n",
    "        )\n",
    "\n",
    "        loss = torch.nn.functional.hinge_embedding_loss(\n",
    "            d, hinge, margin=self.hparams[\"margin\"]**2, reduction=\"mean\"\n",
    "        )\n",
    "\n",
    "        cluster_true = e_bidir.shape[1]\n",
    "        cluster_true_positive = y_cluster.sum()\n",
    "        cluster_positive = len(e_spatial[0])\n",
    "\n",
    "        eff = torch.tensor(cluster_true_positive / cluster_true)\n",
    "        pur = torch.tensor(cluster_true_positive / cluster_positive)\n",
    "\n",
    "        if log:\n",
    "            current_lr = self.optimizers().param_groups[0][\"lr\"]\n",
    "            self.log_dict(\n",
    "                {\"val_loss\": loss, \"eff\": eff, \"pur\": pur, \"current_lr\": current_lr}\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            #             \"distances\": d,\n",
    "            \"preds\": e_spatial,\n",
    "            \"truth\": y_cluster,\n",
    "            \"truth_graph\": e_bidir,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally! Let's train! We instantiate a `Trainer` class that knows things like which hardware to work with, how long to train for, and a **bunch** of default options that we ignore here. Check out the Trainer class docs in Pytorch Lightning. Suffice it to say that it clears away much repetitive boilerplate in training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"halftwin_metric.yaml\") as f:\n",
    "    hparams = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UndirectedHalfTwinEmbedding(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DirectedHalfTwinEmbedding(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger = WandbLogger(\n",
    "    project=hparams[\"project\"], group=\"InitialTest\", save_dir=hparams[\"artifacts\"]\n",
    ")\n",
    "trainer = Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=hparams[\"max_epochs\"],\n",
    "    logger=logger,\n",
    "    num_sanity_val_steps=0,\n",
    ")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-7271bc84a626>:150: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eff = torch.tensor(cluster_true_positive / cluster_true)\n",
      "<ipython-input-2-7271bc84a626>:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pur = torch.tensor(cluster_true_positive / cluster_positive)\n"
     ]
    }
   ],
   "source": [
    "sample = model.valset[0].to(device)\n",
    "results = model.to(device).shared_evaluation(sample, 0, 0.085, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " 'preds': tensor([[   0,    0,    0,  ..., 7171, 7171, 7171],\n",
       "         [   3,   64,   66,  ..., 7163, 7169, 7170]]),\n",
       " 'truth': tensor([False, False, False,  ..., False, False, False]),\n",
       " 'truth_graph': tensor([[ 785, 1557, 2627,  ..., 6966, 1775, 3036],\n",
       "         [1557, 2627, 3792,  ..., 6518,    4, 1775]], device='cuda:0')}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 148759]), torch.Size([148759]), torch.Size([2, 11170]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"preds\"].shape, results[\"truth\"].shape, results[\"truth_graph\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9874), tensor(0.0741))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"truth\"].sum() / results[\"truth_graph\"].shape[1], results[\"truth\"].sum() / results[\"preds\"].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('exatrkx-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "160bbf3460607ce6882228c7f3472b9123241d62d3bf3b05bb085d37e9832afe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
