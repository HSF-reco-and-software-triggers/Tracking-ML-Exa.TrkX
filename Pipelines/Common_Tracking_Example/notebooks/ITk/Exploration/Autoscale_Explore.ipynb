{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore PyG Autoscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "# External imports\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import auc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from torch_sparse import SparseTensor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.transforms import ToSparseTensor\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_autoscale.models import GAT, ScalableGNN\n",
    "from torch_geometric_autoscale import metis, permute, SubgraphLoader\n",
    "from torch_geometric_autoscale import get_data, compute_micro_f1\n",
    "from LightningModules.GNN.utils import make_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get simple memory test loaded (e.g. one event, GAT model applied)\n",
    "2. Apply same model without autoscale! Compare\n",
    "3. Look at memory scaling (i.e. how big can I make the GAT model??)\n",
    "4. Consider model ~32 channels, model ~64 channels, random phi sampled model ~64 channels, autoscaled model ~64 channels\n",
    "5. WANT to show true 64 >= autoscaled 64 >> random sampled 64 >> true 32\n",
    "6. May need to pick the best hidden channels to prove this! i.e. true Nx32 >= autoscaled Nx32 >> random sampled Nx32 >> true 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Memory Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load an embedded graph\n",
    "2. Understand how to sample the graph\n",
    "2. Define a GAS model and a non-GAS model (e.g. GAT)\n",
    "3. Apply both!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Dummy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Load in configs\n",
    "2. Partition graph (i.e. there should only be one adjacency matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Testing Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_nodes = int(1e5)\n",
    "num_edges = int(1e6)\n",
    "x = torch.rand(num_nodes, 3)\n",
    "edge_index = torch.randint(x.shape[0], (2, num_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "adj = SparseTensor(\n",
    "    row=edge_index[0], col=edge_index[1], sparse_sizes=(num_nodes, num_nodes)\n",
    ")\n",
    "adj_t = adj.t()\n",
    "data = Data(x=x, edge_index=edge_index, adj_t=adj_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing METIS partitioning with 10 parts... Done! [4.36s]\n"
     ]
    }
   ],
   "source": [
    "num_parts = 10\n",
    "perm, ptr = metis(adj_t, num_parts=num_parts, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`perm` is the list of nodes, rearranged to be contiguous in the cluster slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31466,  9792, 31517,  ..., 30058, 82892, 30029])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`ptr` is the list of slice edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0,  10002,  20000,  30003,  40005,  50001,  60002,  70004,  80004,\n",
       "         90005, 100000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We simply re-arrange data with the new node indices given in the `perm` lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permuting data... Done! [0.29s]\n"
     ]
    }
   ],
   "source": [
    "data = permute(data, perm, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing subgraphs... Done! [0.13s]\n"
     ]
    }
   ],
   "source": [
    "loader = SubgraphLoader(data, ptr, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"hidden_channels\": 16,\n",
    "    \"hidden_heads\": 1,\n",
    "    \"out_heads\": 1,\n",
    "    \"num_layers\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = GAT(\n",
    "    num_nodes=data.num_nodes,\n",
    "    in_channels=x.shape[1],\n",
    "    out_channels=1,\n",
    "    device=\"cpu\",\n",
    "    **model_config\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(adj_t=[10001, 62203, nnz=99742], x=[62203, 3]) 10001 tensor([50001, 50002, 50003,  ..., 28045, 41056, 74991])\n",
      "Data(adj_t=[10000, 61945, nnz=99700], x=[61945, 3]) 10000 tensor([70004, 70005, 70006,  ..., 57197,  9335, 24587])\n",
      "Data(adj_t=[9998, 61914, nnz=99846], x=[61914, 3]) 9998 tensor([10002, 10003, 10004,  ..., 22262, 56843, 96027])\n",
      "Data(adj_t=[9995, 62105, nnz=100437], x=[62105, 3]) 9995 tensor([90005, 90006, 90007,  ..., 42591, 87234,  8122])\n",
      "Data(adj_t=[10002, 61959, nnz=99672], x=[61959, 3]) 10002 tensor([    0,     1,     2,  ..., 26451, 33989, 69148])\n",
      "Data(adj_t=[10002, 62303, nnz=100466], x=[62303, 3]) 10002 tensor([30003, 30004, 30005,  ...,  2041, 13943, 22381])\n",
      "Data(adj_t=[10001, 62024, nnz=99442], x=[62024, 3]) 10001 tensor([80004, 80005, 80006,  ..., 20870, 32888, 94726])\n",
      "Data(adj_t=[10003, 62295, nnz=100612], x=[62295, 3]) 10003 tensor([20000, 20001, 20002,  ...,  9214, 43816, 59682])\n",
      "Data(adj_t=[10002, 62017, nnz=100169], x=[62017, 3]) 10002 tensor([60002, 60003, 60004,  ..., 74548,  5490, 80488])\n",
      "Data(adj_t=[9996, 62230, nnz=99914], x=[62230, 3]) 9996 tensor([40005, 40006, 40007,  ..., 65436, 94430, 96842])\n"
     ]
    }
   ],
   "source": [
    "for batch, batch_size, n_id, _, _ in loader:\n",
    "    print(batch, batch_size, n_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding to ITk Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_node_features(data):\n",
    "    for key, item in data.to_dict().items():\n",
    "        if type(item) is torch.Tensor and item.dim() == 1:\n",
    "            data[key] = item.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datafile(event):\n",
    "    data = torch.load(event, map_location=\"cpu\")\n",
    "    data.event_file = None\n",
    "    data.y = None\n",
    "    data.modulewise_true_edges = None\n",
    "    data.signal_true_edges = None\n",
    "\n",
    "    transformSparse = ToSparseTensor()\n",
    "    data = transformSparse(data)\n",
    "    convert_node_features(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/global/cfs/cdirs/m3443/data/ITk-upgrade/processed/embedding_processed/0.5GeV_barrel/train\"\n",
    "all_events = [os.path.join(input_dir, event) for event in os.listdir(input_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = all_events[0]\n",
    "data = torch.load(event, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 340 ms, sys: 19.4 ms, total: 359 ms\n",
      "Wall time: 270 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_events = 2\n",
    "dataset = [load_datafile(event) for event in all_events[:num_events]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.8 ms, sys: 2.32 ms, total: 61.1 ms\n",
      "Wall time: 46.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = Batch.from_data_list(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing METIS partitioning with 16 parts... Done! [0.09s]\n"
     ]
    }
   ],
   "source": [
    "num_parts = 8 * num_events\n",
    "perm, ptr = metis(data.adj_t, num_parts=num_parts, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simply re-arrange data with the new node indices given in the `perm` lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = permute(data, perm, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = SubgraphLoader(data, ptr, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"hidden_channels\": 128,\n",
    "    \"hidden_heads\": 2,\n",
    "    \"out_heads\": 1,\n",
    "    \"num_layers\": 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAT(\n",
    "    num_nodes=data.num_nodes,\n",
    "    in_channels=data.x.shape[1],\n",
    "    out_channels=1,\n",
    "    device=\"cpu\",\n",
    "    **model_config\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.train()\n",
    "\n",
    "for batch, batch_size, n_id, _, _ in loader:\n",
    "    print(batch, batch_size, n_id)\n",
    "\n",
    "    batch = batch.to(model.device)\n",
    "    #     n_id = n_id.to(model.device) # This shouldn't be on device, since this is the (node ID <-> partion) map on the host\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(batch.x, batch.adj_t, batch_size, n_id)\n",
    "    loss = out.sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{torch.cuda.max_memory_allocated() / 1024**3}Gb allocated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacking for Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phi Partition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_parts = 4\n",
    "\n",
    "new_ptr = [0]\n",
    "new_perm = []\n",
    "\n",
    "phi_segments = np.linspace(-1, 1, num_parts + 1)\n",
    "phi = data.x[:, 1]\n",
    "\n",
    "for batch in range(data.batch.max() + 1):\n",
    "\n",
    "    for phi_segment_min, phi_segment_max in zip(phi_segments[:-1], phi_segments[1:]):\n",
    "\n",
    "        batch_segment_mask = (\n",
    "            (phi_segment_min < phi) & (phi < phi_segment_max) & (data.batch == batch)\n",
    "        )\n",
    "\n",
    "        segment_idx = torch.where(batch_segment_mask)[0]\n",
    "\n",
    "        new_perm.append(segment_idx)\n",
    "        new_ptr.append(len(segment_idx) + new_ptr[-1])\n",
    "\n",
    "new_ptr = torch.Tensor(new_ptr).int()\n",
    "new_perm = torch.cat(new_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(adj_t=[52533, 52533, nnz=1409928], batch=[52533], cell_data=[52533, 11], hid=[52533, 1], nhits=[52533, 1], pid=[52533, 1], primary=[52533, 1], pt=[52533, 1], ptr=[3], x=[52533, 3])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permuting data... Done! [0.31s]\n"
     ]
    }
   ],
   "source": [
    "data = permute(data, new_perm, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing subgraphs... Done! [0.03s]\n"
     ]
    }
   ],
   "source": [
    "loader = SubgraphLoader(data, new_ptr, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular ResAGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     6,
     14,
     22
    ]
   },
   "outputs": [],
   "source": [
    "class VanillaResAGNN(GNNBase):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__(hparams)\n",
    "        \"\"\"\n",
    "        Initialise the Lightning Module that can scan over different GNN training regimes\n",
    "        \"\"\"\n",
    "        self.edge_network = make_mlp(\n",
    "            (hparams[\"spatial_channels\"] + hparams[\"cell_channels\"] + hparams[\"hidden\"])\n",
    "            * 2,\n",
    "            [hparams[\"spatial_channels\"] + hparams[\"cell_channels\"] + hparams[\"hidden\"]]\n",
    "            * hparams[\"nb_edge_layer\"]\n",
    "            + [1],\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "            output_activation=None,\n",
    "            layer_norm=hparams[\"layernorm\"],\n",
    "        )\n",
    "\n",
    "        self.node_network = make_mlp(\n",
    "            (hparams[\"spatial_channels\"] + hparams[\"cell_channels\"] + hparams[\"hidden\"])\n",
    "            * 2,\n",
    "            [hparams[\"hidden\"]] * hparams[\"nb_node_layer\"],\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "            output_activation=None,\n",
    "            layer_norm=hparams[\"layernorm\"],\n",
    "        )\n",
    "\n",
    "        self.input_network = make_mlp(\n",
    "            hparams[\"spatial_channels\"] + hparams[\"cell_channels\"],\n",
    "            [hparams[\"hidden\"]] * hparams[\"nb_node_layer\"],\n",
    "            output_activation=hparams[\"hidden_activation\"],\n",
    "            layer_norm=hparams[\"layernorm\"],\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        start, end = edge_index\n",
    "        input_x = x\n",
    "\n",
    "        x = self.input_network(x)\n",
    "\n",
    "        # Shortcut connect the inputs onto the hidden representation\n",
    "        x = torch.cat([x, input_x], dim=-1)\n",
    "\n",
    "        # Loop over iterations of edge and node networks\n",
    "        for i in range(self.hparams[\"n_graph_iters\"]):\n",
    "            x_inital = x\n",
    "\n",
    "            # Apply edge network\n",
    "            edge_inputs = torch.cat([x[start], x[end]], dim=1)\n",
    "            e = torch.sigmoid(self.edge_network(edge_inputs))\n",
    "\n",
    "            # Apply node network\n",
    "            messages = scatter_add(\n",
    "                e * x[start], end, dim=0, dim_size=x.shape[0]\n",
    "            ) + scatter_add(e * x[end], start, dim=0, dim_size=x.shape[0])\n",
    "            node_inputs = torch.cat([messages, x], dim=1)\n",
    "            x = self.node_network(node_inputs)\n",
    "\n",
    "            # Shortcut connect the inputs onto the hidden representation\n",
    "            x = torch.cat([x, input_x], dim=-1)\n",
    "\n",
    "            # Residual connection\n",
    "            x = x_inital + x\n",
    "\n",
    "        edge_inputs = torch.cat([x[start], x[end]], dim=1)\n",
    "        return self.edge_network(edge_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "code_folding": [
     6,
     14,
     22
    ]
   },
   "outputs": [],
   "source": [
    "class ScalableAGNN(ScalableGNN):\n",
    "    def __init__(self, num_nodes, hparams, pool_size = None, buffer_size = None, device = None):\n",
    "        super().__init__(num_nodes, hparams[\"hidden\"], hparams[\"n_graph_iters\"], pool_size, buffer_size, device)\n",
    "        \"\"\"\n",
    "        Initialise the Lightning Module that can scan over different GNN training regimes\n",
    "        \"\"\"\n",
    "        self.edge_network = make_mlp(\n",
    "            (hparams[\"spatial_channels\"] + hparams[\"cell_channels\"] + hparams[\"hidden\"]) * 2,\n",
    "            [hparams[\"spatial_channels\"] + hparams[\"cell_channels\"] + hparams[\"hidden\"]] * hparams[\"nb_edge_layer\"] + [1],\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "            output_activation=None,\n",
    "            layer_norm=hparams[\"layernorm\"],\n",
    "        )\n",
    "        \n",
    "        self.node_network = make_mlp(\n",
    "            (hparams[\"spatial_channels\"] + hparams[\"cell_channels\"] + hparams[\"hidden\"]) * 2,\n",
    "            [hparams[\"hidden\"]] * hparams[\"nb_node_layer\"],\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "            output_activation=None,\n",
    "            layer_norm=hparams[\"layernorm\"],\n",
    "        )\n",
    "        \n",
    "        self.input_network = make_mlp(\n",
    "            hparams[\"spatial_channels\"] + hparams[\"cell_channels\"], \n",
    "            [hparams[\"hidden\"]]*hparams[\"nb_node_layer\"],\n",
    "            output_activation=hparams[\"hidden_activation\"],\n",
    "            layer_norm=hparams[\"layernorm\"]\n",
    "        )\n",
    "            \n",
    "    def message_passing(self, x, )\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        start, end = edge_index\n",
    "        input_x = x\n",
    "\n",
    "        x = self.input_network(x)\n",
    "\n",
    "        # Shortcut connect the inputs onto the hidden representation\n",
    "        x = torch.cat([x, input_x], dim=-1)\n",
    "\n",
    "        # Loop over iterations of edge and node networks\n",
    "        for i in range(self.hparams[\"n_graph_iters\"]):\n",
    "            x_inital = x\n",
    "\n",
    "            # Apply edge network\n",
    "            edge_inputs = torch.cat([x[start], x[end]], dim=1)\n",
    "            e = torch.sigmoid(self.edge_network(edge_inputs))\n",
    "\n",
    "            # Apply node network\n",
    "            messages = (\n",
    "                scatter_add(e * x[start], end, dim=0, dim_size=x.shape[0]) \n",
    "                + scatter_add(e * x[end], start, dim=0, dim_size=x.shape[0])\n",
    "            )\n",
    "            node_inputs = torch.cat([messages, x], dim=1)\n",
    "            x = self.node_network(node_inputs)\n",
    "\n",
    "            # Shortcut connect the inputs onto the hidden representation\n",
    "            x = torch.cat([x, input_x], dim=-1)\n",
    "\n",
    "            # Residual connection\n",
    "            x = x_inital + x\n",
    "    \n",
    "        edge_inputs = torch.cat([x[start], x[end]], dim=1)\n",
    "        return self.edge_network(edge_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"example_gnn.yaml\") as f:\n",
    "    model_config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ScalableAGNN(num_nodes=data.num_nodes, hparams=model_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExatrkxTest",
   "language": "python",
   "name": "exatrkx-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
